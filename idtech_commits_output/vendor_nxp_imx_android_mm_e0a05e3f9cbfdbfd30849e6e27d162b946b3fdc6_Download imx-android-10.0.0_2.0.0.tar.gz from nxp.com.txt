e0a05e3 jenkins 2020-05-26

Download imx-android-10.0.0_2.0.0.tar.gz from nxp.com

Change-Id: I782c95cefdd5c4f358c760ae47a4cfcca956f6ef

diff --git a/CactusPlayer/Android.mk b/CactusPlayer/Android.mk
new file mode 100755
index 0000000..a28d852
--- /dev/null
+++ b/CactusPlayer/Android.mk
@@ -0,0 +1,23 @@
+ifeq ($(PRODUCT_MANUFACTURER),freescale)
+LOCAL_PATH:= $(call my-dir)
+
+include $(CLEAR_VARS)
+
+LOCAL_VENDOR_MODULE := true
+
+LOCAL_MODULE_TAGS := optional
+
+LOCAL_SRC_FILES := $(call all-java-files-under, src)
+
+LOCAL_PACKAGE_NAME := CactusPlayer
+
+LOCAL_PRIVATE_PLATFORM_APIS := current
+
+LOCAL_CERTIFICATE := platform
+
+include $(BUILD_PACKAGE)
+
+# Use the folloing include to make our test apk.
+include $(call all-makefiles-under,$(LOCAL_PATH))
+
+endif
diff --git a/CactusPlayer/AndroidManifest.xml b/CactusPlayer/AndroidManifest.xml
new file mode 100755
index 0000000..3c79939
--- /dev/null
+++ b/CactusPlayer/AndroidManifest.xml
@@ -0,0 +1,53 @@
+<?xml version="1.0" encoding="utf-8"?>
+
+<manifest xmlns:android="http://schemas.android.com/apk/res/android"
+    package="com.freescale.cactusplayer"
+    android:versionCode="1"
+    android:versionName="1.0"
+    coreApp="true"
+    >
+
+    <uses-sdk android:minSdkVersion="14" android:targetSdkVersion="28" />
+
+    <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>
+    <uses-permission android:name="android.permission.WAKE_LOCK" />
+    <uses-permission android:name="android.permission.INTERNAL_SYSTEM_WINDOW" />
+    <uses-permission android:name="android.permission.SYSTEM_ALERT_WINDOW" />
+
+    <uses-permission android:name="android.permission.WRITE_SETTINGS" />
+    <uses-permission android:name="android.permission.WRITE_SECURE_SETTINGS" />
+    <uses-permission android:name="android.permission.INTERACT_ACROSS_USERS_FULL" />
+    <uses-permission android:name="android.permission.INTERNET" />
+
+    <application
+        android:name="com.freescale.cactusplayer.HdmiApplication"
+        android:icon="@drawable/icn_media_play_pressed_holo_dark"
+        android:label="@string/app_name" >
+        
+		<activity
+            android:name=".VideoMenu"
+            android:configChanges="orientation|mcc|mnc|locale|touchscreen|keyboard|keyboardHidden|navigation|screenLayout|fontScale|uiMode|screenSize"
+            android:theme="@android:style/Theme.Holo"
+            android:label="@string/app_name" >
+			
+            <intent-filter>
+                <action android:name="android.intent.action.MAIN" />
+                <category android:name="android.intent.category.LAUNCHER" />
+            </intent-filter>
+        </activity>
+
+        <activity
+            android:name=".VideoPlayer"
+            android:configChanges="orientation|mcc|mnc|locale|touchscreen|keyboard|keyboardHidden|navigation|screenLayout|fontScale|uiMode|screenSize"
+            android:theme="@android:style/Theme.Holo"
+            android:label="@string/app_name" >
+
+             <intent-filter>
+			    <action android:name="android.intent.action.VIEW" />
+			    <category android:name="android.intent.category.DEFAULT" /> 
+			    <data android:mimeType="video/*" />
+            </intent-filter>
+       </activity>
+     </application>
+
+</manifest>
diff --git a/CactusPlayer/project.properties b/CactusPlayer/project.properties
new file mode 100644
index 0000000..730e911
--- /dev/null
+++ b/CactusPlayer/project.properties
@@ -0,0 +1,11 @@
+# This file is automatically generated by Android Tools.
+# Do not modify this file -- YOUR CHANGES WILL BE ERASED!
+#
+# This file must be checked in Version Control Systems.
+#
+# To customize properties used by the Ant build system use,
+# "ant.properties", and override values to adapt the script to your
+# project structure.
+
+# Project target.
+target=android-14
diff --git a/CactusPlayer/res/drawable/ff.png b/CactusPlayer/res/drawable/ff.png
new file mode 100644
index 0000000..dbf2e1b
Binary files /dev/null and b/CactusPlayer/res/drawable/ff.png differ
diff --git a/CactusPlayer/res/drawable/frame_overlay_gallery_folder.png b/CactusPlayer/res/drawable/frame_overlay_gallery_folder.png
new file mode 100755
index 0000000..508fe51
Binary files /dev/null and b/CactusPlayer/res/drawable/frame_overlay_gallery_folder.png differ
diff --git a/CactusPlayer/res/drawable/frame_overlay_gallery_video.png b/CactusPlayer/res/drawable/frame_overlay_gallery_video.png
new file mode 100755
index 0000000..3249754
Binary files /dev/null and b/CactusPlayer/res/drawable/frame_overlay_gallery_video.png differ
diff --git a/CactusPlayer/res/drawable/ic_media_pause.bmp b/CactusPlayer/res/drawable/ic_media_pause.bmp
new file mode 100755
index 0000000..b4cc4ff
Binary files /dev/null and b/CactusPlayer/res/drawable/ic_media_pause.bmp differ
diff --git a/CactusPlayer/res/drawable/ic_media_play.bmp b/CactusPlayer/res/drawable/ic_media_play.bmp
new file mode 100755
index 0000000..fe725b5
Binary files /dev/null and b/CactusPlayer/res/drawable/ic_media_play.bmp differ
diff --git a/CactusPlayer/res/drawable/ic_media_play1.png b/CactusPlayer/res/drawable/ic_media_play1.png
new file mode 100755
index 0000000..53fde9b
Binary files /dev/null and b/CactusPlayer/res/drawable/ic_media_play1.png differ
diff --git a/CactusPlayer/res/drawable/ic_search_category_music_song.png b/CactusPlayer/res/drawable/ic_search_category_music_song.png
new file mode 100755
index 0000000..182ac6a
Binary files /dev/null and b/CactusPlayer/res/drawable/ic_search_category_music_song.png differ
diff --git a/CactusPlayer/res/drawable/icn_media_play_pressed_holo_dark.png b/CactusPlayer/res/drawable/icn_media_play_pressed_holo_dark.png
new file mode 100755
index 0000000..1bc4f79
Binary files /dev/null and b/CactusPlayer/res/drawable/icn_media_play_pressed_holo_dark.png differ
diff --git a/CactusPlayer/res/drawable/pause.png b/CactusPlayer/res/drawable/pause.png
new file mode 100644
index 0000000..3455e7e
Binary files /dev/null and b/CactusPlayer/res/drawable/pause.png differ
diff --git a/CactusPlayer/res/drawable/play.png b/CactusPlayer/res/drawable/play.png
new file mode 100644
index 0000000..bac7855
Binary files /dev/null and b/CactusPlayer/res/drawable/play.png differ
diff --git a/CactusPlayer/res/drawable/progress.xml b/CactusPlayer/res/drawable/progress.xml
new file mode 100755
index 0000000..0ee0117
--- /dev/null
+++ b/CactusPlayer/res/drawable/progress.xml
@@ -0,0 +1,18 @@
+<?xml version="1.0" encoding="utf-8"?>
+
+<rotate xmlns:android="http://schemas.android.com/apk/res/android"
+	android:pivotX="50%"
+	android:pivotY="50%"
+	android:duration="4000"
+	android:fromDegrees="0"
+	android:toDegrees="360">
+	<shape android:shape="line">
+		<stroke android:width="10dip"
+			android:color="#FFFF0044"/>
+
+		<size android:width="128dip"
+			android:height="128dip" />
+
+	</shape>
+</rotate>
+
diff --git a/CactusPlayer/res/drawable/readme.txt b/CactusPlayer/res/drawable/readme.txt
new file mode 100644
index 0000000..c62a51d
--- /dev/null
+++ b/CactusPlayer/res/drawable/readme.txt
@@ -0,0 +1,19 @@
+1. Created by NXP
+play.png
+pause.png
+ff.png
+rw.png
+ic_media_pause.bmp
+ic_media_play1.png
+ic_media_play.bmp
+
+2. Copied from Gallery/res/drawable-hdpi (LP51)
+frame_overlay_gallery_folder.png
+frame_overlay_gallery_video.png
+
+3. Copied from Gallery2/res/drawable-hdpi (LP51)
+icn_media_play_pressed_holo_dark.png
+
+3. Copied from Music/res/drawable-hdpi (LP51)
+ic_search_category_music_song.png
+
diff --git a/CactusPlayer/res/drawable/rounded_corners_pop.xml b/CactusPlayer/res/drawable/rounded_corners_pop.xml
new file mode 100755
index 0000000..c65f4c6
--- /dev/null
+++ b/CactusPlayer/res/drawable/rounded_corners_pop.xml
@@ -0,0 +1,15 @@
+<?xml version= "1.0"  encoding= "utf-8" ?>
+<shape xmlns:android= "http://schemas.android.com/apk/res/android">
+    <solid android:color= "#ffffffff"/>
+
+    <stroke android:width="3dp" color="#ffff8080"/>
+
+    <corners android:radius="10dp"/>
+
+    <padding
+    	android:left="3dp"
+    	android:top="3dp"
+        android:right="3dp"
+        android:bottom="3dp"
+    />
+</shape>
diff --git a/CactusPlayer/res/drawable/rounded_corners_view.xml b/CactusPlayer/res/drawable/rounded_corners_view.xml
new file mode 100755
index 0000000..878b65b
--- /dev/null
+++ b/CactusPlayer/res/drawable/rounded_corners_view.xml
@@ -0,0 +1,16 @@
+<?xml version= "1.0"  encoding= "utf-8" ?>
+<shape xmlns:android= "http://schemas.android.com/apk/res/android" >
+	<solid android:color= "#ff606060"/>
+
+	<stroke android:width="3dp"  color="#ffff8080"/>
+
+	<corners android:radius="10dp"/>
+
+	<padding
+		android:left="5dp"
+		android:top="5dp"
+		android:right="5dp"
+		android:bottom="5dp"
+	/>
+</shape>
+
diff --git a/CactusPlayer/res/drawable/rw.png b/CactusPlayer/res/drawable/rw.png
new file mode 100755
index 0000000..a9fb265
Binary files /dev/null and b/CactusPlayer/res/drawable/rw.png differ
diff --git a/CactusPlayer/res/layout/griditemextab.xml b/CactusPlayer/res/layout/griditemextab.xml
new file mode 100755
index 0000000..f423f95
--- /dev/null
+++ b/CactusPlayer/res/layout/griditemextab.xml
@@ -0,0 +1,73 @@
+<?xml version="1.0" encoding="utf-8"?>
+<!--
+
+ Copyright (c) 2011-2012, Freescale Semiconductor Inc.
+ All rights reserved.
+
+ You should get a copy of license in this software package named EULA.txt.
+ Please read EULA.txt carefully first.
+
+-->
+<merge xmlns:android="http://schemas.android.com/apk/res/android">
+
+<LinearLayout
+    android:layout_width="fill_parent"
+    android:layout_height="fill_parent"
+    android:orientation="vertical"
+    >
+
+    <LinearLayout
+        android:layout_width="fill_parent"
+        android:layout_height="wrap_content"
+        android:orientation="horizontal"
+        >
+
+        <RelativeLayout
+            android:layout_width="128dp"
+            android:layout_height="128dp"
+            >
+        <!-- THUMBNAIL -->
+        <ImageView
+            android:id="@+id/grid_item_big_image"
+            android:gravity="center"
+            android:layout_width="fill_parent"
+            android:layout_height="fill_parent"
+            >
+        </ImageView>
+
+        </RelativeLayout>
+
+        <LinearLayout
+            android:layout_width="fill_parent"
+            android:layout_height="wrap_content"
+            android:orientation="vertical"
+            >
+
+            <TextView
+                android:id="@+id/grid_item_duration"
+                android:layout_width="fill_parent"
+                android:layout_height="wrap_content"
+                android:layout_marginTop="15dp"
+                android:gravity="left"
+                android:textSize="16sp"
+                android:textColor="#ffffff">
+            </TextView>
+
+        </LinearLayout>
+
+    </LinearLayout>
+
+    <!-- file name -->
+    <TextView
+        android:id="@+id/grid_item_name"
+        android:layout_width="fill_parent"
+        android:layout_height="fill_parent"
+        android:text="@string/item"
+        android:gravity="left"
+        android:textSize="18sp"
+        android:textColor="#ffffff">
+    </TextView>
+
+</LinearLayout>
+
+</merge>
diff --git a/CactusPlayer/res/layout/popupwindow.xml b/CactusPlayer/res/layout/popupwindow.xml
new file mode 100755
index 0000000..6782e9b
--- /dev/null
+++ b/CactusPlayer/res/layout/popupwindow.xml
@@ -0,0 +1,27 @@
+<?xml version="1.0" encoding="utf-8"?>
+<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    android:orientation="vertical"
+    android:layout_width="fill_parent"
+    android:layout_height="fill_parent"
+    >
+    <TextView
+        android:layout_width="fill_parent"
+        android:layout_height="wrap_content"
+        android:text="@string/ClipsNotFound"
+        />
+
+    <LinearLayout
+        android:gravity="center_horizontal"
+        android:layout_width="fill_parent"
+        android:layout_height="fill_parent"
+        >
+
+        <Button
+            android:id="@+id/BtnOK"
+            android:text="@string/OK"
+            android:textSize="30sp"
+            android:layout_width="120px"
+            android:layout_height="60px"
+            />
+      </LinearLayout>
+</LinearLayout>
diff --git a/CactusPlayer/res/layout/presentation_with_media_router_content.xml b/CactusPlayer/res/layout/presentation_with_media_router_content.xml
new file mode 100755
index 0000000..b954adc
--- /dev/null
+++ b/CactusPlayer/res/layout/presentation_with_media_router_content.xml
@@ -0,0 +1,67 @@
+<?xml version="1.0" encoding="utf-8"?>
+<!-- Copyright (C) 2012 The Android Open Source Project
+
+     Licensed under the Apache License, Version 2.0 (the "License");
+     you may not use this file except in compliance with the License.
+     You may obtain a copy of the License at
+
+          http://www.apache.org/licenses/LICENSE-2.0
+
+     Unless required by applicable law or agreed to in writing, software
+     distributed under the License is distributed on an "AS IS" BASIS,
+     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+     See the License for the specific language governing permissions and
+     limitations under the License.
+-->
+
+<!-- The content that we show on secondary displays.
+     See corresponding Java code PresentationWithMediaRouterActivity.java. -->
+<FrameLayout
+       xmlns:android="http://schemas.android.com/apk/res/android"
+       android:id="@+id/ActiveWindow"
+       android:layout_width="fill_parent"
+       android:layout_height="fill_parent"
+       android:background="#000000"
+       >
+   <VideoView
+         android:id="@+id/videoview1"
+         android:layout_width="fill_parent"
+         android:layout_height="fill_parent"
+         android:layout_gravity="center"
+         />
+   <LinearLayout
+         android:id="@+id/ctrlpanel"
+         android:orientation="horizontal"
+         android:layout_width="fill_parent"
+         android:layout_height="wrap_content"
+         android:layout_gravity="bottom"
+         android:background="#60000000"
+         >
+
+   <TextView android:id="@+id/currentpos"
+         android:layout_width="wrap_content"
+         android:layout_height="wrap_content"
+         android:layout_marginTop="12dp"
+         android:layout_marginLeft="15dp"
+         android:textColor="#ffffff"
+         />
+   <SeekBar
+         android:id="@+id/seekbar"
+         android:layout_weight="1"
+         android:layout_width="0dp"
+         android:layout_height="30dp"
+         android:max="100"
+         android:layout_marginTop="8dp"
+         android:layout_marginLeft="10dp"
+         />
+   <TextView
+         android:id="@+id/duration"
+         android:layout_width="wrap_content"
+         android:layout_height="wrap_content"
+         android:layout_marginTop="12dp"
+         android:layout_marginLeft="10dp"
+         android:layout_marginRight="15dp"
+         android:textColor="#ffffff"
+         />
+   </LinearLayout>
+</FrameLayout>
diff --git a/CactusPlayer/res/layout/presentation_with_media_router_content2.xml b/CactusPlayer/res/layout/presentation_with_media_router_content2.xml
new file mode 100755
index 0000000..9b0898a
--- /dev/null
+++ b/CactusPlayer/res/layout/presentation_with_media_router_content2.xml
@@ -0,0 +1,33 @@
+<?xml version="1.0" encoding="utf-8"?>
+<!-- Copyright (C) 2012 The Android Open Source Project
+
+     Licensed under the Apache License, Version 2.0 (the "License");
+     you may not use this file except in compliance with the License.
+     You may obtain a copy of the License at
+
+          http://www.apache.org/licenses/LICENSE-2.0
+
+     Unless required by applicable law or agreed to in writing, software
+     distributed under the License is distributed on an "AS IS" BASIS,
+     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+     See the License for the specific language governing permissions and
+     limitations under the License.
+-->
+
+<!-- The content that we show on secondary displays.
+     See corresponding Java code PresentationWithMediaRouterActivity.java. -->
+<FrameLayout
+    xmlns:android="http://schemas.android.com/apk/res/android"
+    android:id="@+id/ActiveWindow"
+    android:layout_width="fill_parent"
+    android:layout_height="fill_parent"
+    android:background="#000000"
+    >
+
+    <VideoView
+        android:id="@+id/videoview1"
+        android:layout_width="fill_parent"
+        android:layout_height="fill_parent"
+        />
+
+</FrameLayout>
diff --git a/CactusPlayer/res/layout/scaleplayer.xml b/CactusPlayer/res/layout/scaleplayer.xml
new file mode 100755
index 0000000..061427c
--- /dev/null
+++ b/CactusPlayer/res/layout/scaleplayer.xml
@@ -0,0 +1,189 @@
+<?xml version="1.0" encoding="utf-8"?>
+<!--
+ Copyright 2012, Freescale Semiconductor Inc.
+ All rights reserved.
+-->
+<FrameLayout
+     xmlns:android="http://schemas.android.com/apk/res/android"
+     android:id="@+id/ActiveWindow"
+     android:layout_width="fill_parent"
+     android:layout_height="fill_parent"
+     android:background="#000000"
+     >
+
+     <!-- video: lowest layer -->
+     <com.freescale.cactusplayer.VideoView
+          android:id="@+id/SurfaceView"
+          android:layout_height="fill_parent"
+          android:layout_width="fill_parent"
+          android:layout_gravity="center"
+          >
+     </com.freescale.cactusplayer.VideoView>
+
+     <!-- layer to show some information -->
+     <LinearLayout
+          android:orientation="vertical"
+          android:layout_width="fill_parent"
+          android:layout_height="fill_parent"
+          >
+          <!-- boundary -->
+          <LinearLayout
+               android:orientation="vertical"
+               android:layout_width="fill_parent"
+               android:layout_height="0dp"
+               android:layout_weight=".05"
+               >
+          </LinearLayout>
+
+          <!-- title/chapter, not used, reserve for future use-->
+          <LinearLayout
+               android:orientation="vertical"
+               android:layout_width="fill_parent"
+               android:layout_height="0dp"
+               android:layout_weight=".80"
+               >
+          <com.freescale.cactusplayer.AutoHideTextView
+               android:id="@+id/titlechapter"
+               android:layout_width="wrap_content"
+               android:layout_height="wrap_content"
+               android:layout_gravity="top|center"
+               android:background="#a0404080"
+               android:textColor="#ffff00"
+               android:textStyle="bold"
+               android:textSize="32sp"
+          />
+          </LinearLayout>
+
+          <com.freescale.cactusplayer.AutoHideTextView
+               android:id="@+id/info"
+               android:layout_width="wrap_content"
+               android:layout_height="wrap_content"
+               android:layout_marginLeft="24dp"
+               android:background="#a0404080"
+               android:textColor="#ffff00"
+               android:textSize="24sp"
+          />
+
+          <LinearLayout
+               android:orientation="vertical"
+               android:layout_width="fill_parent"
+               android:layout_height="wrap_content"
+               android:layout_gravity="bottom"
+          >
+          <com.freescale.cactusplayer.AutoHideTextView
+               android:id="@+id/subtitletext"
+               android:layout_width="wrap_content"
+               android:layout_height="wrap_content"
+               android:layout_gravity="bottom|center"
+               android:background="#00404080"
+               android:textColor="#ffff00"
+               android:textStyle="bold"
+               android:textSize="32sp"
+         />
+         </LinearLayout>
+
+         <LinearLayout
+              android:orientation="vertical"
+              android:layout_width="fill_parent"
+              android:layout_height="0dp"
+              android:layout_weight=".08"
+              android:layout_gravity="bottom"
+         >
+        </LinearLayout>
+    </LinearLayout>
+
+    <!--
+        Display law rating string
+    -->
+    <!--
+        <com.freescale.cactusplayer.AutoHideTextView
+            android:id="@+id/lawrating"
+            android:layout_height="wrap_content"
+            android:layout_width="wrap_content"
+            android:layout_marginLeft="48dp"
+            android:layout_marginTop="48dp"
+            android:background="#a0404080"
+            android:textColor="#ff0000"
+            android:textSize="32sp"
+            android:textStyle="bold"
+            android:layout_gravity="top|left"
+         />
+    -->
+    <!--
+        Display error string
+    -->
+    <com.freescale.cactusplayer.AutoHideTextView
+         android:id="@+id/subtitleinfo"
+         android:layout_height="wrap_content"
+         android:layout_width="wrap_content"
+         android:layout_marginTop="48dp"
+         android:layout_marginLeft="48dp"
+         android:layout_marginRight="48dp"
+         android:background="#a0404080"
+         android:textColor="#ff0000"
+         android:textSize="32sp"
+         android:layout_gravity="top|left"
+     />
+
+    <LinearLayout
+         android:id="@+id/ctrlpanel"
+         android:orientation="horizontal"
+         android:layout_width="fill_parent"
+         android:layout_height="wrap_content"
+         android:layout_gravity="bottom"
+         android:background="#60000000"
+    >
+    <ImageButton
+         android:id="@+id/fastback"
+         android:background="@drawable/rw"
+         android:layout_width="33dp"
+         android:layout_height="33dp"
+         android:layout_marginLeft="15dp"
+         android:layout_marginTop="6dp"
+         android:visibility="invisible"
+    />
+    <ImageButton
+         android:id="@+id/playpause"
+         android:layout_width="33dp"
+         android:layout_height="33dp"
+         android:layout_marginLeft="10dp"
+         android:layout_marginTop="6dp"
+    />
+    <ImageButton
+         android:id="@+id/fastforward"
+         android:background="@drawable/ff"
+         android:layout_width="33dp"
+         android:layout_height="33dp"
+         android:layout_marginLeft="10dp"
+         android:layout_marginTop="6dp"
+    />
+    <TextView
+         android:id="@+id/currentpos"
+         android:layout_width="wrap_content"
+         android:layout_height="wrap_content"
+         android:layout_marginTop="12dp"
+         android:layout_marginLeft="15dp"
+         android:textColor="#ffffff"
+     />
+    <SeekBar
+         android:id="@+id/seek"
+         android:layout_weight="1"
+         android:layout_width="0dp"
+         android:layout_height="30dp"
+         android:max="100"
+         android:layout_marginTop="8dp"
+         android:layout_marginLeft="10dp"
+    />
+
+    <TextView android:id="@+id/duration"
+         android:layout_width="wrap_content"
+         android:layout_height="wrap_content"
+         android:layout_marginTop="12dp"
+         android:layout_marginLeft="10dp"
+         android:layout_marginRight="15dp"
+         android:textColor="#ffffff"
+     />
+     </LinearLayout>
+
+</FrameLayout>
+
diff --git a/CactusPlayer/res/layout/secondvideo.xml b/CactusPlayer/res/layout/secondvideo.xml
new file mode 100755
index 0000000..95faa74
--- /dev/null
+++ b/CactusPlayer/res/layout/secondvideo.xml
@@ -0,0 +1,45 @@
+<?xml version="1.0" encoding="utf-8"?>
+<!-- Copyright (C) 2012 The Android Open Source Project
+
+     Licensed under the Apache License, Version 2.0 (the "License");
+     you may not use this file except in compliance with the License.
+     You may obtain a copy of the License at
+
+          http://www.apache.org/licenses/LICENSE-2.0
+
+     Unless required by applicable law or agreed to in writing, software
+     distributed under the License is distributed on an "AS IS" BASIS,
+     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+     See the License for the specific language governing permissions and
+     limitations under the License.
+-->
+
+<LinearLayout
+    xmlns:android="http://schemas.android.com/apk/res/android"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    android:orientation="vertical">
+
+    <RelativeLayout
+        android:id="@+id/hdmi_layout"
+        android:layout_width="match_parent"
+        android:layout_height="wrap_content" >
+
+        <ImageView
+            android:id="@+id/hdmi_image"
+            android:layout_width="match_parent"
+            android:layout_height="match_parent"
+            android:layout_centerInParent="true" />
+
+        <ImageButton
+            android:id="@+id/hdmi_button"
+            android:layout_width="80dp"
+            android:layout_height="80dp"
+            android:layout_alignParentLeft="true"
+            android:layout_centerVertical="true"
+            android:layout_marginLeft="460dp"
+            android:src="@drawable/ic_media_play1"
+            />
+ >
+    </RelativeLayout>
+</LinearLayout>
diff --git a/CactusPlayer/res/layout/selectaudio.xml b/CactusPlayer/res/layout/selectaudio.xml
new file mode 100755
index 0000000..7eafc7b
--- /dev/null
+++ b/CactusPlayer/res/layout/selectaudio.xml
@@ -0,0 +1,40 @@
+<?xml version="1.0" encoding="utf-8"?>
+<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    android:orientation="vertical"
+    android:layout_width="fill_parent"
+    android:layout_height="fill_parent"
+    >
+    <TextView
+        android:gravity="center_horizontal"
+        android:textSize="20sp"
+        android:layout_width="fill_parent"
+        android:layout_height="wrap_content"
+        android:text="@string/SelectAudio"
+        />
+
+    <ListView
+        android:id="@+id/list"
+        android:layout_gravity="center_horizontal"
+        android:layout_marginTop="30px"
+        android:textSize="20sp"
+        android:layout_width="fill_parent"
+        android:layout_height="300px"
+        android:drawSelectorOnTop="false"
+        />
+
+    <LinearLayout
+        android:gravity="center_horizontal"
+        android:layout_marginTop="30px"
+        android:layout_width="fill_parent"
+        android:layout_height="fill_parent"
+        >
+
+    <Button
+        android:id="@+id/BtnCancel"
+        android:textSize="20sp"
+        android:text="@string/Cancel"
+        android:layout_width="120px"
+        android:layout_height="50px"
+        />
+   </LinearLayout>
+</LinearLayout>
diff --git a/CactusPlayer/res/layout/selectsubtitle.xml b/CactusPlayer/res/layout/selectsubtitle.xml
new file mode 100755
index 0000000..fbcb345
--- /dev/null
+++ b/CactusPlayer/res/layout/selectsubtitle.xml
@@ -0,0 +1,41 @@
+<?xml version="1.0" encoding="utf-8"?>
+<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    android:orientation="vertical"
+    android:layout_width="fill_parent"
+    android:layout_height="fill_parent"
+    >
+
+    <TextView
+        android:gravity="center_horizontal"
+        android:textSize="20sp"
+        android:layout_width="fill_parent"
+        android:layout_height="wrap_content"
+        android:text="@string/SelectSubtitle"
+    />
+
+    <ListView
+        android:id="@+id/list"
+        android:layout_gravity="center_horizontal"
+        android:layout_marginTop="30px"
+        android:textSize="20sp"
+        android:layout_width="fill_parent"
+        android:layout_height="300px"
+        android:drawSelectorOnTop="false"
+    />
+
+    <LinearLayout
+        android:gravity="center_horizontal"
+        android:layout_marginTop="30px"
+        android:layout_width="fill_parent"
+        android:layout_height="fill_parent"
+        >
+
+        <Button
+            android:id="@+id/BtnCancel"
+            android:textSize="20sp"
+            android:text="@string/Cancel"
+            android:layout_width="120px"
+            android:layout_height="50px"
+        />
+    </LinearLayout>
+</LinearLayout>
diff --git a/CactusPlayer/res/layout/videomenu.xml b/CactusPlayer/res/layout/videomenu.xml
new file mode 100755
index 0000000..bef942b
--- /dev/null
+++ b/CactusPlayer/res/layout/videomenu.xml
@@ -0,0 +1,38 @@
+<?xml version="1.0" encoding="utf-8"?>
+<!--
+
+Copyright (c) 2012, Freescale Semiconductor Inc.
+All rights reserved.
+
+You should get a copy of license in this software package named EULA.txt.
+Please read EULA.txt carefully first.
+
+-->
+
+<RelativeLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    android:layout_width="fill_parent"
+    android:layout_height="fill_parent"
+    >
+
+    <LinearLayout
+        android:id="@+id/parentview"
+        android:orientation="vertical"
+        android:layout_width="fill_parent"
+        android:layout_height="fill_parent"
+        android:background="#000000">
+
+        <GridView
+            android:id="@+id/contentview"
+            android:layout_width="fill_parent"
+            android:layout_height="fill_parent"
+            android:columnWidth="196dp"
+            android:numColumns="auto_fit"
+            android:verticalSpacing="16dp"
+            android:horizontalSpacing="4dp"
+            android:stretchMode="columnWidth"
+            android:gravity="center"
+         />
+     </LinearLayout>
+
+</RelativeLayout>
+
diff --git a/CactusPlayer/res/values-zh-rCN/string.xml b/CactusPlayer/res/values-zh-rCN/string.xml
new file mode 100755
index 0000000..b35e3e1
--- /dev/null
+++ b/CactusPlayer/res/values-zh-rCN/string.xml
@@ -0,0 +1,29 @@
+<?xml version="1.0" encoding="utf-8"?>
+<resources>
+    <string name="app_name">仙人掌播放器</string>
+    <string name="waiting">等待</string>
+    <string name="Error">错误</string>
+    <string name="item">条目</string>
+    <string name="Scan">搜索</string>
+    <string name="SelectAudio">选择音频</string>
+    <string name="SelectSubtitle">选择字幕</string>
+    <string name="CloseSubtitle">关闭字幕</string>
+    <string name="LoopFile">循环</string>
+    <string name="CastScreen">远程播放</string>
+    <string name="OK">"确定"</string>
+    <string name="Cancel">"取消"</string>
+    <string name="ClipsNotFound">"没有找到可播放文件，请稍后再试"</string>
+    <string name="Continue">"继续？"</string>
+    <string name="SubtitleOff">"Subtitle OFF"</string>
+    <string name="noname">"没有文件名"</string>
+    <string name="Remote_control">"远程播放控制"</string>
+    <string name="noRemote_control">"没有远程播放"</string>
+    <string name="quit">"完全退出"</string>
+    <string name="Warning">警告</string>
+    <string name="PermissionNotGrant">权限未设置，请在设置里授予Storage权限，否则继续运行可能导致程序崩溃，是否继续运行?</string>
+    <array name="str_body">
+        <item>播放</item>
+        <item>远程播放</item>
+
+    </array>
+</resources>
diff --git a/CactusPlayer/res/values/strings.xml b/CactusPlayer/res/values/strings.xml
new file mode 100755
index 0000000..e218bec
--- /dev/null
+++ b/CactusPlayer/res/values/strings.xml
@@ -0,0 +1,29 @@
+<?xml version="1.0" encoding="utf-8"?>
+<resources>
+    <string name="app_name">Cactus Player </string>
+    <string name="waiting">Waiting ...</string>
+    <string name="Error">Error</string>
+    <string name="item">item</string>
+    <string name="Scan">Scanning</string>
+    <string name="SelectAudio">Select Audio</string>
+    <string name="SelectSubtitle">Select Subtitle</string>
+    <string name="CloseSubtitle">Close Subtitle</string>
+    <string name="LoopFile">Loop</string>
+    <string name="CastScreen">CastScreen</string>
+    <string name="OK">"OK"</string>
+    <string name="Cancel">"Cancel"</string>
+    <string name="ClipsNotFound">"No clips found. Perhaps media scanner is not finished yet. Please try later."</string>
+    <string name="Continue">"Continue?"</string>
+    <string name="SubtitleOff">"Subtitle OFF"</string>
+    <string name="noname">"No name"</string>
+    <string name="Remote_control">"Remote Control"</string>
+    <string name="noRemote_control">"No Remote Control"</string>
+    <string name="Warning">Warning</string>
+    <string name="quit">"quit"</string>
+    <string name="PermissionNotGrant">Fail to grant permission.Please grant the storage in Settings,or app maybe crash. Still run it?</string>
+    <array name="str_body">
+        <item>PALY</item>
+        <item>SECOND VIDEO PLAY</item>
+
+    </array>
+</resources>
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/AutoHideTextView.java b/CactusPlayer/src/com/freescale/cactusplayer/AutoHideTextView.java
new file mode 100755
index 0000000..6d887b0
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/AutoHideTextView.java
@@ -0,0 +1,90 @@
+/*
+ * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.freescale.cactusplayer;
+
+import android.content.Context;
+import android.os.Handler;
+import android.os.Message;
+import android.util.AttributeSet;
+import android.view.View;
+import android.widget.TextView;
+
+public class AutoHideTextView extends TextView {
+    private String TAG = "CactusPlayer";
+    private static final String CLASS = "AutoHideTextView: ";
+
+    private boolean mPause = false;
+    private int     mDuration = 0;
+
+    private Handler mTimerHandler = new Handler() {
+        @Override
+        public void handleMessage(Message msg) {
+            // one second elapsed
+            if(!mPause)
+                mDuration -= 1000;
+            // if time out, hide; otherwise, check one second later
+            if(mDuration <= 0)
+                setVisibility(View.INVISIBLE);
+            else
+                mTimerHandler.sendEmptyMessageDelayed(1, 1000);
+         }
+     };
+
+     public AutoHideTextView(Context context) {
+         super(context);
+     }
+
+     public AutoHideTextView(Context context, AttributeSet attrs) {
+         this(context, attrs, 0);
+     }
+
+     public AutoHideTextView(Context context, AttributeSet attrs, int defStyle) {
+         super(context, attrs, defStyle);
+     }
+
+     public void pause() {
+         mPause = true;
+     }
+
+     public void resume() {
+         mPause = false;
+     }
+
+     public void setText(String text, int duration) {
+         // change text
+         super.setText(text);
+
+         mDuration = duration;
+
+        // cancel any previous messages
+         mTimerHandler.removeMessages(1);
+
+         if(text != null){
+             // show me
+             setVisibility(View.VISIBLE);
+
+             if(duration > 0){
+                 // set timer
+                 mTimerHandler.sendEmptyMessageDelayed(1, 1000);
+             }
+          }
+         else{
+             setVisibility(View.INVISIBLE);
+         }
+      }
+ }
+
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/HdmiApplication.java b/CactusPlayer/src/com/freescale/cactusplayer/HdmiApplication.java
new file mode 100755
index 0000000..aeea418
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/HdmiApplication.java
@@ -0,0 +1,420 @@
+/*
+ * Copyright 2012 The Android Open Source Project
+ * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.freescale.cactusplayer;
+
+import android.widget.VideoView;
+
+import android.util.Log;
+import android.media.MediaPlayer;
+import android.media.MediaPlayer.OnCompletionListener;
+import android.media.MediaPlayer.OnErrorListener;
+import android.media.MediaPlayer.OnPreparedListener;
+import android.media.MediaRouter.RouteInfo;
+import android.media.MediaRouter;
+import android.app.Application;
+import android.app.Presentation;
+import java.io.File;
+import java.io.FilenameFilter;
+import android.os.Bundle;
+import android.os.Handler;
+import android.os.HandlerThread;
+import android.os.Looper;
+import android.os.Message;
+import android.os.UserHandle;
+import java.util.List;
+import java.util.ArrayList;
+import android.net.Uri;
+import android.widget.ImageButton;
+import android.widget.ImageView;
+import android.widget.ArrayAdapter;
+import android.widget.SeekBar;
+import android.widget.SeekBar.OnSeekBarChangeListener;
+import android.widget.Spinner;
+import android.widget.TextView;
+import android.view.Display;
+import android.widget.AdapterView.OnItemSelectedListener;
+import android.widget.AdapterView;
+import android.media.ThumbnailUtils;
+import android.provider.MediaStore;
+import android.content.Context;
+import android.content.BroadcastReceiver;
+import android.content.Intent;
+import android.content.IntentFilter;
+import android.view.WindowManager;
+import android.content.res.Resources;
+import android.database.ContentObserver;
+import android.provider.Settings;
+import android.hardware.display.DisplayManager;
+import android.net.wifi.WifiManager;
+public class HdmiApplication extends Application{
+    private static final String TAG = "HdmiApplication";
+    private MediaRouter mMediaRouter = null;
+    private DemoPresentation mPresentation = null;
+    private Uri mVideoUri;
+    public boolean mVideoRunning = false;
+    private int mVideoIndex = -1;
+    private boolean mPresentation_loopstatus = false;
+    private boolean mPresentationEnded = false;
+
+    public final static String EXTRA_HDMI_PLUGGED_STATE = "state";
+    public final static String ACTION_HDMI_PLUGGED = "android.intent.action.HDMI_PLUGGED";
+    public final static String PLATFORM_CHECK = "/sys/class/mxc_ipu/mxc_ipu/dev";
+
+    // It was defined in DisplayManager.java, later removed from Android version O. We have to define it here.
+    public static final String ACTION_WIFI_DISPLAY_DISCONNECTION =
+                 "android.hardware.display.action.WIFI_DISPLAY_DISCONNECTION";
+
+    public interface Callback {
+        public void onPresentationEnded(boolean end);
+        public void onPresentationChanged(boolean plugin);
+    }
+
+    private Callback mListener = null;
+    private Callback mPresentationChangedListener = null;
+
+    public void addListener(Callback listener) {
+        mListener = listener;
+        mPresentationChangedListener = listener;
+    }
+
+    public DemoPresentation getPresentation() {
+        return mPresentation;
+    }
+
+    public boolean getVideoRunning() {
+        return mVideoRunning;
+    }
+
+    public int getVideoIndex() {
+        return mVideoIndex;
+    }
+
+    public boolean getmPresentationEnded(){
+        return mPresentationEnded;
+    }
+
+    public void setmPresentationEnded(boolean ended){
+        mPresentationEnded = ended;
+    }
+
+    public void onCreate() {
+        super.onCreate();
+        mMediaRouter = (MediaRouter)getSystemService(Context.MEDIA_ROUTER_SERVICE);
+        mMediaRouter.addCallback(MediaRouter.ROUTE_TYPE_LIVE_VIDEO, mMediaRouterCallback);
+        // updatePresentation();
+        // Get the current route and its presentation display.
+        MediaRouter.RouteInfo route = mMediaRouter.getSelectedRoute(
+                MediaRouter.ROUTE_TYPE_LIVE_VIDEO);
+        Display presentationDisplay = route != null ? route.getPresentationDisplay() : null;
+        if (mPresentation == null && presentationDisplay != null) {
+            Log.w(TAG, "Showing presentation on display: " + presentationDisplay);
+            mPresentation = new DemoPresentation(this, presentationDisplay);
+            try {
+                WindowManager.LayoutParams l = mPresentation.getWindow().getAttributes();
+                //l.type = WindowManager.LayoutParams.FIRST_SYSTEM_WINDOW + 100;
+                l.type = WindowManager.LayoutParams.TYPE_SYSTEM_ALERT;
+             } catch (WindowManager.InvalidDisplayException ex) {
+                Log.w(TAG, "Couldn't show presentation!  Display was removed in "
+                        + "the meantime.", ex);
+                mPresentation = null;
+             }
+         }
+
+    }
+
+
+    private final MediaRouter.SimpleCallback mMediaRouterCallback =
+        new MediaRouter.SimpleCallback() {
+            @Override
+            public void onRouteSelected(MediaRouter router, int type, RouteInfo info) {
+                Log.w(TAG, "onRouteSelected: type=" + type + ", info=" + info);
+                updatePresentation();
+            }
+
+            @Override
+            public void onRouteUnselected(MediaRouter router, int type, RouteInfo info) {
+                Log.w(TAG, "onRouteUnselected: type=" + type + ", info=" + info);
+                updatePresentation();
+            }
+
+            @Override
+            public void onRoutePresentationDisplayChanged(MediaRouter router, RouteInfo info) {
+                Log.w(TAG, "onRoutePresentationDisplayChanged: info=" + info);
+                updatePresentation();
+            }
+        };
+
+        private void updatePresentation() {
+            // Get the current route and its presentation display.
+            MediaRouter.RouteInfo route = mMediaRouter.getSelectedRoute(
+                MediaRouter.ROUTE_TYPE_LIVE_VIDEO);
+                Display presentationDisplay = route != null ? route.getPresentationDisplay() : null;
+                // presentationDisplay.getRefreshRate();
+                // Dismiss the current presentation if the display has changed.
+                if (mPresentation != null && mPresentation.getDisplay() != presentationDisplay) {
+                     Log.w(TAG, "Dismissing presentation because the current route no longer "
+                     + "has a presentation display.");
+                     //mPresentation disconnect
+                     if (mPresentationChangedListener != null) {
+                         mPresentationChangedListener.onPresentationChanged(false);
+                     }
+
+                     mPresentation.dismiss();
+                     mPresentation = null;
+                }
+
+                // Show a new presentation if needed.
+                if (mPresentation == null && presentationDisplay != null) {
+                    Log.w(TAG, "Showing presentation on display: " + presentationDisplay);
+                    mPresentation = new DemoPresentation(this, presentationDisplay);
+                    try {
+                         WindowManager.LayoutParams l = mPresentation.getWindow().getAttributes();
+                         //l.type = WindowManager.LayoutParams.FIRST_SYSTEM_WINDOW + 100;
+                         l.type = WindowManager.LayoutParams.TYPE_SYSTEM_ALERT;
+                         //mPresentation connect again
+                         if (mPresentationChangedListener != null) {
+                             mPresentationChangedListener.onPresentationChanged(true);
+                          }
+                    } catch (WindowManager.InvalidDisplayException ex) {
+                         Log.w(TAG, "Couldn't show presentation!  Display was removed in "
+                         + "the meantime.", ex);
+                         mPresentation = null;
+                    }
+                 }
+         }
+
+        public class DemoPresentation extends Presentation {
+            protected static final String TAG2 = "DemoPresentation ";
+            private VideoView mvideoview;
+            private SeekBar mseekbar;
+            private TextView mcurrentpos,mduration;
+            private static final int    SHOW_PROGRESSBAR  = 0;
+            private static final int    SHOW_PROGRESSTIME = 1;
+            private int myPresentationState;
+            private ProgressHandler mHandler;
+
+            private class ProgressHandler extends Handler {
+                @Override
+                public void handleMessage(Message msg) {
+                    switch (msg.what) {
+                        case SHOW_PROGRESSBAR:
+                             mseekbar.setMax(mvideoview.getDuration());
+                             mseekbar.setProgress(mvideoview.getCurrentPosition());
+                             mHandler.sendEmptyMessageDelayed(SHOW_PROGRESSBAR, 500);
+                             break;
+
+                        case SHOW_PROGRESSTIME:
+                             show_ProgressTime();
+                             mHandler.sendEmptyMessageDelayed(SHOW_PROGRESSTIME, 500);
+                             break;
+
+                        default:
+                             break;
+                     }
+                 }
+            };
+
+            public void show_ProgressTime(){
+                //mPresentation duration
+                int a=mvideoview.getDuration();
+                long seconds = a / 1000;
+                long minutes = seconds / 60;
+                seconds = seconds - minutes * 60;
+                long hours = minutes / 60;
+                minutes = minutes - hours * 60;
+                String s = "";
+                if(hours < 10)
+                    s += "0";
+                s += hours + ":";
+                if(minutes < 10)
+                    s += "0";
+                s += minutes + ":";
+                if(seconds < 10)
+                    s += "0";
+                s += seconds;
+                mduration.setText(s);
+                seconds = mvideoview.getCurrentPosition() / 1000;
+                minutes = seconds / 60;
+                seconds = seconds - minutes * 60;
+                hours = minutes / 60;
+                minutes = minutes - hours * 60;
+                s = "";
+                if(hours < 10)
+                    s += "0";
+                s += hours + ":" ;
+                if(minutes < 10)
+                    s += "0";
+                s += minutes + ":";
+                if(seconds < 10)
+                    s += "0";
+                s += seconds;
+                mcurrentpos.setText(s);
+           }
+
+           public DemoPresentation(Context context, Display display) {
+               super(context, display);
+           }
+
+           @Override
+           protected void onCreate(Bundle savedInstanceState) {
+               // Be sure to call the super class.
+               super.onCreate(savedInstanceState);
+               // Get the resources for the context of the presentation.
+               // Notice that we are getting the resources from the context of the presentation.
+               Resources r = getContext().getResources();
+
+               // Inflate the layout.
+               setContentView(R.layout.presentation_with_media_router_content);
+
+               // Set up the surface view for visual interest.
+               mvideoview = (VideoView)findViewById(R.id.videoview1);
+               mvideoview.setOnCompletionListener(new MediaPlayer.OnCompletionListener(){
+                  @Override
+                  public void onCompletion(MediaPlayer mp)  {
+                      if(mPresentation_loopstatus == true){
+                          mvideoview.start();
+                          mListener.onPresentationEnded(false);
+                      }
+                      else{
+                          mPresentationEnded = true;
+                          if(mListener != null){
+                              mListener.onPresentationEnded(true);
+                              mVideoRunning = false;
+                          }
+                       }
+                  }
+               });
+
+               mvideoview.setOnErrorListener(new MediaPlayer.OnErrorListener(){
+                  @Override
+                  public boolean onError(MediaPlayer mp, int what, int extra){
+                      mvideoview.setVideoURI(mVideoUri);
+                      mvideoview.start();
+                      return true;
+                  }
+               });
+               mseekbar = (SeekBar)findViewById(R.id.seekbar);
+               mcurrentpos = (TextView)findViewById(R.id.currentpos);
+               mduration = (TextView)findViewById(R.id.duration);
+               mHandler = new ProgressHandler();
+         }
+
+        private final ContentObserver mSettingsObserver = new ContentObserver(mHandler) {
+            @Override
+            public void onChange(boolean selfChange, Uri uri) {
+                boolean connected = Settings.Global.getInt(getContentResolver(),
+                Settings.Global.WIFI_ON, 0) != 0;
+                if (!connected) {
+                    pauseVideo();
+                    Log.d(TAG,"ContentObserver wifi_off pauseVideo");
+                }
+            }
+        };
+
+        private final BroadcastReceiver mReceiver = new BroadcastReceiver(){
+            @Override
+            public void onReceive(Context context, Intent intent){
+                String action = intent.getAction();
+                if(action.equals(ACTION_WIFI_DISPLAY_DISCONNECTION)){
+                    pauseVideo();
+                }
+                Log.d(TAG,"BroadcastReceiver WIFI_DISPLAY_DISCONNECTION");
+             }
+         };
+
+         protected void onStart() {
+             super.onStart();
+             getContentResolver().registerContentObserver(Settings.Global.getUriFor(
+                 Settings.Global.WIFI_ON), false, mSettingsObserver, UserHandle.USER_ALL);
+             mHandler.sendEmptyMessageDelayed(SHOW_PROGRESSBAR, 500);
+             mHandler.sendEmptyMessageDelayed(SHOW_PROGRESSTIME, 500);
+             IntentFilter filter = new IntentFilter();
+             filter.addAction(ACTION_WIFI_DISPLAY_DISCONNECTION);
+             registerReceiver(mReceiver, filter);
+         }
+
+         protected void onStop() {
+             super.onStop();
+             unregisterReceiver(mReceiver);
+             mHandler.removeMessages(SHOW_PROGRESSBAR);
+             mHandler.removeMessages(SHOW_PROGRESSTIME);
+         }
+
+         public void setPresentation_LoopStatus(boolean loopstatus){
+             mPresentation_loopstatus = loopstatus;
+         }
+
+         public boolean getPresentation_LoopStatus(){
+             return mPresentation_loopstatus;
+         }
+
+         public void startVideo(Uri uri) {
+             mVideoRunning = true;
+             mVideoUri = uri;
+             mvideoview.setVideoURI(uri);
+             mvideoview.requestFocus();
+             mvideoview.start();
+         }
+
+         public Uri getmyUri(){
+             return mVideoUri;
+         }
+
+         public void mseekTo(int msec){
+             mVideoRunning = true;
+             int ms = msec;
+             mvideoview.seekTo(ms);
+         }
+
+         public int getcurrentPos(){
+             int mcurPos = mvideoview.getCurrentPosition();
+             return mcurPos;
+         }
+
+         public int getDuration(){
+             return mvideoview.getDuration();
+         }
+
+         //   0 means no presentation
+         //   1 means presentation is playing
+         //   2 means presentation is pausing
+         public void setPresentationState(int State){
+             myPresentationState = State;
+         }
+
+         public int getPresentationState(){
+             return myPresentationState;
+         }
+
+         public void pauseVideo() {
+             mVideoRunning = false;
+             mvideoview.pause();
+         }
+
+         public void resumeVideo() {
+             mVideoRunning = true;
+             mvideoview.start();
+         }
+
+         public void stopVideo() {
+             mVideoRunning = false;
+             mvideoview.stopPlayback();
+         }
+    }
+}
+
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/ImageTextAdapter.java b/CactusPlayer/src/com/freescale/cactusplayer/ImageTextAdapter.java
new file mode 100755
index 0000000..a365b20
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/ImageTextAdapter.java
@@ -0,0 +1,183 @@
+/*
+ * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.freescale.cactusplayer;
+
+import android.app.AlertDialog;
+import android.content.Context;
+import android.content.DialogInterface;
+
+import android.view.View;
+import android.view.ViewGroup;
+import android.widget.BaseAdapter;
+import android.util.Log;
+
+
+// display small icon and text
+public class ImageTextAdapter extends BaseAdapter {
+    private Context mContext = null;
+    private Bucket mBuckets[] = null;
+    private int mBucketCount = 0;
+    private int mCurrentBucket = -1; // -1: root
+    public ImageTextAdapter(Context c) {
+        mContext = c;
+        mBuckets = new Bucket [4];
+        int i;
+        for(i=0; i<mBuckets.length; i++)
+            mBuckets[i] = new Bucket();
+        mBucketCount = 0;
+        mCurrentBucket = -1;
+    }
+
+    synchronized public int getCount() {
+    if(mCurrentBucket == -1)
+        return mBucketCount;
+    else
+        return mBuckets[mCurrentBucket].length();
+    }
+
+    public Object getItem(int position) {
+        return null;
+    }
+
+    public long getItemId(int position) {
+        return 0;
+    }
+
+    synchronized public View getView(int position, View convertView, ViewGroup parent) {
+
+        ImageTextView itv = (ImageTextView) convertView;
+        if (itv == null)
+            itv = new ImageTextView(mContext);
+        if(mCurrentBucket == -1 && position >= 0 && position < mBucketCount)
+            itv.update(mBuckets[position].name(), mBuckets[position].length(), position);
+        else if(mCurrentBucket >= 0 && mCurrentBucket < mBucketCount && position >= 0 && position < mBuckets[mCurrentBucket].length())
+            itv.update(mBuckets[mCurrentBucket].item(position));
+        else
+            itv.clear();
+
+        return itv;
+     }
+
+    private void createBuckets(ItemData[] data, int count) {
+        int i;
+        for(i=0; i<count; i++) {
+            String bucketName = data[i].mBucket;
+            // find a bucket with bucketName
+            int j;
+            for(j=0; j<mBucketCount; j++) {
+                if(mBuckets[j].name().equals(bucketName))
+                    break;
+            }
+
+            // check bucket array size
+            if(j >= mBuckets.length) {
+                // assert(j == mBucketCount)
+                Bucket [] newBuckets = new Bucket [(mBuckets.length+1) * 2];
+                int k;
+                for(k=0; k<mBucketCount; k++) {
+                    newBuckets[k] = mBuckets[k];
+                }
+                for(; k<newBuckets.length; k++)
+                    newBuckets[k] = new Bucket();
+
+                mBuckets = newBuckets;
+            }
+
+            mBuckets[j].insert(data[i]);
+
+            if(j == mBucketCount)
+                mBucketCount++;
+        }
+    }
+
+    synchronized public void setData(ItemData[] data, int count) {
+        createBuckets(data, count);
+        mCurrentBucket = -1;
+        notifyDataSetChanged();
+    }
+
+    public void clickItem(final ImageTextView itv) {
+        if(itv == null)
+            return;
+
+        if(itv.isDir()) {
+            mCurrentBucket = itv.dirId();
+            notifyDataSetChanged();
+        }
+        else {
+            itv.onFileClicked();
+        }
+    }
+
+    public boolean onBackPressed() {
+        if(mCurrentBucket == -1) {
+            return false;
+        }
+        else {
+            mCurrentBucket = -1;
+            notifyDataSetChanged();
+            return true;
+        }
+     }
+
+    private class Bucket {
+        private String mName;
+        private ItemData [] mData = null;
+        private int mItemCount = 0;
+        public Bucket() {
+            mName = null;
+            mData = new ItemData [4];
+            mItemCount = 0;
+        }
+
+    public void insert(ItemData data) {
+        // if this is the first item, then get its bucket name
+        if(mName == null)
+            mName = data.mBucket;
+
+        // if overflow
+        if(mItemCount + 1  == mData.length) {
+            ItemData [] newData = new ItemData [(mData.length+1) * 2];
+            int i;
+            for(i = 0; i < mItemCount; i++) {
+                newData[i] = mData[i];
+            }
+            mData = newData;
+        }
+
+        // insert the item
+        mData[mItemCount] = data;
+        mItemCount++;
+    }
+
+    public String name() {
+        return mName;
+    }
+
+    public int length() {
+        return mItemCount;
+    }
+
+    public ItemData item(int pos) {
+        if(pos < 0 || pos >= length())
+            return null;
+        else
+            return mData[pos];
+     }
+  }
+}
+
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/ImageTextView.java b/CactusPlayer/src/com/freescale/cactusplayer/ImageTextView.java
new file mode 100755
index 0000000..0856742
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/ImageTextView.java
@@ -0,0 +1,217 @@
+/*
+ * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package com.freescale.cactusplayer;
+
+import android.content.Intent;
+import android.content.Context;
+
+import android.widget.TextView;
+import android.widget.ImageView;
+import android.widget.LinearLayout;
+import android.util.Log;
+import android.view.LayoutInflater;
+import android.graphics.Bitmap;
+import android.graphics.BitmapFactory;
+import android.net.Uri;
+import android.os.AsyncTask;
+
+public class ImageTextView extends LinearLayout {
+    private static final String CLASS = "ImageTextView: ";
+    // access to owner activity
+    private Context mContext;
+    // directory or file
+    private boolean mDir;
+    // if directory, then have an ID attached
+    private int     mDirId;
+    private ImageView mThumbnailImage;
+    private TextView  mNameView; // directory or file name
+    private TextView  mDurationView;
+    private String mName;
+    private String mUrl;
+    private String mAlbumArt;
+    private long   mDuration;
+    private String mMime;
+
+    // task for displaying photo thumbnails
+    private DisplayPicture mThumbNailTask = null;
+    public ImageTextView(Context context) {
+        super(context);
+        mContext = context;
+        mThumbNailTask = null;
+        LayoutInflater inflater =
+            (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE);
+        inflater.inflate(R.layout.griditemextab, this, true);
+
+        // findViewById's performance is low
+        mThumbnailImage = (ImageView)findViewById(R.id.grid_item_big_image);
+        mDurationView   = (TextView) findViewById(R.id.grid_item_duration);
+        mNameView      = (TextView) findViewById(R.id.grid_item_name);
+        clear();
+    }
+
+    public void onFileClicked() {
+        if(!mDir)
+            SendToLocalRenderer(mUrl, mMime);
+    }
+
+    public boolean isDir() {
+        return mDir;
+    }
+
+    public int dirId() {
+        if(!isDir())
+            return -1;
+        return mDirId;
+    }
+
+    private void SendToLocalRenderer(String url, String mime) {
+        if(url == null)
+            return;
+        Intent intent;
+        intent = new Intent(mContext, VideoPlayer.class);
+        intent.setDataAndType(Uri.parse(url), mime);
+        mContext.startActivity(intent);  //send file name
+    }
+
+    public void clear() {
+        // cancel previous tasks
+        if(mThumbNailTask != null){
+            mThumbNailTask.cancel(true);
+            mThumbNailTask.setCancelled();
+        }
+        mName     = "Bad file";
+        mUrl      = null;
+        mDuration = 0;
+        mAlbumArt = null;
+        mDir      = false;
+        mDirId    = -1;
+        mNameView     .setText(mName);
+        mDurationView  .setText(null);
+        mThumbnailImage.setImageDrawable(null);
+    }
+
+    public void update(String dirName, int childCount, int id) {
+        // cancel previous tasks
+        if(mThumbNailTask != null){
+            mThumbNailTask.cancel(true);
+            mThumbNailTask.setCancelled();
+        }
+        mName = dirName;
+        mUrl   = null;
+        mDuration = 0;
+        mAlbumArt = null;
+        mDir   = true;
+        mDirId = id;
+        mNameView.setText(mName);
+        mDurationView.setText(null);
+        mThumbnailImage.setImageResource(R.drawable.frame_overlay_gallery_folder);
+        if(mAlbumArt != null){
+            Log.d(CLASS, "Set art " + mAlbumArt);
+            setImage(mAlbumArt);
+        }
+    }
+
+    public Uri get_myUri(){
+        return Uri.parse(mUrl);
+    }
+
+    public void update(ItemData data) {
+        // cancel previous tasks
+        if(mThumbNailTask != null){
+            mThumbNailTask.cancel(true);
+            mThumbNailTask.setCancelled();
+        }
+        if(data == null)
+            return;
+        mName  = data.mName;
+        mUrl   = data.mPath;
+        mDuration = data.mDuration;
+        mAlbumArt = data.mArt;
+        mDir   = false;
+        mDirId = -1;
+        mMime = data.mMime;
+        mNameView.setText(mName);
+        long seconds = mDuration / 1000;
+        long minutes = seconds / 60;
+        long hours = minutes / 60;
+        minutes = minutes % 60;
+        seconds = seconds % 60;
+        String fmtDuration = hours + ":";
+        if(minutes < 10)
+            fmtDuration += "0";
+        fmtDuration += minutes + ":";
+        if(seconds < 10)
+            fmtDuration += "0";
+        fmtDuration += seconds;
+        mDurationView.setText(fmtDuration);
+        if(mMime.startsWith("audio"))
+            mThumbnailImage.setImageResource(R.drawable.ic_search_category_music_song);
+        else
+            mThumbnailImage.setImageResource(R.drawable.frame_overlay_gallery_video);
+        if(mAlbumArt != null){
+            Log.d(CLASS, "Set art " + mAlbumArt);
+            setImage(mAlbumArt);
+        }
+    }
+
+    private void setImage(String file) {
+        // cancel previous tasks
+        if(mThumbNailTask != null){
+            mThumbNailTask.cancel(true);
+            mThumbNailTask.setCancelled();
+        }
+
+        mThumbNailTask = new DisplayPicture();
+        try {
+            mThumbNailTask.execute(file);
+        }
+        catch(IllegalStateException e) {
+            Log.d(CLASS, "image decoded failed or cancelled");
+        }
+    }
+
+    // non-static inner class: will access enclosing class instance's non-static member
+    private  class DisplayPicture extends AsyncTask<String, Integer, Bitmap> {
+        private boolean mCancelled = false;
+        protected Bitmap doInBackground(String... sUrl) {
+            mCancelled = false;
+            Bitmap bitmap = BitmapFactory.decodeFile(sUrl[0]);
+            return bitmap;
+        }
+
+        public void setCancelled() {
+            mCancelled = true;
+        }
+
+        @Override
+        protected void onCancelled() {
+            //Log.d(TAG, "image decoded cancelled");
+        }
+
+        @Override
+        protected void onPostExecute(Bitmap result) {
+            if(mCancelled == false && result != null) {
+                mThumbnailImage.setImageBitmap(result);
+            }
+            else {
+                //Log.d(TAG, "image decoded failed or cancelled");
+            }
+        }
+    }
+
+ }
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/ItemData.java b/CactusPlayer/src/com/freescale/cactusplayer/ItemData.java
new file mode 100755
index 0000000..db21806
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/ItemData.java
@@ -0,0 +1,40 @@
+/*
+ * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package com.freescale.cactusplayer;
+
+public class ItemData {
+	public String mTitle;
+	public String mName;
+	public String mPath;
+	public String mMime;
+	public long   mDuration;
+	public String mArt;
+	public String mBucket;
+
+	public ItemData() {
+		mTitle = null;
+		mName  = null;
+		mPath  = null;
+		mMime  = null;
+		mDuration = 0;
+		mArt   = null;
+		mBucket = null;
+	}
+
+}
+
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/VideoMenu.java b/CactusPlayer/src/com/freescale/cactusplayer/VideoMenu.java
new file mode 100755
index 0000000..652afc5
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/VideoMenu.java
@@ -0,0 +1,710 @@
+/*
+ * Copyright (C) 2014-2016 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package com.freescale.cactusplayer;
+
+import java.sql.Date;
+import java.text.SimpleDateFormat;
+import java.util.Locale;
+
+import android.app.ActionBar;
+import android.app.Activity;
+import android.app.ProgressDialog;
+import android.content.ContentResolver;
+import android.content.Context;
+import android.content.DialogInterface;
+import android.content.Intent;
+import android.database.Cursor;
+import android.media.MediaPlayer;
+import android.media.MediaScannerConnection;
+import android.net.Uri;
+import android.os.AsyncTask;
+import android.os.Bundle;
+import android.os.Environment;
+import android.provider.MediaStore;
+import android.util.Log;
+import android.widget.AdapterView;
+import android.widget.AdapterView.OnItemClickListener;
+import android.widget.Button;
+import android.widget.EditText;
+import android.widget.GridView;
+import android.widget.ImageButton;
+import android.widget.PopupWindow;
+import android.widget.SeekBar;
+import android.widget.TextView;
+import android.view.Gravity;
+import android.view.LayoutInflater;
+import android.view.Menu;
+import android.view.MenuItem;
+import android.view.View;
+import android.view.ViewGroup.LayoutParams;
+import android.view.View.OnClickListener;
+import android.view.Window;
+import android.content.pm.PackageManager;
+import android.Manifest;
+import android.app.AlertDialog;
+import android.app.Dialog;
+import android.content.DialogInterface;
+
+public class VideoMenu extends Activity {
+    private static final String TAG   = "CactusPlayer";
+    private static final String CLASS = "VideoMenu: ";
+    // cache 10000 items each page
+    // TODO: add a button to navigate to next 10000 items
+    private static final int MAX_ITEMS = 10000;
+
+    private static final int REGISTER_DEVICE      = Menu.FIRST+1;
+    private static final int DEREGISTER_DEVICE    = Menu.FIRST+2;
+
+    private ImageTextAdapter mAdapter;
+    private GridView mGridView;
+
+    private TaskToScanVideoClips mVideoScanTask = null;
+
+    private HdmiApplication.DemoPresentation mPresentation;
+    private HdmiApplication mHdmiApp;
+    private static final int Remote_control = Menu.FIRST+1;
+    private static final int mPresentation_disabled = 0;
+    private static final int mPresentation_playing = 1;
+    private static final int mPresentation_pausing = 2;
+	
+	//Permission related member
+	private int mNumPermissionsToRequest = 0;
+	private boolean mShouldRequestStoragePermission = false;
+	private boolean mFlagHasStoragePermission = true;
+	private int mIndexPermissionRequestStorage = 0;
+	private static final int PERMISSION_REQUEST_CODE = 0;
+/*
+    // Try to be smarter
+    // Return EXTERNAL_STORAGE_DIRECTORY_SD if SD card is ready
+    // Return EXTERNAL_STORAGE_DIRECTORY_UDISK if SD card is absent but udisk is ready
+    // Return EXTERNAL_STORAGE_DIRECTORY_SD if both sd card and udisk are not ready
+    String propSD = SystemProperties.get("EXTERNAL_STORAGE_STATE_SD", MEDIA_REMOVED);
+    String propUDISK = SystemProperties.get("EXTERNAL_STORAGE_STATE_UDISK", MEDIA_REMOVED);
+    String propEXTSD = SystemProperties.get("EXTERNAL_STORAGE_STATE_EXTSD", MEDIA_REMOVED);
+    if (propSD.equals(MEDIA_MOUNTED) || propSD.equals(MEDIA_MOUNTED_READ_ONLY)) {
+    return EXTERNAL_STORAGE_DIRECTORY_SD;
+    } else if (propUDISK.equals(MEDIA_MOUNTED) || propUDISK.equals(MEDIA_MOUNTED_READ_ONLY)) {
+    return EXTERNAL_STORAGE_DIRECTORY_UDISK;
+    } else if (propEXTSD.equals(MEDIA_MOUNTED) || propEXTSD.equals(MEDIA_MOUNTED_READ_ONLY)) {
+    return EXTERNAL_STORAGE_DIRECTORY_EXTSD;
+    } else {
+    return EXTERNAL_STORAGE_DIRECTORY_SD;
+    }
+    }
+
+    Environment.getExternalStorageDirectory().getAbsolutePath()
+*/
+
+    @Override
+    protected void onCreate(Bundle savedInstanceState) {
+        Log.d(TAG, CLASS + "onCreate");
+        super.onCreate(savedInstanceState);
+		boolean isRestored = (savedInstanceState != null);
+        //HDPlusPlayer.loadNativeLibs();
+        //requestWindowFeature(Window.FEATURE_NO_TITLE);//hide label bar
+        setContentView(R.layout.videomenu);
+		checkPermission();
+        ActionBar mActionBar = getActionBar();
+        mActionBar.setHomeButtonEnabled(true);
+        mActionBar.setDisplayHomeAsUpEnabled(true);
+    }
+	
+	private void checkPermission(){
+
+		if(checkSelfPermission(Manifest.permission.WRITE_EXTERNAL_STORAGE)
+				!= PackageManager.PERMISSION_GRANTED){
+			mNumPermissionsToRequest++;
+			mShouldRequestStoragePermission  = true;
+		}else{
+			mFlagHasStoragePermission  = true;
+		}
+
+		String[] permissionToRequest = new String[mNumPermissionsToRequest];
+		int permissionRequestIndex = 0;
+
+		if(mShouldRequestStoragePermission){
+			permissionToRequest[permissionRequestIndex] = Manifest.permission.WRITE_EXTERNAL_STORAGE;
+			mIndexPermissionRequestStorage= permissionRequestIndex;
+			permissionRequestIndex++;
+		}
+
+		if(permissionToRequest.length > 0){
+			requestPermissions(permissionToRequest, PERMISSION_REQUEST_CODE);
+		}else{
+			initView();
+		}
+	}	
+
+	@Override
+	public void onRequestPermissionsResult(int requestCode,
+			String permissions[], int[] grantResults) {
+		switch (requestCode) {
+		case PERMISSION_REQUEST_CODE:
+			if (grantResults.length > 0
+					&& grantResults[0] == PackageManager.PERMISSION_GRANTED) {
+				Log.v(TAG, "Grant permission successfully");
+				initView();
+			} else {
+				popupWarningDialog();
+			}
+			break;
+		default:
+			break;
+		}
+	}
+	
+	private void popupWarningDialog(){
+
+		DialogInterface.OnClickListener dialogOnclicListener=new DialogInterface.OnClickListener(){
+
+			@Override
+			public void onClick(DialogInterface dialog, int which) {
+				switch(which){
+				case Dialog.BUTTON_POSITIVE:
+					initView();
+					break;
+				case Dialog.BUTTON_NEGATIVE:
+					VideoMenu.this.finish();
+					break;
+				default:
+					break;
+				}
+			}
+		};
+
+		AlertDialog.Builder builder=new AlertDialog.Builder(this);
+		builder.setTitle(R.string.Warning);
+		builder.setMessage(R.string.PermissionNotGrant);
+		builder.setPositiveButton(R.string.OK,dialogOnclicListener);
+		builder.setNegativeButton(R.string.Cancel, dialogOnclicListener);
+		builder.create().show();
+	}	
+	
+	private void initView(){
+        mAdapter = new ImageTextAdapter(this);
+        mGridView = (GridView) findViewById(R.id.contentview);
+        if(mGridView == null)
+            return;
+        mGridView.setAdapter(mAdapter);
+        mGridView.setOnItemClickListener(new OnItemClickListener() {
+            public void onItemClick(AdapterView<?> parent, View v, int position, long id) {
+                ImageTextView itv = (ImageTextView)v;
+                mAdapter.clickItem(itv);
+                //if the presentation is running, restart a new one
+                if((itv!=null)&&(!itv.isDir())){
+                    Uri a = itv.get_myUri();
+                    mHdmiApp = (HdmiApplication)getApplication();
+                    mPresentation = mHdmiApp.getPresentation();
+                    if(mPresentation != null){
+                        if(mPresentation.getPresentationState() == mPresentation_playing ||
+                            mPresentation.getPresentationState() == mPresentation_pausing){
+                                mPresentation.setPresentationState(mPresentation_playing);
+                                mPresentation.show();
+                                mPresentation.startVideo(a);
+                            }
+                     }
+                 }
+             }
+        });
+
+        mVideoScanTask = new TaskToScanVideoClips();
+        mVideoScanTask.Attach(this);
+        mVideoScanTask.SetTask(0);
+        try {
+            mVideoScanTask.execute("");
+        }
+        catch(IllegalStateException e) {
+            Log.d(TAG, CLASS + "Exception caught during executing scanning task");
+        }
+	}
+	
+    //--------------------------------remote control -------------------------------
+
+    @Override
+    public boolean onPrepareOptionsMenu (Menu menu) {
+        MenuItem item = null;
+        super.onPrepareOptionsMenu(menu);
+        Log.d(TAG,"onPrepareOptionsMenu ");
+        mHdmiApp = (HdmiApplication)getApplication();
+        mPresentation = mHdmiApp.getPresentation();
+        item = menu.findItem(Remote_control);
+        if(mPresentation != null){
+            int myPresentationState = mPresentation.getPresentationState();
+            if(item != null && (myPresentationState == mPresentation_playing
+                ||myPresentationState == mPresentation_pausing))
+                    item.setEnabled(true);
+            else
+                item.setEnabled(false);
+        }
+        else
+            item.setEnabled(false);
+                return true;
+    }
+
+    @Override
+    public boolean onCreateOptionsMenu(Menu menu) {
+        super.onCreateOptionsMenu(menu);
+        MenuItem item = menu.add(0, Remote_control, 0, getString(R.string.Remote_control));
+        return true;
+    }
+
+    @Override
+    public boolean onOptionsItemSelected(MenuItem item) {
+        boolean ret = super.onOptionsItemSelected(item);
+        int itemId = item.getItemId();
+        if(itemId == Remote_control){
+            mHdmiApp = (HdmiApplication)getApplication();
+            mPresentation = mHdmiApp.getPresentation();
+            Uri uri1 = mPresentation.getmyUri();
+            Intent intent;
+            intent = new Intent(VideoMenu.this, VideoPlayer.class);
+            intent.setData(uri1);
+            startActivity(intent);  //send file name
+        }
+        else if(itemId == android.R.id.home){
+            onBackPressed();
+            return true;
+        }
+        return ret;
+    }
+
+    @Override
+    protected void onRestart() {
+        // TODO Auto-generated method stub
+        super.onRestart();
+    }
+
+    @Override
+    protected void onDestroy() {
+        // TODO Auto-generated method stub
+        super.onDestroy();
+    }
+
+    @Override
+    public void onBackPressed() {
+        if(mAdapter.onBackPressed())
+            return;
+        super.onBackPressed(); // allows standard use of backbutton for page 1
+    }
+
+    public void refreshDialog(View parent) {
+        LayoutInflater inflater = (LayoutInflater) getSystemService(Context.LAYOUT_INFLATER_SERVICE);
+
+        final View dialogView = inflater.inflate(R.layout.popupwindow, null ,false);
+        dialogView.setBackgroundResource(R.drawable.rounded_corners_view);
+        final PopupWindow pw = new PopupWindow(dialogView, 480, LayoutParams.WRAP_CONTENT, true);
+        pw.setBackgroundDrawable(getResources().getDrawable(R.drawable.rounded_corners_pop));
+
+        Button btnOK     = (Button)   dialogView.findViewById(R.id.BtnOK);
+        btnOK.setOnClickListener(new OnClickListener() {
+            @Override
+            public void onClick(View v) {
+                pw.dismiss();
+            }
+        });
+        pw.showAtLocation(parent, Gravity.CENTER, 0, 0);
+    }
+
+    // start a task to list all avi/mkv video clips
+    private class TaskToScanVideoClips extends AsyncTask<String, Integer, Integer> {
+        private ProgressDialog mDialog = null;
+        private Activity mContext      = null;
+        private int mOffset            = 0;
+        private ItemData[] mData       = new ItemData[VideoMenu.MAX_ITEMS];
+        private int mCount             = 0;
+
+        private class CancelListener implements DialogInterface.OnClickListener, DialogInterface.OnCancelListener {
+            public void onClick(DialogInterface dialog, int which) {
+            }
+
+            public void onCancel(DialogInterface dialog) {
+                cancel(false);
+            }
+        }
+
+        private CancelListener mCancelListener = new CancelListener();
+
+
+        //-----------------------------------------------------------------------------------------
+        // Attach/detach to/from activity
+        //-----------------------------------------------------------------------------------------
+        public void Attach(Activity act) {
+            mContext   = act;
+            if(mDialog != null && mContext != null){
+                mDialog.setOwnerActivity(mContext);
+                mDialog.show();
+            }
+        }
+
+        public void Detach() {
+            if(mDialog != null){
+                mDialog.dismiss();
+            }
+            mContext   = null;
+        }
+
+        //-----------------------------------------------------------------------------------------
+        // parameters for the task
+        //-----------------------------------------------------------------------------------------
+        public void SetTask(int offset) {
+            if(offset < 0)
+                mOffset = 0;
+            else
+                mOffset = offset;
+        }
+
+        //-----------------------------------------------------------------------------------------
+        // overrides
+        //-----------------------------------------------------------------------------------------
+        @Override
+        protected void onPreExecute() {
+            createDialog();
+        }
+
+        /** The system calls this to perform work in a worker thread and
+        * delivers it the parameters given to AsyncTask.execute() */
+        protected Integer doInBackground(String... sUrl) {
+        int count = 0; // counter for mkv/avi clip
+
+        if(OpenAudioDB() == -1)
+            return -1;
+
+        if(OpenVideoDB() == -1){
+            CloseAudioDB();
+            return -1;
+        }
+
+        while(true) {
+            String info[] = new String[11];
+            int ret = ReadAudioRecord(info);
+            if(ret == -1){
+                ret = ReadVideoRecord(info);
+                if(ret == -1)
+                    break;
+            }
+
+            String mime = info[3];
+            Log.d(TAG,"title is " + info[0] + " mime is " + mime);
+            if(mime != null && (
+                    mime.startsWith("video/") ||
+                    mime.startsWith("audio/") )) {
+                // skip to offset
+                if(count >= mOffset) {
+                    mData[mCount] = new ItemData();
+                    mData[mCount].mTitle    = info[0];
+                    mData[mCount].mName     = info[1];
+                    mData[mCount].mPath     = info[2];
+                    mData[mCount].mMime     = info[3];
+                    mData[mCount].mDuration = Long.parseLong(info[4]);
+                    if(mime.startsWith("video/"))
+                        mData[mCount].mArt      = info[9];
+                    mData[mCount].mBucket   = info[10];
+                    // bucket name should not be null
+                    if(mData[mCount].mBucket == null)
+                        mData[mCount].mBucket = "General";
+
+                    mCount++;
+
+                    if(mCount == VideoMenu.MAX_ITEMS)
+                        break;
+                 }
+                 count++;
+            }
+        }
+
+        CloseAudioDB();
+        CloseVideoDB();
+
+        return 0;
+    }
+
+    @Override
+    protected void onCancelled() {
+        destroyDialog();
+    }
+
+    @Override
+    protected void onPostExecute(Integer result) {
+        destroyDialog();
+        if(mContext != null) {
+            ((VideoMenu)mContext).mAdapter.setData(mData, mCount);
+            if(mCount == 0)
+                refreshDialog(findViewById(R.id.parentview));
+        }
+    }
+
+    //-----------------------------------------------------------------------------------------
+    // private functions
+    //-----------------------------------------------------------------------------------------
+    private void createDialog() {
+        mDialog = null;
+
+        // dialog needs activity
+        if(mContext != null){
+            mDialog = new ProgressDialog(mContext);
+            mDialog.setTitle(mContext.getString(R.string.Scan));
+            mDialog.setMessage("Scanning clips");
+            mDialog.setCancelable(true);
+            mDialog.setOnCancelListener(mCancelListener);
+            mDialog.show();
+        }
+    }
+
+    private void destroyDialog() {
+        if(mDialog != null){
+            mDialog.dismiss();
+            mDialog = null;
+        }
+    }
+
+    private Cursor mVideoCursor;
+    private Cursor mAudioCursor;
+    private int	  mFirstVideoRecord = 1;
+    private int	  mFirstAudioRecord = 1;
+    private ContentResolver contentResolver;
+
+    public int OpenAudioDB() {
+        if(mAudioCursor != null || mContext == null)
+            return -1; // previous not closed
+
+        contentResolver = mContext.getContentResolver();
+
+        // _data:         [MediaStore.MediaColumns.DATA, DATA STREAM] path name
+        // _display_name: [MediaStore.MediaColumns.DISPLAY_NAME, TEXT] file name
+        // _size:         [MediaStore.MediaColumns.SIZE, long] file size
+        // mine_type:     [MediaStore.MediaColumns.MIME_TYPE, TEXT] e.g. audio/mepg
+        // title:         [MediaStore.MediaColumns.TITLE, TEXT]
+        // duration:      [MediaStore.Video.VideoColumns.DURATION, long] in ms
+        // artist:        [MediaStore.Video.VideoColumns.ARTIST, TEXT]
+        // album:         [MediaStore.Video.VideoColumns.ALBUM, TEXT]
+        // datetaken:     [MediaStore.Video.VideoColumns.DATE_TAKEN, long] The date & time that the image was taken in units of milliseconds since jan 1, 1970.
+        // resolution:    [MediaStore.Video.VideoColumns.RESOLUTION, TEXT] The resolution of the video file, formatted as "XxY".
+        // _id:           [MediaStore.Video.Media._ID, long]
+        String [] columns = {
+            MediaStore.MediaColumns.DATA,// 0
+            MediaStore.MediaColumns.DISPLAY_NAME,// 1
+            MediaStore.MediaColumns.SIZE,// 2
+            MediaStore.MediaColumns.MIME_TYPE,// 3
+            MediaStore.MediaColumns.TITLE,// 4
+            MediaStore.Audio.AudioColumns.DURATION, // 5
+            MediaStore.Audio.AudioColumns.ARTIST,// 6
+            MediaStore.Audio.AudioColumns.ALBUM,// 7
+                /*
+            MediaStore.Video.VideoColumns.DATE_TAKEN,// 8
+            MediaStore.Video.VideoColumns.RESOLUTION,// 9
+            MediaStore.Video.VideoColumns._ID,// 10
+            MediaStore.Video.VideoColumns.BUCKET_DISPLAY_NAME// 11
+  */      };
+
+        // TODO: use where clause
+        mAudioCursor = contentResolver.query(// also can use managedQuery
+            MediaStore.Audio.Media.EXTERNAL_CONTENT_URI,
+            columns,
+            null, // where
+            null, // args for where
+            MediaStore.MediaColumns.DISPLAY_NAME + " ASC"); // order
+
+        if(mAudioCursor != null) {
+            mFirstAudioRecord = 1;
+        }
+
+        return 0;
+    }
+
+    public int OpenVideoDB() {
+        if(mVideoCursor != null || mContext == null)
+            return -1; // previous not closed
+
+        contentResolver = mContext.getContentResolver();
+
+        // _data:         [MediaStore.MediaColumns.DATA, DATA STREAM] path name
+        // _display_name: [MediaStore.MediaColumns.DISPLAY_NAME, TEXT] file name
+        // _size:         [MediaStore.MediaColumns.SIZE, long] file size
+        // mine_type:     [MediaStore.MediaColumns.MIME_TYPE, TEXT] e.g. audio/mepg
+        // title:         [MediaStore.MediaColumns.TITLE, TEXT]
+        // duration:      [MediaStore.Video.VideoColumns.DURATION, long] in ms
+        // artist:        [MediaStore.Video.VideoColumns.ARTIST, TEXT]
+        // album:         [MediaStore.Video.VideoColumns.ALBUM, TEXT]
+        // datetaken:     [MediaStore.Video.VideoColumns.DATE_TAKEN, long] The date & time that the image was taken in units of milliseconds since jan 1, 1970.
+        // resolution:    [MediaStore.Video.VideoColumns.RESOLUTION, TEXT] The resolution of the video file, formatted as "XxY".
+        // _id:           [MediaStore.Video.Media._ID, long]
+        String [] columns = {
+            MediaStore.MediaColumns.DATA,// 0
+            MediaStore.MediaColumns.DISPLAY_NAME,// 1
+            MediaStore.MediaColumns.SIZE,// 2
+            MediaStore.MediaColumns.MIME_TYPE,// 3
+            MediaStore.MediaColumns.TITLE,// 4
+            MediaStore.Video.VideoColumns.DURATION, // 5
+            MediaStore.Video.VideoColumns.ARTIST,// 6
+            MediaStore.Video.VideoColumns.ALBUM,// 7
+            MediaStore.Video.VideoColumns.DATE_TAKEN,// 8
+            MediaStore.Video.VideoColumns.RESOLUTION,// 9
+            MediaStore.Video.VideoColumns._ID,// 10
+            MediaStore.Video.VideoColumns.BUCKET_DISPLAY_NAME// 11
+        };
+
+        // TODO: use where clause
+        mVideoCursor = contentResolver.query(// also can use managedQuery
+            MediaStore.Video.Media.EXTERNAL_CONTENT_URI,
+            columns,
+            null, // where
+            null, // args for where
+            MediaStore.MediaColumns.DISPLAY_NAME + " ASC"); // order
+
+        if(mVideoCursor != null) {
+            mFirstVideoRecord = 1;
+        }
+
+        return 0;
+    }
+
+    public void CloseVideoDB() {
+        if(mVideoCursor != null) {
+            mVideoCursor.close();
+            mVideoCursor = null;
+        }
+    }
+
+    public void CloseAudioDB() {
+        if(mAudioCursor != null) {
+            mAudioCursor.close();
+            mAudioCursor = null;
+        }
+    }
+
+    public int ReadAudioRecord(String [] info) {
+        if(mAudioCursor == null) {
+            return -1;
+        }
+
+        boolean toNext;
+        if(mFirstAudioRecord == 1) {
+            toNext = mAudioCursor.moveToFirst();
+            mFirstAudioRecord = 0;
+        }
+        else {
+            toNext = mAudioCursor.moveToNext();
+        }
+
+        if(toNext == false) {
+            return -1;
+        }
+/*
+        long vidoId = mAudioCursor.getLong(10);
+        String art = GetVideoArt(vidoId);
+
+        long millis = mAudioCursor.getLong(8);
+        Date date = new Date(millis);
+        SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd", Locale.US);
+*/
+        info[0] = mAudioCursor.getString(4);  // title
+        info[1] = mAudioCursor.getString(1);  // display name
+        info[2] = mAudioCursor.getString(0);  // path
+        info[3] = mAudioCursor.getString(3);  // mime
+        info[4] = Long.toString(mAudioCursor.getLong(5)); // duration
+        info[5] = mAudioCursor.getString(6);  // artist
+        info[6] = mAudioCursor.getString(7);  // album
+  //      info[7] = mAudioCursor.getString(9);  // resolution
+  //      info[8] = sdf.format(date); // date
+  //      info[9] = art; // art
+        info[10] = mAudioCursor.getString(3);  // default : use mine as bucket
+        int p1 = info[2].lastIndexOf('/');
+        if(p1 > 0){
+            int p2 = info[2].lastIndexOf('/', p1 - 1);
+            if(p2 != -1)
+                info[10] = info[2].substring(p2 + 1, p1);
+        }
+            
+
+        //Log.d(VideoMenu.TAG, VideoMenu.CLASS + info[0]+"," + info[1]+"," + info[2]+"," + info[3]+"," + info[4]+"," + info[5]+"," + info[6]);
+
+        return 0;
+    }
+
+    // info size: at least 11
+    public int ReadVideoRecord(String [] info) {
+        if(mVideoCursor == null) {
+            return -1;
+        }
+
+        boolean toNext;
+        if(mFirstVideoRecord == 1) {
+            toNext = mVideoCursor.moveToFirst();
+            mFirstVideoRecord = 0;
+        }
+        else {
+            toNext = mVideoCursor.moveToNext();
+        }
+
+        if(toNext == false) {
+            return -1;
+        }
+
+        long vidoId = mVideoCursor.getLong(10);
+        String art = GetVideoArt(vidoId);
+
+        long millis = mVideoCursor.getLong(8);
+        Date date = new Date(millis);
+        SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd", Locale.US);
+
+        info[0] = mVideoCursor.getString(4);  // title
+        info[1] = mVideoCursor.getString(1);  // display name
+        info[2] = mVideoCursor.getString(0);  // path
+        info[3] = mVideoCursor.getString(3);  // mime
+        info[4] = Long.toString(mVideoCursor.getLong(5)); // duration
+        info[5] = mVideoCursor.getString(6);  // artist
+        info[6] = mVideoCursor.getString(7);  // album
+        info[7] = mVideoCursor.getString(9);  // resolution
+        info[8] = sdf.format(date); // date
+        info[9] = art; // art
+        info[10] = mVideoCursor.getString(11);  // bucket
+
+        //Log.d(VideoMenu.TAG, VideoMenu.CLASS + info[0] + info[1] + info[2] + info[3] + info[4] + info[5] + info[6] + info[7] + info[8] + info[9]);
+
+        return 0;
+    }
+
+    private String GetVideoArt(long videoId) {
+        String [] columns = { MediaStore.Video.Thumbnails.DATA };
+        String art = null;
+
+        Cursor cursor = contentResolver.query(
+            MediaStore.Video.Thumbnails.EXTERNAL_CONTENT_URI,
+            columns,
+            MediaStore.Video.Thumbnails.VIDEO_ID + " = '" + videoId + "'",
+            null,
+            null);
+
+        if(cursor != null) {
+            if(cursor.moveToFirst()) {
+                do {
+                    art = cursor.getString(0); // first column
+                    if(art != null) {
+                        break;
+                    }
+                } while(cursor.moveToNext());
+            }
+
+            cursor.close();
+        }
+
+        return art;
+    }
+
+ }
+}
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/VideoPlayer.java b/CactusPlayer/src/com/freescale/cactusplayer/VideoPlayer.java
new file mode 100755
index 0000000..d799351
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/VideoPlayer.java
@@ -0,0 +1,1843 @@
+ /*
+ * Copyright (C) 2013-2016 Freescale Semiconductor, Inc.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+ /* Copyright 2018 NXP */
+
+
+package com.freescale.cactusplayer;
+
+import java.io.File;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Timer;
+import java.util.TimerTask;
+import java.io.FilenameFilter;
+
+import android.app.Activity;
+import android.app.Dialog;
+import android.net.Uri;
+import android.os.Build;
+import android.os.Build.VERSION;
+import android.os.Bundle;
+import android.os.Handler;
+import android.os.Message;
+import android.os.PowerManager;
+import android.os.UserHandle;
+import android.util.Log;
+import android.view.Gravity;
+import android.view.LayoutInflater;
+import android.view.Menu;
+import android.view.MenuItem;
+import android.view.Surface;
+import android.view.SurfaceHolder;
+import android.view.View;
+import android.view.ViewGroup.LayoutParams;
+import android.view.Window;
+import android.widget.AdapterView;
+import android.widget.AdapterView.OnItemClickListener;
+import android.widget.ArrayAdapter;
+import android.widget.Button;
+//import android.widget.EditText;
+import android.widget.ImageButton;
+import android.widget.ImageView;
+import android.widget.LinearLayout;
+import android.widget.ListView;
+import android.widget.PopupWindow;
+import android.widget.PopupWindow.OnDismissListener;
+import android.widget.SeekBar;
+import android.widget.TextView;
+//import android.widget.Toast;
+import android.content.ActivityNotFoundException;
+import android.content.Intent;
+import android.content.Context;
+import android.content.BroadcastReceiver;
+import android.content.IntentFilter;
+import android.graphics.Bitmap;
+import android.view.View.OnClickListener;
+
+import android.media.MediaPlayer;
+import android.media.ThumbnailUtils;
+import android.media.MediaPlayer.OnCompletionListener;
+import android.media.MediaPlayer.OnErrorListener;
+import android.media.AudioManager;
+import java.io.IOException;
+
+import com.freescale.cactusplayer.HdmiApplication;
+import com.freescale.cactusplayer.R;
+
+import android.os.Parcel;
+import android.provider.MediaStore;
+import android.app.ActionBar;
+//import android.view.MenuInflater;
+import android.media.TimedText;
+import android.database.ContentObserver;
+import android.provider.Settings;
+import android.hardware.display.DisplayManager;
+import android.net.wifi.WifiManager;
+import android.media.PlaybackParams;
+import com.freescale.cactusplayer.utils.PathUtils;
+import android.content.pm.PackageManager;
+import android.Manifest;
+public class VideoPlayer extends Activity implements HdmiApplication.Callback,
+    SeekBar.OnSeekBarChangeListener {
+        private static final String TAG   = "Cactus";
+        private static final String CLASS = "VideoPlayer: ";
+
+        private static final int STATE_INVALID = -1;
+        private static final int PLAYER_STOPPED = 0;
+        private static final int PLAYER_PREPARED = 1;
+        private static final int PLAYER_PLAYING = 2;
+        private static final int PLAYER_PAUSED  = 3;
+        private static final int PLAYER_EXITED  = 4;
+
+
+    //------------------------------------------------------------------------------------
+    // widgets
+    //-----------------------------------------------------------------------------------
+        private MediaPlayer mMediaPlayer = null;
+    //private   SurfaceHolder mPlayerSurfaceHolder = null;
+        private int         mVideoWidth;
+        private int         mVideoHeight;
+        private int         mSurfaceWidth;
+        private int         mSurfaceHeight;
+        private int         mSpeed = 1;
+        private boolean     mDragging;
+        private int         mAudioTrackCount = 0;
+        private int         mSubtitleTrackCount = 0;
+        private int         mCurSubtitleTrack = -1;
+        private int         mCurSubtitleIndex = -1;
+        private int         mCurAudioTrack = -1;
+        private int         mCurAudioIndex = -1;
+        private boolean     mLoopFile = false;
+        private boolean     mCastScreen = false;
+
+     // video display
+        private   VideoView    mVideoView;
+        private   SurfaceHolder mSurfaceHolder = null;
+
+    // subtitle
+        private   AutoHideTextView    mSubtitleTextView;
+        private   AutoHideTextView    mSubtitleInfoView;
+
+    // track, ff/rw information
+        private   AutoHideTextView    mInfoView;
+
+        private   AutoHideTextView    mTrackInfoView;
+
+    // error sign
+        private   AutoHideTextView    mErrSign;
+
+    // control bar and seek bar
+        private   ImageButton mBtnFastBack;
+        private   ImageButton mBtnPlayPause;
+        private   ImageButton mBtnFastForward;
+        private   TextView    mCurPosView;
+        private   TextView    mEndPosView;
+        private   SeekBar     mProgressBar;
+
+    // waiting dialog
+        private Dialog mWaitingDialog = null;
+
+        private PowerManager.WakeLock wl = null;
+
+    //------------------------------------------------------------------------------------
+    // properties (url, speed, state, etc.)
+    //------------------------------------------------------------------------------------
+        private   String      mUrl       = null;
+        private   String      mMime      = null;
+        private   Uri         uri1       = null;
+        private   int         mPlayState = PLAYER_STOPPED;
+        private   int         mTargetState = STATE_INVALID;
+        private   float       mPlaySpeed = 1;
+        private   long        mDuration  = 0; // cache of file duration and current playback position
+        private   long        mCurPos    = 0;
+        private   boolean     mSubtitleEnabled = true;
+        private   long        mTimeOffset = 0;
+
+    //------------------------------------------------------------------------------------
+    // constants
+    //------------------------------------------------------------------------------------
+        private static final int UPDATE_PLAYBACK_STATE  = 1;
+        private static final int UPDATE_PLAYBACK_SPEED  = 2;
+        private static final int UPDATE_PLAYBACK_PROGRESS = 4;
+        private static final int UPDATE_PLAYBACK_ERROR  = 8;
+
+        private static final int LOOP_FILE  = Menu.FIRST+1;
+        private static final int SELECT_AUDIO    = Menu.FIRST+2;
+        private static final int SELECT_SUBTITLE  = Menu.FIRST+3;
+        private static final int CLOSE_SUBTITLE  = Menu.FIRST+4;
+        private static final int Cast_Screen = Menu.FIRST+5;
+        private static final int Quit = Menu.FIRST+6;
+
+        private static final int mPresentation_disabled = 0;
+        private static final int mPresentation_playing = 1;
+        private static final int mPresentation_pausing = 2;
+        private long progressBarProhibitTime = -1;
+
+        private String locale = "eng";
+
+        private static final int    SHOW_PROGRESS = 1;
+        private static final int RESTART_PAUSE = 0;
+
+        private final static String IMEDIA_PLAYER = "android.media.IMediaPlayer";
+        private static final int INVOKE_ID_SELECT_TRACK = 4;
+
+        private static final float forward_speed[] = {0.5f, 1.5f, 2, 4};
+        private static final float backward_speed[] = {-2, -4, -8, -16};
+        private int forward_speed_index = -1;
+        private int backward_speed_index = -1;
+
+        private HdmiApplication.DemoPresentation mPresentation;
+        private HdmiApplication mHdmiApp;
+        private int mVideoIndex = -1;
+        private boolean mVideoRunning = false;
+        private Bitmap mVideoBitmap;
+        private ImageView mVideoImage;
+        private ImageButton mImageButton;
+        private List<String> mVideoFileList = null;
+        private boolean CastScreen_flag = false;
+        private int mcurrpos = 0;
+        private int mCurrentProgress = 0;
+        private long mLastDuration = 0;
+        private int mLastPlayState = -1;
+        private boolean restart = false;
+        private boolean bGetTrackInfo = false;
+	//Permission related member
+	private int mNumPermissionsToRequest = 0;
+	private boolean mShouldRequestStoragePermission = false;
+	private boolean mFlagHasStoragePermission = true;
+	private int mIndexPermissionRequestStorage = 0;
+	private static final int PERMISSION_REQUEST_CODE = 0;
+
+// onPresentationEnded
+    public void onPresentationEnded(boolean end) {
+        mPresentation = mHdmiApp.getPresentation();
+        if (end) {
+            mImageButton.setImageDrawable(getResources().getDrawable(R.drawable.ic_media_play));
+            mPresentation.setPresentationState(mPresentation_pausing);
+            mPresentation.pauseVideo();
+            mImageButton.postInvalidate();
+            mImageButton.setVisibility(View.VISIBLE);
+        }
+    }
+
+
+// onPresentationChanged
+    public void onPresentationChanged(boolean plugin) {
+        mPresentation = mHdmiApp.getPresentation();
+        //dismiss
+        if (!plugin) {
+            Log.d(TAG, "PresentationChanged");
+            if(CastScreen_flag == true) {
+                CastScreen_flag = false;
+
+                if (!mHdmiApp.getmPresentationEnded()) {
+                    mcurrpos = mPresentation.getcurrentPos();
+                }
+                else {
+                    mCurrentProgress = 0;
+                }
+                Local_onCreate();
+                mHdmiApp.setmPresentationEnded(false);
+            }
+            else {
+                pause();
+                mLastPlayState = -1;
+            }
+        }
+        mLastPlayState = PLAYER_PAUSED;
+    }
+
+
+
+	private void parseIntent(Intent intent) {
+		Log.d(TAG, CLASS + "parseIntent");
+		if(intent == null) {
+			return;
+		}
+
+		uri1 = intent.getData();
+        mMime = intent.getType();
+		if(uri1 != null) {
+			// set url to load
+			mUrl = PathUtils.getPath(this, uri1);
+			mCurrentProgress = 0;
+			// display waiting dialog if possible
+			/*
+			if(mWaitingDialog == null)
+			{
+				mWaitingDialog = new Dialog(this, android.R.style.Theme_Translucent);
+				mWaitingDialog.requestWindowFeature(Window.FEATURE_NO_TITLE);
+				mWaitingDialog.setContentView(R.layout.myprogressdlg);
+				mWaitingDialog.setCancelable(true); // just a indication; no need to block user operations
+				mWaitingDialog.setCanceledOnTouchOutside(false);
+				mWaitingDialog.show();
+			}
+			*/
+		}
+	}
+
+
+
+    @Override
+    protected void onCreate(Bundle savedInstanceState) {
+        Log.d(TAG, CLASS + "onCreate");
+        super.onCreate(savedInstanceState);
+        boolean isRestored = (savedInstanceState != null);
+        checkPermission();
+        ActionBar mActionBar = getActionBar();
+        mActionBar.setHomeButtonEnabled(true);
+        mActionBar.setDisplayHomeAsUpEnabled(true);
+    }
+
+    public void initView(){
+        //loadNativeLibs();
+        initLocaleTable();
+        Intent intent = getIntent();
+        parseIntent(intent);
+        mHdmiApp = (HdmiApplication)getApplication();
+        mPresentation = mHdmiApp.getPresentation();
+        mHdmiApp.addListener(this);
+        if(mPresentation != null){
+            if(mPresentation.getPresentationState() == mPresentation_playing ||
+                mPresentation.getPresentationState() == mPresentation_pausing)
+                    Remote_onCreate();
+            else
+                Local_onCreate();
+        }
+        else
+            Local_onCreate();
+
+    }
+
+	private void checkPermission(){
+
+		if(checkSelfPermission(Manifest.permission.WRITE_EXTERNAL_STORAGE)
+				!= PackageManager.PERMISSION_GRANTED){
+			mNumPermissionsToRequest++;
+			mShouldRequestStoragePermission  = true;
+		}else{
+			mFlagHasStoragePermission  = true;
+		}
+
+		String[] permissionToRequest = new String[mNumPermissionsToRequest];
+		int permissionRequestIndex = 0;
+
+		if(mShouldRequestStoragePermission){
+			permissionToRequest[permissionRequestIndex] = Manifest.permission.WRITE_EXTERNAL_STORAGE;
+			mIndexPermissionRequestStorage= permissionRequestIndex;
+			permissionRequestIndex++;
+		}
+
+		if(permissionToRequest.length > 0){
+			requestPermissions(permissionToRequest, PERMISSION_REQUEST_CODE);
+		}else{
+			Log.i(TAG,"no need to request permission.WRITE_EXTERNAL_STORAGE");
+		}
+	}
+
+    public void Local_onCreate(){
+        CastScreen_flag = false ;
+        setContentView(R.layout.scaleplayer);
+        mVideoView = (VideoView)findViewById(R.id.SurfaceView);
+        mVideoView.getHolder().addCallback(mSHCallback);
+        mBtnFastBack     = (ImageButton) findViewById(R.id.fastback);
+        mBtnPlayPause    = (ImageButton) findViewById(R.id.playpause);
+        mBtnFastForward  = (ImageButton) findViewById(R.id.fastforward);
+        mBtnFastBack  .setOnClickListener(mOnBtnClicked);
+        mBtnPlayPause  .setOnClickListener(mOnBtnClicked);
+        mBtnFastForward  .setOnClickListener(mOnBtnClicked);
+        mCurPosView      = (TextView)    findViewById(R.id.currentpos);
+        mEndPosView      = (TextView)    findViewById(R.id.duration);
+        mBtnPlayPause    .setBackgroundResource(R.drawable.play);
+        mInfoView        = (AutoHideTextView)    findViewById(R.id.info);
+        mInfoView        .setVisibility(View.INVISIBLE);
+        mSubtitleTextView  = (AutoHideTextView)    findViewById(R.id.subtitletext);
+        mSubtitleTextView  .setVisibility(View.INVISIBLE);
+        mSubtitleInfoView  = (AutoHideTextView)    findViewById(R.id.subtitleinfo);
+        mSubtitleInfoView  .setVisibility(View.INVISIBLE);
+        mProgressBar     = (SeekBar)      findViewById(R.id.seek);
+        mProgressBar     .setOnSeekBarChangeListener(this);
+        mLastPlayState = -1;
+    }
+
+    public void Remote_onCreate(){
+        mHdmiApp = (HdmiApplication)getApplication();
+        mHdmiApp.addListener(this);
+        CastScreen_flag = true;
+        setContentView(R.layout.secondvideo);
+        mImageButton = (ImageButton)findViewById(R.id.hdmi_button);
+        if(mPresentation.getPresentationState() == mPresentation_playing ){
+            mImageButton.setImageDrawable(getResources().getDrawable(R.drawable.ic_media_pause));
+        }
+        else if (mPresentation.getPresentationState() == mPresentation_pausing){
+            mImageButton.setImageDrawable(getResources().getDrawable(R.drawable.ic_media_play));
+        }
+
+        mImageButton.setVisibility(View.VISIBLE);
+        mImageButton.setOnClickListener(new View.OnClickListener() {
+            @Override
+            public void onClick(View arg0) {
+                switch(arg0.getId()) {
+                    case R.id.hdmi_button:
+                         mHdmiApp = (HdmiApplication)getApplication();
+                         mPresentation = mHdmiApp.getPresentation();
+                         if(mPresentation != null){
+                             mVideoRunning = mHdmiApp.getVideoRunning();
+                             if(mVideoRunning == true) {
+                                 if (mPresentation != null) {
+                                     mPresentation.pauseVideo();
+                                     mPresentation.setPresentationState(mPresentation_pausing);
+                                     mImageButton.setImageDrawable(getResources().getDrawable(R.drawable.ic_media_play));
+                                     mImageButton.setVisibility(View.VISIBLE);
+                                 }
+                              }
+                              else {
+                                  if (mPresentation != null) {
+                                      mPresentation.resumeVideo();
+                                      mPresentation.setPresentationState(mPresentation_playing);
+                                      mImageButton.setImageDrawable(getResources().getDrawable(R.drawable.ic_media_pause));
+                                      mImageButton.setVisibility(View.VISIBLE);
+                                      mHdmiApp.setmPresentationEnded(false);
+                                 }
+                             }
+                         }
+                         else
+                             break;
+
+                         break;
+
+                     default:
+                         break;
+                }
+            }
+         });
+      }
+
+
+   @Override
+   protected void onNewIntent (Intent intent) {
+        Log.d(TAG, CLASS + "onNewIntent");
+        // if video view not ready, just record the smil file
+        if(mVideoView.getSurface() == null) {
+          parseIntent(intent);
+          return;
+        }
+        // stop current player
+        stop();
+        mUrl = null;
+        // get new file path
+        parseIntent(intent);
+   }
+
+   private final ContentObserver mSettingsObserver = new ContentObserver(null) {
+        @Override
+        public void onChange(boolean selfChange, Uri uri) {
+             boolean connected = Settings.Global.getInt(getContentResolver(),
+             Settings.Global.WIFI_ON, 0) != 0;
+             if (!connected) {
+                  mHdmiApp = (HdmiApplication)getApplication();
+                  mPresentation = mHdmiApp.getPresentation();
+                  if(mPresentation != null){
+                      if(mPresentation.getPresentationState() == mPresentation_playing ||
+                          mPresentation.getPresentationState() == mPresentation_pausing){
+                              mPresentation.pauseVideo();
+                              mPresentation.setPresentationState(mPresentation_pausing);
+                      }
+                      else {
+                          pause();
+                          mLastPlayState = -1;
+                      }
+                  }
+                  Log.d(TAG,"ContentObserver wifi_off pausePresentation");
+              }
+          }
+    };
+
+    private final BroadcastReceiver mReceiver = new BroadcastReceiver(){
+        @Override
+        public void onReceive(Context context, Intent intent){
+            String action = intent.getAction();
+            if(action.equals(HdmiApplication.ACTION_WIFI_DISPLAY_DISCONNECTION)){
+                mHdmiApp = (HdmiApplication)getApplication();
+                mPresentation = mHdmiApp.getPresentation();
+                if(mPresentation != null){
+                    if(mPresentation.getPresentationState() == mPresentation_playing ||
+                        mPresentation.getPresentationState() == mPresentation_pausing){
+                            mPresentation.pauseVideo();
+                            mPresentation.setPresentationState(mPresentation_pausing);
+                    }
+                    else {
+                        pause();
+                        mLastPlayState = -1;
+                    }
+                }
+                Log.d(TAG,"BroadcastReceiver WIFI_DISPLAY_DISCONNECTION");
+            }
+        }
+   };
+
+   @Override
+   protected void onStart() {
+        Log.d(TAG, CLASS + "onStart");
+        super.onStart();
+       // keep screen bright
+        PowerManager pm = (PowerManager) getSystemService(Context.POWER_SERVICE);
+        wl = pm.newWakeLock(PowerManager.FULL_WAKE_LOCK, "Cactus Player");
+        wl.acquire();
+        getContentResolver().registerContentObserver(Settings.Global.getUriFor(
+            Settings.Global.WIFI_ON), false, mSettingsObserver);
+        IntentFilter filter = new IntentFilter();
+        filter.addAction(HdmiApplication.ACTION_WIFI_DISPLAY_DISCONNECTION);
+        registerReceiver(mReceiver, filter);
+   }
+
+
+   @Override
+   protected void onResume() {
+       Log.d(TAG, CLASS + "onResume mLastPlayState:" + mLastPlayState);
+       super.onResume();
+
+       if(mLastPlayState != PLAYER_PAUSED && mLastPlayState != PLAYER_PLAYING) {
+           initView();
+       } else if (false == CastScreen_flag) {
+           setContentView(R.layout.scaleplayer);
+           mVideoView = (VideoView)findViewById(R.id.SurfaceView);
+           mVideoView.getHolder().addCallback(mSHCallback);
+           mBtnFastBack     = (ImageButton) findViewById(R.id.fastback);
+           mBtnPlayPause    = (ImageButton) findViewById(R.id.playpause);
+           mBtnFastForward  = (ImageButton) findViewById(R.id.fastforward);
+           mBtnFastBack  .setOnClickListener(mOnBtnClicked);
+           mBtnPlayPause  .setOnClickListener(mOnBtnClicked);
+           mBtnFastForward  .setOnClickListener(mOnBtnClicked);
+           mCurPosView      = (TextView)    findViewById(R.id.currentpos);
+           mEndPosView      = (TextView)    findViewById(R.id.duration);
+           mBtnPlayPause    .setBackgroundResource(R.drawable.play);
+           mInfoView        = (AutoHideTextView)    findViewById(R.id.info);
+           mInfoView        .setVisibility(View.INVISIBLE);
+           mSubtitleTextView  = (AutoHideTextView)    findViewById(R.id.subtitletext);
+           mSubtitleTextView  .setVisibility(View.INVISIBLE);
+           mSubtitleInfoView  = (AutoHideTextView)    findViewById(R.id.subtitleinfo);
+           mSubtitleInfoView  .setVisibility(View.INVISIBLE);
+           mProgressBar     = (SeekBar)      findViewById(R.id.seek);
+           mProgressBar     .setOnSeekBarChangeListener(this);
+       }
+
+       if(mVideoView != null)
+           mVideoView.setVisibility(View.VISIBLE);
+
+       if (mMediaPlayer != null && mLastPlayState != PLAYER_PAUSED) {
+           Log.d(TAG, CLASS + "onResume call mMediaPlayer.start()");
+           mMediaPlayer.start();
+           mPlayState = PLAYER_PLAYING;
+           Log.d(TAG,"onResume: player is started and state is playing");
+           if(mDuration < 0)
+               mDuration = mMediaPlayer.getDuration();
+            updateButtons(UPDATE_PLAYBACK_STATE, mPlayState, 0, 0);
+            mHandler.sendEmptyMessage(SHOW_PROGRESS);
+       }
+
+       if (mMediaPlayer != null) {
+           mLastPlayState = -1;
+       }
+    }
+
+    @Override
+    protected void onRestart() {
+        // TODO Auto-generated method stub
+        super.onRestart();
+    }
+
+
+    @Override
+    protected void onPause() {
+        Log.d(TAG, CLASS + "onPause play state:" + mPlayState);
+        super.onPause();
+        mLastPlayState = mPlayState;
+        if(mPlayState == PLAYER_PLAYING){
+            pause();
+            Log.d(TAG,"speed is "  + mPlaySpeed);
+            if(mPlaySpeed != 1)
+                setNormalSpeed();
+        }
+        else{
+            // If current state is stopped or prepared, player may switch to playing state in surfaceChanged or onPrepared,
+            // so onPause fails to make player really paused. This shall be avoided. save a flag here, check it in
+            // surfaceChanged and onPrepared and then pause player.
+            mTargetState = PLAYER_PAUSED;
+        }
+
+    }
+
+    @Override
+    protected void onStop() {
+        Log.d(TAG, CLASS + "onStop");
+        super.onStop();
+        unregisterReceiver(mReceiver);
+        //stop();
+        //mUrl = null;
+        // stop screen bright
+        wl.release();
+        // clean gui to not disturb onStart() next time
+        //initPlay();
+        //mcurrpos=mMediaPlayer.getCurrentPosition();
+    }
+
+    @Override
+    protected void onDestroy() {
+        Log.d(TAG, CLASS + "onDestroy");
+        super.onDestroy();
+    }
+
+
+    //------------------------------------------------------------------------------------
+    // Update GUI
+    //------------------------------------------------------------------------------------
+
+    private void updateButtons(int reason, long val1, long val2, float val3) {
+        if(reason == UPDATE_PLAYBACK_SPEED)
+        {
+		    float newSpeed = val3;
+			if(newSpeed == 1)
+			{
+    			mInfoView.setText(null, 0);
+			}
+			else
+			{
+				// trick play
+				String text;
+				if(newSpeed > 0f)
+					text = "FF X" + newSpeed;
+				else
+					text = "RW X" + (-newSpeed);
+
+                if(val1 == 0){
+                    mInfoView.setText(text, -1);
+                    mSubtitleTextView.setText(null,0);
+                }
+                else if(val1 == -1){
+                    text = text.concat(" Fail");
+                    mInfoView.setText(text, -1);
+                }
+
+			}
+        }
+        else if(reason == UPDATE_PLAYBACK_STATE){
+            mPlayState = (int) val1;
+            //Log.d(TAG,"play state changed to " + mPlayState);
+        }
+        else if(reason == UPDATE_PLAYBACK_PROGRESS){
+            /**
+            if(val3 == 0){ // no video frame updated, maybe this event can be discarded
+                if(progressBarProhibitTime > 0) {
+                    long curTime = System.currentTimeMillis();
+                    if(curTime - progressBarProhibitTime < 2000)
+                        return;
+
+                    progressBarProhibitTime = -1;
+                 }
+             }
+            **/
+
+            if(val1 > 0)
+                mDuration = val1;
+            else if(mDuration == 0 && mMediaPlayer != null && mPlayState != PLAYER_STOPPED)
+                mDuration = mMediaPlayer.getDuration();
+            val2 -= mTimeOffset; // offset by mTimeOffset
+            if(mDuration != 0 && val2 > mDuration)
+                val2 = mDuration;
+            else if(val2 < 0)
+                val2 = 0;
+            mCurPos   = val2;
+            long seconds = mDuration / 1000;
+            long minutes = seconds / 60;
+            seconds = seconds - minutes * 60;
+            long hours = minutes / 60;
+            minutes = minutes - hours * 60;
+            String s = "";
+            if(hours < 10)
+                s += "0";
+            s += hours + ":";
+            if(minutes < 10)
+                s += "0";
+            s += minutes + ":";
+            if(seconds < 10)
+                s += "0";
+            s += seconds;
+            mEndPosView.setText(s);
+            seconds = mCurPos / 1000;
+            minutes = seconds / 60;
+            seconds = seconds - minutes * 60;
+            hours = minutes / 60;
+            minutes = minutes - hours * 60;
+            s = "";
+            if(hours < 10)
+                s += "0";
+            s += hours + ":";
+            if(minutes < 10)
+                s += "0";
+            s += minutes + ":";
+            if(seconds < 10)
+                s += "0";
+            s += seconds;
+            mCurPosView.setText(s);
+            if(mDuration > 0) {
+                int pos = (int) (mCurPos/1000*1000 * 100 / mDuration + 1);
+                if(pos < 0 || mCurPos == 0)
+                    pos = 0;
+                else if(pos > 100)
+                    pos = 100;
+                mProgressBar.setProgress(pos);
+            }
+            else {
+                mProgressBar.setProgress(0);
+            }
+        }
+        else if(reason == UPDATE_PLAYBACK_ERROR){
+            // show error sign
+            //mErrSign.setVisibility(View.VISIBLE);
+            // dismiss waiting dialog
+            if(mWaitingDialog != null){
+                mWaitingDialog.dismiss();
+                mWaitingDialog = null;
+            }
+        }
+        if(mPlayState == PLAYER_EXITED) { // exit
+            finish();
+        }
+        // now update buttons/progressbar
+        boolean enablefb = true;
+        boolean enableplaypause = true;
+        boolean enableff = true;
+        boolean enablestop = true;
+        boolean enablesub = true;
+        boolean enableseek = true;
+        boolean enableplay = true;
+
+        if(mUrl == null) {
+            enablefb = false;
+            enableplaypause = false;
+            enableff = false;
+            enablestop = false;
+            enablesub = false;
+            enableseek = false;
+            enableplay = false;
+        }
+
+        if(mPlayState == PLAYER_PLAYING)
+            mBtnPlayPause.setBackgroundResource(R.drawable.pause);
+        else // paused or stopped
+            mBtnPlayPause.setBackgroundResource(R.drawable.play);
+
+        if(mPlayState == PLAYER_STOPPED) {
+            // stopped: BOF or EOF or user stopped
+            // finish(); // back to storefront, according to DivX requirement
+            // need to distinguish the reason
+            enablefb = false;
+            enableplaypause = true;
+            enableff = false;
+            enablestop = true;
+            enablesub = false;
+            enableseek = false;
+            enableplay = true;
+        }
+        else { // 0 - playing; 1 - paused
+            if(mPlaySpeed != 1)
+                enableseek = false;
+        }
+
+        if(mPlayState == PLAYER_PAUSED || mPlayState == PLAYER_STOPPED)
+            pauseMetadataShow();
+        else
+            resumeMetadataShow();
+
+        mBtnFastBack   .setEnabled(enablefb);
+        mBtnPlayPause  .setEnabled(enableplaypause);
+        mBtnFastForward.setEnabled(enableff);
+        mProgressBar   .setEnabled(enableseek);
+    }
+
+    //------------------------------------------------------------------------------------
+    // Playback control
+    //------------------------------------------------------------------------------------
+
+    private void initPlay() {
+        mPlayState   = PLAYER_STOPPED;
+        mPlaySpeed   = 0;
+        mLastDuration = mDuration;
+        mDuration    = 0;
+        mCurPos      = 0;
+        mTimeOffset  = 0;
+
+        resumeMetadataShow();
+        if(mWaitingDialog != null){
+            mWaitingDialog.dismiss();
+            mWaitingDialog = null;
+        }
+        mInfoView.setText(null, 0);
+        mSubtitleTextView.setText(null,0);
+        mSubtitleTextView.setText(null,0);
+        mEndPosView.setText(null);
+        mCurPosView.setText(null);
+        mProgressBar.setProgress(0);
+        mCurSubtitleIndex = -1;
+        mCurSubtitleTrack = -1;
+        updateButtons(-1, 0, 0, 0);
+    }
+
+    SurfaceHolder.Callback mSHCallback = new SurfaceHolder.Callback(){
+        public void surfaceChanged(SurfaceHolder holder, int format,
+            int w, int h){
+            Log.d(TAG,"surfaceChanged: parameter w/h " + w + "/" + h + " mSurfaceW/H " + mSurfaceWidth + "/" + mSurfaceHeight + ",mPlayState: " + mPlayState + " mTargetState: " + mTargetState);
+            mSurfaceWidth = w;
+            mSurfaceHeight = h;
+            boolean hasValidSize = (mVideoWidth == w && mVideoHeight == h);
+            if(mLastPlayState == -1 && mPlayState == PLAYER_PAUSED){
+                mLastPlayState = mPlayState;
+            }
+            if(mMediaPlayer != null && hasValidSize && mPlayState == PLAYER_PREPARED) {
+                start();
+                if(mTargetState == PLAYER_PAUSED && mPlayState == PLAYER_PLAYING){
+                    pause();
+                    mTargetState = STATE_INVALID;
+                }
+            }
+        }
+
+        @Override
+        public void surfaceCreated(SurfaceHolder holder) {
+            // TODO Auto-generated method stub
+            Log.d(TAG,"surfaceCreated");
+            mSurfaceHolder = holder;
+            initPlay();
+            play();
+        }
+
+        @Override
+        public void surfaceDestroyed(SurfaceHolder holder) {
+            // TODO Auto-generated method stub
+            mSurfaceHolder = null;
+            stop();
+        }
+    };
+
+    MediaPlayer.OnPreparedListener mPreparedListener = new MediaPlayer.OnPreparedListener() {
+        public void onPrepared(MediaPlayer mp) {
+            mPlaySpeed = 1;
+            Log.d(TAG,"onPrepared: play state " + mPlayState + " video:" + mVideoWidth + "," + mVideoHeight + " mSurface:" + mSurfaceWidth + ","
+                + mSurfaceHeight + " mTargetState:" + mTargetState);
+            mPlayState = PLAYER_PREPARED; // from now on, we can call start(), getDuration()
+            if (mMime != null && mMime.startsWith("video") && mVideoWidth != 0 && mVideoHeight != 0){
+                mVideoView.getHolder().setFixedSize(mVideoWidth, mVideoHeight);
+                if (mSurfaceWidth != mVideoWidth || mSurfaceHeight != mVideoHeight) {
+                    return;
+                }
+            }
+
+            if(mCurrentProgress <= 0 && mcurrpos <= 0){
+                mDuration = -1;
+            }
+            if(mPlayState == PLAYER_PAUSED){
+                mLastPlayState = PLAYER_PAUSED;
+            }
+            start();
+            if(mTargetState == PLAYER_PAUSED && mPlayState == PLAYER_PLAYING){
+                pause();
+                mTargetState = STATE_INVALID;
+            }
+
+        }
+    };
+
+    MediaPlayer.OnVideoSizeChangedListener mSizeChangedListener =
+        new MediaPlayer.OnVideoSizeChangedListener() {
+            public void onVideoSizeChanged(MediaPlayer mp, int width, int height) {
+                Log.d(TAG,"onVideoSizeChanged");
+                mVideoWidth = mp.getVideoWidth();
+                mVideoHeight = mp.getVideoHeight();
+                mVideoView.onVideoSizeChanged(mVideoWidth, mVideoHeight, 1, 1);
+            }
+    };
+
+    private MediaPlayer.OnCompletionListener mCompletionListener =
+        new MediaPlayer.OnCompletionListener() {
+            public void onCompletion(MediaPlayer mp) {
+                Log.d(TAG,"onCompletion");
+            /*
+            if(mPlaySpeed < 0){
+                mPlaySpeed = 1;
+                updateButtons(UPDATE_PLAYBACK_SPEED, 0, 0, mPlaySpeed);
+                return;
+            }
+            */
+
+            /*
+            if(mPlaySpeed >= 2){
+                mPlaySpeed = 1;
+                updateButtons(UPDATE_PLAYBACK_SPEED, 0, 0, mPlaySpeed);
+                return;
+            }
+            */
+                stop();
+                updateButtons(UPDATE_PLAYBACK_PROGRESS, 0, 0, 0);
+                if(mLoopFile){
+                    //play();
+                    mVideoView.setVisibility(View.VISIBLE);  // call Play() in surfaceCreated()
+                    if(mCurSubtitleTrack >= 0){
+                        Log.d(TAG,"onCompletion: select subtitle " + mCurSubtitleTrack);
+                        mMediaPlayer.selectTrack(mCurSubtitleTrack);
+                    }
+                    if(mCurAudioTrack >= 0){
+                        mMediaPlayer.selectTrack(mCurAudioTrack);
+                        Log.d(TAG,"onCompletion: select audio " + mCurAudioTrack);
+                    }
+                }
+            /*
+            if(mLoopFile){
+                seekTo(0);
+                start();
+            }
+            else
+                stop();
+            */
+            }
+        };
+
+    private MediaPlayer.OnErrorListener mErrorListener =
+        new MediaPlayer.OnErrorListener() {
+            public boolean onError(MediaPlayer mp, int framework_err, int impl_err) {
+                Log.d(TAG, "Error: " + framework_err + "," + impl_err);
+                return true;
+            }
+        };
+
+    private MediaPlayer.OnTimedTextListener mTimedTextListener =
+        new MediaPlayer.OnTimedTextListener() {
+            public void onTimedText(MediaPlayer mp, TimedText text){
+                Log.d(TAG,"onTimeText"+ mPlaySpeed);
+                if(mPlaySpeed == 1){
+                    if(text != null && null != text.getText()){
+                        int start_pos = 0;
+                        if(text.getText().startsWith("{\pos")){
+                            start_pos = text.getText().indexOf('}') + 1;
+                        }
+                        mSubtitleTextView.setText(text.getText().substring(start_pos), 0);
+                    }
+                    else
+                        mSubtitleTextView.setText(null, 0);
+                }
+            }
+
+        };
+
+    class FileAccept implements FilenameFilter
+    {
+        String str = null;
+        FileAccept(String s){
+            str = s;
+        }
+        public boolean accept(File dir,String name){
+            if(name.endsWith(".srt") && name.startsWith(str))
+                return true;
+            else
+                return false;
+        }
+    }
+    private void play() {
+        if(mUrl != null && mSurfaceHolder != null) {
+            try {
+                mMediaPlayer = new MediaPlayer();
+                mMediaPlayer.setOnPreparedListener(mPreparedListener);
+                mMediaPlayer.setOnVideoSizeChangedListener(mSizeChangedListener);
+                mDuration = -1;
+                mMediaPlayer.setOnCompletionListener(mCompletionListener);
+                mMediaPlayer.setOnErrorListener(mErrorListener);
+                mMediaPlayer.setOnTimedTextListener(mTimedTextListener);
+                mMediaPlayer.setDataSource(getBaseContext(), uri1);
+                if(mVideoView == null)
+                    Log.d(TAG, "mVideoView is null");
+                if(mSurfaceHolder.getSurface() == null)
+                    Log.d(TAG, "surface is null");
+                mMediaPlayer.setDisplay(mSurfaceHolder);
+                mMediaPlayer.setAudioStreamType(AudioManager.STREAM_MUSIC);
+                mMediaPlayer.setScreenOnWhilePlaying(true);
+                Log.w(TAG,"Url is " + mUrl);
+
+                do{
+                    if(true == mUrl.startsWith("udp"))
+                        break;
+                    if(mUrl.lastIndexOf('.') <= 0 || mUrl.lastIndexOf('.') >= mUrl.length()-1)
+                        break;
+                    if(mUrl.lastIndexOf('/') < 0 || mUrl.lastIndexOf('/') >= mUrl.length()-1)
+                        break;
+
+                    File f_url = new File(mUrl);
+                    if (!f_url.exists())
+                        break;
+                    //Log.w(TAG,"abs path:" + f_url.getAbsolutePath() + " path:" + f_url.getPath() + " name:" + f_url.getName());
+                    //Log.w(TAG,"parent:" + f_url.getParent());
+                    File f_path = f_url.getParentFile();
+                    String name = f_url.getName();
+                    FileAccept filenameFilter = new FileAccept(name.substring(0, name.lastIndexOf('.')));
+                    File list[] = f_path.listFiles(filenameFilter);
+                    for(int i = 0; i < list.length; i++){
+                        String srt_file = list[i].getAbsolutePath();
+                        Log.w(TAG, "srt:" + srt_file);
+                        mMediaPlayer.addTimedTextSource(srt_file, MediaPlayer.MEDIA_MIMETYPE_TEXT_SUBRIP);
+                    }
+                }while(false);
+                mMediaPlayer.prepareAsync();
+            } catch (IOException ex) {
+                Log.w(TAG, "Unable to open content: " + mUrl, ex);
+                return;
+            } catch (IllegalArgumentException ex) {
+                Log.w(TAG, "Unable to open content: " + mUrl, ex);
+                return;
+            }
+        }
+    }
+
+    public void mediaStart() {
+        if(mMediaPlayer != null) {
+            if(mcurrpos != 0){
+                mDuration = mLastDuration;
+                if(mDuration <= 0 && mPlayState != PLAYER_STOPPED){
+                    mDuration = mMediaPlayer.getDuration();
+                }
+                seekTo(mcurrpos);
+                updateButtons(UPDATE_PLAYBACK_PROGRESS, 0, mcurrpos, 0);
+                mcurrpos = 0;
+            }
+            else if (mCurrentProgress > 0) {
+                mDuration = mLastDuration;
+                if(mDuration <= 0 && mPlayState != PLAYER_STOPPED) {
+                    mDuration = mMediaPlayer.getDuration();
+                }
+                long newposition = (mDuration * mCurrentProgress) / 100L;
+                seekTo( (int) newposition);
+                updateButtons(UPDATE_PLAYBACK_PROGRESS, 0, mCurrentProgress * mDuration / 100, 0);
+            }
+            else if(mDuration < 0 && mPlayState != PLAYER_STOPPED) {
+                mDuration = mMediaPlayer.getDuration();
+                updateButtons(UPDATE_PLAYBACK_STATE, mPlayState, 0, 0);
+            }
+
+            mHandler.sendEmptyMessage(SHOW_PROGRESS);
+        }
+    }
+
+    public void start() {
+        if(mMediaPlayer == null) {
+            return;
+        }
+        mediaStart();
+        Log.d(TAG,"start(), last state " + mLastPlayState);
+        if(mLastPlayState != PLAYER_PAUSED) {
+            mMediaPlayer.start();
+            Log.d(TAG,"start(), change state to playing");
+            mPlayState = PLAYER_PLAYING;
+        }
+        else {
+            Log.d(TAG,"start(), change state to " + mLastPlayState);
+            mPlayState = mLastPlayState;
+        }
+        mLastPlayState = -1;
+    }
+
+    private void pause() {
+        if(mMediaPlayer != null) {
+            mMediaPlayer.pause();
+            mPlayState = PLAYER_PAUSED;
+            updateButtons(UPDATE_PLAYBACK_STATE, mPlayState, 0, 0);
+        }
+    }
+
+    private void stop() {
+        if(mMediaPlayer != null) {
+            mMediaPlayer.stop();
+            mMediaPlayer.release();
+            mMediaPlayer = null;
+            mPlayState = PLAYER_STOPPED;
+            Log.d(TAG,"stop(), state is stopped");
+            mPlaySpeed = 1;
+            updateButtons(UPDATE_PLAYBACK_STATE, mPlayState, 0, 0);
+            mSubtitleTextView.setText(null,0);
+            mInfoView.setText(null,0);
+            mVideoView.setVisibility(View.INVISIBLE);
+        }
+    }
+
+    private void fastForward() {
+        if(mMediaPlayer != null) {
+            int savedState = -1;
+            float newSpeed;
+            long val1 = 0;
+
+            int newIndex = forward_speed_index;
+
+            if(++newIndex >= forward_speed.length)
+                newIndex = 0;
+
+            newSpeed = forward_speed[newIndex];
+
+            if(mPlayState == PLAYER_PAUSED || mPlayState == PLAYER_PLAYING){
+                Log.d(TAG,"set speed to " + newSpeed);
+                try{
+                    mMediaPlayer.setPlaybackParams(new PlaybackParams().setSpeed(newSpeed));
+                }
+                catch (Exception e){
+                    Log.d(TAG, "Failed to setPlaybackkParams " + e);
+                    val1 = -1 ;
+                }
+
+                mPlaySpeed = newSpeed;
+                forward_speed_index = newIndex;
+                updateButtons(UPDATE_PLAYBACK_SPEED, val1, 0, mPlaySpeed);
+                backward_speed_index = -1;
+                if(mPlayState == PLAYER_PAUSED)
+                    start();
+            }
+            else{
+                Log.d(TAG,"wrong state " + mPlayState + " to ff");
+            }
+
+        }
+    }
+
+    private void fastBackward() {
+        Log.d(TAG,"fastBackward");
+
+        if(false){//mMediaPlayer != null) {
+            int savedState = -1;
+            float newSpeed;
+
+            if(++backward_speed_index >= backward_speed.length)
+                backward_speed_index = 0;
+
+            newSpeed = backward_speed[backward_speed_index];
+
+            if(mPlayState == PLAYER_PLAYING || mPlayState == PLAYER_PAUSED){
+                Log.d(TAG,"set speed to " + newSpeed);
+                mMediaPlayer.setPlaybackParams(new PlaybackParams().setSpeed(newSpeed));
+                mPlaySpeed = newSpeed;
+                updateButtons(UPDATE_PLAYBACK_SPEED, 0, 0, mPlaySpeed);
+                forward_speed_index = -1;
+                if(mPlayState == PLAYER_PAUSED)
+                    start();
+            }
+            else{
+                Log.d(TAG,"wrong state to fw");
+            }
+        }
+
+    }
+
+    private void setNormalSpeed() {
+        if(mMediaPlayer != null) {
+            mPlaySpeed = 1;
+            Log.d(TAG,"set speed to " + mPlaySpeed);
+            mMediaPlayer.setPlaybackParams(new PlaybackParams().setSpeed(mPlaySpeed));
+
+            updateButtons(UPDATE_PLAYBACK_SPEED, 0, 0, mPlaySpeed);
+            forward_speed_index = backward_speed_index = -1;
+        }
+    }
+
+    private void seekTo(long ms) {
+        if(mMediaPlayer != null) {
+            mMediaPlayer.seekTo((int)ms);
+        }
+    }
+
+    private void createAudioAndSubtitleMenu(Menu menu)
+    {
+        Log.d(TAG,"createAudioAndSubtitleMenu");
+        //add select audio icon
+        if(mMediaPlayer != null){
+            MediaPlayer.TrackInfo[] ti ;
+            try{
+                ti = mMediaPlayer.getTrackInfo();
+
+            }
+            catch (Exception e){
+                Log.d(TAG, "Failed to get track info when creating menu");
+                return ;
+            }
+            int totalCount = ti.length;
+            Log.v(TAG,"total track count " + totalCount);
+            for(int i = 0; i< totalCount ; i++){
+                if(ti[i].getTrackType() == MediaPlayer.TrackInfo.MEDIA_TRACK_TYPE_AUDIO)
+                    mAudioTrackCount++;
+                else if(ti[i].getTrackType() == MediaPlayer.TrackInfo.MEDIA_TRACK_TYPE_TIMEDTEXT)
+                    mSubtitleTrackCount++;
+            }
+        }
+
+        if(mAudioTrackCount >= 2 && null == menu.findItem(SELECT_AUDIO)){
+            menu.add(0, SELECT_AUDIO, 0, getString(R.string.SelectAudio));
+        }
+        
+        if(mSubtitleTrackCount >= 1){
+            menu.add(0, SELECT_SUBTITLE, 0, getString(R.string.SelectSubtitle));
+            menu.add(0, CLOSE_SUBTITLE,	0, getString(R.string.CloseSubtitle));
+        }
+
+    }
+    //------------------------------------------------------------------------------------
+    // GUI messages
+    //------------------------------------------------------------------------------------
+
+    @Override
+    public boolean onPrepareOptionsMenu (Menu menu) {
+        MenuItem item;
+        super.onPrepareOptionsMenu(menu);
+        Log.d(TAG,"==========onPrepareOptionsMenu ");
+        boolean enabled = false;
+        mHdmiApp = (HdmiApplication)getApplication();
+        mPresentation = mHdmiApp.getPresentation();
+        if(mPlaySpeed == 1 && (mPlayState == PLAYER_PLAYING || mPlayState == PLAYER_PAUSED))
+            enabled = true;
+
+        if((mPlayState == PLAYER_PLAYING || mPlayState == PLAYER_PAUSED) && false == bGetTrackInfo){
+            createAudioAndSubtitleMenu( menu);
+            bGetTrackInfo = true;
+        }
+
+        item = menu.findItem(SELECT_AUDIO);
+        if(item != null)
+            item.setEnabled(enabled);
+        item = menu.findItem(SELECT_SUBTITLE);
+        if(item != null)
+            item.setEnabled(enabled);
+        enabled = enabled && mCurSubtitleTrack >= 0;
+        item = menu.findItem(CLOSE_SUBTITLE);
+        if(item != null)
+            item.setEnabled(enabled);
+
+        item = menu.findItem(Cast_Screen);
+        if(item != null){
+            if(mPresentation != null){
+                if( mPresentation.getPresentationState() == mPresentation_playing ||
+                    mPresentation.getPresentationState() == mPresentation_pausing){
+                        item.setEnabled(true);
+                }
+                else{
+                    item.setEnabled(true);
+                    item.setCheckable(true);
+                    item.setChecked(false);
+                }
+            }
+            else if(mPresentation == null && CastScreen_flag == true){
+                item.setCheckable(true);
+                item.setChecked(false);
+                item.setEnabled(false);
+                CastScreen_flag = false;
+            }
+            else if(mPresentation == null && CastScreen_flag == false){
+                item.setEnabled(false);
+                item.setChecked(false);
+            }
+        }
+        if(mPresentation != null){
+            if( mPresentation.getPresentationState() == mPresentation_playing ||
+                mPresentation.getPresentationState() == mPresentation_pausing){
+                    item = menu.findItem(Quit);
+                    item.setEnabled(true);
+                    item.setCheckable(true);
+            }
+            else {
+                item = menu.findItem(Quit);
+                item.setEnabled(false);
+            }
+        }
+        else {
+            item = menu.findItem(Quit);
+            item.setEnabled(false);
+        }
+        return true;
+    }
+
+    @Override
+    public boolean onCreateOptionsMenu(Menu menu) {
+        Log.d(TAG,"==========onCreateOptionsMenu ");
+        super.onCreateOptionsMenu(menu);
+        /*
+        MenuInflater inflater = getMenuInflater();
+        inflater.inflate(R.menu.operation, menu);
+        */
+        mHdmiApp = (HdmiApplication)getApplication();
+        mPresentation = mHdmiApp.getPresentation();
+        MenuItem item = menu.add(0, LOOP_FILE,	0, getString(R.string.LoopFile));
+        MenuItem item2 = menu.add(1,Cast_Screen,1,getString(R.string.CastScreen));
+        MenuItem item3 = menu.add(2,Quit,2, getString(R.string.quit));
+        item.setCheckable(true);
+        if(mPresentation != null){
+            if (mPresentation.getPresentation_LoopStatus() == true){
+                item.setChecked(true);
+                mLoopFile = true;
+            }
+            else
+                item.setChecked(false);
+
+            item2.setCheckable(true);
+            item3.setCheckable(true);
+            if( mPresentation.getPresentationState() == mPresentation_playing ||
+                mPresentation.getPresentationState() == mPresentation_pausing){
+                    item2.setChecked(true);
+                    CastScreen_flag = true;
+                    item3.setEnabled(true);
+            }
+            else {
+                item2.setChecked(false);
+                item3.setEnabled(false);
+                CastScreen_flag = false;
+            }
+        }
+        else {
+            item2.setEnabled(false);
+            item3.setEnabled(false);
+            CastScreen_flag = false;
+        }
+
+        return true;
+    }
+
+    @Override
+    public boolean onOptionsItemSelected(MenuItem item) {
+        boolean ret = super.onOptionsItemSelected(item);
+        int itemId = item.getItemId();
+        if(itemId == LOOP_FILE){
+            if (item.isChecked()) {
+                item.setChecked(false);
+                if(mPresentation != null)
+                    mPresentation.setPresentation_LoopStatus(false);
+            }
+            else {
+                item.setChecked(true);
+                if(mPresentation != null)
+                    mPresentation.setPresentation_LoopStatus(true);
+            }
+            mLoopFile = item.isChecked();
+            //if(mMediaPlayer != null)
+            //mMediaPlayer.setLooping(mLoopFile);
+        }
+     //******************cast screen ***********************
+        else if(itemId == Cast_Screen){
+            if (item.isChecked()) {
+                if(mPresentation != null){
+                    item.setChecked(false);
+                    CastScreen_flag = false;
+                    if(!mHdmiApp.getmPresentationEnded())
+                        mcurrpos = mPresentation.getcurrentPos();
+                    mPresentation.cancel();
+                    mPresentation.setPresentationState(mPresentation_disabled);
+                    mPlayState = PLAYER_PLAYING;
+                    Local_onCreate();
+                    mHdmiApp.setmPresentationEnded(false);
+                }
+                else{
+                    item.setChecked(false);
+                    CastScreen_flag = false;
+                    mPlayState = PLAYER_PLAYING;
+                    Local_onCreate();
+                }
+            }
+            else {
+                item.setChecked(true);
+                if(mPlayState == PLAYER_PLAYING){
+                    mMediaPlayer.pause();
+                    mPlayState = PLAYER_PAUSED;
+                }
+                mPresentation.setPresentationState(mPresentation_playing);
+                mPresentation.show();
+                mPresentation.startVideo(uri1);
+                if(mPlayState != PLAYER_STOPPED){
+                    int curr = mMediaPlayer.getCurrentPosition();
+                        mPresentation.mseekTo(curr);
+                }
+                Remote_onCreate();
+                CastScreen_flag = true;
+            }
+        }
+
+        //************************totally quit
+        if(itemId == Quit){
+            if (item.isChecked()) {
+                item.setChecked(false);
+            }
+            else {
+                item.setChecked(true);
+                mPresentation.cancel();
+                System.exit(0);
+                CastScreen_flag = false;
+            }
+            //if(mMediaPlayer != null)
+            //    mMediaPlayer.setLooping(mLoopFile);
+        }
+
+        else if(itemId == SELECT_AUDIO){
+            selectAudioDialog();
+        }
+
+        else if(itemId == SELECT_SUBTITLE){
+            selectSubtitleDialog();
+        }
+
+        else if(itemId == CLOSE_SUBTITLE){
+            if(mCurSubtitleTrack >= 0 && mMediaPlayer != null){
+                Log.v(TAG,"to deselected track  " + mCurSubtitleTrack);
+                try{
+                    mMediaPlayer.deselectTrack(mCurSubtitleTrack);
+                }
+                catch(Exception e){
+                    Log.d(TAG, "Failed to deselect track !!!");
+                }
+                mCurSubtitleTrack = -1;
+                mCurSubtitleIndex = -1;
+                mSubtitleTextView.setText(null,0);
+            }
+        }
+        else if(itemId == android.R.id.home){
+            this.finish();
+            return true;
+        }
+        return ret;
+    }
+
+
+
+    /** Button messages
+    */
+    private OnClickListener mOnBtnClicked = new OnClickListener() {
+        public void onClick(View view) {
+            if(view == mBtnFastBack){
+                fastBackward();
+            }
+            else if(view == mBtnPlayPause){
+                 forward_speed_index = backward_speed_index = -1;
+
+                if(mPlayState == PLAYER_PLAYING){
+                    if(mPlaySpeed != 1)
+                        setNormalSpeed();
+                    pause();
+                }
+                else if(mPlayState == PLAYER_PAUSED){
+                    mLastPlayState = -1;
+                    mMediaPlayer.start();
+                    mPlayState = PLAYER_PLAYING;
+                    updateButtons(UPDATE_PLAYBACK_STATE, mPlayState, 0, 0);
+                    mHandler.sendEmptyMessage(SHOW_PROGRESS);
+                }
+                else if(mPlayState == PLAYER_STOPPED){
+                    //play();
+                    mLastPlayState = -1;
+                    mVideoView.setVisibility(View.VISIBLE);
+                    // call play() in surfaceCreated()
+                }
+            }
+            else if(view == mBtnFastForward){
+                if(mPlayState != PLAYER_PLAYING && mPlayState != PLAYER_PAUSED)
+                    return;
+                fastForward();
+            }
+        }
+    };
+
+    /** Seekbar messages
+     */
+    public void onProgressChanged(SeekBar seekBar, int progress, boolean fromUser) {
+        if (mDuration != 0) {
+            mCurrentProgress = progress;
+        }
+        if (!fromUser) {
+            // We're not interested in programmatically generated changes to
+            // the progress bar's position.
+            return;
+        }
+        if(mDuration == 0)
+            return;
+
+        long newposition = (mDuration * progress) / 100L;
+        seekTo( (int) newposition);
+        updateButtons(UPDATE_PLAYBACK_PROGRESS, 0, progress * mDuration / 100, 0);
+    }
+
+
+    public void onStartTrackingTouch(SeekBar seekBar) {
+        Log.d(TAG,"onStartTrackingTouch");
+        mDragging = true;
+        mHandler.removeMessages(SHOW_PROGRESS);
+    }
+
+    public void onStopTrackingTouch(SeekBar seekBar) {
+        mDragging = false;
+        mHandler.sendEmptyMessage(SHOW_PROGRESS);
+    }
+
+    private Handler mHandler = new Handler() {
+        @Override
+        public void handleMessage(Message msg) {
+            int pos;
+            switch (msg.what) {
+                case SHOW_PROGRESS:
+                    if(mMediaPlayer == null)
+                        break;
+
+                    if (!mDragging && mMediaPlayer.isPlaying()) {
+                        int curr = mMediaPlayer.getCurrentPosition();
+                        updateButtons(UPDATE_PLAYBACK_PROGRESS, 0, curr, 0);
+                        msg = obtainMessage(SHOW_PROGRESS);
+                        sendMessageDelayed(msg, 500);//1000 - (pos % 1000));
+                     }
+                        break;
+
+            }
+        }
+    };
+
+    private void selectAudioDialog() {
+
+        String[] audioList;
+        MediaPlayer.TrackInfo[] ti;
+        int totalCount = 0;
+        int audioCount = 0;
+        if(mMediaPlayer == null)
+            return;
+        ti = mMediaPlayer.getTrackInfo();
+        totalCount = ti.length;
+        Log.v(TAG,"total track count " + totalCount);
+        for(int i = 0; i< totalCount ; i++){
+            if(ti[i].getTrackType() == MediaPlayer.TrackInfo.MEDIA_TRACK_TYPE_AUDIO)
+                audioCount++;
+        }
+        audioList = new String[audioCount];
+        audioCount = 0;
+        for(int i = 0; i< totalCount ; i++){
+            Log.v(TAG,"track " + i + " type is " + ti[i].getTrackType()+ " lan " + ti[i].getLanguage());
+            if(ti[i].getTrackType() == MediaPlayer.TrackInfo.MEDIA_TRACK_TYPE_AUDIO){
+                audioList[audioCount] = ti[i].getLanguage();
+                audioCount++;
+            }
+        }
+
+        LayoutInflater inflater = (LayoutInflater) getSystemService(Context.LAYOUT_INFLATER_SERVICE);
+
+        final View dialogView = inflater.inflate(R.layout.selectaudio, null ,false);
+        dialogView.setBackgroundResource(R.drawable.rounded_corners_view);
+
+        final PopupWindow pw = new PopupWindow(dialogView, 480, LayoutParams.WRAP_CONTENT, true);
+        pw.setBackgroundDrawable(getResources().getDrawable(R.drawable.rounded_corners_pop));
+
+        ListView list = (ListView) dialogView.findViewById(R.id.list);
+
+        // add item index to chapter name
+        String items[] = new String[audioList.length];
+        int i;
+        for(i=0; i<audioList.length; i++) {
+            items[i] = Integer.toString(i+1) + ": "; // add index to title name
+            if(audioList[i] != null){
+                String fullName = map.get(audioList[i]);
+                if(fullName != null)
+                    items[i] += fullName;
+                else
+                    items[i] += "Audio track " + Integer.toString(i+1);
+            }
+            else
+                items[i] += "Audio track " + Integer.toString(i+1);
+        }
+
+        ArrayAdapter<String> adapter = new ArrayAdapter<String>(this,
+        android.R.layout.simple_list_item_1,
+        items);
+        list.setAdapter(adapter);
+        list.setOnItemClickListener(new OnItemClickListener(){
+        @Override
+            public void onItemClick(AdapterView<?> av, View v, int i, long l) {
+                if(mMediaPlayer != null) {
+                    //String itemText = ((TextView)v).getText().toString();
+                    //String sub[] = itemText.split(":");
+                    //Log.d(TAG,"====clicked item is " + itemText + " index " + i);
+                    //nativeExecuteCommand("at " + sub[0]);
+                    int index = -1;
+                    MediaPlayer.TrackInfo[] ti = mMediaPlayer.getTrackInfo();
+                    int totalCount = ti.length;
+                    for(int j = 0; j< totalCount ; j++){
+                        if(ti[j].getTrackType() == MediaPlayer.TrackInfo.MEDIA_TRACK_TYPE_AUDIO)
+                            index++;
+                        if(index == i){
+                            //mMediaPlayer.selectTrack(j);
+                            Parcel request = Parcel.obtain();
+                            Parcel reply = Parcel.obtain();
+                            try {
+                                request.writeInterfaceToken(IMEDIA_PLAYER);
+                                request.writeInt(INVOKE_ID_SELECT_TRACK);
+                                request.writeInt(j);
+                                mMediaPlayer.invoke(request, reply);
+                            } finally {
+                                request.recycle();
+                                reply.recycle();
+                            }
+                            //mInfoView.setText();
+                            mCurAudioTrack = j;
+                            mCurAudioIndex = i;
+                            Log.d(TAG,"select audio track " + mCurAudioTrack);
+                            break;
+                        }
+                    }
+                }
+                pw.dismiss();
+            }
+        });
+
+
+        Button btnCancel = (Button)   dialogView.findViewById(R.id.BtnCancel);
+        btnCancel.setOnClickListener(new OnClickListener() {
+            @Override
+            public void onClick(View v) {
+                pw.dismiss();
+            }
+        });
+        pw.showAtLocation((View)findViewById(R.id.ActiveWindow), Gravity.CENTER, 0, 0);
+    }
+
+    private void selectSubtitleDialog() {
+        String[] subtitleList;
+        MediaPlayer.TrackInfo[] ti;
+        int totalCount = 0;
+        int subtitleCount = 0;
+        if(mMediaPlayer == null)
+            return;
+        ti = mMediaPlayer.getTrackInfo();
+        totalCount = ti.length;
+        Log.v(TAG,"total track count " + totalCount);
+        for(int i = 0; i< totalCount ; i++){
+            if(ti[i].getTrackType() == MediaPlayer.TrackInfo.MEDIA_TRACK_TYPE_TIMEDTEXT)
+                subtitleCount++;
+        }
+
+        subtitleList = new String[subtitleCount];
+        subtitleCount = 0;
+        for(int i = 0; i < totalCount ; i++){
+            Log.v(TAG,"track " + i + " type is " + ti[i].getTrackType()+ " lan " + ti[i].getLanguage());
+            if(ti[i].getTrackType() == MediaPlayer.TrackInfo.MEDIA_TRACK_TYPE_TIMEDTEXT){
+                subtitleList[subtitleCount] = ti[i].getLanguage();
+                subtitleCount++;
+            }
+        }
+
+        LayoutInflater inflater = (LayoutInflater) getSystemService(Context.LAYOUT_INFLATER_SERVICE);
+
+        final View dialogView = inflater.inflate(R.layout.selectsubtitle, null ,false);
+        dialogView.setBackgroundResource(R.drawable.rounded_corners_view);
+
+        final PopupWindow pw = new PopupWindow(dialogView, 480, LayoutParams.WRAP_CONTENT, true);
+        pw.setBackgroundDrawable(getResources().getDrawable(R.drawable.rounded_corners_pop));
+
+        ListView list = (ListView) dialogView.findViewById(R.id.list);
+
+        // add item index to chapter name
+        String items[] = new String[subtitleList.length];
+        int i;
+        for(i = 0; i < subtitleList.length; i++) {
+            items[i] = Integer.toString(i+1) + ": "; // add index to title name
+            if(subtitleList[i] != null){
+                String fullName = map.get(subtitleList[i]);
+                if(fullName != null)
+                    items[i] += fullName;
+                else
+                    items[i] += "Subtitle track " + Integer.toString(i+1);
+            }
+            else
+                items[i] += "Subtitle track " + Integer.toString(i+1);
+        }
+
+        ArrayAdapter<String> adapter = new ArrayAdapter<String>(this,
+        android.R.layout.simple_list_item_1,
+        items);
+        list.setAdapter(adapter);
+        list.setOnItemClickListener(new OnItemClickListener(){
+            @Override
+            public void onItemClick(AdapterView<?> av, View v, int i, long l) {
+                if(mMediaPlayer != null) {
+                    int index = -1;
+                    MediaPlayer.TrackInfo[] ti = mMediaPlayer.getTrackInfo();
+                    int totalCount = ti.length;
+                    for(int j = 0; j < totalCount ; j++){
+                        Log.v(TAG,"track " + j + " type is " + ti[j].getTrackType());
+                        if(ti[j].getTrackType() == MediaPlayer.TrackInfo.MEDIA_TRACK_TYPE_TIMEDTEXT)
+                            index++;
+                        if(index == i){
+                            Log.v(TAG,"selected track " + j);
+                            try{
+                                mMediaPlayer.selectTrack(j);
+                            }
+                            catch(Exception e){
+                                Log.d(TAG, "Failed to select subtitle track!!!");
+                                break;
+                            }
+                            mCurSubtitleTrack = j;
+                            mCurSubtitleIndex = i;
+                            break;
+                        }
+                    }
+                }
+                pw.dismiss();
+            }
+        });
+
+
+        Button btnCancel = (Button)   dialogView.findViewById(R.id.BtnCancel);
+        btnCancel.setOnClickListener(new OnClickListener() {
+            @Override
+            public void onClick(View v) {
+                pw.dismiss();
+            }
+        });
+        pw.showAtLocation((View)findViewById(R.id.ActiveWindow), Gravity.CENTER, 0, 0);
+    }
+
+
+    private void pauseMetadataShow() {
+        //mErrSign.pause();
+        mInfoView.pause();
+        mSubtitleTextView.pause();
+    }
+
+    private void resumeMetadataShow() {
+        //mErrSign.resume();
+        mInfoView.resume();
+        mSubtitleTextView.resume();
+    }
+
+    private Map<String, String> map = new HashMap<String, String>();
+
+    private void initLocaleTable() {
+        map.put("alb", "Albanian");
+        map.put("sqi", "Albanian");
+        map.put("sq" , "Albanian");
+        map.put("ara", "Arabic");
+        map.put("ar" , "Arabic");
+        map.put("arm", "Armenian");
+        map.put("hye", "Armenian");
+        map.put("hy" , "Armenian");
+        map.put("art", "Artificial languages");
+        map.put("ast", "Asturian");
+        map.put("aus", "Australian languages");
+        map.put("aze", "Azerbaijani");
+        map.put("az" , "Azerbaijani");
+        map.put("ast", "Bable");
+        map.put("bat", "Baltic languages");
+        map.put("bam", "Bambara");
+        map.put("bm" , "Bambara");
+        map.put("chi", "Chinese");
+        map.put("zho", "Chinese");
+        map.put("zh" , "Chinese");
+        map.put("zha", "Chuang");
+        map.put("za" , "Chuang");
+        map.put("mus", "Creek");
+        map.put("cze", "Czech");
+        map.put("ces", "Czech");
+        map.put("cs" , "Czech");
+        map.put("dan", "Danish");
+        map.put("da" , "Danish");
+        map.put("dut", "Dutch");
+        map.put("nld", "Dutch");
+        map.put("nl" , "Dutch");
+        map.put("eng", "English");
+        map.put("en" , "English");
+        map.put("est", "Estonian");
+        map.put("et" , "Estonian");
+        map.put("fan", "Fang");
+        map.put("fat", "Fanti");
+        map.put("fin", "Finnish");
+        map.put("fi" , "Finnish");
+        map.put("fre", "French");
+        map.put("fra", "French");
+        map.put("fr" , "French");
+        map.put("geo", "Georgian");
+        map.put("kat", "Georgian");
+        map.put("ka" , "Georgian");
+        map.put("ger", "German");
+        map.put("deu", "German");
+        map.put("de" , "German");
+        map.put("hun", "Hungarian");
+        map.put("hu" , "Hungarian");
+        map.put("ice", "Icelandic");
+        map.put("isl", "Icelandic");
+        map.put("is" , "Icelandic");
+        map.put("ind", "Indonesian");
+        map.put("in" , "Indonesian");
+        map.put("ira", "Iranian languages");
+        map.put("gle", "Irish");
+        map.put("ga" , "Irish");
+        map.put("ita", "Italian");
+        map.put("it" , "Italian");
+        map.put("jpn", "Japanese");
+        map.put("ja" , "Japanese");
+        map.put("kon", "Kongo");
+        map.put("kg" , "Kongo");
+        map.put("kor", "Korean");
+        map.put("ko" , "Korean");
+        map.put("kur", "Kurdish");
+        map.put("ku" , "Kurdish");
+        map.put("lao", "Lao");
+        map.put("lo" , "Lao");
+        map.put("lat", "Latin");
+        map.put("la" , "Latin");
+        map.put("per", "Persian");
+        map.put("fas", "Persian");
+        map.put("fa" , "Persian");
+        map.put("phi", "Philippine languages");
+        map.put("pol", "Polish");
+        map.put("pl" , "Polish");
+        map.put("por", "Portuguese");
+        map.put("pt" , "Portugueses");
+        map.put("rum", "Romanian");
+        map.put("ron", "Romanian");
+        map.put("ro" , "Romanian");
+        map.put("rus", "Russian");
+        map.put("ru" , "Russian");
+        map.put("sco", "sco");
+        map.put("srp", "Serbian");
+        map.put("sr" , "Serbian");
+        map.put("spa", "Spanish");
+        map.put("es" , "Spanish");
+        map.put("swe", "Swedish");
+        map.put("sv" , "Swedish");
+        map.put("tha", "Thai");
+        map.put("th" , "Thai");
+        map.put("tur", "Turkish");
+        map.put("tr" , "Turkish");
+        map.put("ukr", "Ukrainian");
+        map.put("uk" , "Ukrainian");
+        map.put("vie", "Vietnamese");
+        map.put("vi" , "Vietnamese");
+        map.put("nor", "Norwegian");
+        map.put("no" , "Norwegian");
+        map.put("grc", "Greek");
+        map.put("gre", "Greek");
+        map.put("ell", "Greek");
+        map.put("el" , "Greek");
+    }
+    private String localeToLangName(String locale) {
+        String name = null;
+        if(locale != null)
+            name = map.get(locale);
+        if(name == null)
+            name = "Unspecified language";
+        return name;
+    }
+}
+
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/VideoView.java b/CactusPlayer/src/com/freescale/cactusplayer/VideoView.java
new file mode 100755
index 0000000..6402622
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/VideoView.java
@@ -0,0 +1,140 @@
+/*
+ * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package com.freescale.cactusplayer;
+
+import android.util.AttributeSet;
+import android.util.Log;
+import android.view.Surface;
+import android.view.SurfaceHolder;
+import android.view.SurfaceView;
+import android.content.Context;
+
+public class VideoView extends SurfaceView {
+    private String       TAG = "CactusPlayer";
+    private static final String CLASS = "VideoView: ";
+    private int          mVideoWidth;
+    private int          mVideoHeight;
+    private float        mOldPar;
+    private void initVideoView() {
+        mVideoWidth     = 0;
+        mVideoHeight    = 0;
+        mOldPar         = (float) 0.0;
+        //getHolder().addCallback(mSHCallback);
+        getHolder().setType(SurfaceHolder.SURFACE_TYPE_PUSH_BUFFERS);
+        //getHolder().setFixedSize(mVideoWidth, mVideoHeight); // default to 1:1
+    }
+
+    Surface getSurface() {
+        return getHolder().getSurface();
+    }
+/*
+    SurfaceHolder.Callback mSHCallback = new SurfaceHolder.Callback()
+    {
+        public void surfaceChanged(SurfaceHolder holder, int format,
+                                    int w, int h)
+        {
+            mSurfaceWidth = w;
+            mSurfaceHeight = h;
+        }
+
+        public void surfaceCreated(SurfaceHolder holder)
+        {
+            mSurfaceHolder = holder;
+        }
+
+        public void surfaceDestroyed(SurfaceHolder holder)
+        {
+            // after we return from this we can't use the surface any more
+            mSurfaceHolder = null;
+            // TODO: release
+        }
+    };
+*/
+    public VideoView(Context context) {
+        super(context);
+        initVideoView();
+    }
+
+    public VideoView(Context context, AttributeSet attrs) {
+        this(context, attrs, 0);
+        initVideoView();
+    }
+
+    public VideoView(Context context, AttributeSet attrs, int defStyle) {
+        super(context, attrs, defStyle);
+        initVideoView();
+    }
+
+    // onMeasure will be called when surface is created or size changed
+    @Override
+    protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) {
+        Log.d(TAG, "onMeasure " + "mVideoW " + mVideoWidth + " mVideoH " + mVideoHeight
+            + " widthMesaureSpec " + widthMeasureSpec + " heightMeasureSpec " + heightMeasureSpec);
+        int width  = getDefaultSize(mVideoWidth,  widthMeasureSpec);
+        int height = getDefaultSize(mVideoHeight, heightMeasureSpec);
+        if(mVideoWidth == 0 || mVideoHeight == 0) { // no video now
+            setMeasuredDimension(width, height);
+            return;
+        }
+
+        if (width > 0 && height > 0 && mVideoWidth > 0 && mVideoHeight > 0) {
+            float win_asp = (float)width / height;
+            float pic_asp = (float)mVideoWidth / mVideoHeight;
+            if ( pic_asp > win_asp ) {
+                height = (int)((float)width / pic_asp);
+            }
+            else if ( pic_asp < win_asp ) {
+                width = (int)((float)height * pic_asp);
+            }
+
+            setMeasuredDimension(width, height); // set view's content size to maintain same aspect ratio as video sepcified
+        }
+        else {
+            // bad parameters
+            super.onMeasure(widthMeasureSpec, heightMeasureSpec);
+        }
+    }
+
+    public void onVideoSizeChanged(int newWidth, int newHeight, int sarW, int sarH) {
+        Log.d(TAG, "onVideoSizeChanged: " + newWidth + " x " + newHeight + ", (" + sarW + "/" + sarH + ")");
+        // TODO: will support non-square pixel display later
+
+        float sar = (float)sarW / sarH;
+
+        if(sar >= 1.0f) {
+            mVideoWidth = (int)(sar * newWidth + 0.5);
+            mVideoHeight = newHeight;
+        }
+        else {
+            mVideoWidth = newWidth;
+            mVideoHeight = (int)(newHeight / sar + 0.5);
+        }
+
+        // video size changed, but view content size is unchanged if picture aspect ratio is unchanged
+        float par = (float)mVideoWidth/mVideoHeight;
+        float diff = par - mOldPar;
+        if(diff < 0) diff = -diff;
+            float distortion = diff / par;
+        if(mOldPar == 0 || distortion > 0.05) {
+            // will call onMeasure, and then surfaceChanged(size is same as setFixedSize)
+            getHolder().setFixedSize(mVideoWidth, mVideoHeight);
+            mOldPar = par;
+        }
+    }
+}
+
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/utils/DefaultParsePath.java b/CactusPlayer/src/com/freescale/cactusplayer/utils/DefaultParsePath.java
new file mode 100755
index 0000000..e62cc4a
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/utils/DefaultParsePath.java
@@ -0,0 +1,26 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.freescale.cactusplayer.utils;
+
+import android.net.Uri;
+import android.content.Context;
+public class DefaultParsePath implements IParsePath{
+
+	@Override
+	public String parseUrl(Context context, Uri uri) {
+		return uri.toString();
+	}
+}
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/utils/ExternalStorageDocumentParsePath.java b/CactusPlayer/src/com/freescale/cactusplayer/utils/ExternalStorageDocumentParsePath.java
new file mode 100755
index 0000000..e427d02
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/utils/ExternalStorageDocumentParsePath.java
@@ -0,0 +1,41 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.freescale.cactusplayer.utils;
+
+import android.net.Uri;
+import android.os.Environment;
+import android.provider.DocumentsContract;
+import android.content.Context;
+public class ExternalStorageDocumentParsePath implements IParsePath{
+
+	@Override
+	public String parseUrl(Context context, Uri uri) {
+		final String docId = DocumentsContract.getDocumentId(uri);
+		final String[] split = docId.split(":");
+		final String type = split[0];
+		String storageDefinition;
+
+		if("primary".equalsIgnoreCase(type)){
+			return Environment.getExternalStorageDirectory() + "/" + split[1];
+		} else {
+			if(Environment.isExternalStorageRemovable()){
+				return System.getenv("EXTERNAL_STORAGE") + "/" + split[1];
+			} else{
+				return  "/storage/" + type + "/" + split[1];
+			}
+		}
+	}
+}
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/utils/IParsePath.java b/CactusPlayer/src/com/freescale/cactusplayer/utils/IParsePath.java
new file mode 100755
index 0000000..950f5c8
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/utils/IParsePath.java
@@ -0,0 +1,22 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.freescale.cactusplayer.utils;
+
+import android.net.Uri;
+import android.content.Context;
+public interface IParsePath {
+	public String parseUrl(Context context, Uri uri);
+}
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/utils/MediaStoreParsePath.java b/CactusPlayer/src/com/freescale/cactusplayer/utils/MediaStoreParsePath.java
new file mode 100644
index 0000000..4f156b6
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/utils/MediaStoreParsePath.java
@@ -0,0 +1,33 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.freescale.cactusplayer.utils;
+
+import android.net.Uri;
+import android.content.Context;
+import android.provider.MediaStore;
+import android.database.Cursor;
+public class MediaStoreParsePath implements IParsePath{
+
+    @Override
+    public String parseUrl(Context context, Uri uri) {
+        Cursor cursor = context.getContentResolver().query(uri, new String[]{MediaStore.Video.Media.DATA},
+                null, null, null);
+        int column = cursor.getColumnIndexOrThrow(MediaStore.Video.Media.DATA);
+        cursor.moveToFirst();
+        String path = cursor.getString(column);
+        return path;
+    }
+}
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/utils/PathUtils.java b/CactusPlayer/src/com/freescale/cactusplayer/utils/PathUtils.java
new file mode 100755
index 0000000..7d79b6c
--- /dev/null
+++ b/CactusPlayer/src/com/freescale/cactusplayer/utils/PathUtils.java
@@ -0,0 +1,43 @@
+/*
+ * Copyright (C) 2016 Freescale Semiconductor, Inc.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.freescale.cactusplayer.utils;
+
+import android.content.Context;
+import android.net.Uri;
+import android.os.Build;
+import android.provider.DocumentsContract;
+
+public class PathUtils {
+
+	public static String getPath(final Context context, final Uri uri) {
+
+		IParsePath parsePath = null;
+		if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT && DocumentsContract.isDocumentUri(context, uri)) {
+
+			if ("com.android.externalstorage.documents".equals(uri.getAuthority())){
+				parsePath = new ExternalStorageDocumentParsePath();
+			}
+			else{
+				//Other content provider uri operation
+			}
+		} else{
+            if ("media".equals(uri.getAuthority())) {
+                parsePath = new MediaStoreParsePath();
+            }
+		}
+		return parsePath != null ? parsePath.parseUrl(context, uri) : new DefaultParsePath().parseUrl(context, uri);
+	}
+}
diff --git a/codec2/Android.bp b/codec2/Android.bp
new file mode 100644
index 0000000..6414d40
--- /dev/null
+++ b/codec2/Android.bp
@@ -0,0 +1,38 @@
+
+cc_defaults {
+    name: "imx_defaults",
+
+    cflags: [
+        "-Wl,-Bsymbolic",
+        "-Wno-unused-parameter",
+        "-Wno-implicit-fallthrough",
+        "-Werror",
+    ],
+
+    sanitize: {
+          misc_undefined: [
+            "signed-integer-overflow",
+            "unsigned-integer-overflow",
+            "bounds",],
+          diag: {
+              misc_undefined: [
+                "signed-integer-overflow",
+                "unsigned-integer-overflow",
+                "bounds",],
+          },
+          cfi: true,
+    },
+
+    soc_specific: true,
+    vendor: true
+}
+
+subdirs = [
+    "base",
+    "tsm",
+    "v4l2_dev",
+    "video_dec",
+    "audio_dec",
+    "store",
+    "process",
+]
diff --git a/codec2/audio_dec/Android.bp b/codec2/audio_dec/Android.bp
new file mode 100644
index 0000000..00ea6ef
--- /dev/null
+++ b/codec2/audio_dec/Android.bp
@@ -0,0 +1,4 @@
+subdirs = [
+    "common",
+    "aac_dec",
+]
diff --git a/codec2/audio_dec/aac_dec/AacDecodeUtil.cpp b/codec2/audio_dec/aac_dec/AacDecodeUtil.cpp
new file mode 100755
index 0000000..3c34bad
--- /dev/null
+++ b/codec2/audio_dec/aac_dec/AacDecodeUtil.cpp
@@ -0,0 +1,535 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "AacDecUtil"
+#include <log/log.h>
+
+#include <AacFrameParser.h>
+#include <C2Config_imx.h>
+#include <IMXC2Interface.h>
+#include <media/stagefright/foundation/MediaDefs.h>
+#include <UniaDecoder.h>
+#include <C2ComponentFactory.h>
+#include <C2PlatformSupport.h>
+
+#include "AacDecodeUtil.h"
+
+namespace android {
+
+#define AACD_FRAME_SIZE  1024
+#define AAC_PUSH_MODE_LEN   (6*768+7)//max frame lenth + another frame header size
+#define ADIF_FILE 0x41444946
+#define DSP_WRAPPER_LIB_NAME "lib_dsp_wrap_arm12_android.so"
+
+#define AAC_MAX_CHANNELS 8
+/* pcm channgel layout for AAC*/
+static uint32 aacd_1channel_layout[] = {
+    /* FC */
+    UA_CHANNEL_FRONT_CENTER
+};
+
+static uint32 aacd_2channel_layout[] = {
+    /* FL,FR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT
+};
+
+static uint32 aacd_3channel_layout[] = {
+    /* FL,FR,FC */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER
+};
+
+static uint32 aacd_4channel_layout[] = {
+    /* FC,FCL,FCR,BC */
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_FRONT_LEFT_CENTER,
+    UA_CHANNEL_FRONT_RIGHT_CENTER,
+    UA_CHANNEL_REAR_CENTER
+};
+
+static uint32 aacd_5channel_layout[] = {
+    /* FL,FR,FC,BL,BR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT
+};
+
+static uint32 aacd_6channel_layout[] = {
+    /* FL,FR,FC,LFE,BL,BR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_LFE,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT,
+};
+
+static uint32 aacd_8channel_layout[] = {
+    /* FC,LFE,,BL,BR,FCL,FCR,SL,SR */
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_LFE,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT,
+    UA_CHANNEL_FRONT_LEFT_CENTER,
+    UA_CHANNEL_FRONT_RIGHT_CENTER,
+    UA_CHANNEL_SIDE_LEFT,
+    UA_CHANNEL_SIDE_RIGHT
+};
+
+static uint32 * aacd_channel_layouts[] = {
+    NULL,
+    aacd_1channel_layout, // 1
+    aacd_2channel_layout, // 2
+    aacd_3channel_layout,
+    aacd_4channel_layout,
+    aacd_5channel_layout,
+    aacd_6channel_layout,
+    NULL,
+    aacd_8channel_layout,
+};
+
+
+class AacDecodeUtil::IntfImpl : public IMXInterface<void>::BaseParams {
+public:
+    explicit IntfImpl(const std::shared_ptr<C2ReflectorHelper> &helper, C2String componentName)
+        : IMXInterface<void>::BaseParams(
+                helper,
+                componentName,
+                C2Component::KIND_DECODER,
+                C2Component::DOMAIN_AUDIO,
+                MEDIA_MIMETYPE_AUDIO_AAC) {
+        noPrivateBuffers();
+        noInputReferences();
+        noOutputReferences();
+        noInputLatency();
+        noTimeStretch();
+
+        addParameter(
+                DefineParam(mSampleRate, C2_NAME_STREAM_SAMPLE_RATE_SETTING)
+                .withDefault(new C2StreamSampleRateInfo::output(0u, 44100))
+                .withFields({C2F(mSampleRate, value).oneOf({
+                    7350, 8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000, 96000
+                })})
+                .withSetter(Setter<decltype(*mSampleRate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mChannelCount, C2_NAME_STREAM_CHANNEL_COUNT_SETTING)
+                .withDefault(new C2StreamChannelCountInfo::output(0u, 1))
+                .withFields({C2F(mChannelCount, value).inRange(1, 8)})
+                .withSetter(Setter<decltype(*mChannelCount)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mBitrate, C2_NAME_STREAM_BITRATE_SETTING)
+                .withDefault(new C2BitrateTuning::input(0u, 64000))
+                .withFields({C2F(mBitrate, value).inRange(8000, 960000)})
+                .withSetter(Setter<decltype(*mBitrate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mInputMaxBufSize, C2_PARAMKEY_INPUT_MAX_BUFFER_SIZE)
+                .withConstValue(new C2StreamMaxBufferSizeInfo::input(0u, 8192))
+                .build());
+
+        addParameter(
+                DefineParam(mAacFormat, C2_NAME_STREAM_AAC_FORMAT_SETTING)
+                .withDefault(new C2StreamAacFormatInfo::input(0u, C2AacStreamFormatRaw))
+                .withFields({C2F(mAacFormat, value).oneOf({
+                    C2AacStreamFormatRaw, C2AacStreamFormatAdts, C2AacStreamFormatAdif
+                })})
+                .withSetter(Setter<decltype(*mAacFormat)>::StrictValueWithNoDeps)
+                .build());
+/*
+        addParameter(
+                DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+                .withDefault(new C2StreamProfileLevelInfo::input(0u,
+                        C2Config::PROFILE_AAC_LC, C2Config::LEVEL_UNUSED))
+                .withFields({
+                    C2F(mProfileLevel, profile).oneOf({
+                            C2Config::PROFILE_AAC_LC,
+                            C2Config::PROFILE_AAC_HE,
+                            C2Config::PROFILE_AAC_HE_PS,
+                            C2Config::PROFILE_AAC_LD,
+                            C2Config::PROFILE_AAC_ELD,
+                            C2Config::PROFILE_AAC_ER_SCALABLE,
+                            C2Config::PROFILE_AAC_XHE}),
+                    C2F(mProfileLevel, level).oneOf({
+                            C2Config::LEVEL_UNUSED
+                    })
+                })
+                .withSetter(ProfileLevelSetter)
+                .build());
+*/
+    }
+
+    static C2R ProfileLevelSetter(bool mayBlock, C2P<C2StreamProfileLevelInfo::input> &me) {
+        (void)mayBlock;
+        (void)me;  // TODO: validate
+        return C2R::Ok();
+    }
+
+    uint32_t getSampleRate() const { return mSampleRate->value; };
+    uint32_t getChannelCount() const { return mChannelCount->value; };
+    uint32_t getBitrate() const { return mBitrate->value; };
+    C2Config::aac_packaging_t getAacFormat() const { return mAacFormat->value; };
+    void setSampleRate(uint32_t value) { mSampleRate->value = value; };
+    void setChannelCount(uint32_t value) { mChannelCount->value = value; };
+    void setBitrate(uint32_t value) { mBitrate->value = value; };
+    void setAacFormat(C2Config::aac_packaging_t fmt) { mAacFormat->value = fmt; };
+
+private:
+    std::shared_ptr<C2StreamSampleRateInfo::output> mSampleRate;
+    std::shared_ptr<C2StreamChannelCountInfo::output> mChannelCount;
+    std::shared_ptr<C2BitrateTuning::input> mBitrate;
+    std::shared_ptr<C2StreamMaxBufferSizeInfo::input> mInputMaxBufSize;
+    std::shared_ptr<C2StreamAacFormatInfo::input> mAacFormat;
+    std::shared_ptr<C2StreamProfileLevelInfo::input> mProfileLevel;
+};
+
+AacDecodeUtil::AacDecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl)
+    : AudioDecodeUtil(),
+    bFrameChecked(false),
+    mIntf(intfImpl)
+{
+    LOGV("entry %p", this);
+    if(codecName.find("c2.imx.aac.decoder.sw", 0) != std::string::npos){
+        wrapperLibName = "lib_aacd_wrap_arm12_elinux_android.so";
+        optionalWrapperLibName = "lib_aacplusd_wrap_arm12_elinux_android.so";
+    }
+    else if(codecName.find("c2.imx.aac.decoder.hw", 0) != std::string::npos){
+        wrapperLibName = DSP_WRAPPER_LIB_NAME;
+        optionalWrapperLibName = nullptr;
+    }
+    else{
+        // error
+        LOGE("invalid codecName %s", codecName.c_str());
+        wrapperLibName = nullptr;
+        optionalWrapperLibName = nullptr;
+    }
+}
+
+AacDecodeUtil::~AacDecodeUtil()
+{
+    LOGV("entry");
+}
+
+c2_status_t AacDecodeUtil::getLibName(const char ** lib, const char ** optionalLib)
+{
+    LOGV("entry");
+    *lib = wrapperLibName;
+    *optionalLib = optionalWrapperLibName;
+    return C2_OK;
+}
+
+uint32_t AacDecodeUtil::getFrameHdrBufLen()
+{
+    LOGV("entry");
+    return AAC_PUSH_MODE_LEN;
+}
+
+uint32_t AacDecodeUtil::getOutBufferLen()
+{
+    LOGV("entry");
+    return 6*AACD_FRAME_SIZE*2*4;
+}
+
+c2_status_t AacDecodeUtil::checkFrameHeader(unsigned char * pBuffer, size_t length, uint32_t *pOffset)
+{
+    LOGV("entry");
+    uint32_t nActuralLen = 0;
+    uint32_t nVal = 0;
+    AUDIO_FRAME_INFO FrameInfo;
+    memset(&FrameInfo, 0, sizeof(AUDIO_FRAME_INFO));
+
+    if(bFrameChecked){
+        return C2_OK;
+    }
+
+    do{
+        LOGI("data length: %zu
", length);
+
+        nVal = *pBuffer<<24|*(pBuffer+1)<<16|*(pBuffer+2)<<8|*(pBuffer+3);
+
+        if(nVal == ADIF_FILE){
+            LOGD("ADIF_FILE");
+            mFrameInput = false;
+            bFrameChecked = true;
+            mIntf->setAacFormat((C2Config::aac_packaging_t)C2AacStreamFormatAdif);
+            break;
+        }
+
+        if(AFP_SUCCESS != AacCheckFrame(&FrameInfo, pBuffer, length)){
+            LOGD("CHECK FAILED");
+            break;
+        }
+
+        if(FrameInfo.bGotOneFrame){
+            LOGD("ADTS_FILE");
+            mIntf->setAacFormat(C2AacStreamFormatAdts);
+            mFrameInput = false;
+            bFrameChecked = true;
+            break;
+        }
+
+        mIntf->setAacFormat(C2AacStreamFormatRaw);
+        mFrameInput = true;
+        bFrameChecked = true;
+        LOGD("AacFormat Raw");
+    }while(0);
+
+    return C2_OK;
+
+}
+c2_status_t AacDecodeUtil::parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info)
+{
+    LOGV("entry");
+    AUDIO_FRAME_INFO FrameInfo;
+
+    if(pBuffer == nullptr || info == nullptr || len <= 0)
+        return C2_BAD_VALUE;
+
+    memset(&FrameInfo, 0, sizeof(AUDIO_FRAME_INFO));
+
+    if(mIntf->getAacFormat() !=  C2AacStreamFormatRaw){
+        if(AFP_SUCCESS == AacCheckFrame(&FrameInfo, pBuffer, len)){
+            info->bGotOneFrame = FrameInfo.bGotOneFrame;
+            info->nConsumedOffset = FrameInfo.nConsumedOffset;
+            info->nHeaderCount = FrameInfo.nHeaderCount;
+            info->nHeaderSize = FrameInfo.nHeaderSize;
+            info->nFrameSize = FrameInfo.nFrameSize;
+            info->nNextSize = FrameInfo.nNextFrameSize;
+        }
+    }else{
+        info->bGotOneFrame = true;
+        info->nFrameSize = len;
+        info->nNextSize = len/2;
+    }
+
+    return C2_OK;
+
+}
+
+c2_status_t AacDecodeUtil::getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased)
+{
+    LOGV("entry");
+    if (formatType)
+        *formatType = AAC;
+    if (isHwBased)
+        *isHwBased = !strcmp(wrapperLibName, DSP_WRAPPER_LIB_NAME);
+
+    if(*isHwBased)
+        *formatType = AAC_PLUS;
+    return C2_OK;
+}
+
+c2_status_t AacDecodeUtil::handleBOS(uint32_t* offset, uint32_t length) {
+    return C2_OK;
+}
+
+c2_status_t AacDecodeUtil::handleEOS(uint8_t **ppBuffer, uint32_t* length)
+{
+    LOGV("entry");
+    uint32_t padding = 0;
+
+    // pad the end of the stream with one buffer of which the value are all 2(avoid gap/overlap),
+    // since that the actual last buffer isn't sent by aac decoder.
+    padding = AACD_FRAME_SIZE * mIntf->getChannelCount() * sizeof(int16_t);
+    // TODO:
+    //memset(pOutBufferHdr->pBuffer + pOutBufferHdr->nOffset + pOutBufferHdr->nFilledLen, 2, padding);
+    //pOutBufferHdr->nFilledLen += padding;
+
+    return C2_OK;
+}
+
+c2_status_t AacDecodeUtil::setParameter(UA_ParaType index,int32_t value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            LOGV("sample rate %d",value);
+            //mIntf->setSampleRate(value);
+            C2StreamSampleRateInfo::output sampleRateInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &sampleRateInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            LOGV("channel num %d",value);
+            //mIntf->setChannelCount(value);
+            C2StreamChannelCountInfo::output channelCountInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &channelCountInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            LOGV("bitrate %d",value);
+            mIntf->setBitrate(value);
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+}
+
+c2_status_t AacDecodeUtil::getParameter(UA_ParaType index,int32_t * value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    if(value == nullptr){
+        ret = C2_BAD_VALUE;
+        return ret;
+    }
+
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            *value = (int32_t)mIntf->getSampleRate();
+            LOGV("sample rate %d",*value);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            *value = (int32_t)mIntf->getChannelCount();
+            LOGV("channel num %d",*value);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            *value = (int32_t)mIntf->getBitrate();
+            LOGV("bitrate %d",*value);
+            break;
+        }
+        case UNIA_STREAM_TYPE:
+        {
+            C2Config::aac_packaging_t fmt = mIntf->getAacFormat();
+            if(fmt == C2AacStreamFormatAdts){
+                *value = STREAM_ADTS;
+            }else if(fmt == (C2Config::aac_packaging_t)C2AacStreamFormatAdif){
+                *value = STREAM_ADIF;
+            }else if(fmt == C2AacStreamFormatRaw){
+                *value = STREAM_RAW;
+                mFrameInput = true;
+            }else{
+                *value = STREAM_UNKNOW;
+            }
+            LOGV("stream type %s",*value == STREAM_RAW ?"RAW":(*value == STREAM_ADTS?"ADTS"\
+                :(*value == STREAM_ADIF?"ADIF":"UNKNOWN")));
+            break;
+        }
+        case UNIA_FRAMED:
+        {
+            *value = true;
+            LOGV("framed %d",*value);
+            break;
+        }
+        case UNIA_CHAN_MAP_TABLE:
+        {
+            CHAN_TABLE table;
+            memset(&table,0,sizeof(table));
+            table.size = AAC_MAX_CHANNELS;
+            memcpy(&table.channel_table,aacd_channel_layouts,sizeof(aacd_channel_layouts));
+            memcpy(value,&table,sizeof(CHAN_TABLE));
+            LOGV("map table");
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+
+}
+
+size_t AacDecodeUtil::getPushModeInputLen()
+{
+    return AAC_PUSH_MODE_LEN;
+}
+
+
+class IMXC2AacDecFactory : public C2ComponentFactory {
+public:
+    IMXC2AacDecFactory(C2String name) : mHelper(std::static_pointer_cast<C2ReflectorHelper>(
+            GetImxC2Store()->getParamReflector()))
+    {
+            if(!name.empty())
+                mCodecName.assign(name);
+            else
+                mCodecName.assign("c2.imx.aac.decoder.sw");
+    }
+
+    virtual c2_status_t createComponent(
+            c2_node_id_t id,
+            std::shared_ptr<C2Component>* const component,
+            std::function<void(C2Component*)> deleter) override {
+
+            auto impl = std::make_shared<AacDecodeUtil::IntfImpl>(mHelper, mCodecName.c_str());
+            AacDecodeUtil * pAacUtil = new AacDecodeUtil(mCodecName, impl);
+
+        *component = std::shared_ptr<C2Component>(
+                new UniaDecoder(std::make_shared<IMXC2Interface<AacDecodeUtil::IntfImpl>>(mCodecName.c_str(), id, impl),
+                                            pAacUtil),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual c2_status_t createInterface(
+            c2_node_id_t id, std::shared_ptr<C2ComponentInterface>* const interface,
+            std::function<void(C2ComponentInterface*)> deleter) override {
+        *interface = std::shared_ptr<C2ComponentInterface>(
+                new IMXC2Interface<AacDecodeUtil::IntfImpl>(
+                        mCodecName, id, std::make_shared<AacDecodeUtil::IntfImpl>(mHelper, mCodecName.c_str())),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual ~IMXC2AacDecFactory() override = default;
+
+private:
+    std::shared_ptr<C2ReflectorHelper> mHelper;
+    std::string mCodecName;
+};
+
+}  // namespace android
+
+extern "C" ::C2ComponentFactory* IMXCreateCodec2Factory(C2String name) {
+    LOGV("entry codecName %s", name.c_str());
+    return new ::android::IMXC2AacDecFactory(name);
+}
+
+extern "C" void IMXDestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+/*
+extern "C" ::C2ComponentFactory* CreateCodec2Factory() {
+    LOGV("entry");
+    return new ::android::IMXC2AacDecFactory(nullptr);
+}
+
+extern "C" void DestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+*/
diff --git a/codec2/audio_dec/aac_dec/AacDecodeUtil.h b/codec2/audio_dec/aac_dec/AacDecodeUtil.h
new file mode 100755
index 0000000..39e6dde
--- /dev/null
+++ b/codec2/audio_dec/aac_dec/AacDecodeUtil.h
@@ -0,0 +1,43 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef AAC_DECODE_UTIL_h
+#define AAC_DECODE_UTIL_h
+
+#include <AudioDecodeUtil.h>
+
+namespace android {
+
+class AacDecodeUtil  : public AudioDecodeUtil {
+    public:
+        class IntfImpl;
+
+        AacDecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl);
+        virtual ~AacDecodeUtil();
+        virtual c2_status_t getLibName(const char ** lib, const char ** optionalLib) override;
+        virtual uint32_t getFrameHdrBufLen() override;
+        virtual uint32_t getOutBufferLen() override;
+        virtual c2_status_t checkFrameHeader(unsigned char * pBuffer, size_t length, uint32_t *pOffset) override;
+        virtual c2_status_t parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info) override;
+        virtual c2_status_t getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased) override;
+        virtual c2_status_t handleBOS(uint32_t* offset, uint32_t length) override;
+        virtual c2_status_t handleEOS(uint8_t **ppBuffer, uint32_t* length) override;
+        virtual c2_status_t setParameter(UA_ParaType index,int32_t value) override;
+        virtual c2_status_t getParameter(UA_ParaType index,int32_t * value) override;
+        virtual size_t getPushModeInputLen() override;
+
+    private:
+        bool bFrameChecked;
+        std::shared_ptr<IntfImpl> mIntf;
+
+};
+
+}
+#endif
+
+
diff --git a/codec2/audio_dec/aac_dec/Android.bp b/codec2/audio_dec/aac_dec/Android.bp
new file mode 100644
index 0000000..07f168a
--- /dev/null
+++ b/codec2/audio_dec/aac_dec/Android.bp
@@ -0,0 +1,45 @@
+cc_library_shared {
+    name: "lib_c2_imx_aac_dec",
+
+    srcs: [
+        "AacDecodeUtil.cpp",
+    ],
+
+    include_dirs: [
+        "vendor/nxp/imx_android_mm/codec2/base/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/fsl-codec/ghdr/common",
+        "hardware/google/av/codec2/include",
+        "system/core/include",
+        "hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+    ],
+
+    local_include_dirs: [
+        ".",
+    ],
+
+    export_include_dirs: [
+        ".",
+    ],
+
+    header_libs: [
+        "libsystem_headers",
+    ],
+
+    shared_libs: [
+        "lib_c2_imx_audio_dec_common",
+        "lib_imx_c2_componentbase",
+        "liblog",
+        "libcodec2_vndk",
+        "libstagefright_foundation",
+        "lib_c2_imx_store",
+    ],
+
+    ldflags: ["-Wl,-Bsymbolic"],
+
+    defaults: [
+        "imx_defaults",
+    ],
+    //compile_multilib: "32",
+}
diff --git a/codec2/audio_dec/ac3_dec/Ac3DecodeUtil.cpp b/codec2/audio_dec/ac3_dec/Ac3DecodeUtil.cpp
new file mode 100755
index 0000000..e6a5aa0
--- /dev/null
+++ b/codec2/audio_dec/ac3_dec/Ac3DecodeUtil.cpp
@@ -0,0 +1,356 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "Ac3DecUtil"
+#include <log/log.h>
+
+#include "Ac3FrameParser.h"
+
+#include <C2Config_imx.h>
+#include <IMXC2Interface.h>
+#include <media/stagefright/foundation/MediaDefs.h>
+#include <UniaDecoder.h>
+#include <C2ComponentFactory.h>
+#include <C2PlatformSupport.h>
+
+#include "Ac3DecodeUtil.h"
+
+namespace android {
+
+#define AC3D_FRAME_SIZE  1536
+#define AC3_PUSH_MODE_LEN (3840+8)//max frame size + another frame header size
+
+class Ac3DecodeUtil::IntfImpl : public IMXInterface<void>::BaseParams  {
+public:
+    explicit IntfImpl(const std::shared_ptr<C2ReflectorHelper> &helper, C2String componentName)
+        : IMXInterface<void>::BaseParams(
+                helper,
+                componentName,
+                C2Component::KIND_DECODER,
+                C2Component::DOMAIN_AUDIO,
+                MEDIA_MIMETYPE_AUDIO_AC3){
+        noPrivateBuffers(); // TODO: account for our buffers here
+        noInputReferences();
+        noOutputReferences();
+        noInputLatency();
+        noTimeStretch();
+
+        addParameter(
+                DefineParam(mAttrib, C2_PARAMKEY_COMPONENT_ATTRIBUTES)
+                .withConstValue(new C2ComponentAttributesSetting(
+                    C2Component::ATTRIB_IS_TEMPORAL))
+                .build());
+
+        addParameter(
+                DefineParam(mSampleRate, C2_NAME_STREAM_SAMPLE_RATE_SETTING)
+                .withDefault(new C2StreamSampleRateInfo::output(0u, 44100))
+                .withFields({C2F(mSampleRate, value).oneOf({
+                    32000, 44100, 48000
+                })})
+                .withSetter(Setter<decltype(*mSampleRate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mChannelCount, C2_NAME_STREAM_CHANNEL_COUNT_SETTING)
+                .withDefault(new C2StreamChannelCountInfo::output(0u, 1))
+                .withFields({C2F(mChannelCount, value).inRange(1, 8)})
+                .withSetter(Setter<decltype(*mChannelCount)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mBitrate, C2_NAME_STREAM_BITRATE_SETTING)
+                .withDefault(new C2BitrateTuning::input(0u, 64000))
+                .withFields({C2F(mBitrate, value).inRange(8000, 960000)})
+                .withSetter(Setter<decltype(*mBitrate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mInputMaxBufSize, C2_PARAMKEY_INPUT_MAX_BUFFER_SIZE)
+                .withConstValue(new C2StreamMaxBufferSizeInfo::input(0u, 8192))
+                .build());
+
+    }
+
+    uint32_t getSampleRate() const { return mSampleRate->value; };
+    uint32_t getChannelCount() const { return mChannelCount->value; };
+    uint32_t getBitrate() const { return mBitrate->value; };
+    void setSampleRate(uint32_t value) { mSampleRate->value = value; };
+    void setChannelCount(uint32_t value) { mChannelCount->value = value; };
+    void setBitrate(uint32_t value) { mBitrate->value = value; };
+
+private:
+    std::shared_ptr<C2StreamSampleRateInfo::output> mSampleRate;
+    std::shared_ptr<C2StreamChannelCountInfo::output> mChannelCount;
+    std::shared_ptr<C2BitrateTuning::input> mBitrate;
+    std::shared_ptr<C2StreamMaxBufferSizeInfo::input> mInputMaxBufSize;
+};
+
+Ac3DecodeUtil::Ac3DecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl)
+    : AudioDecodeUtil(),
+    bFrameChecked(false),
+    mIntf(intfImpl)
+{
+    LOGV("entry %p", this);
+    if(codecName.find("c2.imx.ac3.decoder.sw", 0) != std::string::npos){
+        wrapperLibName = "lib_ac3d_wrap_arm11_elinux_android.so";
+        optionalWrapperLibName = "lib_ac3d_wrap_arm_android.so"; // 64 bits
+    }
+    else{
+        // error
+        LOGE("invalid codecName %s", codecName.c_str());
+        wrapperLibName = nullptr;
+        optionalWrapperLibName = nullptr;
+    }
+}
+
+Ac3DecodeUtil::~Ac3DecodeUtil()
+{
+    LOGV("entry");
+}
+
+c2_status_t Ac3DecodeUtil::getLibName(const char ** lib, const char ** optionalLib)
+{
+    LOGV("entry");
+    *lib = wrapperLibName;
+    *optionalLib = optionalWrapperLibName;
+    return C2_OK;
+}
+
+uint32_t Ac3DecodeUtil::getFrameHdrBufLen()
+{
+    LOGV("entry");
+    return AC3_PUSH_MODE_LEN;
+}
+
+uint32_t Ac3DecodeUtil::getOutBufferLen()
+{
+    LOGV("entry");
+    return 256*6*6*sizeof(int32);
+}
+
+c2_status_t Ac3DecodeUtil::checkFrameHeader(unsigned char * pBuffer, size_t length, uint32_t *pOffset)
+{
+    LOGV("entry");
+    uint32_t nVal = 0;
+    AUDIO_FRAME_INFO FrameInfo;
+    bool bFound = false;
+    memset(&FrameInfo, 0, sizeof(AUDIO_FRAME_INFO));
+
+    if(bFrameChecked){
+        return C2_OK;
+    }
+
+    do{
+        //LOGI("Get stream length: %zu
", length);
+
+        if(AFP_SUCCESS != Ac3CheckFrame(&FrameInfo, pBuffer, length)){
+            LOGD("CHECK FAILED");
+            break;
+        }
+
+        if(FrameInfo.bGotOneFrame){
+            bFound = true;
+            LOGD("get one frame");
+        }
+
+        uint32_t nOffset = FrameInfo.nConsumedOffset;
+
+        if(nOffset < length)
+            LOGD("buffer=%02x%02x%02x%02x",pBuffer[nOffset],pBuffer[nOffset+1],pBuffer[nOffset+2],pBuffer[nOffset+1]);
+
+        *pOffset = nOffset;
+
+        if(bFound)
+            return C2_OK;
+    }while(0);
+
+    return C2_NOT_FOUND;
+
+}
+
+c2_status_t Ac3DecodeUtil::parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info)
+{
+    LOGV("entry");
+    return C2_OK;
+}
+
+c2_status_t Ac3DecodeUtil::getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased)
+{
+    LOGV("entry");
+    if (formatType)
+        *formatType = AC3;
+    if (isHwBased)
+        *isHwBased = false;
+
+    return C2_OK;
+}
+
+c2_status_t Ac3DecodeUtil::handleBOS(uint32_t* offset, uint32_t length) {
+    return C2_OK;
+}
+
+c2_status_t Ac3DecodeUtil::handleEOS(uint8_t **ppBuffer, uint32_t* length)
+{
+    return C2_OK;
+}
+
+c2_status_t Ac3DecodeUtil::setParameter(UA_ParaType index,int32_t value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            LOGV("sample rate %d",value);
+            //mIntf->setSampleRate(value);
+            C2StreamSampleRateInfo::output sampleRateInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &sampleRateInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            LOGV("channel num %d",value);
+            //mIntf->setChannelCount(value);
+            C2StreamChannelCountInfo::output channelCountInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &channelCountInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            LOGV("bitrate %d",value);
+            mIntf->setBitrate(value);
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+}
+
+c2_status_t Ac3DecodeUtil::getParameter(UA_ParaType index,int32_t * value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    if(value == nullptr){
+        ret = C2_BAD_VALUE;
+        return ret;
+    }
+
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            *value = (int32_t)mIntf->getSampleRate();
+            LOGV("sample rate %d",*value);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            *value = (int32_t)mIntf->getChannelCount();
+            LOGV("channel num %d",*value);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            *value = (int32_t)mIntf->getBitrate();
+            LOGV("bitrate %d",*value);
+            break;
+        }
+        case UNIA_FRAMED:
+        {
+            *value = true;
+            LOGV("framed %d",*value);
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+
+}
+
+size_t Ac3DecodeUtil::getPushModeInputLen()
+{
+    return AC3_PUSH_MODE_LEN;
+}
+
+
+class IMXC2Ac3DecFactory : public C2ComponentFactory {
+public:
+    IMXC2Ac3DecFactory(C2String name) : mHelper(std::static_pointer_cast<C2ReflectorHelper>(
+            GetImxC2Store()->getParamReflector()))
+    {
+            if(!name.empty())
+                mCodecName.assign(name);
+            else
+                mCodecName.assign("c2.imx.ac3.decoder.sw");
+    }
+
+    virtual c2_status_t createComponent(
+            c2_node_id_t id,
+            std::shared_ptr<C2Component>* const component,
+            std::function<void(C2Component*)> deleter) override {
+
+            auto impl = std::make_shared<Ac3DecodeUtil::IntfImpl>(mHelper, mCodecName.c_str());
+            Ac3DecodeUtil * pAc3Util = new Ac3DecodeUtil(mCodecName, impl);
+
+        *component = std::shared_ptr<C2Component>(
+                new UniaDecoder(std::make_shared<IMXC2Interface<Ac3DecodeUtil::IntfImpl>>(mCodecName.c_str(), id, impl),
+                                            pAc3Util),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual c2_status_t createInterface(
+            c2_node_id_t id, std::shared_ptr<C2ComponentInterface>* const interface,
+            std::function<void(C2ComponentInterface*)> deleter) override {
+        *interface = std::shared_ptr<C2ComponentInterface>(
+                new IMXInterface<Ac3DecodeUtil::IntfImpl>(
+                        mCodecName, id, std::make_shared<Ac3DecodeUtil::IntfImpl>(mHelper, mCodecName.c_str())),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual ~IMXC2Ac3DecFactory() override = default;
+
+private:
+    std::shared_ptr<C2ReflectorHelper> mHelper;
+    std::string mCodecName;
+};
+
+}  // namespace android
+
+extern "C" ::C2ComponentFactory* IMXCreateCodec2Factory(C2String name) {
+    LOGV("entry codecName %s", name.c_str());
+    return new ::android::IMXC2Ac3DecFactory(name);
+}
+
+extern "C" void IMXDestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+/*
+extern "C" ::C2ComponentFactory* CreateCodec2Factory() {
+    LOGV("entry");
+    return new ::android::IMXC2AacDecFactory(nullptr);
+}
+
+extern "C" void DestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+*/
diff --git a/codec2/audio_dec/ac3_dec/Ac3DecodeUtil.h b/codec2/audio_dec/ac3_dec/Ac3DecodeUtil.h
new file mode 100755
index 0000000..309e99d
--- /dev/null
+++ b/codec2/audio_dec/ac3_dec/Ac3DecodeUtil.h
@@ -0,0 +1,43 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef AC3_DECODE_UTIL_h
+#define AC3_DECODE_UTIL_h
+
+#include <AudioDecodeUtil.h>
+
+namespace android {
+
+class Ac3DecodeUtil  : public AudioDecodeUtil {
+    public:
+        class IntfImpl;
+
+        Ac3DecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl);
+        virtual ~Ac3DecodeUtil();
+        virtual c2_status_t getLibName(const char ** lib, const char ** optionalLib) override;
+        virtual uint32_t getFrameHdrBufLen() override;
+        virtual uint32_t getOutBufferLen() override;
+        virtual c2_status_t checkFrameHeader(unsigned char * pBuffer, size_t length, uint32_t *pOffset) override;
+        virtual c2_status_t parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info) override;
+        virtual c2_status_t getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased) override;
+        virtual c2_status_t handleBOS(uint32_t* offset, uint32_t length) override;
+        virtual c2_status_t handleEOS(uint8_t **ppBuffer, uint32_t* length) override;
+        virtual c2_status_t setParameter(UA_ParaType index,int32_t value) override;
+        virtual c2_status_t getParameter(UA_ParaType index,int32_t * value) override;
+        virtual size_t getPushModeInputLen() override;
+
+    private:
+        bool bFrameChecked;
+        std::shared_ptr<IntfImpl> mIntf;
+
+};
+
+}
+#endif
+
+
diff --git a/codec2/audio_dec/ac3_dec/Android.bp b/codec2/audio_dec/ac3_dec/Android.bp
new file mode 100644
index 0000000..4921038
--- /dev/null
+++ b/codec2/audio_dec/ac3_dec/Android.bp
@@ -0,0 +1,45 @@
+cc_library_shared {
+    name: "lib_c2_imx_ac3_dec",
+
+    srcs: [
+        "Ac3DecodeUtil.cpp",
+    ],
+
+    include_dirs: [
+        "vendor/nxp/imx_android_mm/codec2/base/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/fsl-codec/ghdr/common",
+        "hardware/google/av/codec2/include",
+        "system/core/include",
+        "hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+    ],
+
+    local_include_dirs: [
+        ".",
+    ],
+
+    export_include_dirs: [
+        ".",
+    ],
+
+    header_libs: [
+        "libsystem_headers",
+    ],
+
+    shared_libs: [
+        "lib_c2_imx_audio_dec_common",
+        "lib_imx_c2_componentbase",
+        "liblog",
+        "libcodec2_vndk",
+        "libstagefright_foundation",
+        "lib_c2_imx_store",
+    ],
+
+    ldflags: ["-Wl,-Bsymbolic"],
+
+    defaults: [
+        "imx_defaults",
+    ],
+    //compile_multilib: "32",
+}
diff --git a/codec2/audio_dec/common/Android.bp b/codec2/audio_dec/common/Android.bp
new file mode 100644
index 0000000..8f6cd78
--- /dev/null
+++ b/codec2/audio_dec/common/Android.bp
@@ -0,0 +1,46 @@
+cc_library_shared {
+    name: "lib_c2_imx_audio_dec_common",
+
+    srcs: [
+        "AudioTSManager.cpp",
+        "IMXAudioDecComponent.cpp",
+        "RingBuffer.cpp",
+        "UniaDecoder.cpp",
+        "audio_frame_parser/AacFrameParser.c",
+        "audio_frame_parser/Mp3FrameParser.c",
+        "audio_frame_parser/Ac3FrameParser.c",
+        "audio_frame_parser/AudioFrameParser.c",
+    ],
+
+    include_dirs: [
+        "vendor/nxp/imx_android_mm/codec2/base/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/fsl-codec/ghdr/common",
+        "hardware/google/av/codec2/include",
+        "system/core/include",
+        "hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+    ],
+
+    //local_include_dirs: [
+    //    ".",
+    //    "audio_frame_parser",
+    //],
+
+    export_include_dirs: [
+        ".",
+        "audio_frame_parser",
+    ],
+
+    shared_libs: [
+        "liblog",
+        "lib_imx_c2_componentbase",
+        "libcodec2_vndk",
+    ],
+
+    ldflags: ["-Wl,-Bsymbolic"],
+
+    defaults: [
+        "imx_defaults",
+    ],
+}
diff --git a/codec2/audio_dec/common/AudioDecodeUtil.h b/codec2/audio_dec/common/AudioDecodeUtil.h
new file mode 100755
index 0000000..3c1c72f
--- /dev/null
+++ b/codec2/audio_dec/common/AudioDecodeUtil.h
@@ -0,0 +1,52 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef AUDIO_DECODE_UTIL_h
+#define AUDIO_DECODE_UTIL_h
+
+#include <C2.h>
+#include <C2_imx.h>
+#include <fsl_unia.h>
+
+namespace android {
+
+struct UniaDecFrameInfo;
+
+class AudioDecodeUtil {
+    public:
+        AudioDecodeUtil():mFrameInput(false){};
+        virtual c2_status_t getLibName(const char ** lib, const char ** optionalLib) = 0;
+        virtual uint32_t getFrameHdrBufLen(){ return 0;};
+        virtual uint32_t getOutBufferLen() = 0;
+        virtual c2_status_t checkFrameHeader(unsigned char * pBuffer, size_t length, uint32_t *pOffset){
+            return C2_OK;
+        };
+        virtual c2_status_t parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info){
+            return C2_OMITTED;
+        };
+        virtual c2_status_t getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased) = 0;
+        virtual c2_status_t handleBOS(uint32_t* offset, uint32_t length) = 0;
+        virtual c2_status_t handleEOS(uint8_t **ppBuffer, uint32_t* length) = 0;
+        virtual c2_status_t setParameter(UA_ParaType index,int32_t value) = 0;
+        virtual c2_status_t getParameter(UA_ParaType index,int32_t * value) = 0;
+        bool isFrameInput() { return mFrameInput; };
+        virtual c2_status_t checkParameter() { return C2_OK; };
+        virtual size_t getPushModeInputLen(){ return 2048;};
+
+        virtual ~AudioDecodeUtil(){ };
+
+    protected:
+        const char * wrapperLibName;
+        const char * optionalWrapperLibName;
+        bool mFrameInput;
+
+};
+
+}
+#endif
+
diff --git a/codec2/audio_dec/common/AudioTSManager.cpp b/codec2/audio_dec/common/AudioTSManager.cpp
new file mode 100755
index 0000000..46c747b
--- /dev/null
+++ b/codec2/audio_dec/common/AudioTSManager.cpp
@@ -0,0 +1,239 @@
+/**
+ *  Copyright (c) 2012, Freescale Semiconductor Inc.,
+ *  Copyright 2017 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "AudioTSMgr"
+#include <log/log.h>
+
+#include <stdio.h>
+#include <dlfcn.h>
+#include <malloc.h>
+#include "AudioTSManager.h"
+#include <C2_imx.h>
+
+AudioTSManager::AudioTSManager()
+{
+    TS_Queue = nullptr;
+    CurrentTS = 0;
+    PreTS = -1;
+    bHaveTS = false;
+    TotalConsumeLen = 0;
+    TotalReceivedLen = 0;
+    nOneByteTime = 0;
+}
+
+AUDIO_TS_MANAGER_ERRORTYPE AudioTSManager::Create()
+{
+    AUDIO_TS_MANAGER_ERRORTYPE ret = AUDIO_TS_MANAGER_SUCCESS;
+
+    /** Create queue for TS. */
+    TS_Queue = new List<TS_ITEM>();
+    if (!TS_Queue)
+    {
+        LOGE("Can't get memory.
");
+        return AUDIO_TS_MANAGER_INSUFFICIENT_RESOURCES;
+    }
+
+    CurrentTS = 0;
+    PreTS = -1;
+    bHaveTS = false;
+    TotalConsumeLen = 0;
+    TotalReceivedLen = 0;
+
+    return ret;
+}
+
+AUDIO_TS_MANAGER_ERRORTYPE AudioTSManager::SetOneByteTime(uint32_t OneByteTime)
+{
+    AUDIO_TS_MANAGER_ERRORTYPE ret = AUDIO_TS_MANAGER_SUCCESS;
+    nOneByteTime = OneByteTime;
+    return ret;
+}
+
+AUDIO_TS_MANAGER_ERRORTYPE AudioTSManager::Reset()
+{
+    AUDIO_TS_MANAGER_ERRORTYPE ret = AUDIO_TS_MANAGER_SUCCESS;
+
+    if(TS_Queue){
+        while (TS_Queue->GetNodeCnt() > 0)
+        {
+            TS_ITEM *TS_Item = TS_Queue->GetNode(0);
+            if(!TS_Item || TS_Queue->Remove(TS_Item) != LIST_SUCCESS)
+            {
+                LOGE("Can't remove audio TS item.
");
+                return AUDIO_TS_MANAGER_FAILURE;
+            }
+            free(TS_Item);
+        }
+    }
+
+    CurrentTS = 0;
+    PreTS = -1;
+    bHaveTS = false;
+    TotalConsumeLen = 0;
+    TotalReceivedLen = 0;
+
+    return ret;
+}
+
+AUDIO_TS_MANAGER_ERRORTYPE AudioTSManager::Free()
+{
+    AUDIO_TS_MANAGER_ERRORTYPE ret = AUDIO_TS_MANAGER_SUCCESS;
+
+    if(TS_Queue){
+        delete TS_Queue;
+        TS_Queue = nullptr;
+    }
+    LOGD("TS queue deleted
");
+
+    return ret;
+}
+
+AUDIO_TS_MANAGER_ERRORTYPE AudioTSManager::TS_Add(int64_t ts, uint32_t BufferLen)
+{
+    AUDIO_TS_MANAGER_ERRORTYPE ret = AUDIO_TS_MANAGER_SUCCESS;
+    TS_ITEM *TS_Item = nullptr;
+
+    do {
+        // Core parser EOS.
+        // Core parser will output same audio time stamp if the audio data in
+        // same trunk.
+        if (ts < 0 \
+                || (ts == 0 && BufferLen == 0) \
+                || ts == PreTS)
+        {
+            TotalReceivedLen += BufferLen;
+            break;
+        }
+
+        TS_Item = (TS_ITEM*)malloc(sizeof(TS_ITEM));
+
+        TS_Item->ts = ts;
+        PreTS = ts;
+        /** Should add TS first after received buffer from input port */
+        TS_Item->begin = TotalReceivedLen;
+    
+        if(TS_Queue->GetNodeCnt() >= TS_QUEUE_SIZE){
+            LOGE("Queue overflow, can't add TS item, max queue size: %d 
", TS_QUEUE_SIZE);
+            ret = AUDIO_TS_MANAGER_FAILURE;
+            break;
+        }
+
+        if (TS_Queue->Add(TS_Item) != LIST_SUCCESS) {
+            LOGE("Can't add TS item to audio ts queue. 
");
+            ret = AUDIO_TS_MANAGER_FAILURE;
+            break;
+        }
+
+        TotalReceivedLen += BufferLen;
+        LOGV("item(ts: %lld, begin: %lld), BufferLen %d, TotalReceivedLen %lld
", (long long)TS_Item->ts, 
+            (long long)TS_Item->begin, BufferLen,(long long)TotalReceivedLen);
+        
+    }while (0);
+
+    if(ret != AUDIO_TS_MANAGER_SUCCESS && TS_Item)
+        free(TS_Item);
+
+    return ret;
+}
+
+AUDIO_TS_MANAGER_ERRORTYPE AudioTSManager::TS_Get(int64_t *ts)
+{
+    AUDIO_TS_MANAGER_ERRORTYPE ret = AUDIO_TS_MANAGER_SUCCESS;
+    *ts = CurrentTS;
+    LOGV("Get CurrentTS = %lld
", (long long)CurrentTS);
+    return ret;
+}
+
+AUDIO_TS_MANAGER_ERRORTYPE AudioTSManager::TS_SetIncrease(int64_t ts)
+{
+    AUDIO_TS_MANAGER_ERRORTYPE ret = AUDIO_TS_MANAGER_SUCCESS;
+    if (bHaveTS == false) {
+        CurrentTS += ts;
+        LOGV("ts %lld, update CurrentTS to %lld
", (long long)ts, (long long)CurrentTS);
+    }
+    else{
+        LOGV("ts %lld, do nothing
", (long long)ts);
+    }
+    bHaveTS = false;
+    return ret;
+}
+
+uint32_t AudioTSManager::GetFrameLen()
+{
+    TS_ITEM *TS_Item = TS_Queue->GetNode(0);
+    uint32_t nFrameLen = 0;
+
+    if (!TS_Item) {
+        LOGV("Can't get first audio TS item.
");
+        return TotalReceivedLen - TotalConsumeLen;
+    }
+
+    nFrameLen = TS_Item->begin - TotalConsumeLen;
+    LOGV("item(ts: %lld, begin: %lld), TotalConsumeLen: %lld => nFrameLen %d
", 
+        (long long)TS_Item->ts, (long long)TS_Item->begin, (long long)TotalConsumeLen, nFrameLen);
+
+    //free(TS_Item);
+    return nFrameLen;
+}
+
+AUDIO_TS_MANAGER_ERRORTYPE AudioTSManager::Consumed(uint32_t ConsumedLen)
+{
+        AUDIO_TS_MANAGER_ERRORTYPE ret = AUDIO_TS_MANAGER_SUCCESS;
+
+	if (TotalReceivedLen < TotalConsumeLen + ConsumedLen) {
+		LOGE("audio ts manager consumer point set error.
");
+		return AUDIO_TS_MANAGER_FAILURE;
+	}
+
+	TotalConsumeLen += ConsumedLen;
+        LOGV("len %d, TotalConsumeLen %lld", ConsumedLen, (long long)TotalConsumeLen);
+
+	if (TS_Queue->GetNodeCnt() < 1){
+            LOGW("no ts item!");
+            return ret;
+       }
+
+	/** Adjust current TS */
+	TS_ITEM *TS_Item;
+
+	while (1) {
+            TS_Item = TS_Queue->GetNode(0);
+            if (!TS_Item) {
+                LOGV("Can't get first audio TS item.
");
+                return AUDIO_TS_MANAGER_SUCCESS;
+            }
+
+            if (TotalConsumeLen >= TS_Item->begin) {
+                CurrentTS = TS_Item->ts;
+                if (nOneByteTime) {
+                    CurrentTS += (TotalConsumeLen - TS_Item->begin) \
+                                 * nOneByteTime;
+                    LOGV("update CurrentTS to %lld by nOneByteTime", (long long)CurrentTS);
+                }
+                bHaveTS = true;
+
+                LOGV("bHaveTS, remove item(ts(CurrentTS) %lld, begin %lld)",(long long)TS_Item->ts,(long long)TS_Item->begin);
+
+                if (TS_Queue->Remove(TS_Item) != LIST_SUCCESS) {
+                    LOGE("Can't get audio TS item.
");
+                    return AUDIO_TS_MANAGER_FAILURE;
+                }
+                else
+                    free(TS_Item);
+            }
+            else
+                break;
+	}
+
+	return ret;
+}
+
+/* File EOF */
diff --git a/codec2/audio_dec/common/AudioTSManager.h b/codec2/audio_dec/common/AudioTSManager.h
new file mode 100755
index 0000000..d41ce89
--- /dev/null
+++ b/codec2/audio_dec/common/AudioTSManager.h
@@ -0,0 +1,62 @@
+/**
+ *  Copyright (c) 2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+/**
+ *  @file AudioTSManager.h
+ *  @brief Class definition of audio time stamp manager.
+ *  @ingroup AudioTSManager
+ */
+
+
+#ifndef AudioTSManager_h
+#define AudioTSManager_h
+
+#define TS_QUEUE_SIZE (1024*20)
+
+#include <List.h>
+
+typedef enum {
+    AUDIO_TS_MANAGER_SUCCESS,
+    AUDIO_TS_MANAGER_FAILURE,
+    AUDIO_TS_MANAGER_INSUFFICIENT_RESOURCES
+}AUDIO_TS_MANAGER_ERRORTYPE;
+
+typedef struct _TS_ITEM{
+    int64_t ts;
+    int64_t begin;
+}TS_ITEM;
+
+class AudioTSManager {
+	public:
+		AudioTSManager();
+		AUDIO_TS_MANAGER_ERRORTYPE Create();
+        AUDIO_TS_MANAGER_ERRORTYPE SetOneByteTime(uint32_t OneByteTime);
+        AUDIO_TS_MANAGER_ERRORTYPE Free();
+		AUDIO_TS_MANAGER_ERRORTYPE Reset();
+		AUDIO_TS_MANAGER_ERRORTYPE TS_Add(int64_t ts, uint32_t BufferLen);
+		/** Set TS increase after decode one of audio data */
+		AUDIO_TS_MANAGER_ERRORTYPE TS_SetIncrease(int64_t ts);
+		/** Get TS for output audio data of audio decoder. The output TS is calculated for
+		 every frame of audio data */
+		AUDIO_TS_MANAGER_ERRORTYPE TS_Get(int64_t *ts);
+		uint32_t GetFrameLen();
+		/** Set consumered point for ring buffer. */
+		AUDIO_TS_MANAGER_ERRORTYPE Consumed(uint32_t ConsumeredLen);
+	private:
+		List<TS_ITEM> *TS_Queue;
+		int64_t CurrentTS;
+		int64_t PreTS;
+		bool bHaveTS;
+		int64_t TotalConsumeLen;
+		int64_t TotalReceivedLen;
+               uint32_t nOneByteTime;
+};
+
+#endif
+/* File EOF */
diff --git a/codec2/audio_dec/common/IMXAudioDecComponent.cpp b/codec2/audio_dec/common/IMXAudioDecComponent.cpp
new file mode 100755
index 0000000..c9f58cb
--- /dev/null
+++ b/codec2/audio_dec/common/IMXAudioDecComponent.cpp
@@ -0,0 +1,776 @@
+/**
+ *  Copyright 2019,2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "AudDecComp"
+#include "IMXAudioDecComponent.h"
+#include <C2Buffer.h>
+#include <sys/stat.h>
+#include <stdio.h>
+#include <numeric>
+
+#define MAX(a,b) ((a)>=(b)?(a):(b))
+
+namespace android {
+
+IMXAudioDecComponent::IMXAudioDecComponent(const std::shared_ptr<C2ComponentInterface> &intf)
+: IMXC2ComponentBase(intf),
+    bConvertEnable(true),
+    ePlayMode(DEC_FILE_MODE),
+    bFirstOutput(true),
+    fpOutput(nullptr),
+    frameIndex(0)
+{
+    LOGV("entry %p", this);
+}
+
+IMXAudioDecComponent::~IMXAudioDecComponent()
+{
+    LOGV("entry");
+    if(fpOutput != nullptr)
+        fclose(fpOutput);
+}
+
+c2_status_t IMXAudioDecComponent::onInit()
+{
+    LOGV("entry");
+    RINGBUFFER_ERRORTYPE BufferRet = RINGBUFFER_SUCCESS;
+    BufferRet = AudioRingBuffer.BufferCreate(nPushModeInputLen, nRingBufferScale);
+    if (BufferRet != RINGBUFFER_SUCCESS)
+    {
+    	LOGE("Create ring buffer fail.
");
+    	return C2_NO_MEMORY;
+    }
+    LOGD("Ring buffer nPushModeInputLen %d
", nPushModeInputLen);
+
+    AUDIO_TS_MANAGER_ERRORTYPE Ret = AUDIO_TS_MANAGER_SUCCESS;
+    Ret = TS_Manager.Create();
+    if (Ret != AUDIO_TS_MANAGER_SUCCESS)
+    {
+    	LOGE("Create audio ts manager fail.
");
+    	return C2_NO_MEMORY;
+    }
+
+    bReceivedEOS = false;
+    bCodecInit = false;
+    bDecoderEOS = false;
+    bDecoderInitFail = false;
+    bFirstInBuffer = true;
+    bFirstOutput = true;
+    nRequiredSize = 0;
+    nOutputBitPerSample = 16;
+    pConvertBuffer = nullptr;
+    nConvertBufferSize = 200000;
+    bCheckFrameHeader = false;
+    mTimestampDelta = 0;
+    if(bConvertEnable){
+        pConvertBuffer = (uint8_t *)malloc(nConvertBufferSize);
+    }
+
+    if(C2_OK != doInit()){
+        LOGE("doInit fail!");
+        return C2_NO_MEMORY;
+    }
+    
+    return C2_OK;
+}
+
+c2_status_t IMXAudioDecComponent::onStop()
+{
+    LOGV("entry");
+    onFlush_sm();
+    return C2_OK;
+}
+
+void IMXAudioDecComponent::onReset()
+{
+    LOGV("entry");
+    (void) onStop();
+}
+
+void IMXAudioDecComponent::onRelease()
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+
+    ret = unInit();
+    if (ret != C2_OK)
+    {
+    	LOGE("Audio decoder de-init fail.
");
+    	return;
+    }
+
+    LOGD("Audio decoder instance de-init.
");
+    AudioRingBuffer.BufferFree();
+    TS_Manager.Free();
+
+    free(pConvertBuffer);
+    pConvertBuffer = nullptr;
+
+    return;
+}
+
+c2_status_t IMXAudioDecComponent::onFlush_sm()
+{
+    LOGV("entry");
+    bReceivedEOS = false;
+    bDecoderEOS = false;
+    bFirstOutput = true;
+    bCheckFrameHeader = false;
+    mTimestampDelta = 0;
+    AudioRingBuffer.BufferReset();
+    TS_Manager.Reset();
+
+    doReset();
+    LOGD("Clear ring buffer.
");
+    return C2_OK;
+}
+
+   
+void IMXAudioDecComponent::processWork(const std::unique_ptr<C2Work> &work)
+{
+    LOGV("====================");
+    c2_status_t ret = C2_OK;
+    uint32_t threshold = 0; // lower limit of data length when starting decoding
+
+    work->workletsProcessed = 0u;
+    work->result = C2_OK;
+    work->worklets.front()->output.configUpdate.clear();
+    //if (mSignalledError) {
+    //    return;
+    //}
+
+    _processInputFlag(work);
+    if(work->workletsProcessed == 1u){
+        LOGV("processWork done after _processInputFlag");
+        return;
+    }
+
+    _processInputData(work);
+
+    //uint64_t frameIndex = work->input.ordinal.frameIndex.peeku();
+
+    if (bCheckFrameHeader)
+    {
+    	ret = checkFrameHeader();
+    	if (ret != C2_OK)
+    	{
+    		LOGE("CheckFrameHeader fail.
");
+    	}
+    }
+
+    //only 2 frames in audio ringbuffer for DEC_STREAM_MODE
+    if(ePlayMode == DEC_FILE_MODE){
+        threshold = nPushModeInputLen;
+    }else if(nRequiredSize > 0){
+        threshold = nRequiredSize;
+    }else{
+        threshold = nRequiredSize = AudioRingBuffer.AudioDataLen()+DEFAULT_REQUIRED_SIZE;
+    }
+#ifdef DECODE_EACH_INPUT
+    // force decode input data in every work
+    threshold = 1;
+#endif
+
+    LOGV("playMode %s, nRequiredSize %d, nPushModeInputLen %d, result threshold %d",
+        (ePlayMode == DEC_FILE_MODE)?"file":"stream", nRequiredSize, nPushModeInputLen, threshold);
+
+    if ((AudioRingBuffer.AudioDataLen() < threshold && bReceivedEOS == false)
+        || bDecoderEOS == true)
+    {
+        LOGV("RingBuffer data is not enough or DecoderEOS true, skip decoding.
");
+        work->worklets.front()->output.flags = work->input.flags;
+        work->worklets.front()->output.ordinal = work->input.ordinal;
+        work->worklets.front()->output.buffers.clear();
+        work->workletsProcessed = 1u;
+        return;
+    }
+
+    // this seems just for aac, need to move into UniaDecoder or AacDecodeUtil
+    if (!bCodecInit)
+    {
+        LOGV("call CodecInit");
+    	bCodecInit = true;
+    	ret = codecInit();
+    	if (ret != C2_OK)
+    	{
+    		LOGE("CodecInit fail.
");
+    		bDecoderInitFail = true;
+    	}
+    }
+
+    ret = _processOutput(work);
+    if(C2_OK != ret){
+        LOGE("_processOutput fail ret %d", ret);
+    }
+
+    work->worklets.front()->output.flags = work->input.flags;
+    work->workletsProcessed = 1u;
+
+    LOGV("return input work: flags 0x%x, Processed %d", work->worklets.front()->output.flags, work->workletsProcessed);
+
+    //work->worklets.front()->output.ordinal = work->input.ordinal;
+    /*
+   for (const auto &p : work->worklets.front()->output.configUpdate) {
+        if (!p) {
+            continue;
+        }
+        LOGV("param size is %zu", p->size());
+    }  
+    */
+    
+}
+
+c2_status_t IMXAudioDecComponent::_processInputFlag(const std::unique_ptr<C2Work> &work)
+{
+    //LOGV("entry");
+    c2_status_t ret = C2_OK;
+    C2ReadView view = mDummyReadView;
+    size_t size = 0u;
+    if (!work->input.buffers.empty()) {
+        view = work->input.buffers[0]->data().linearBlocks().front().map().get();
+        size = view.capacity();
+    }
+
+    bool eos = (work->input.flags & C2FrameData::FLAG_END_OF_STREAM) != 0;
+    bool codecConfig = (work->input.flags & C2FrameData::FLAG_CODEC_CONFIG) != 0;
+    uint64_t timestamp = work->input.ordinal.timestamp.peeku();
+    uint64_t frameIndex = work->input.ordinal.frameIndex.peeku();
+    LOGV("ts %lld , size %zu, eos %d, frameIndex %lld", (long long)timestamp,size, eos, (long long)frameIndex);
+
+    if (codecConfig && size > 0u) 
+    {
+        LOGV("audio codec config data received.
");
+        
+        if(C2_OK != checkCodecConfig(view.data(), size))
+            LOGE("checkCodecConfig fail!");
+        work->worklets.front()->output.flags = work->input.flags;
+        work->worklets.front()->output.ordinal = work->input.ordinal;
+        work->worklets.front()->output.buffers.clear();
+        work->workletsProcessed = 1u;
+
+        return C2_OK;
+    }
+
+    // vts sends last input with index 0, this leads to reset actions wrongly
+    // add conditions of eos and data len to avoid it.
+    if(frameIndex == 0l && !(eos && (AudioRingBuffer.AudioDataLen() > 0)))
+    {
+        LOGV("first frame received.
");
+        AudioRingBuffer.BufferReset();
+        TS_Manager.Reset();
+        doReset();
+        bReceivedEOS = false;
+        bDecoderEOS = false;
+        bCheckFrameHeader = true;
+    }
+
+    if(eos)
+    {
+    	bReceivedEOS = true;
+        LOGV("EOS received.
");
+    }
+
+    if (bFirstInBuffer && eos)
+    {
+    	LOGV("bFirstInBuffer && eos. call getParamDirectly
");
+        getParamDirectly();
+    }
+
+    if (bFirstInBuffer)
+        bFirstInBuffer = false;
+
+    TS_Manager.TS_Add(timestamp, size);
+
+    return C2_OK;
+}
+
+c2_status_t IMXAudioDecComponent::_processInputData(const std::unique_ptr<C2Work> &work)
+{
+    //LOGV("entry");
+    c2_status_t ret = C2_OK;
+    uint32_t nActualLen = 0;
+    uint8_t * pBuffer = nullptr;
+    C2ReadView view = mDummyReadView;
+    size_t size = 0;
+
+    if(ePlayMode == DEC_STREAM_MODE && nRequiredSize > 0 && AudioRingBuffer.AudioDataLen() > nRequiredSize){
+        LOGV("don't handle this input becauseof stream mode");
+        // need modify for codec2
+        return ret;
+    }
+
+    if (!work->input.buffers.empty()) {
+        view = work->input.buffers[0]->data().linearBlocks().front().map().get();
+        size = view.capacity();
+        pBuffer = const_cast<uint8_t *>(view.data());
+    }
+
+    /** Process audio data */
+    if(size > 0 && pBuffer != nullptr){
+        AudioRingBuffer.BufferAdd(pBuffer, size,  &nActualLen);
+        LOGV("add input %zu to ringBuffer, %d added, total %d",  size, nActualLen, AudioRingBuffer.AudioDataLen());
+        /*
+        LOGV("%2x %2x %2x %2x %2x, %2x %2x %2x %2x %2x ",
+            pBuffer[0],pBuffer[1],pBuffer[2],pBuffer[3],pBuffer[4],
+            pBuffer[size-5],pBuffer[size-4],pBuffer[size-3],pBuffer[size-2],pBuffer[size-1]
+            ); */
+    }
+    else{
+        // no data in this work, don't keep it in mPendingWork
+        work->workletsProcessed = 1u;
+    }
+
+    if (nActualLen < size)
+    {
+        LOGW("ringbuffer full !added %d, expect %zu, total %d", nActualLen, size, AudioRingBuffer.AudioDataLen());
+        uint32_t left = size - nActualLen;
+        uint32_t newLen = MAX(AudioRingBuffer.AudioDataLen() * 2, size+1024);
+        AudioRingBuffer.Resize(newLen);
+        AudioRingBuffer.BufferAdd(pBuffer + nActualLen, left, &nActualLen);
+        if (nActualLen < left){
+            LOGE("Can't resize ringbuffer to receive all data!");
+        }
+    }
+
+    return C2_OK;
+
+}
+
+c2_status_t IMXAudioDecComponent::_processOutput(const std::unique_ptr<C2Work> &work)
+{
+    LOGV("entry");
+    int64_t nTimeStamp = 0l;
+    uint8_t * pOutBuffer = nullptr;
+    uint32_t nOutBufferLen = 0;
+    uint32_t nOutBufferOffset = 0;
+    c2_status_t ret = C2_OK;
+    std::list<uint8_t *> outputBuffers;
+    std::list<uint32_t> outputSizes;
+    AUDIO_DECODE_RETURN_TYPE DecodeRet;
+    bool eos;
+
+    if (bFirstOutput) {
+        TS_Manager.Consumed(0);
+        TS_Manager.TS_SetIncrease(0);
+    }
+    TS_Manager.TS_Get(&nTimeStamp);
+
+    if (mTimestampDelta > 0 && mTimestampDelta < nTimeStamp)
+        nTimeStamp -= mTimestampDelta;
+    LOGV("tsm output ts %lld mTimestampDelta %lld", (long long)nTimeStamp, (long long)mTimestampDelta);
+
+    if (bDecoderInitFail)
+    {
+    	AudioRingBuffer.BufferReset();
+    	TS_Manager.Reset();
+    	bReceivedEOS = true;
+        DecodeRet = AUDIO_DECODE_EOS;
+        LOGW("InitFail, set bReceivedEOS and skip decoding");
+    }
+    else
+    {
+        DecodeRet = doDecode(work, outputBuffers, outputSizes);
+        if(DecodeRet != AUDIO_DECODE_SUCCESS){
+            LOGV("doDecode return %s", _decodeRetToString(DecodeRet));
+        }
+
+    	if (DecodeRet == AUDIO_DECODE_FAILURE)
+    	{
+            LOGW("Decode frame fail!.
");
+            return C2_OK;
+    	}else if(DecodeRet == AUDIO_DECODE_FATAL_ERROR){
+            LOGE("Decode fatal error!, set EOS.
");
+            AudioRingBuffer.BufferReset();
+            TS_Manager.Reset();
+            bReceivedEOS = true;
+            DecodeRet = AUDIO_DECODE_EOS;
+        }
+    }
+
+    if (DecodeRet == AUDIO_DECODE_EOS && bReceivedEOS == true && AudioRingBuffer.AudioDataLen() == 0)
+    {
+        //if buffer is both the first and the last one, and is empty, send out EOS event directly.
+        if((bFirstOutput && work->worklets.front()->output.buffers.size() == 0)) {
+            LOGD("AudioDecComp send EOS at first output
");
+            uint32_t flags = work->worklets.front()->output.flags;
+            flags |= C2FrameData::FLAG_END_OF_STREAM;
+            work->worklets.front()->output.flags = (C2FrameData::flags_t)flags;
+            bDecoderEOS = true;
+        }
+    }
+
+    // when getting first output, don't checkFrameHeader anymore
+    if (bCheckFrameHeader)
+    {
+        bCheckFrameHeader = false;
+    }
+
+    //if(DecodeRet == AUDIO_DECODE_NEEDMORE){
+    //    return C2_OK;
+    //}
+
+    //
+    //malloc pOutBuffer, copy output data from list outputBuffers
+    //
+    if(!outputBuffers.empty() && !outputSizes.empty()){
+        nOutBufferLen = std::accumulate(outputSizes.begin(), outputSizes.end(), 0);
+        pOutBuffer = (uint8_t *)malloc(nOutBufferLen);
+        if(!pOutBuffer){
+            LOGE("malloc output buffer fail! size %d", nOutBufferLen);
+            nOutBufferLen = 0;
+        }
+        else{
+            uint32_t index = 0;
+            while(!outputSizes.empty() && !outputBuffers.empty()){
+                uint8_t * p = *outputBuffers.begin();
+                outputBuffers.erase(outputBuffers.begin());
+                uint32_t size = *outputSizes.begin();
+                outputSizes.erase(outputSizes.begin());
+                if(p != nullptr && size > 0){
+                    memcpy(pOutBuffer+index, p, size);
+                    index += size;
+                    free(p);
+                }
+            }
+        }
+
+    }
+
+    if(pOutBuffer == nullptr || nOutBufferLen == 0){
+        LOGW("No valid output for this decoding");
+        return C2_OK;
+    }
+
+    eos = ((work->input.flags & C2FrameData::FLAG_END_OF_STREAM) != 0);
+
+    if(bFirstOutput) {
+        if(C2_OK == handleBOS(&nOutBufferOffset, nOutBufferLen))
+            bFirstOutput = false;
+    }
+
+    if (eos) {
+        handleEOS(&pOutBuffer, &nOutBufferLen);
+    }
+
+
+    //
+    // Convert to 16 bits if necessary, result is in pData/dataLen
+    //
+    uint32_t dataLen = nOutBufferLen - nOutBufferOffset;
+    uint8_t * pData = pOutBuffer + nOutBufferOffset;
+    LOGV("nOutBufferLen %d nOutBufferOffset %d", nOutBufferLen, nOutBufferOffset);
+
+    //LOGV("bConvertEnable %d, pConvertBuffer %p",  bConvertEnable, pConvertBuffer);
+    if(bConvertEnable && pConvertBuffer != nullptr){
+        uint32_t outSize = 0;
+        if(PcmMode.nBitPerSample != 16){
+            nOutputBitPerSample = PcmMode.nBitPerSample;
+            PcmMode.nBitPerSample = 16;
+        }
+        //LOGV("nOutputBitPerSample %d",  nOutputBitPerSample);
+        if(nOutputBitPerSample != 16){
+            // check convert buffer size
+            if(nOutputBitPerSample == 8 && nConvertBufferSize < dataLen * 2){
+                LOGV("enlarge pConvertBuffer %d=>%d", nConvertBufferSize, dataLen * 2);
+                nConvertBufferSize = dataLen * 2;
+                pConvertBuffer = (uint8_t *)realloc(pConvertBuffer, nConvertBufferSize);
+            }
+            if(nOutputBitPerSample == 24 && nConvertBufferSize < dataLen * 2 / 3){
+                LOGV("enlarge pConvertBuffer %d=>%d", nConvertBufferSize, dataLen * 2 / 3);
+                nConvertBufferSize = dataLen * 2 / 3;
+                pConvertBuffer = (uint8_t *)realloc(pConvertBuffer, nConvertBufferSize);
+            }
+            // do converting...
+            if(pConvertBuffer != nullptr && C2_OK == _convertData(pConvertBuffer,&outSize,pData,dataLen)){
+                LOGV("convert ok");
+                pData = pConvertBuffer;
+                dataLen = outSize;
+            }
+        }
+    }
+
+#if 1
+
+    std::shared_ptr<C2LinearBlock> block;
+    C2MemoryUsage usage = { C2MemoryUsage::CPU_READ, C2MemoryUsage::CPU_WRITE };
+
+    do{
+        LOGV("fetchLinearBlock... len %d, usage %d ",  dataLen, (int32_t)usage.expected);
+        c2_status_t err = mOutputBlockPool->fetchLinearBlock(dataLen, usage, &block);
+        if (err != C2_OK){
+            LOGE("fetchLinearBlock fail!");
+            work->result = C2_NO_MEMORY;
+            ret = C2_NO_MEMORY;
+            break;
+        }
+        //LOGI("map to WriteView");
+        C2WriteView wView = block->map().get();
+        if (wView.error() != C2_OK){
+            LOGE("block->map() fail!");
+            work->result = wView.error();
+            ret = work->result;
+            break;
+        }
+        uint8_t *pBuffer = reinterpret_cast<uint8_t *> (wView.data());
+        memcpy(pBuffer, pData, dataLen);
+
+        //_fileDump(&fpOutput, pData, dataLen);
+    }while(0);
+    
+    free(pOutBuffer);
+
+    if(C2_OK == ret){
+        work->worklets.front()->output.buffers.clear();
+        work->worklets.front()->output.buffers.push_back(createLinearBuffer(block, 0, dataLen));
+    }
+    work->worklets.front()->output.flags = work->input.flags;
+    work->worklets.front()->output.ordinal.frameIndex = work->input.ordinal.frameIndex.peeku();
+
+    // for imxextractor
+    work->worklets.front()->output.ordinal.timestamp = nTimeStamp;
+
+    work->workletsProcessed = 1u;
+
+    LOGV("output size %d, ts %lld, frameIndex %lld,configUpdate %zu, flags 0x%x",
+        dataLen, (long long)work->worklets.front()->output.ordinal.timestamp.peeku(),
+        (long long)work->worklets.front()->output.ordinal.frameIndex.peeku(),
+        work->worklets.front()->output.configUpdate.size(), work->worklets.front()->output.flags);
+
+    //_fileDump(&fpOutput, work);
+    //_compareData(work, pData, dataLen);
+
+#else
+    //_fileDump(&fpOutput, pData, dataLen);
+
+    nTimeStamp = work->input.ordinal.timestamp.peeku();
+    LOGV("use ts from input %lld ms", (long long)nTimeStamp/1000);
+
+    // keep input work in ComponentBase, use finish() to let it return work
+    _drainOutput(work, pData, dataLen, nTimeStamp, false);
+
+#endif
+
+    return ret;
+}
+
+void IMXAudioDecComponent::_fileDump(FILE** ppFp, uint8_t * pBits, uint32_t nSize)
+{
+    static const char * fileName = "/data/audioComp.bit";
+    if(nSize==0)
+        return;
+
+    if(*ppFp==nullptr)
+    {
+        // dump to file only when this file doesn't exist
+        // avoid dumping file everytime playing
+        // remove this file before you want to dump data
+        struct stat sb;
+        if (stat(fileName, &sb) != -1)
+            return;
+
+        *ppFp=fopen(fileName,"wb");
+        if(*ppFp==nullptr)
+        {
+            LOGE("Can't open %s", fileName);
+            return;
+        }
+        LOGI("Open %s OK", fileName);
+    }
+
+    fwrite(pBits,1,nSize,*ppFp);
+    fflush(*ppFp);
+    return;
+}
+
+void IMXAudioDecComponent::_fileDump(FILE** ppFp, const std::unique_ptr<C2Work> &work)
+{
+    static const char * fileName = "/data/audioComp.bit";
+
+    if(*ppFp==nullptr)
+    {
+        // dump to file only when this file doesn't exist
+        // avoid dumping file everytime playing
+        // remove this file before you want to dump data
+        struct stat sb;
+        if (stat(fileName, &sb) != -1)
+            return;
+
+        *ppFp=fopen(fileName,"wb");
+        if(*ppFp==nullptr)
+        {
+            LOGE("Can't open %s", fileName);
+            return;
+        }
+        LOGI("Open %s OK", fileName);
+    }
+
+    std::vector<std::shared_ptr<C2Buffer>> &buffers = work->worklets.front()->output.buffers;
+    if(buffers.size() < 1){
+        LOGD("no buffer in this work");
+        return;
+    }
+
+    if(buffers.size() != 1){
+        LOGD("contain more than one output buffer %zu!", buffers.size());
+    }
+    std::shared_ptr<C2Buffer> buf = buffers[0];
+    C2ReadView view = buf->data().linearBlocks()[0].map().get();
+    if (view.error() != C2_OK) {
+        LOGD("Error while mapping: %d", view.error());
+        return;
+    }
+
+    fwrite(view.data(),1,view.capacity(),*ppFp);
+    fflush(*ppFp);
+    return;
+}
+
+void IMXAudioDecComponent::_compareData(const std::unique_ptr<C2Work> &work, uint8_t * pBits, uint32_t nSize)
+{
+    std::vector<std::shared_ptr<C2Buffer>> &buffers = work->worklets.front()->output.buffers;
+    if(buffers.size() < 1){
+        LOGD("no buffer in this work");
+        return;
+    }
+
+    if(buffers.size() != 1){
+        LOGD("contain more than one output buffer %zu!", buffers.size());
+    }
+    std::shared_ptr<C2Buffer> buf = buffers[0];
+    C2ReadView view = buf->data().linearBlocks()[0].map().get();
+    if (view.error() != C2_OK) {
+        LOGD("Error while mapping: %d", view.error());
+        return;
+    }
+
+    for(int i=0; i<nSize; i++){
+        if(*(view.data()+i) != *(pBits+i))
+            LOGI("mismatch index %d, write %02x, read %02x" ,i, *(pBits+i), *(view.data()+i));
+    }
+}
+
+c2_status_t IMXAudioDecComponent::_convertData(uint8_t * pOut, uint32_t *nOutSize, uint8_t *pIn, uint32_t nInSize)
+{
+    LOGV("entry");
+    if(nullptr == pOut || nullptr == pIn)
+        return C2_BAD_VALUE;
+
+    if(nOutputBitPerSample == 8) {
+        // Convert to U16
+        int32_t i,Len;
+        uint16_t *pDst =(uint16_t *)pOut;
+        int8_t *pSrc =(int8_t *)pIn;
+        Len = nInSize;
+        for(i=0;i<Len;i++) {
+            *pDst++ = (uint16_t)(*pSrc++) << 8;
+        }
+        nInSize *= 2;
+    } else if(nOutputBitPerSample == 24) {
+        int32_t i,j,Len;
+        uint8_t *pDst =(uint8_t *)pOut;
+        uint8_t *pSrc =(uint8_t *)pIn;
+        Len = nInSize / (nOutputBitPerSample>>3) / PcmMode.nChannels;
+        for(i=0;i<Len;i++) {
+            for(j=0;j<(int32_t)PcmMode.nChannels;j++) {
+                pDst[0] = pSrc[1];
+                pDst[1] = pSrc[2];
+                pDst+=2;
+                pSrc+=3;
+            }
+        }
+        nInSize = Len * (16>>3) * PcmMode.nChannels;
+    }
+
+    *nOutSize = nInSize;
+    return C2_OK;
+}
+
+void IMXAudioDecComponent::_drainOutput(
+        const std::unique_ptr<C2Work> &currInputWork,
+        uint8_t * pData,
+        uint32_t dataLen,
+        int64_t nTimeStamp,
+        bool eos) {
+    LOGV("entry");
+    std::shared_ptr<C2LinearBlock> block;
+
+    std::function<void(const std::unique_ptr<C2Work>&)> fillWork =
+        [&block, pData, dataLen, nTimeStamp, this, &currInputWork](const std::unique_ptr<C2Work> &work){
+
+            if(work == nullptr){
+                LOGW("fillWork() got null work");
+                return;
+            }
+
+            C2MemoryUsage usage = { C2MemoryUsage::CPU_READ, C2MemoryUsage::CPU_WRITE };
+            c2_status_t err = mOutputBlockPool->fetchLinearBlock(
+                    dataLen, usage, &block);
+            if (err != C2_OK) {
+                LOGE("fillWork() failed to fetch a linear block (%d)", err);
+                return;
+            }
+            C2WriteView wView = block->map().get();
+            uint8_t *pBuffer = reinterpret_cast<uint8_t *> (wView.data());
+            memcpy(pBuffer, pData, dataLen);
+
+            #define DUMP_OUTPUT
+            #ifdef DUMP_OUTPUT
+                //_fileDump(&fpOutput, pData, dataLen);
+            #endif
+
+            work->result = C2_OK;
+            C2FrameData &output = work->worklets.front()->output;
+            output.flags = work->input.flags; // shall be currInputWork flags?
+            output.buffers.clear();
+            output.buffers.push_back(createLinearBuffer(block, 0, dataLen));
+            //output.ordinal = work->input.ordinal;
+            output.ordinal.timestamp = nTimeStamp;
+            output.ordinal.frameIndex = ++frameIndex;
+            std::vector<std::unique_ptr<C2Param>> *configUpdate = &currInputWork->worklets.front()->output.configUpdate;
+            if (!configUpdate->empty()){
+                LOGI("fillWork() copy config to output, size %zu", configUpdate->size());
+                std::vector<std::unique_ptr<C2Param>> * outputConfig = &work->worklets.front()->output.configUpdate;
+                outputConfig->clear();
+                for (auto it = configUpdate->begin() ; it != configUpdate->end(); ++it)
+                    outputConfig->push_back(std::move(*it));
+            }
+            work->workletsProcessed = 1u;
+            LOGI("fillWork() out timestamp %lld, size %u, frameIndex %d, flags %x", 
+                (long long)nTimeStamp/1000, block ? block->capacity() : 0, frameIndex, output.flags);
+        };
+
+        finish(nTimeStamp, fillWork);
+
+}
+
+
+const char * IMXAudioDecComponent::_decodeRetToString(AUDIO_DECODE_RETURN_TYPE decodeRet)
+{
+    switch(decodeRet){
+        case AUDIO_DECODE_EOS:
+            return "AUDIO_DECODE_EOS";
+        case AUDIO_DECODE_FAILURE:
+            return "AUDIO_DECODE_FAILURE";
+        case AUDIO_DECODE_NEEDMORE:
+            return "AUDIO_DECODE_NEEDMORE";
+        case AUDIO_DECODE_FATAL_ERROR:
+            return "AUDIO_DECODE_FATAL_ERROR";
+        default:
+            return "invalid";
+    };
+}
+
+c2_status_t IMXAudioDecComponent::drainInternal(uint32_t drainMode)
+{
+    LOGI("entry");
+    return C2_OK;
+}
+
+}
+
diff --git a/codec2/audio_dec/common/IMXAudioDecComponent.h b/codec2/audio_dec/common/IMXAudioDecComponent.h
new file mode 100755
index 0000000..6a099be
--- /dev/null
+++ b/codec2/audio_dec/common/IMXAudioDecComponent.h
@@ -0,0 +1,130 @@
+/**
+ *  Copyright 2019,2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef IMX_AUDIO_DEC_COMPONENT_H_
+#define IMX_AUDIO_DEC_COMPONENT_H_
+
+#include <IMXC2ComponentBase.h>
+
+#include "RingBuffer.h"
+#include "AudioTSManager.h"
+#include <C2_imx.h>
+
+#define DEFAULT_REQUIRED_SIZE 10
+
+/* don't use ringbuffer to accumulate input, just decode each input when it comes, and mark it as Processed,
+     and no need to call finish() */
+//#define DECODE_EACH_INPUT
+
+typedef enum {
+    AUDIO_DECODE_SUCCESS,
+    AUDIO_DECODE_EOS,
+    AUDIO_DECODE_FAILURE,
+    AUDIO_DECODE_NEEDMORE,
+    AUDIO_DECODE_FATAL_ERROR,
+}AUDIO_DECODE_RETURN_TYPE;
+
+typedef struct AUDIO_PARAM_PCMMODETYPE {
+    uint32_t nChannels;                /**< Number of channels (e.g. 2 for stereo) */
+    //OMX_NUMERICALDATATYPE eNumData;   /**< indicates PCM data as signed or unsigned */
+    //OMX_ENDIANTYPE eEndian;           /**< indicates PCM data as little or big endian */
+    //bool bInterleaved;
+                                            /**< True for normal interleaved data; false for
+                                           non-interleaved data (e.g. block data) */
+    uint32_t nBitPerSample;
+    uint32_t nSamplingRate;            /**< Sampling rate of the source data.  Use 0 for
+                                           variable or unknown sampling rate. */
+    //OMX_AUDIO_PCMMODETYPE ePCMMode;   /**< PCM mode enumeration */
+    //OMX_AUDIO_CHANNELTYPE eChannelMapping[OMX_AUDIO_MAXCHANNELS]; /**< Slot i contains channel defined by eChannelMap[i] */
+
+} AUDIO_PARAM_PCMMODETYPE;
+
+
+namespace android {
+
+class IMXAudioDecComponent : public IMXC2ComponentBase {
+
+public:
+    class IntfImpl;
+
+    IMXAudioDecComponent(const std::shared_ptr<C2ComponentInterface> &intf);
+    virtual ~IMXAudioDecComponent();
+
+protected:
+
+    // From IMXC2Component
+    c2_status_t onInit() override;
+    c2_status_t onStop() override;
+    void        onReset() override;
+    void        onRelease() override;
+    c2_status_t onFlush_sm() override;
+    void        processWork(const std::unique_ptr<C2Work> &work) override;
+    c2_status_t drainInternal(uint32_t drainMode) override;
+
+    virtual c2_status_t doInit() = 0;
+    virtual c2_status_t unInit() = 0;
+    virtual c2_status_t checkCodecConfig(const uint8_t * data, size_t size) = 0;
+    virtual AUDIO_DECODE_RETURN_TYPE doDecode(const std::unique_ptr<C2Work> &work,
+                                                    std::list<uint8_t *> &outputBuffers,
+                                                    std::list<uint32_t> &outputSizes) = 0;
+    virtual void        doReset() = 0;
+    virtual c2_status_t checkFrameHeader() = 0;
+    virtual c2_status_t codecInit() = 0;
+    virtual c2_status_t handleEOS(uint8_t **ppBuffer, uint32_t* length) { return C2_OK; };
+    virtual c2_status_t handleBOS(uint32_t* offset, uint32_t length) { return C2_OK; };
+    virtual c2_status_t getParamDirectly() { return C2_OK; };
+
+    RingBuffer AudioRingBuffer;
+    bool       bDecoderEOS;
+
+    uint32_t nPushModeInputLen;
+    uint32_t nRingBufferScale;
+    uint64_t TS_PerFrame;
+    uint32_t nRequiredSize;//set by subclass for audio ring buffer len
+
+    AUDIO_PARAM_PCMMODETYPE PcmMode;
+    uint32_t nOutputBitPerSample;
+    bool     bConvertEnable;
+    decode_mode_t ePlayMode;
+    AudioTSManager TS_Manager;
+    bool bReceivedEOS;
+    int64_t mTimestampDelta;
+
+private:
+
+    bool bCheckFrameHeader;
+    bool bCodecInit;
+    bool bDecoderInitFail;
+
+    bool bFirstInBuffer;
+    uint8_t * pConvertBuffer;
+    uint32_t nConvertBufferSize;
+    bool  bFirstOutput;
+    FILE* fpOutput;
+    uint32_t frameIndex;
+
+    c2_status_t _processInputFlag(const std::unique_ptr<C2Work> &work);
+    c2_status_t _processInputData(const std::unique_ptr<C2Work> &work);
+    c2_status_t _processOutput(const std::unique_ptr<C2Work> &work);
+    c2_status_t _convertData(uint8_t * pOut, uint32_t *nOutSize, uint8_t *pIn, uint32_t nInSize);
+    const char * _decodeRetToString(AUDIO_DECODE_RETURN_TYPE decodeRet);
+    void _fileDump(FILE** ppFp, uint8_t* pBits, uint32_t nSize);
+    void _fileDump(FILE** ppFp, const std::unique_ptr<C2Work> &work);
+    void _compareData(const std::unique_ptr<C2Work> &work, uint8_t * pBits, uint32_t nSize);
+    void _drainOutput(
+        const std::unique_ptr<C2Work> &work,
+        uint8_t * pData,
+        uint32_t dataLen,
+        int64_t nTimeStamp,
+        bool eos);
+};
+
+}  // namespace android
+
+#endif
+
diff --git a/codec2/audio_dec/common/List.h b/codec2/audio_dec/common/List.h
new file mode 100755
index 0000000..61fe1de
--- /dev/null
+++ b/codec2/audio_dec/common/List.h
@@ -0,0 +1,297 @@
+/**
+ *  Copyright (c) 2009-2010, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+/**
+ *  @file utils/List.h
+ *  @brief List template class.
+ *  @ingroup utils
+ */
+
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef List_h
+#define List_h
+
+//#define LOG_NDEBUG 0
+//#define LOG_TAG "List"
+#include <log/log.h>
+
+typedef enum LIST_RETURNTYPE {
+    LIST_SUCCESS = 0,
+    LIST_FAILURE
+} LSIT_RETURNTYPE;
+
+template<class T> class List
+{
+	public:
+		List();
+		LSIT_RETURNTYPE Add(T *node, uint32_t priority = 0); /**< Add node at the tail or based on priority*/
+		LSIT_RETURNTYPE Add(T *node, T *pUpNode); /**< Add node behind up node*/
+		LSIT_RETURNTYPE Remove(T *node); /**< Remove one node */
+		LSIT_RETURNTYPE Replace(T *node, T *nodeNew); /**< Replace one node with new node */
+		uint32_t GetNodeCnt();
+		T *GetNode(uint32_t index); /**< Get one node based on index, first index is 0 */
+		~List(); /**< Free all node */
+	private:
+		struct NODE{
+			NODE *pNext;
+			T *pT;
+			uint32_t priority;
+		};
+		NODE *pFirst;
+		uint32_t NodeCnt;
+};
+
+template<class T> List<T>::List()
+{
+	pFirst = NULL;
+	NodeCnt = 0;
+}
+
+template<class T>
+LSIT_RETURNTYPE List<T>::Add(T *node, uint32_t priority)
+{
+	NODE **ppTmp = &pFirst, **ppTmp2 = &pFirst, *pTmp3;
+
+	if (node == NULL)
+	{
+		ALOGE("List: Add NULL to list.
");
+		return LIST_FAILURE;
+	}
+
+	while (*ppTmp != NULL)
+	{
+		if (priority > (*ppTmp)->priority)
+		{
+			break;
+		}
+		ppTmp2 = ppTmp;
+		ppTmp = &((*ppTmp)->pNext);
+	}
+
+	pTmp3 = new NODE();
+	pTmp3->pT = node;
+	pTmp3->pNext = NULL;
+	pTmp3->priority = priority;
+	NodeCnt ++;
+
+	if (priority == 0)
+	{
+		*ppTmp = pTmp3;
+	}
+	else
+	{
+		if (*ppTmp == *ppTmp2)
+		{
+			/** Insert to begin. */
+			if (pFirst != NULL)
+			{
+				pTmp3->pNext = pFirst;
+			}
+			*ppTmp2 = pTmp3;
+		}
+		else if (*ppTmp == NULL)
+		{
+			/** Insert to the end */
+			*ppTmp = pTmp3;
+		}
+		else
+		{
+			/** Insert to the middle */
+			pTmp3->pNext = *ppTmp;
+			(*ppTmp2)->pNext = pTmp3;
+		}
+	}
+
+	return LIST_SUCCESS;
+}
+
+template<class T>
+LSIT_RETURNTYPE List<T>::Add(T *node, T *pUpNode)
+{
+	NODE **ppTmp = &pFirst, **ppTmp2 = &pFirst, *pTmp3;
+
+	if (node == NULL)
+	{
+		ALOGE("List: Add NULL to list.
");
+		return LIST_FAILURE;
+	}
+
+	while (*ppTmp != NULL)
+	{
+		if (pUpNode == (*ppTmp)->pT)
+		{
+			ppTmp2 = ppTmp;
+			break;
+		}
+		ppTmp = &((*ppTmp)->pNext);
+	}
+
+	if (*ppTmp == NULL)
+	{
+		ALOGE("List: Add NULL to list.
");
+		return LIST_FAILURE;
+	}
+	ppTmp = &((*ppTmp)->pNext);
+
+	pTmp3 = new NODE();
+	pTmp3->pT = node;
+	pTmp3->pNext = NULL;
+	pTmp3->priority = (*ppTmp2)->priority;
+	NodeCnt ++;
+
+	if (*ppTmp == *ppTmp2)
+	{
+		/** Insert to begin. */
+		if (pFirst != NULL)
+		{
+			pTmp3->pNext = pFirst;
+		}
+		*ppTmp2 = pTmp3;
+	}
+	else if (*ppTmp == NULL)
+	{
+		/** Insert to the end */
+		*ppTmp = pTmp3;
+	}
+	else
+	{
+		/** Insert to the middle */
+		pTmp3->pNext = *ppTmp;
+		(*ppTmp2)->pNext = pTmp3;
+	}
+
+	return LIST_SUCCESS;
+}
+
+
+template<class T>
+LSIT_RETURNTYPE List<T>::Remove(T *node)
+{
+	NODE *pTmp, *pTmp2;
+
+	if (node == NULL)
+	{
+		ALOGE("List: Remove NULL from list.
");
+		return LIST_FAILURE;
+	}
+
+	pTmp = pFirst;
+	pTmp2 = pFirst;
+	while (pTmp != NULL)
+	{
+		if (pTmp->pT == node)
+		{
+			//ALOGI("List: Found the node in the list.
");
+			if (pTmp == pFirst)
+			{
+				pFirst = pTmp->pNext;
+			}
+			else
+			{
+				pTmp2->pNext = pTmp->pNext;
+			}
+			delete pTmp;
+			NodeCnt --;
+			if (NodeCnt == 0)
+			{
+				pFirst = NULL;
+			}
+
+			return LIST_SUCCESS;
+		}
+		pTmp2 = pTmp;
+		pTmp = pTmp->pNext;
+	}
+
+	ALOGE("List: Can't find the node.
");
+	return LIST_FAILURE;
+}
+
+template<class T>
+uint32_t List<T>::GetNodeCnt()
+{
+	return NodeCnt;
+}
+
+template<class T>
+T *List<T>::GetNode(uint32_t index)
+{
+	NODE *pTmp;
+	uint32_t i;
+
+	if (NodeCnt == 0)
+	{
+		ALOGV("List: No node in the list.
");
+		return NULL;
+	}
+
+	if (index > NodeCnt - 1)
+	{
+		ALOGI("List: No so many node in the list.
");
+		return NULL;
+	}
+
+	pTmp = pFirst;
+	for (i = 0; i < index; i ++)
+	{
+		pTmp = pTmp->pNext;
+	}
+
+	return pTmp->pT;
+}
+
+template<class T>
+LSIT_RETURNTYPE List<T>::Replace(T *node, T *nodeNew)
+{
+	NODE *pTmp;
+
+	if (node == NULL)
+	{
+		ALOGE("List: Remove NULL from list.
");
+		return LIST_FAILURE;
+	}
+
+	pTmp = pFirst;
+	while (pTmp != NULL)
+	{
+		if (pTmp->pT == node)
+		{
+			pTmp->pT = nodeNew;
+			return LIST_SUCCESS;
+		}
+		pTmp = pTmp->pNext;
+	}
+
+	ALOGE("List: Can't find the node.
");
+	return LIST_FAILURE;
+}
+
+
+template<class T> List<T>::~List()
+{
+	NODE *pTmp = pFirst, *pTmp2 = pFirst;
+
+	while (pTmp != NULL)
+	{
+		pTmp2 = pTmp;
+		pTmp = pTmp->pNext;
+		delete pTmp2;
+	}
+}
+
+
+#endif
+/* File EOF */
diff --git a/codec2/audio_dec/common/RingBuffer.cpp b/codec2/audio_dec/common/RingBuffer.cpp
new file mode 100755
index 0000000..11bc96c
--- /dev/null
+++ b/codec2/audio_dec/common/RingBuffer.cpp
@@ -0,0 +1,261 @@
+/**
+ *  Copyright (c) 2009-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "RingBuffer"
+#include <log/log.h>
+
+#include <stdio.h>
+#include <dlfcn.h>
+#include "RingBuffer.h"
+#include <malloc.h>
+#include <string.h>
+#include <C2_imx.h>
+
+RingBuffer::RingBuffer()
+{
+	RingBufferPtr = NULL;
+	Reserved = NULL;
+	TotalConsumeLen = 0;
+	nPrevOffset = 0;
+	nPushModeInputLen = 0;
+	nOneByteTime = 0;
+	nRingBufferLen = 0;
+	ReservedLen = 0;
+	Begin = NULL;
+	End = NULL;
+	Consumered = NULL;
+}
+
+RINGBUFFER_ERRORTYPE RingBuffer::BufferCreate(uint32_t nPushModeLen, uint32_t nRingBufferScale)
+{
+    RINGBUFFER_ERRORTYPE ret = RINGBUFFER_SUCCESS;
+
+	nPushModeInputLen = nPushModeLen;
+	nRingBufferLen = nPushModeInputLen * nRingBufferScale;
+
+	/** Create ring buffer for audio decoder input stream. */
+	LOGD("Ring buffer len: %d
", nRingBufferLen);
+	RingBufferPtr = (uint8_t *)malloc(nRingBufferLen+8);
+	if (RingBufferPtr == NULL)
+	{
+		LOGE("Can't get memory.
");
+		return RINGBUFFER_INSUFFICIENT_RESOURCES;
+	}
+
+	Reserved = (uint8_t *)malloc(nPushModeInputLen);
+	if (Reserved == NULL)
+	{
+		free(RingBufferPtr);
+		LOGE("Can't get memory.
");
+		return RINGBUFFER_INSUFFICIENT_RESOURCES;
+	}
+
+	TotalConsumeLen = 0;
+	ReservedLen = nPushModeInputLen;
+	Begin = RingBufferPtr;
+	End = RingBufferPtr;
+	Consumered = RingBufferPtr;
+	nPrevOffset = 0;
+
+    return ret;
+}
+
+RINGBUFFER_ERRORTYPE RingBuffer::Resize(uint32_t nLength)
+{
+
+    uint32_t beginOffset = Begin - RingBufferPtr;
+    uint32_t endOffset = End - RingBufferPtr;
+
+	uint8_t *RingBufferPtr2 = (uint8_t *)malloc(nLength+8);
+	if (RingBufferPtr2 == NULL)
+	{
+		LOGE("Can't get memory.
");
+		return RINGBUFFER_INSUFFICIENT_RESOURCES;
+	}
+    if(Begin > End)
+        memcpy(RingBufferPtr2, End, AudioDataLen());
+    else{
+        uint32_t secondSegment = RingBufferPtr + nRingBufferLen - End;
+        memcpy(RingBufferPtr2, End, secondSegment);
+        memcpy(RingBufferPtr2 + secondSegment, RingBufferPtr, Begin - RingBufferPtr);
+    }
+    Begin = RingBufferPtr2 + AudioDataLen();
+    End = RingBufferPtr2;
+    nRingBufferLen = nLength+8;
+
+    free(RingBufferPtr);
+    RingBufferPtr = RingBufferPtr2;
+    LOGI("new length %d", nLength);
+
+    return RINGBUFFER_SUCCESS;
+}
+
+RINGBUFFER_ERRORTYPE RingBuffer::BufferReset()
+{
+	RINGBUFFER_ERRORTYPE ret = RINGBUFFER_SUCCESS;
+
+	TotalConsumeLen = 0;
+	Begin = RingBufferPtr;
+	End = RingBufferPtr;
+	Consumered = RingBufferPtr;
+	nPrevOffset = 0;
+
+	return ret;
+}
+
+RINGBUFFER_ERRORTYPE RingBuffer::BufferFree()
+{
+	RINGBUFFER_ERRORTYPE ret = RINGBUFFER_SUCCESS;
+
+    free(RingBufferPtr);
+    RingBufferPtr = NULL;
+
+    free(Reserved);
+    Reserved = NULL;
+
+	return ret;
+}
+
+RINGBUFFER_ERRORTYPE RingBuffer::BufferAdd(uint8_t *pBuffer, uint32_t BufferLen, uint32_t *pActualLen)
+{
+    RINGBUFFER_ERRORTYPE ret = RINGBUFFER_SUCCESS;
+
+	int32_t DataLen = AudioDataLen();
+	int32_t FreeBufferLen = nRingBufferLen - DataLen - 1;
+	if (FreeBufferLen < (int32_t)BufferLen)
+	{
+		*pActualLen = FreeBufferLen;
+	}
+	else
+	{
+		*pActualLen = BufferLen;
+	}
+
+	if (Begin + *pActualLen > RingBufferPtr + nRingBufferLen)
+	{
+		uint32_t FirstSegmentLen = nRingBufferLen - (Begin - RingBufferPtr);
+		memcpy(Begin, pBuffer, FirstSegmentLen);
+		memcpy(RingBufferPtr, pBuffer + FirstSegmentLen, *pActualLen - FirstSegmentLen);
+		Begin = RingBufferPtr + *pActualLen - FirstSegmentLen;
+	}
+	else
+	{
+		memcpy(Begin, pBuffer, *pActualLen);
+		Begin += *pActualLen;
+	}
+
+	LOGV("nRingBufferLen = %d	 DataLen = %d
", nRingBufferLen, DataLen);
+
+    return ret;
+}
+
+RINGBUFFER_ERRORTYPE RingBuffer::BufferAddZeros(uint32_t BufferLen, uint32_t *pActualLen)
+{
+    RINGBUFFER_ERRORTYPE ret = RINGBUFFER_SUCCESS;
+
+	uint32_t DataLen = AudioDataLen();
+	uint32_t FreeBufferLen = nRingBufferLen - DataLen - 1;
+	if (FreeBufferLen < BufferLen)
+	{
+		*pActualLen = FreeBufferLen;
+	}
+	else
+	{
+		*pActualLen = BufferLen;
+	}
+
+	if (Begin + *pActualLen > RingBufferPtr + nRingBufferLen)
+	{
+		uint32_t FirstSegmentLen = nRingBufferLen - (Begin - RingBufferPtr);
+		memset(Begin, 0, FirstSegmentLen);
+		memset(RingBufferPtr, 0, *pActualLen - FirstSegmentLen);
+		Begin = RingBufferPtr + *pActualLen - FirstSegmentLen;
+	}
+	else
+	{
+		memset(Begin, 0, *pActualLen);
+		Begin += *pActualLen;
+	}
+
+	LOGV("nRingBufferLen = %d	 DataLen = %d
", nRingBufferLen, DataLen);
+
+    return ret;
+}
+
+
+uint32_t RingBuffer::AudioDataLen()
+{
+	int32_t DataLen = Begin - End;
+	if (DataLen < 0)
+	{
+		DataLen = nRingBufferLen - (End - Begin);
+	}
+
+    return (uint32_t)DataLen;
+}
+
+RINGBUFFER_ERRORTYPE RingBuffer::BufferGet(uint8_t **ppBuffer, uint32_t BufferLen, uint32_t *pActualLen)
+{
+    RINGBUFFER_ERRORTYPE ret = RINGBUFFER_SUCCESS;
+	int32_t DataLen = AudioDataLen();
+	if (DataLen < (int32_t)BufferLen)
+	{
+		*pActualLen = DataLen;
+	}
+	else
+	{
+		*pActualLen = BufferLen;
+	}
+	if (ReservedLen < *pActualLen)
+	{
+		LOGW("Reserved buffer is too short.
");
+		*pActualLen = ReservedLen;
+	}
+
+	if (End + *pActualLen > RingBufferPtr + nRingBufferLen)
+	{
+		uint32_t FirstSegmentLen = nRingBufferLen - (End - RingBufferPtr);
+		memcpy(Reserved, End, FirstSegmentLen);
+		memcpy(Reserved + FirstSegmentLen, RingBufferPtr, *pActualLen - FirstSegmentLen);
+		*ppBuffer = Reserved;
+	}
+	else
+	{
+		*ppBuffer = End;
+	}
+
+	LOGV("nRingBufferLen = %d	 DataLen = %d
", nRingBufferLen, DataLen);
+    return ret;
+}
+
+RINGBUFFER_ERRORTYPE RingBuffer::BufferConsumed(uint32_t ConsumedLen)
+{
+    RINGBUFFER_ERRORTYPE ret = RINGBUFFER_SUCCESS;
+	int32_t DataLen = AudioDataLen();
+	if (DataLen < (int32_t)ConsumedLen)
+	{
+		LOGE("Ring buffer consumer point set error.
");
+		return RINGBUFFER_FAILURE;
+	}
+
+	if (End + ConsumedLen > RingBufferPtr + nRingBufferLen)
+	{
+		End -= nRingBufferLen - ConsumedLen;
+	}
+	else
+	{
+		End += ConsumedLen;
+	}
+
+	TotalConsumeLen += ConsumedLen;
+	LOGV("nRingBufferLen = %d	 DataLen = %d
", nRingBufferLen, DataLen);
+	return ret;
+}
+
+/* File EOF */
diff --git a/codec2/audio_dec/common/RingBuffer.h b/codec2/audio_dec/common/RingBuffer.h
new file mode 100755
index 0000000..0f42279
--- /dev/null
+++ b/codec2/audio_dec/common/RingBuffer.h
@@ -0,0 +1,57 @@
+/**
+ *  Copyright (c) 2009-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+/**
+ *  @file RingBuffer.h
+ *  @brief Class definition of ring buffer
+ *  @ingroup RingBuffer
+ */
+
+
+#ifndef RingBuffer_h
+#define RingBuffer_h
+
+#define RING_BUFFER_SCALE 5
+
+typedef enum {
+    RINGBUFFER_SUCCESS,
+    RINGBUFFER_FAILURE,
+    RINGBUFFER_INSUFFICIENT_RESOURCES
+}RINGBUFFER_ERRORTYPE;
+
+class RingBuffer {
+	public:
+		RingBuffer();
+		RINGBUFFER_ERRORTYPE BufferCreate(uint32_t nPushModeLen, uint32_t nRingBufferScale = RING_BUFFER_SCALE);
+        RINGBUFFER_ERRORTYPE BufferFree();
+		RINGBUFFER_ERRORTYPE BufferReset();
+		RINGBUFFER_ERRORTYPE BufferAdd(uint8_t *pBuffer, uint32_t BufferLen, uint32_t *pActualLen);
+		RINGBUFFER_ERRORTYPE BufferAddZeros(uint32_t BufferLen, uint32_t *pActualLen);
+		uint32_t AudioDataLen();
+		RINGBUFFER_ERRORTYPE BufferGet(uint8_t **ppBuffer, uint32_t BufferLen, uint32_t *pActualLen);
+		/** Set consumered point for ring buffer. */
+		RINGBUFFER_ERRORTYPE BufferConsumed(uint32_t ConsumedLen);
+		RINGBUFFER_ERRORTYPE Resize(uint32_t nLength);
+		uint32_t nPrevOffset;
+	private:
+		uint32_t nPushModeInputLen;
+		int64_t TotalConsumeLen;
+        uint32_t nOneByteTime;
+		uint8_t *RingBufferPtr;
+		uint32_t nRingBufferLen; /**< Should at least RING_BUFFER_SCALE * PUSH model input buffer length */
+		uint8_t *Reserved;
+		uint32_t ReservedLen;   /**< 1/RING_BUFFER_SCALE length of ring buffer length,
+								 used for the end of ring buffer data */
+		uint8_t *Begin;
+		uint8_t *End;
+		uint8_t *Consumered;
+};
+
+#endif
+/* File EOF */
diff --git a/codec2/audio_dec/common/UniaDecoder.cpp b/codec2/audio_dec/common/UniaDecoder.cpp
new file mode 100755
index 0000000..8b3368d
--- /dev/null
+++ b/codec2/audio_dec/common/UniaDecoder.cpp
@@ -0,0 +1,830 @@
+/**
+ *  Copyright 2019,2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "UniaDecodr"
+#include <log/log.h>
+#include "UniaDecoder.h"
+#include "AudioFrameParser.h"
+#include <C2Config.h>
+#include <dlfcn.h>
+
+#define MAX_PROFILE_ERROR_COUNT 1500 //about 1 second decoding time, 30 seconds' audio data length
+#define TICKS_PER_SECOND 1000000
+
+namespace android {
+
+/*****************************************************************************
+ * Function:    appLocalMalloc
+ *
+ * Description: Implements the local malloc
+ *
+ * Return:      Value of the address.
+ *
+ ****************************************************************************/
+
+static void* appLocalMalloc (uint32 TotalSize)
+{
+
+    void *PtrMalloc = nullptr;
+
+    if(0 == TotalSize)
+        LOGW("
Warning: ZERO size IN LOCAL MALLOC");
+
+    PtrMalloc = malloc(TotalSize);
+
+    if (PtrMalloc == nullptr) {
+
+        LOGE("
Error: MEMORY FAILURE IN LOCAL MALLOC");
+    }
+    return (PtrMalloc);
+}
+
+
+/*****************************************************************************
+ * Function:    appLocalFree
+ *
+ * Description: Implements to Free the memory.
+ *
+ * Return:      Void
+ *
+ ****************************************************************************/
+static void appLocalFree (void *MemoryBlock)
+{
+    if(MemoryBlock != nullptr)
+        free(MemoryBlock);
+}
+
+static void *appLocalCalloc(uint32 TotalNumber, uint32 TotalSize)
+{
+    void *PtrCalloc = nullptr;
+
+    if((0 == TotalSize)||(0==TotalNumber))
+        LOGW("
Warning: ZERO size IN LOCAL CALLOC");
+
+    PtrCalloc = malloc(TotalNumber*TotalSize);
+
+    if (PtrCalloc == nullptr) {
+
+        LOGE("
Error: MEMORY FAILURE IN LOCAL CALLOC");
+                return nullptr;
+    }
+    memset(PtrCalloc, 0, TotalSize*TotalNumber);
+    return (PtrCalloc);
+}
+
+/*****************************************************************************
+ * Function:    appLocalReAlloc
+ *
+ * Description: Implements to Free the memory.
+ *
+ * Return:      Void
+ *
+ ****************************************************************************/
+static void * appLocalReAlloc (void *MemoryBlock, uint32 TotalSize)
+{
+    void *PtrMalloc = nullptr;
+
+    if(0 == TotalSize)
+        LOGW("
Warning: ZERO size IN LOCAL REALLOC");
+
+    PtrMalloc = (void *)realloc(MemoryBlock, TotalSize);
+    if (PtrMalloc == nullptr) {
+        LOGE("
Error: MEMORY FAILURE IN LOCAL REALLOC");
+    }
+
+    return PtrMalloc;
+}
+UniaDecoder::UniaDecoder(const std::shared_ptr<C2ComponentInterface> &intf, AudioDecodeUtil *pDecodeUtil)
+    : IMXAudioDecComponent(intf),
+      mUtil(pDecodeUtil)
+{
+    LOGV("entry %p", this);
+    nPushModeInputLen = mUtil->getPushModeInputLen();
+    nRingBufferScale = RING_BUFFER_SCALE;
+
+    //these values must be reset by subclass
+    errorCount = 0;
+    profileErrorCount = 0;
+
+    accumulatedOutputLen = 0;
+}
+
+UniaDecoder::~UniaDecoder()
+{
+    LOGV("entry");
+}
+
+c2_status_t UniaDecoder::doInit()
+{
+    LOGV("entry");
+    AUDIOFORMAT format = FORMAT_UNKNOW;
+    bool hwBased = false;
+
+    // from InitComponent
+    c2_status_t ret = C2_OK;
+    LOGD("UniaDecoder::doInit");
+
+    memOps.Calloc = appLocalCalloc;
+    memOps.Malloc = appLocalMalloc;
+    memOps.Free= appLocalFree;
+    memOps.ReAlloc= appLocalReAlloc;
+
+    errorCount = 0;
+    inputFrameCount = 0;
+    consumeFrameCount= 0;
+    profileErrorCount = 0;
+    mWrapper = nullptr;
+    mLibHandle = nullptr;
+
+    if(nPushModeInputLen == 0){
+        LOGE("audio decoder param not inited!");
+        return C2_BAD_VALUE;
+    }
+    LOGD("nPushModeInputLen=%d" ,nPushModeInputLen);
+
+    PcmMode.nChannels = 2;
+    PcmMode.nBitPerSample = 16;
+    PcmMode.nSamplingRate = 44100;
+
+    ret = _createWrapperInterface();
+    if(ret != C2_OK)
+        return ret;
+
+    // from AudioFilterInstanceInit
+    codecConfig.buf = nullptr;
+    codecConfig.size = 0;
+    errorCount = 0;
+    profileErrorCount = 0;
+    mWrapperHandle = nullptr;
+
+    do{
+        LOGI("SetupWrapper %s
", mWrapper->GetVersionInfo());
+
+        ret = mUtil->getDecoderProp(&format, &hwBased);
+
+        if (ret == C2_OK && mWrapper->CreateDecoderPlus != nullptr && hwBased)
+            mWrapperHandle = mWrapper->CreateDecoderPlus(&memOps, format);
+        else
+            mWrapperHandle = mWrapper->CreateDecoder(&memOps);
+
+        if(ret == C2_OMITTED)
+            ret = C2_OK;
+
+        if(mWrapperHandle == nullptr){
+            ret = C2_OMITTED;
+            break;
+        }
+
+        _initWrapperWithParam();
+    }while(0);
+
+    return ret;
+}
+
+c2_status_t UniaDecoder::handleEOS(uint8_t **ppBuffer, uint32_t* length)
+{
+    LOGV("entry");
+    return mUtil->handleEOS(ppBuffer, length);
+}
+
+c2_status_t UniaDecoder::handleBOS(uint32_t* offset, uint32_t length)
+{
+    LOGV("entry");
+    uint64_t off1, off2;
+    c2_status_t err = C2_OK;
+
+    off1 = *offset;
+    err = mUtil->handleBOS(offset, length);
+    off2 = *offset;
+
+    if (off2 > off1) {
+        // need adjust timestamp because handleBOS cut samples from this buffer
+        uint64_t bitrate = PcmMode.nChannels*PcmMode.nSamplingRate*nOutputBitPerSample;
+        LOGV("bitrate %lld handled length %lld", (long long)bitrate, (long long)(off2-off1));
+        mTimestampDelta += (int64_t)((off2-off1)*8*TICKS_PER_SECOND + bitrate - 1)/bitrate;
+    }
+    return err;
+}
+
+AUDIO_DECODE_RETURN_TYPE UniaDecoder::doDecode(const std::unique_ptr<C2Work> &work,
+                                                    std::list<uint8_t *> &outputBuffers, std::list<uint32_t> &outputSizes)
+{
+    LOGV("entry");
+    AUDIO_DECODE_RETURN_TYPE ret;
+    do{
+        uint32_t nTmpOutBufferLen = 0;
+        uint8_t * pTmpOutBuffer = nullptr;
+        ret = _doDecodeInternal(work, &pTmpOutBuffer, &nTmpOutBufferLen);
+        if(pTmpOutBuffer != nullptr){
+            //_calcCheckSum(pTmpOutBuffer, nTmpOutBufferLen);
+            outputBuffers.push_back(pTmpOutBuffer);
+            outputSizes.push_back(nTmpOutBufferLen);
+            LOGV("push %d to outputSizes", nTmpOutBufferLen);
+        }
+        /*
+        if(ret == AUDIO_DECODE_NEEDMORE
+            && (AudioRingBuffer.AudioDataLen() < nPushModeInputLen)
+            && !bReceivedEOS
+            )
+            return AUDIO_DECODE_SUCCESS;
+        */
+        if(ret == AUDIO_DECODE_FATAL_ERROR || ret == AUDIO_DECODE_EOS)
+            break;
+
+        if(AudioRingBuffer.AudioDataLen() < nPushModeInputLen && !bReceivedEOS)
+            break;
+    }while(true);
+
+    return ret;
+}
+
+AUDIO_DECODE_RETURN_TYPE UniaDecoder::_doDecodeInternal(
+    const std::unique_ptr<C2Work> &work, uint8_t **ppOutputBuffer, uint32_t *pOutputSize)
+{
+    LOGV("entry");
+    AUDIO_DECODE_RETURN_TYPE ret = AUDIO_DECODE_SUCCESS;
+    int32_t decoderRet = ACODEC_SUCCESS;
+    uint32_t nActualOutLen = 0;
+    //uint32_t InputOffsetBegin = 0;
+    uint32_t consumeLen = 0;
+    uint32_t InputLen = 0;;
+    uint32_t InputOffset = 0;
+    uint8_t * pInputBuffer = nullptr;
+    *ppOutputBuffer = nullptr;
+    *pOutputSize = 0;
+    UniaDecFrameInfo FrameInfo;
+    memset(&FrameInfo, 0, sizeof(UniaDecFrameInfo));
+
+    AudioRingBuffer.BufferGet(&pInputBuffer, nPushModeInputLen, &InputLen);
+    LOGV("nPushModeInputLen %d,InputLen %d,isFrameInput %d",
+              nPushModeInputLen, InputLen, mUtil->isFrameInput());
+
+    if(ePlayMode == DEC_STREAM_MODE && C2_OK == mUtil->parseFrame(pInputBuffer,InputLen,&FrameInfo)){
+        if(FrameInfo.bGotOneFrame){
+            LOGV("got one frame,size=%d,next=%d,header=%d"
+                ,FrameInfo.nFrameSize,FrameInfo.nNextSize,FrameInfo.nHeaderSize);
+            uint32_t nActualInLen = 0;
+            InputLen = FrameInfo.nFrameSize;
+            InputOffset = 0;
+            AudioRingBuffer.BufferGet(&pInputBuffer, InputLen, &nActualInLen);
+
+            if(FrameInfo.nNextSize > 0)
+                nRequiredSize = FrameInfo.nNextSize+DEFAULT_REQUIRED_SIZE;
+            else
+                nRequiredSize = 0;
+
+            if(nActualInLen < InputLen){
+                LOGE("Can't get a full frame(%d) from ringbuffer, nActualLen=%d",InputLen, nActualInLen);
+                return ret;
+            }
+        }else{
+            nRequiredSize = FrameInfo.nFrameSize+DEFAULT_REQUIRED_SIZE;
+            LOGI("can't get one frame,size=%d",FrameInfo.nFrameSize);
+            return ret;
+        }
+    }else if(mUtil->isFrameInput() && InputLen != 0){
+        uint32_t nFrameLen;
+        nFrameLen = TS_Manager.GetFrameLen();
+        LOGV("nFrameLen from tsm %d",   nFrameLen);
+        if (nFrameLen == 0)
+            nFrameLen = nPushModeInputLen;
+
+        AudioRingBuffer.BufferGet(&pInputBuffer, nFrameLen, &InputLen);
+    }
+    //struct timeval tv, tv1;
+    //gettimeofday (&tv, nullptr);
+    //InputOffsetBegin = InputOffset;
+
+    uint32_t outputBufferSize = mUtil->getOutBufferLen();
+    uint8_t * pOutputBuffer = (uint8_t *)malloc(outputBufferSize);
+    if(!pOutputBuffer){
+        LOGE("malloc output buffer fail! size %d", outputBufferSize);
+        return AUDIO_DECODE_FAILURE;
+    }
+
+    LOGV("now decoding...  InputLen %d, outBufSize %d",InputLen, outputBufferSize);
+
+    if(pInputBuffer && InputLen > 0){
+        decoderRet = mWrapper->DecodeFrame(mWrapperHandle,pInputBuffer,InputLen,
+            &InputOffset,&pOutputBuffer,&nActualOutLen);
+        if(!mUtil->isFrameInput()){
+            if(decoderRet == ACODEC_ERR_UNKNOWN && InputOffset == 0)
+                InputOffset = InputLen; // skip this block of data, avoid dead loop in doDecode
+            LOGV("ringbuffer consumed InputOffset %d", InputOffset);
+            AudioRingBuffer.BufferConsumed(InputOffset);
+            LOGV("ringbuffer left %d", AudioRingBuffer.AudioDataLen());
+        }
+        inputFrameCount += InputOffset;
+    }else{
+        decoderRet = mWrapper->DecodeFrame(mWrapperHandle,nullptr,0,&InputOffset,&pOutputBuffer,&nActualOutLen);
+    }
+    LOGV("wrapperRet \"%s\", InputOffset=%d, nActualOutLen=%d",  _wrapperRet2string(decoderRet),InputOffset,nActualOutLen);
+    //gettimeofday (&tv1, nullptr);
+    //LOGD("AudioFilterFrame decode cost: %d
", (tv1.tv_sec-tv.tv_sec)*1000+(tv1.tv_usec-tv.tv_usec)/1000);
+
+    if(decoderRet == ACODEC_SUCCESS || decoderRet == ACODEC_CAPIBILITY_CHANGE){
+        /*
+        int32_t channelCount = 0;
+        int32_t sampleRate = 0;
+        if(mUtil->getParameter(UNIA_CHANNEL, &channelCount) != C2_OK
+            || mUtil->getParameter(UNIA_SAMPLERATE, &sampleRate) != C2_OK)
+            LOGE("Can't get channelCount and sampleRate!");
+            */
+        if(decoderRet == ACODEC_CAPIBILITY_CHANGE)
+                _updateParamFromWrapper(&work->worklets.front()->output.configUpdate);
+
+        TS_PerFrame = (int64_t)nActualOutLen*8*TICKS_PER_SECOND/PcmMode.nChannels \
+                /PcmMode.nSamplingRate/nOutputBitPerSample;//PcmMode.nBitPerSample;
+
+        mWrapper->GetParameter(mWrapperHandle,UNIA_CONSUMED_LENGTH,(UniACodecParameter*)&consumeLen);
+
+        TS_Manager.Consumed(consumeLen);
+        LOGV("AudioTime.TS_Increase TS_PerFrame=%lld",(long long)TS_PerFrame);
+        TS_Manager.TS_SetIncrease(TS_PerFrame);
+
+        // finetune ts with total output len to match with vts
+        accumulatedOutputLen += nActualOutLen;
+        uint64_t totalTS = (int64_t)accumulatedOutputLen*8*TICKS_PER_SECOND/PcmMode.nChannels \
+                /PcmMode.nSamplingRate/nOutputBitPerSample;//PcmMode.nBitPerSample;
+        int64_t current;
+        TS_Manager.TS_Get(&current);
+        if(totalTS == (current + 1))
+            TS_Manager.TS_SetIncrease(1);
+
+        consumeFrameCount += consumeLen;
+        if(mUtil->isFrameInput()){
+            //more than one frames could be in a frame buffer, so consume one frame's length.
+            LOGV("ringbuffer consumed consumeLen %d", consumeLen);
+            AudioRingBuffer.BufferConsumed(consumeLen);
+            LOGV("ringbuffer left %d", AudioRingBuffer.AudioDataLen());
+        }
+
+        if(nActualOutLen == 0){
+            ret = AUDIO_DECODE_NEEDMORE;
+        }
+
+        #if 0
+        FILE * pfile;
+        pfile = fopen("/data/data/pcm","ab");
+        if(pfile){
+            fwrite(pOutputBuffer,1,nActualOutLen,pfile);
+            fclose(pfile);
+        }
+        #endif
+        if(nActualOutLen != 0){
+            *ppOutputBuffer = pOutputBuffer;
+            *pOutputSize = nActualOutLen;
+            profileErrorCount = 0;
+        }
+    }else if(decoderRet == ACODEC_END_OF_STREAM){
+        ret = AUDIO_DECODE_EOS;
+    }else if(decoderRet == ACODEC_NOT_ENOUGH_DATA){
+        ret = AUDIO_DECODE_NEEDMORE;
+    }else if((decoderRet == ACODEC_ERROR_STREAM || decoderRet == ACODEC_ERR_UNKNOWN) && pInputBuffer){
+        mWrapper->GetParameter(mWrapperHandle,UNIA_CONSUMED_LENGTH,(UniACodecParameter*)&consumeLen);
+        mWrapper->ResetDecoder(mWrapperHandle);
+        if(mUtil->isFrameInput()){
+            LOGV("ringbuffer consumed InputOffset %d", InputOffset);
+            AudioRingBuffer.BufferConsumed(InputOffset);
+            LOGV("ringbuffer left %d", AudioRingBuffer.AudioDataLen());
+        }
+        TS_Manager.Consumed(InputOffset);
+        consumeFrameCount += InputOffset;
+        LOGD("consumeLen=%d,InputOffset=%d",consumeLen,InputOffset);
+        ret = AUDIO_DECODE_FAILURE;
+        errorCount ++;
+    }else if((decoderRet == ACODEC_ERROR_STREAM || decoderRet == ACODEC_ERR_UNKNOWN) && !pInputBuffer){
+        LOGD("SET TO EOS");
+        ret = AUDIO_DECODE_EOS;
+    }else if(decoderRet == ACODEC_PROFILE_NOT_SUPPORT){
+        ret = AUDIO_DECODE_EOS;
+        profileErrorCount++;
+    }else if(decoderRet == ACODEC_INIT_ERR){
+        ret = AUDIO_DECODE_FATAL_ERROR;
+    }else if(ACODEC_PARA_ERROR == decoderRet){
+        if(C2_OK != mUtil->checkParameter()){
+            mWrapper->ResetDecoder(mWrapperHandle);
+            ret = AUDIO_DECODE_FATAL_ERROR;
+            LOGE("ACODEC_PARA_ERROR check failed");
+        }
+    }else{
+        ret = AUDIO_DECODE_FAILURE;
+        errorCount ++;
+    }
+
+    //for test usage
+    if(errorCount > 500){
+        LOGD("Unia Decoder error count > 500 ***!!!");
+        errorCount = 0;
+    }
+
+    //check if count of profile error reaches the limited.
+    if(profileErrorCount > MAX_PROFILE_ERROR_COUNT){
+        ret = AUDIO_DECODE_FATAL_ERROR;
+        profileErrorCount = 0;
+        LOGD("return AUDIO_DECODE_FATAL_ERROR instead of ACODEC_PROFILE_NOT_SUPPORT");
+    }
+
+    // outputbuffer doesn't contain valid data, free it here
+    if(*ppOutputBuffer == nullptr)
+        free(pOutputBuffer);
+
+    return ret;
+}
+
+
+c2_status_t UniaDecoder::checkFrameHeader()
+{
+    LOGV("entry");
+    uint8_t *pBuffer;
+    uint32_t nActualLen = 0;
+    uint32_t nVal = 0;
+    uint32_t nOffset = 0;
+    c2_status_t ret = C2_OK;
+    //AUDIO_FRAME_INFO FrameInfo;
+    //memset(&FrameInfo, 0, sizeof(AUDIO_FRAME_INFO));
+
+    size_t pushModeLen = mUtil->getFrameHdrBufLen();
+    if(pushModeLen <= 0)
+        return ret;
+
+    AudioRingBuffer.BufferGet(&pBuffer, pushModeLen, &nActualLen);
+    LOGV("Get stream length: %d, pushModeLen %zu
", nActualLen, pushModeLen);
+
+#ifdef DECODE_EACH_INPUT
+    pushModeLen = 1;
+#endif
+
+    if (nActualLen < pushModeLen && ePlayMode == DEC_FILE_MODE){
+        LOGW("no enough data to check frame header");
+        return C2_OK;
+    }
+
+    ret = mUtil->checkFrameHeader(pBuffer, nActualLen, &nOffset);
+    if(nOffset > 0){
+        AudioRingBuffer.BufferConsumed(nOffset);
+        TS_Manager.Consumed(nOffset);
+    }
+    LOGI("isFrameInput %d", mUtil->isFrameInput());
+
+    return ret;
+}
+
+c2_status_t UniaDecoder::codecInit()
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    int32_t value = 0;
+    //set stream type here for aac type after got from frame header
+    if(C2_OK == mUtil->getParameter(UNIA_STREAM_TYPE,&value)){
+        LOGV("mWrapper SetParameter UNIA_STREAM_TYPE=%d",value);
+        mWrapper->SetParameter(mWrapperHandle,UNIA_STREAM_TYPE,(UniACodecParameter*)&value);
+    }
+    return ret;
+}
+
+
+void UniaDecoder::doReset()
+{
+    LOGV("entry");
+    if(mWrapper == nullptr || mWrapperHandle == nullptr){
+        LOGE("performReset invalid argument");
+        return;
+    }
+
+    int32_t ret = mWrapper->ResetDecoder(mWrapperHandle);
+    if(ret != ACODEC_SUCCESS){
+        LOGE("wrapper ResetDecoder fail! ret=%d",ret);
+    }
+    return;
+}
+
+
+c2_status_t UniaDecoder::checkCodecConfig(const uint8 * data, size_t size)
+{
+    LOGV("entry, size %zu", size);
+    if(mWrapper == nullptr || mWrapperHandle == nullptr)
+        return C2_BAD_VALUE;
+
+    /*
+    const uint8 * pBuffer = data;
+    LOGV("codec config %2x %2x %2x %2x %2x, %2x %2x %2x %2x %2x ",
+        pBuffer[0],pBuffer[1],pBuffer[2],pBuffer[3],pBuffer[4],
+        pBuffer[size-5],pBuffer[size-4],pBuffer[size-3],pBuffer[size-2],pBuffer[size-1]
+        );
+    */
+    if (codecConfig.buf != nullptr) {
+        codecConfig.buf = (char *)realloc(codecConfig.buf, \
+            codecConfig.size + size);
+        if (codecConfig.buf == nullptr)
+        {
+            LOGE("Can't get memory.
");
+            return C2_NO_MEMORY;
+        }
+        memcpy(codecConfig.buf + codecConfig.size, data, size);
+        codecConfig.size += size;
+
+    } else {
+         codecConfig.buf = (char *)malloc(size);
+        if (codecConfig.buf == nullptr)
+        {
+            LOGE("Can't get memory.
");
+            return C2_NO_MEMORY;
+        }
+        memcpy(codecConfig.buf, data , size);
+        codecConfig.size = size;
+    }
+
+    LOGV("mWrapper SetParameter UNIA_CODEC_DATA len %d", codecConfig.size);
+    int32_t ret = mWrapper->SetParameter(mWrapperHandle,UNIA_CODEC_DATA,(UniACodecParameter*)&codecConfig);
+    if(ret != ACODEC_SUCCESS){
+        LOGE("UniaDec::performCheckCodecConfig fail size %zu,ret=%d",size, ret);
+        return C2_CORRUPTED;
+    }
+
+    return C2_OK;
+}
+
+c2_status_t UniaDecoder::unInit()
+{
+    LOGV("entry");
+    free(codecConfig.buf);
+    codecConfig.buf = nullptr;
+
+    if(mWrapper != nullptr && mWrapperHandle != nullptr){
+        mWrapper->DeleteDecoder(mWrapperHandle);
+        mWrapperHandle = nullptr;
+    }
+
+    if (mLibHandle)
+        dlclose(mLibHandle);
+    mLibHandle = nullptr;
+    free(mWrapper);
+    mWrapper = nullptr;
+    LOGV("UniaDec::DeInitComponent inputFrameCount=%d,consumeFrameCount=%d",inputFrameCount,consumeFrameCount);
+    return C2_OK;
+}
+
+c2_status_t UniaDecoder::getParamDirectly()
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    int32_t decoderRet = ACODEC_SUCCESS;
+    UniAcodecOutputPCMFormat outputValue;
+
+    decoderRet = mWrapper->GetParameter(mWrapperHandle,UNIA_OUTPUT_PCM_FORMAT,(UniACodecParameter*)&outputValue);
+    if(ACODEC_SUCCESS != decoderRet || outputValue.samplerate == 0 || PcmMode.nSamplingRate == 0) {
+        return C2_BAD_VALUE;
+    }
+
+    PcmMode.nSamplingRate = outputValue.samplerate;
+    PcmMode.nChannels = outputValue.channels;
+
+    return ret;
+
+}
+
+c2_status_t UniaDecoder::_initWrapperWithParam()
+{
+    int32_t value;
+
+    for ( uint32_t i = UNIA_SAMPLERATE; i < UNIA_STREAM_TYPE; i++){
+        if(i == UNIA_CODEC_DATA)
+            continue;
+
+        value = 0;
+        if(C2_OK == mUtil->getParameter((UA_ParaType)i,&value)){
+            LOGV("mWrapper SetParameter %d=%d, SetParameterToDecoder",i, value);
+            mWrapper->SetParameter(mWrapperHandle,(UA_ParaType)i,(UniACodecParameter*)&value);
+        }
+    }
+
+    //set output format for channel layout
+    memset(&channelTable,0,sizeof(CHAN_TABLE));
+    if(C2_OK == mUtil->getParameter(UNIA_CHAN_MAP_TABLE,(int32_t*)&channelTable)){
+        LOGI("mWrapper SetParameter UNIA_CHAN_MAP_TABLE");
+        mWrapper->SetParameter(mWrapperHandle,UNIA_CHAN_MAP_TABLE,(UniACodecParameter*)&channelTable);
+    }
+
+    value = 0;
+    if(C2_OK == mUtil->getParameter(UNIA_WMA_BlOCKALIGN,&value)){
+        LOGI("mWrapper SetParameter UNIA_WMA_BlOCKALIGN %d", value);
+        mWrapper->SetParameter(mWrapperHandle,UNIA_WMA_BlOCKALIGN,(UniACodecParameter*)&value);
+    }
+
+    value = 0;
+    if(C2_OK == mUtil->getParameter(UNIA_WMA_VERSION,&value)){
+        LOGI("mWrapper SetParameter UNIA_WMA_VERSION %d", value);
+        mWrapper->SetParameter(mWrapperHandle,UNIA_WMA_VERSION,(UniACodecParameter*)&value);
+    }
+
+    value = 0;
+    if(C2_OK == mUtil->getParameter(UNIA_RA_FRAME_BITS,&value)){
+        LOGI("mWrapper SetParameter UNIA_RA_FRAME_BITS %d", value);
+        mWrapper->SetParameter(mWrapperHandle,UNIA_RA_FRAME_BITS,(UniACodecParameter*)&value);
+    }
+
+    return C2_OK;
+}
+
+void UniaDecoder::_updateParamFromWrapper(std::vector<std::unique_ptr<C2Param>> *configUpdate)
+{
+    LOGV("entry");
+    UniAcodecOutputPCMFormat outputValue;
+    int32_t original = 0;
+    int32_t neu = 0;
+
+    if(ACODEC_SUCCESS == mWrapper->GetParameter(mWrapperHandle,UNIA_OUTPUT_PCM_FORMAT,(UniACodecParameter*)&outputValue)){
+        if(outputValue.samplerate == 0 || outputValue.channels == 0 || outputValue.depth == 0){
+            LOGE("bad value: sample rate=%d,channel=%d,depth=%d",
+                outputValue.samplerate,outputValue.channels,outputValue.depth);
+            return;
+        }
+
+        LOGI("PCM FORMAT sample rate %d=>%d, channels %d=>%d, bitdepth %d=>%d",
+            PcmMode.nSamplingRate, outputValue.samplerate,
+            PcmMode.nChannels, outputValue.channels,
+            PcmMode.nBitPerSample, outputValue.depth);
+        PcmMode.nSamplingRate = outputValue.samplerate;
+        PcmMode.nChannels = outputValue.channels;
+        nOutputBitPerSample = PcmMode.nBitPerSample = outputValue.depth;
+        //PcmMode.bInterleaved = (bool)outputValue.interleave;
+
+        //Will codec2 use channel mapping ?
+        /*
+        if(PcmMode.nChannels > 2){
+            MapOutputLayoutChannel(&outputValue);
+        }
+
+        LOGD("OUTPUT CHANGED channel=%d,layout=%d,%d,%d,%d,%d,%d,%d,%d",PcmMode.nChannels,
+            PcmMode.eChannelMapping[0],PcmMode.eChannelMapping[1],PcmMode.eChannelMapping[2],
+            PcmMode.eChannelMapping[3],PcmMode.eChannelMapping[4],PcmMode.eChannelMapping[5],
+            PcmMode.eChannelMapping[6],PcmMode.eChannelMapping[7]);
+        */
+    }
+
+    neu = original = 0;
+    if(ACODEC_SUCCESS == mWrapper->GetParameter(mWrapperHandle,UNIA_SAMPLERATE,(UniACodecParameter*)&neu)
+        && C2_OK == mUtil->getParameter(UNIA_SAMPLERATE, &original)){
+        if(neu != original){
+            LOGI("update samplereate %d=>%d", original, neu);
+            if(C2_OK == mUtil->setParameter(UNIA_SAMPLERATE,neu)){
+                C2StreamSampleRateInfo::output sampleRateInfo(0u, neu);
+                configUpdate->push_back(C2Param::Copy(sampleRateInfo));
+            }
+        }
+    }
+
+    neu = original = 0;
+    if(ACODEC_SUCCESS == mWrapper->GetParameter(mWrapperHandle,UNIA_CHANNEL,(UniACodecParameter*)&neu)
+        && C2_OK == mUtil->getParameter(UNIA_CHANNEL, &original)){
+        if(neu != original){
+            LOGI("update channel num %d=>%d", original, neu);
+            if(C2_OK == mUtil->setParameter(UNIA_CHANNEL, neu)){
+                C2StreamChannelCountInfo::output channelCountInfo(0u, neu);
+                configUpdate->push_back(C2Param::Copy(channelCountInfo));
+            }
+        }
+    }
+
+    neu = original = 0;
+    if(ACODEC_SUCCESS == mWrapper->GetParameter(mWrapperHandle,UNIA_BITRATE,(UniACodecParameter*)&neu)
+        && C2_OK == mUtil->getParameter(UNIA_BITRATE, &original)){
+        if(neu != original && neu != 0){
+            LOGI("update bitrate %d=>%d", original, neu);
+            if(C2_OK == mUtil->setParameter(UNIA_BITRATE,neu)){
+                C2StreamBitrateInfo::input bitrate(0u, neu);
+                configUpdate->push_back(C2Param::Copy(bitrate));
+            }
+        }
+    }
+
+    neu = original = 0;
+    if(ACODEC_SUCCESS == mWrapper->GetParameter(mWrapperHandle,UNIA_DEPTH,(UniACodecParameter*)&neu)
+        && C2_OK == mUtil->getParameter(UNIA_DEPTH, &original)){
+        if(neu > 0 && neu != original){
+            LOGI("update bitdepth %d=>%d", original, neu);
+            mUtil->setParameter(UNIA_DEPTH,neu);
+        }
+        // todo : send to configUpdate
+    }
+
+    return;
+}
+
+c2_status_t UniaDecoder::_createWrapperInterface()
+{
+    int32_t ret = C2_OK;
+
+    do{
+        const char * wrapperLibName;
+        const char * optionalWrapperLibName;
+
+        mUtil->getLibName(&wrapperLibName, &optionalWrapperLibName);
+
+        tUniACodecQueryInterface  myQueryInterface;
+
+        if(wrapperLibName == nullptr){
+            ret = C2_BAD_VALUE;
+            break;
+        }
+        if(optionalWrapperLibName != nullptr){
+            mLibHandle = dlopen(optionalWrapperLibName, RTLD_NOW);
+            LOGD("Audio Decoder library name 1: %s
", optionalWrapperLibName);
+        }
+
+        if(mLibHandle == nullptr){
+            mLibHandle = dlopen(wrapperLibName, RTLD_NOW);
+            LOGD("Audio Decoder library name 2: %s
", wrapperLibName);
+        }
+
+        if(mLibHandle == nullptr){
+            LOGE("Fail to open Decoder library
");
+            ret = C2_CORRUPTED;
+            break;
+        }
+
+        mWrapper = (UniaDecInterface *)malloc(sizeof(UniaDecInterface));
+        if(mWrapper == nullptr){
+            ret = C2_NO_MEMORY;
+            break;
+        }
+        memset(mWrapper,0 ,sizeof(UniaDecInterface));
+
+        myQueryInterface = (tUniACodecQueryInterface)dlsym(mLibHandle, (char *)"UniACodecQueryInterface");
+        if(!myQueryInterface)
+        {
+            LOGE("Fail to query decoder interface
");
+            ret = C2_OMITTED;
+            break;
+        }
+
+        ret = myQueryInterface(ACODEC_API_GET_VERSION_INFO, (void **)&mWrapper->GetVersionInfo);
+
+        ret |= myQueryInterface(ACODEC_API_CREATE_CODEC, (void **)&mWrapper->CreateDecoder);
+        ret |= myQueryInterface(ACODEC_API_DELETE_CODEC, (void **)&mWrapper->DeleteDecoder);
+        ret |= myQueryInterface(ACODEC_API_RESET_CODEC, (void **)&mWrapper->ResetDecoder);
+        ret |= myQueryInterface(ACODEC_API_SET_PARAMETER, (void **)&mWrapper->SetParameter);
+        ret |= myQueryInterface(ACODEC_API_GET_PARAMETER, (void **)&mWrapper->GetParameter);
+        ret |= myQueryInterface(ACODEC_API_DEC_FRAME, (void **)&mWrapper->DecodeFrame);
+        ret |= myQueryInterface(ACODEC_API_GET_LAST_ERROR, (void **)&mWrapper->GetLastError);
+
+        if(ret != C2_OK){
+            LOGE("Fail to query decoder API
");
+            ret = C2_OMITTED;
+            break;
+        }
+
+        ret = myQueryInterface(ACODEC_API_CREATE_CODEC_PLUS, (void **)&mWrapper->CreateDecoderPlus);
+        if (ret != C2_OK){
+            LOGD("ACODEC_API_CREATE_CODEC_PLUS is not implemented
");
+            ret = C2_OK;
+        }
+
+    }while(0);
+
+    if(ret != C2_OK){
+        LOGE("UniaDecoder::CreateDecoderInterface ret=%d",ret);
+        if (mLibHandle)
+            dlclose(mLibHandle);
+        mLibHandle = nullptr;
+        free(mWrapper);
+        mWrapper = nullptr;
+    }
+
+    return (c2_status_t)ret;
+}
+
+const char * UniaDecoder::_wrapperRet2string(uint32_t uniaDecodeRet){
+    switch(uniaDecodeRet){
+        case ACODEC_SUCCESS:             return "success";
+        case ACODEC_ERROR_STREAM:        return "error stream";
+        case ACODEC_PARA_ERROR:          return "para error";
+        case ACODEC_INSUFFICIENT_MEM:    return "insufficient mem";
+        case ACODEC_ERR_UNKNOWN:         return "error unknown";
+        case ACODEC_PROFILE_NOT_SUPPORT: return "profile not support";
+        case ACODEC_INIT_ERR:            return "init error";
+        case ACODEC_NO_OUTPUT:           return "no output";
+        case ACODEC_NOT_ENOUGH_DATA:     return "not enough data";
+        case ACODEC_CAPIBILITY_CHANGE:   return "capability change";
+        case ACODEC_END_OF_STREAM:       return "eos";
+        default:                         return "unknown";
+    }
+}
+
+void UniaDecoder::_calcCheckSum(uint8_t *pBuffer, uint32_t size)
+{
+    uint32_t sum = 0;
+    for(uint32_t i=0; i<size; i++)
+        sum += pBuffer[i];
+    LOGI("checksum is %d", sum);
+}
+
+}
+
diff --git a/codec2/audio_dec/common/UniaDecoder.h b/codec2/audio_dec/common/UniaDecoder.h
new file mode 100755
index 0000000..34af94e
--- /dev/null
+++ b/codec2/audio_dec/common/UniaDecoder.h
@@ -0,0 +1,88 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef UNIA_DECODER_h
+#define UNIA_DECODER_h
+
+#include "IMXAudioDecComponent.h"
+#include "AudioDecodeUtil.h"
+#include <fsl_unia.h>
+
+namespace android {
+
+struct UniaDecInterface
+{
+    UniACodecVersionInfo                GetVersionInfo;
+    UniACodecCreate                     CreateDecoder;
+    UniACodecCreatePlus                 CreateDecoderPlus;
+    UniACodecDelete                     DeleteDecoder;
+    UniACodecReset                      ResetDecoder;
+    UniACodecSetParameter               SetParameter;
+    UniACodecGetParameter               GetParameter;
+    UniACodec_decode_frame              DecodeFrame;
+    UniACodec_get_last_error            GetLastError;
+};
+
+struct UniaDecFrameInfo {
+    bool bGotOneFrame;//true when get one frame and next frame's header
+    uint32_t nHeaderCount;
+    uint32_t nConsumedOffset;//frame header offset if get one frame
+    uint32_t nFrameSize;//frame size
+    uint32_t nNextSize;//frame size
+    uint32_t nHeaderSize;
+};
+
+class UniaDecoder : public IMXAudioDecComponent {
+    public:
+        UniaDecoder(const std::shared_ptr<C2ComponentInterface> &intf, AudioDecodeUtil *);
+        virtual ~UniaDecoder();
+
+    protected:
+        // from IMXAudioDecComponent
+        c2_status_t doInit() override;
+        c2_status_t unInit() override;
+        c2_status_t checkCodecConfig(const uint8 * data, size_t size) override;
+        AUDIO_DECODE_RETURN_TYPE doDecode(const std::unique_ptr<C2Work> &work,
+                                                    std::list<uint8_t *> &outputBuffers, std::list<uint32_t> &outputSizes) override;
+        void            doReset() override;
+        c2_status_t checkFrameHeader() override;
+        c2_status_t codecInit() override;
+        c2_status_t handleEOS(uint8_t **ppBuffer, uint32_t* length) override;
+        c2_status_t handleBOS(uint32_t* offset, uint32_t length) override;
+        c2_status_t getParamDirectly() override;
+
+    private:
+
+        void * mLibHandle;
+        UniaDecInterface * mWrapper;
+        void * mWrapperHandle;
+        AudioDecodeUtil * mUtil;
+
+        UniACodecMemoryOps memOps;
+        UniACodecParameterBuffer codecConfig;
+        CHAN_TABLE channelTable;
+        int32_t errorCount;//debug
+        int32_t profileErrorCount;
+        uint32_t consumeFrameCount;
+        uint32_t inputFrameCount;
+        uint32_t accumulatedOutputLen;
+
+        AUDIO_DECODE_RETURN_TYPE _doDecodeInternal(const std::unique_ptr<C2Work> &work,
+                                                        uint8_t **ppOutputBuffer, uint32_t *pOutputSize);
+
+        c2_status_t _createWrapperInterface();
+        c2_status_t _initWrapperWithParam();
+        void _updateParamFromWrapper(std::vector<std::unique_ptr<C2Param>> *configUpdate);
+        const char * _wrapperRet2string(uint32_t uniaDecodeRet);
+        void _calcCheckSum(uint8_t *pBuffer, uint32_t size);
+
+};
+
+};
+#endif
+
diff --git a/codec2/audio_dec/common/audio_frame_parser/AacFrameParser.c b/codec2/audio_dec/common/audio_frame_parser/AacFrameParser.c
new file mode 100755
index 0000000..a710fa4
--- /dev/null
+++ b/codec2/audio_dec/common/audio_frame_parser/AacFrameParser.c
@@ -0,0 +1,102 @@
+/**
+ *  Copyright (c) 2010-2015, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+#include "AacFrameParser.h"
+
+static const uint32_t aac_sampling_frequency[] = {96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000};
+#define AAC_SAMPLERATE_TABLE_SIZE (uint32_t)(sizeof(aac_sampling_frequency)/sizeof(aac_sampling_frequency[0]))
+#define AAC_FRAME_SIZE 1024
+static eimx_linux_bool IsADTSFrameHeader(uint8_t * pHeader,FRAME_INFO * Info)
+{
+    int32_t id;
+    int32_t layer;
+    int32_t rotection_abs = 0;
+    int32_t profile;
+    int32_t sampling_freq_idx;
+    int32_t private_bit;
+    int32_t channel_config;
+    int32_t original_copy;
+    int32_t home;
+    int32_t copyright_id_bit;
+    int32_t copyright_id_start;
+    int32_t frame_length;
+    int32_t adts_buffer_fullness;
+    int32_t num_of_rdb;
+    int32_t protection_abs;
+
+    if(pHeader == NULL || Info == NULL)
+        return E_IMX_FALSE;
+
+    if(pHeader[0] !=0xFF || (pHeader[1] & 0xF0) != 0xF0)
+        return E_IMX_FALSE;
+
+    id = ((int32_t)pHeader[1]&0x08)>>3;
+    layer = ((int32_t)pHeader[1]&0x06)>>1;
+    protection_abs = (int32_t)pHeader[1]&0x01;
+
+    if(layer != 0){
+        return E_IMX_FALSE;
+    }
+
+    profile = ((int32_t)pHeader[2]&0xC0) >> 6;
+    //do not check the profile level, decoder will check it.
+   // if(profile != 1){
+    //    return E_IMX_FALSE;
+   // }
+
+    sampling_freq_idx = ((int32_t)pHeader[2]&0x3C) >> 2;
+    if (sampling_freq_idx >= 0xc){
+        return E_IMX_FALSE;
+    }
+
+    private_bit = ((int32_t)pHeader[2]&0x02) >> 1;
+    channel_config = (((int32_t)pHeader[2]&0x01) << 2) + (((int32_t)pHeader[3]&0xC0) >> 6);
+    original_copy = ((int32_t)pHeader[3]&0x20) >> 5;
+    home = ((int32_t)pHeader[3]&0x10) >> 4;
+
+    copyright_id_bit = ((int32_t)pHeader[3]&0x08) >> 3;
+    copyright_id_start = ((int32_t)pHeader[3]&0x04) >> 2;
+    frame_length = (((int32_t)pHeader[3]&0x03) << 11) + (((int32_t)pHeader[4]) << 3) + (((int32_t)pHeader[5]&0xE0) >> 5);
+
+    adts_buffer_fullness = (((int32_t)pHeader[5]&0x1F) << 6) + (((int32_t)pHeader[6]&0xFC) >> 2);
+    num_of_rdb = ((int32_t)pHeader[6]&0x03);
+
+    Info->channels = channel_config;
+
+    //ref to 13818-7AAC (2).pdf, Table 42  Channel Configuration
+    if(Info->channels == 7)
+    {
+        Info->channels = 8;
+    }
+    else if(Info->channels == 0) //if 0, should parsed in raw block, so just set 1
+    {
+        Info->channels = 1;
+    }
+
+    if((uint32_t)sampling_freq_idx < AAC_SAMPLERATE_TABLE_SIZE)
+    {
+        Info->sampling_rate = aac_sampling_frequency[sampling_freq_idx];
+    }
+
+    Info->sample_per_fr = AAC_FRAME_SIZE;
+    Info->b_rate = (frame_length << 3) * Info->sampling_rate / Info->sample_per_fr; // / 1000;
+
+    Info->frm_size = frame_length;
+
+    if(1 == protection_abs)
+        Info->header_size = 7;
+    else
+        Info->header_size = 9;
+
+    return E_IMX_TRUE;
+}
+AFP_RETURN AacCheckFrame(AUDIO_FRAME_INFO *pFrameInfo, uint8_t *pBuffer, uint32_t nBufferLen)
+{
+    return CheckFrame(pFrameInfo,pBuffer,nBufferLen,AAC_FRAME_HEAD_SIZE,IsADTSFrameHeader);
+}
diff --git a/codec2/audio_dec/common/audio_frame_parser/AacFrameParser.h b/codec2/audio_dec/common/audio_frame_parser/AacFrameParser.h
new file mode 100755
index 0000000..1c3e2ef
--- /dev/null
+++ b/codec2/audio_dec/common/audio_frame_parser/AacFrameParser.h
@@ -0,0 +1,28 @@
+/**
+ *  Copyright (c) 2009-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductors Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+#ifndef AacFrameParser_h
+#define AacFrameParser_h
+
+#include "AudioFrameParser.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define AAC_FRAME_HEAD_SIZE  7
+
+//check frame function
+AFP_RETURN AacCheckFrame(AUDIO_FRAME_INFO *pFrameInfo, uint8_t *pBuffer, uint32_t nBufferLen);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif//AacFrameParser_h
diff --git a/codec2/audio_dec/common/audio_frame_parser/Ac3FrameParser.c b/codec2/audio_dec/common/audio_frame_parser/Ac3FrameParser.c
new file mode 100755
index 0000000..0937ded
--- /dev/null
+++ b/codec2/audio_dec/common/audio_frame_parser/Ac3FrameParser.c
@@ -0,0 +1,104 @@
+/**
+ *  Copyright (c) 2010-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+#include "Ac3FrameParser.h"
+#define NFSCOD      3   /* # defined sample rates */
+#define NDATARATE   38  /* # defined data rates */
+#define AC3D_FRAME_SIZE 1536
+//these tables got from http://rmworkshop.com/dvd_info/related_info/ac3hdr.html
+static const int16_t ac3_frame_size[NFSCOD][NDATARATE] =
+{   {   64, 64, 80, 80, 96, 96, 112, 112,
+    128, 128, 160, 160, 192, 192, 224, 224,
+    256, 256, 320, 320, 384, 384, 448, 448,
+    512, 512, 640, 640, 768, 768, 896, 896,
+    1024, 1024, 1152, 1152, 1280, 1280 },
+{   69, 70, 87, 88, 104, 105, 121, 122,
+    139, 140, 174, 175, 208, 209, 243, 244,
+    278, 279, 348, 349, 417, 418, 487, 488,
+    557, 558, 696, 697, 835, 836, 975, 976,
+    1114, 1115, 1253, 1254, 1393, 1394 },
+{   96, 96, 120, 120, 144, 144, 168, 168,
+    192, 192, 240, 240, 288, 288, 336, 336,
+    384, 384, 480, 480, 576, 576, 672, 672,
+    768, 768, 960, 960, 1152, 1152, 1344, 1344,
+    1536, 1536, 1728, 1728, 1920, 1920 }
+    };
+//these tables got from http://rmworkshop.com/dvd_info/related_info/ac3hdr.html
+static const int32_t ac3_sampling_rate[NFSCOD] = {48000,44100,32000};
+static const int32_t ac3_channel[] = {2,1,2,3,3,4,4,5};
+
+static eimx_linux_bool IsAC3FrameHeader(uint8_t * pHeader,FRAME_INFO * Info)
+{
+    int fscod = 0;
+    int frmsizecod;
+    int bsid;
+    int bsmode;
+    int acmod;
+    int lfeonOffset = 0;
+    int lfeon = 0;
+    int samplerate;
+    int framesize;
+    eimx_linux_bool bigEndian = E_IMX_FALSE;
+
+    if(pHeader == NULL || Info == NULL)
+        return E_IMX_FALSE;
+
+    if ((pHeader[0] == 0x0b && pHeader[1] == 0x77) || (pHeader[0] == 0x77 && pHeader[1] == 0x0b)){
+        ;
+    }else{
+        return E_IMX_FALSE;
+    }
+
+    if(pHeader[0] == 0x0b && pHeader[1] == 0x77){
+        fscod = pHeader[4] >> 6;
+        frmsizecod = pHeader[4] & 0x3f;
+        acmod = pHeader[6] >> 5;
+        bigEndian = E_IMX_TRUE;
+    }
+    else if(pHeader[0] == 0x77 && pHeader[1] == 0x0b){
+        fscod = pHeader[5] >> 6;
+        frmsizecod = pHeader[5] & 0x3f;
+        acmod = pHeader[7] >> 5;
+    }
+
+    if (fscod>=NFSCOD || frmsizecod>=NDATARATE){
+        return E_IMX_FALSE;
+    }
+
+    samplerate = ac3_sampling_rate[fscod];
+    framesize = 2 * ac3_frame_size[fscod][frmsizecod];
+
+    if ((acmod & 0x1) && (acmod != 0x1)){
+        lfeonOffset += 2;
+    }
+    if (acmod & 0x4){
+        lfeonOffset += 2;
+    }
+    if (acmod == 0x2){
+        lfeonOffset += 2;
+    }
+
+    if(lfeonOffset <= 5){
+        lfeon = (pHeader[bigEndian?6:7] >> (4 - lfeonOffset)) & 0x01;
+    }else{
+        lfeon = (pHeader[bigEndian?7:6] >> 6)& 0x01;
+    }
+
+    Info->frm_size = framesize;
+    Info->sampling_rate = samplerate;
+    Info->b_rate = (framesize<<3)*samplerate/AC3D_FRAME_SIZE/1000;
+    Info->sample_per_fr = AC3D_FRAME_SIZE;
+    Info->channels = ac3_channel[acmod] + lfeon;
+    return E_IMX_TRUE;
+}
+
+AFP_RETURN Ac3CheckFrame(AUDIO_FRAME_INFO *pFrameInfo, uint8_t *pBuffer, uint32_t nBufferLen)
+{
+    return CheckFrame(pFrameInfo,pBuffer,nBufferLen,AC3_FRAME_HEAD_SIZE,IsAC3FrameHeader);
+}
diff --git a/codec2/audio_dec/common/audio_frame_parser/Ac3FrameParser.h b/codec2/audio_dec/common/audio_frame_parser/Ac3FrameParser.h
new file mode 100755
index 0000000..f9a9b6f
--- /dev/null
+++ b/codec2/audio_dec/common/audio_frame_parser/Ac3FrameParser.h
@@ -0,0 +1,28 @@
+/**
+ *  Copyright (c) 2009-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductors Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+#ifndef Ac3FrameParser_h
+#define Ac3FrameParser_h
+
+#include "AudioFrameParser.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define AC3_FRAME_HEAD_SIZE  8
+
+//check frame function
+AFP_RETURN Ac3CheckFrame(AUDIO_FRAME_INFO *pFrameInfo, uint8_t *pBuffer, uint32_t nBufferLen);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif//Ac3FrameParser_h
diff --git a/codec2/audio_dec/common/audio_frame_parser/AudioFrameParser.c b/codec2/audio_dec/common/audio_frame_parser/AudioFrameParser.c
new file mode 100755
index 0000000..07852d3
--- /dev/null
+++ b/codec2/audio_dec/common/audio_frame_parser/AudioFrameParser.c
@@ -0,0 +1,123 @@
+/**
+ *  Copyright (c) 2010-2013, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+#include "AudioFrameParser.h"
+#include <malloc.h>
+#include <log/log.h>
+#include <string.h>
+
+AFP_RETURN CheckFrame(AUDIO_FRAME_INFO *pFrameInfo, uint8_t *pBuffer, uint32_t nBufferLen,uint32_t nHeadSize,IsValidHeader fpIsValidHeader)
+{
+    AFP_RETURN ret = AFP_SUCCESS;
+
+    uint32_t nOffset = 0;
+    uint32_t nFrameOffset = 0;
+    uint32_t nFirstFrameSize = 0;
+    uint32_t nFirstHeaderSize = 0;
+    uint32_t nHeaderCount = 0;
+    FRAME_INFO Info;
+    uint8_t* pHeader = NULL;
+
+    if(!pFrameInfo || !pBuffer){
+        return AFP_FAILED;
+    }
+
+    memset(pFrameInfo, 0, sizeof(AUDIO_FRAME_INFO));
+
+    pFrameInfo->bGotOneFrame = false;
+    pFrameInfo->nHeaderCount = 0;
+    pFrameInfo->nConsumedOffset = 0;
+    pFrameInfo->nFrameSize = 0;
+    pFrameInfo->nBitRate = 0;
+    pFrameInfo->nSamplesPerFrame = 0;
+
+    memset(&Info, 0x0, sizeof(FRAME_INFO));
+    ALOGI("CheckFrame start nBufferLen=%d",nBufferLen);
+
+    while(nOffset + nHeadSize <= nBufferLen){
+
+        pHeader = pBuffer + nOffset;
+
+        if(!fpIsValidHeader(pHeader,&Info)){
+            nOffset++;
+            continue;
+        }
+        //check the frame size
+        if(0 == Info.frm_size){
+            nOffset++;
+            continue;
+        }
+
+        nHeaderCount ++;
+        nFrameOffset = nOffset;
+        nFirstFrameSize = Info.frm_size;
+        nFirstHeaderSize = Info.header_size;
+
+        ALOGI("CheckFrame nOffset=%d,frm_size=%d",nOffset,Info.frm_size);
+
+        if(Info.frm_size + nOffset == nBufferLen){
+            printf("CheckFrame frame size=%d,buffer len=%d",Info.frm_size,nBufferLen);
+            pFrameInfo->bGotOneFrame = true;
+            pFrameInfo->nNextFrameSize = 0;
+            nHeaderCount ++;
+            break;
+        }else if(Info.frm_size + nOffset + nHeadSize < nBufferLen){
+            nOffset += Info.frm_size;
+        }else{
+            nOffset++;
+            continue;
+        }
+
+        pHeader = pBuffer + nOffset;
+
+        if(fpIsValidHeader(pHeader,&Info)){
+            pFrameInfo->bGotOneFrame = true;
+            pFrameInfo->nNextFrameSize = Info.frm_size;
+            nHeaderCount ++;
+            break;
+        }else{
+            nHeaderCount --;
+            nOffset = nFrameOffset+1;
+            continue;
+        }
+    }
+
+    if(nFirstFrameSize > nHeadSize){
+        pFrameInfo->nFrameSize = nFirstFrameSize;
+        pFrameInfo->nHeaderSize = nFirstHeaderSize;
+    }else{
+        pFrameInfo->nFrameSize = 0;
+    }
+
+    if(nHeaderCount > 0){
+        pFrameInfo->nConsumedOffset = nFrameOffset;
+    }else{
+        pFrameInfo->nConsumedOffset = nBufferLen;
+        pFrameInfo->nFrameSize = 0;
+    }
+
+    pFrameInfo->nBitRate = Info.b_rate;
+    pFrameInfo->nSamplesPerFrame = Info.sample_per_fr;
+    pFrameInfo->nSamplingRate = Info.sampling_rate;
+    pFrameInfo->nChannels = Info.channels;
+    pFrameInfo->nHeaderCount = nHeaderCount;
+    ALOGD("CheckFrame parse one frame,bGotOneFrame=%d,nFrameCount=%d,nConsumedOffset=%d,nFrameSize=%d,\
+samplerate=%d,bitrate=%d,channel=%d,samplePerFrame=%d",
+        pFrameInfo->bGotOneFrame,
+        pFrameInfo->nHeaderCount,
+        pFrameInfo->nConsumedOffset,
+        pFrameInfo->nFrameSize,
+        pFrameInfo->nSamplingRate,
+        pFrameInfo->nBitRate,
+        pFrameInfo->nChannels,
+        pFrameInfo->nSamplesPerFrame
+    );
+
+    return ret;
+}
diff --git a/codec2/audio_dec/common/audio_frame_parser/AudioFrameParser.h b/codec2/audio_dec/common/audio_frame_parser/AudioFrameParser.h
new file mode 100755
index 0000000..0c0879d
--- /dev/null
+++ b/codec2/audio_dec/common/audio_frame_parser/AudioFrameParser.h
@@ -0,0 +1,66 @@
+/**
+ *  Copyright (c) 2009-2015, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductors Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+#ifndef AudioFrameParser_h
+#define AudioFrameParser_h
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include <unistd.h>
+
+//audio frame parser return value
+#define AFP_RETURN int32_t
+#define AFP_SUCCESS 0
+#define AFP_FAILED  1
+
+/*!	boolean type*/
+typedef enum eimx_linux_bool
+{
+	E_IMX_FALSE = 0,
+	E_IMX_TRUE
+}eimx_linux_bool;
+
+
+//audio frame information
+typedef struct AUDIO_FRAME_INFO {
+    eimx_linux_bool bGotOneFrame;//true when get one frame and next frame's header
+    uint32_t nHeaderCount;
+    uint32_t nConsumedOffset;//frame header offset if get one frame
+    uint32_t nFrameSize;//frame size
+    uint32_t nBitRate;
+    uint32_t nSamplesPerFrame;
+    uint32_t nSamplingRate;
+    uint32_t nChannels;
+    uint32_t nNextFrameSize;//frame size
+    uint32_t nHeaderSize;
+} AUDIO_FRAME_INFO;
+
+typedef struct FRAME_INFO
+{
+    uint32_t frm_size;
+    uint32_t b_rate;
+    uint32_t sampling_rate;
+    uint32_t sample_per_fr;
+    uint32_t layer;
+    uint32_t version;
+    uint32_t channels;
+    uint32_t header_size;
+}FRAME_INFO;
+
+typedef eimx_linux_bool (*IsValidHeader)(uint8_t * pHeader,FRAME_INFO * Info);
+
+AFP_RETURN CheckFrame(AUDIO_FRAME_INFO *pFrameInfo, uint8_t *pBuffer, uint32_t nBufferLen,uint32_t nHeadSize,IsValidHeader fpIsValidHeader);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif//AudioFrameParser_h
diff --git a/codec2/audio_dec/common/audio_frame_parser/Mp3FrameParser.c b/codec2/audio_dec/common/audio_frame_parser/Mp3FrameParser.c
new file mode 100755
index 0000000..818595b
--- /dev/null
+++ b/codec2/audio_dec/common/audio_frame_parser/Mp3FrameParser.c
@@ -0,0 +1,142 @@
+/**
+ *  Copyright (c) 2010-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+#include "Mp3FrameParser.h"
+//bit rate table
+int16_t mp3_bit_rate[16][6]= {
+    /* bitrate in Kbps
+    * MPEG-1 layer 1, 2, 3; MPEG-2 layer 1,2,3; MPEG-2.5 layer 1,2,3
+    */
+    {0,      0,	    0, 	    0,	    0,	    0},
+    {32,     32,	    32,	    32,	    8,	    8},
+    {64,	    48,	    40,	    48,	    16,	    16},
+    {96,	    56,	    48,	    56,	    24,	    24},
+    {128,    64,	    56,	    64,	    32,	    32},
+    {160,    80,	    64, 	80,	    40,	    40},
+    {192,	96,	    80, 	96,	    48,	    48},
+    {224,	112,	96,	    112,	56,	    56},
+    {256,	128,	112,	128,	64,	    64},
+    {288,	160,	128,	144,	80,	    80},
+    {320,	192,	160,	160,	96,	    96},
+    {352,	224,	192,	176,	112,	112},
+    {384,	256,	224,    192,	128,	128},
+    {416,	320,	256,    224,	144,	144},
+    {448,	384,	320,    256,	160,	160},
+    {999,	999,	999,    999,	999,	999}
+};
+
+//sampling rate table
+uint32_t mp3_sampling_rate[4][3] = {
+    {44100, 22050, 11025},
+    {48000, 24000, 12000},
+    {32000, 16000, 8000},
+    {99999, 99999, 99999}
+};
+
+//sample per frame table
+uint32_t mp3_sample_per_frame[3][3] = {
+    {384,   384,       84},
+    {1152,  1152,   1152},
+    {1152,  576,    576}
+};
+static eimx_linux_bool IsMP3FrameHeader(uint8_t * pHeader,FRAME_INFO * Info)
+{
+    int32_t mpeg_version;
+    int32_t layer;
+    int32_t bit_rate_index;
+    int32_t bit_rate;
+    int32_t sampling_frequency;
+    int32_t sampling_frequency_index;
+    int32_t padding;
+    int32_t private_bit;
+    int32_t channel_mode;
+    int32_t frame_size;
+    int32_t channel_num;
+    int32_t has_crc = 0;
+
+    if(pHeader == NULL || Info == NULL)
+        return E_IMX_FALSE;
+
+    if(pHeader[0] !=0xFF || (pHeader[1] & 0xE0) != 0xE0)
+        return E_IMX_FALSE;
+
+    mpeg_version = ((int32_t)pHeader[1]&0x18)>>3;
+
+    if(mpeg_version == 3){
+        mpeg_version = 0;  /* mpeg ver 1 */
+    }else if(mpeg_version == 2){
+        mpeg_version = 1;  /* mpeg ver 2 */
+    }
+    else if(mpeg_version == 0){
+        mpeg_version = 2;  /* mpeg ver 2.5 */
+    }
+
+    layer  = 4 - (((int32_t)pHeader[1]&0x06)>>1);
+
+    if (( 3!= layer) && (2 != layer) && (1 != layer))  {
+        return E_IMX_FALSE;
+    }
+
+    Info->version = mpeg_version;
+    Info->layer = layer;
+
+    /* has crc ? */
+    has_crc = !(((uint8_t) pHeader[1]) & 0x01);
+
+    bit_rate_index = ((int32_t)pHeader[2]&0xF0)>>4;
+
+    if(mpeg_version == 0)
+        bit_rate = mp3_bit_rate[bit_rate_index][mpeg_version+layer-1];
+    else
+        bit_rate = mp3_bit_rate[bit_rate_index][3+layer-1];
+
+    Info->b_rate = bit_rate;
+
+    if (bit_rate > 448 || bit_rate == 0)
+    {
+        return E_IMX_FALSE;
+    }
+
+    sampling_frequency_index =((int32_t)pHeader[2]&0x0C)>>2;
+    sampling_frequency  = mp3_sampling_rate[sampling_frequency_index][mpeg_version];
+
+    Info->sampling_rate = sampling_frequency;
+    Info->sample_per_fr = mp3_sample_per_frame[layer-1][mpeg_version];
+
+    padding = ((int32_t)pHeader[2]&0x02)>>1;
+
+    private_bit = ((int32_t)pHeader[2]&0x01);
+
+    channel_mode = ((int32_t)pHeader[3]&0xC0)>>6;
+
+    if(layer ==1)
+        frame_size = (int32_t)((12*bit_rate*1000)/sampling_frequency+ padding)*4;
+    else
+        frame_size = (int32_t)((Info->sample_per_fr/8*bit_rate*1000)/sampling_frequency)+ padding;
+
+    Info->frm_size = frame_size ;
+
+    if (3 == channel_mode)
+    {
+        channel_num = 1;
+    }
+    else
+    {
+        channel_num = 2;
+    }
+
+    Info->channels = channel_num;
+
+    return E_IMX_TRUE;
+}
+
+AFP_RETURN Mp3CheckFrame(AUDIO_FRAME_INFO *pFrameInfo, uint8_t *pBuffer, uint32_t nBufferLen)
+{
+    return CheckFrame(pFrameInfo,pBuffer,nBufferLen,MP3_FRAME_HEAD_SIZE,IsMP3FrameHeader);
+}
\ No newline at end of file
diff --git a/codec2/audio_dec/common/audio_frame_parser/Mp3FrameParser.h b/codec2/audio_dec/common/audio_frame_parser/Mp3FrameParser.h
new file mode 100755
index 0000000..a6e68da
--- /dev/null
+++ b/codec2/audio_dec/common/audio_frame_parser/Mp3FrameParser.h
@@ -0,0 +1,28 @@
+/**
+ *  Copyright (c) 2009-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductors Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+#ifndef Mp3FrameParser_h
+#define Mp3FrameParser_h
+
+#include "AudioFrameParser.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define MP3_FRAME_HEAD_SIZE  4
+
+//check frame function
+AFP_RETURN Mp3CheckFrame(AUDIO_FRAME_INFO *pFrameInfo, uint8_t *pBuffer, uint32_t nBufferLen);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif//AudioFrameParser_h
diff --git a/codec2/audio_dec/eac3_dec/Android.bp b/codec2/audio_dec/eac3_dec/Android.bp
new file mode 100644
index 0000000..4a33f76
--- /dev/null
+++ b/codec2/audio_dec/eac3_dec/Android.bp
@@ -0,0 +1,44 @@
+cc_library_shared {
+    name: "lib_c2_imx_eac3_dec",
+
+    srcs: [
+        "Eac3DecodeUtil.cpp",
+    ],
+
+    include_dirs: [
+        "vendor/nxp/imx_android_mm/codec2/base/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/fsl-codec/ghdr/common",
+        "hardware/google/av/codec2/include",
+        "system/core/include",
+        "hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+    ],
+
+    local_include_dirs: [
+        ".",
+    ],
+
+    export_include_dirs: [
+        ".",
+    ],
+
+    header_libs: [
+        "libsystem_headers",
+    ],
+
+    shared_libs: [
+        "lib_c2_imx_audio_dec_common",
+        "lib_imx_c2_componentbase",
+        "liblog",
+        "libcodec2_vndk",
+        "libstagefright_foundation",
+        "lib_c2_imx_store",
+    ],
+
+    ldflags: ["-Wl,-Bsymbolic"],
+
+    defaults: [
+        "imx_defaults",
+    ],
+}
diff --git a/codec2/audio_dec/eac3_dec/Eac3DecodeUtil.cpp b/codec2/audio_dec/eac3_dec/Eac3DecodeUtil.cpp
new file mode 100755
index 0000000..7ca3f75
--- /dev/null
+++ b/codec2/audio_dec/eac3_dec/Eac3DecodeUtil.cpp
@@ -0,0 +1,377 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "Eac3DecUtil"
+#include <log/log.h>
+
+#include <C2Config_imx.h>
+#include <IMXC2Interface.h>
+#include <media/stagefright/foundation/MediaDefs.h>
+#include <UniaDecoder.h>
+#include <C2ComponentFactory.h>
+#include <C2PlatformSupport.h>
+
+#include "Eac3DecodeUtil.h"
+
+namespace android {
+
+#define EAC3_PUSH_MODE_LEN (6144+8)//max frame size + another frame header size
+
+#define EAC3_MAX_CHANNELS 8
+/* pcm channel layout for eac3 */
+static uint32 eac3d_1channel_layout[] = {
+    /* FC */
+    UA_CHANNEL_FRONT_CENTER
+};
+static uint32 eac3d_2channel_layout[] = {
+    /* FL,FR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT
+};
+static uint32 eac3d_3channel_layout[] = {
+    /* FL,FR, FC */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER
+    };
+static uint32 eac3d_4channel_layout[] = {
+    /* FL,FR,BL,BR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT
+};
+static uint32 eac3d_5channel_layout[] = {
+    /* FL,FR,FC,BL,BR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT
+    };
+static uint32 eac3d_6channel_layout[] = {
+    /* FL,FR,FC,LFE,BL,BR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_LFE,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT
+};
+static uint32 eac3d_8channel_layout[] = {
+/* FL, FR, FC, LFE, BL, BR, SL, SR */
+  UA_CHANNEL_FRONT_LEFT,
+  UA_CHANNEL_FRONT_RIGHT,
+  UA_CHANNEL_FRONT_CENTER,
+  UA_CHANNEL_LFE,
+  UA_CHANNEL_REAR_LEFT,
+  UA_CHANNEL_REAR_RIGHT,
+  UA_CHANNEL_SIDE_LEFT,
+  UA_CHANNEL_SIDE_RIGHT,
+};
+static uint32 * eac3d_channel_layouts[] = {
+    NULL,
+    eac3d_1channel_layout,// 1
+    eac3d_2channel_layout,// 2
+    eac3d_3channel_layout,
+    eac3d_4channel_layout,
+    eac3d_5channel_layout,
+    eac3d_6channel_layout,
+    NULL,
+    eac3d_8channel_layout
+};
+
+
+class Eac3DecodeUtil::IntfImpl : public IMXInterface<void>::BaseParams  {
+public:
+    explicit IntfImpl(const std::shared_ptr<C2ReflectorHelper> &helper, C2String componentName)
+        : IMXInterface<void>::BaseParams(
+                helper,
+                componentName,
+                C2Component::KIND_DECODER,
+                C2Component::DOMAIN_AUDIO,
+                MEDIA_MIMETYPE_AUDIO_EAC3){
+        noPrivateBuffers(); // TODO: account for our buffers here
+        noInputReferences();
+        noOutputReferences();
+        noInputLatency();
+        noTimeStretch();
+
+        addParameter(
+                DefineParam(mAttrib, C2_PARAMKEY_COMPONENT_ATTRIBUTES)
+                .withConstValue(new C2ComponentAttributesSetting(
+                    C2Component::ATTRIB_IS_TEMPORAL))
+                .build());
+
+        addParameter(
+                DefineParam(mSampleRate, C2_NAME_STREAM_SAMPLE_RATE_SETTING)
+                .withDefault(new C2StreamSampleRateInfo::output(0u, 44100))
+                .withFields({C2F(mSampleRate, value).oneOf({
+                    32000, 44100, 48000
+                })})
+                .withSetter(Setter<decltype(*mSampleRate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mChannelCount, C2_NAME_STREAM_CHANNEL_COUNT_SETTING)
+                .withDefault(new C2StreamChannelCountInfo::output(0u, 1))
+                .withFields({C2F(mChannelCount, value).inRange(1, 8)})
+                .withSetter(Setter<decltype(*mChannelCount)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mBitrate, C2_NAME_STREAM_BITRATE_SETTING)
+                .withDefault(new C2BitrateTuning::input(0u, 64000))
+                .withFields({C2F(mBitrate, value).inRange(8000, 960000)})
+                .withSetter(Setter<decltype(*mBitrate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mInputMaxBufSize, C2_PARAMKEY_INPUT_MAX_BUFFER_SIZE)
+                .withConstValue(new C2StreamMaxBufferSizeInfo::input(0u, 8192))
+                .build());
+
+    }
+
+    uint32_t getSampleRate() const { return mSampleRate->value; };
+    uint32_t getChannelCount() const { return mChannelCount->value; };
+    uint32_t getBitrate() const { return mBitrate->value; };
+    void setSampleRate(uint32_t value) { mSampleRate->value = value; };
+    void setChannelCount(uint32_t value) { mChannelCount->value = value; };
+    void setBitrate(uint32_t value) { mBitrate->value = value; };
+
+private:
+    std::shared_ptr<C2StreamSampleRateInfo::output> mSampleRate;
+    std::shared_ptr<C2StreamChannelCountInfo::output> mChannelCount;
+    std::shared_ptr<C2BitrateTuning::input> mBitrate;
+    std::shared_ptr<C2StreamMaxBufferSizeInfo::input> mInputMaxBufSize;
+};
+
+Eac3DecodeUtil::Eac3DecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl)
+    : AudioDecodeUtil(),
+    bFrameChecked(false),
+    mIntf(intfImpl)
+{
+    LOGV("entry %p", this);
+    if(codecName.find("c2.imx.eac3.decoder.sw", 0) != std::string::npos){
+        wrapperLibName = "lib_ddpd_wrap_arm12_elinux_android.so";
+        optionalWrapperLibName = "lib_ddpd_wrap_arm_android.so"; // 64 bits
+    }
+    else{
+        LOGE("invalid codecName %s", codecName.c_str());
+        wrapperLibName = nullptr;
+        optionalWrapperLibName = nullptr;
+    }
+}
+
+Eac3DecodeUtil::~Eac3DecodeUtil()
+{
+    LOGV("entry");
+}
+
+c2_status_t Eac3DecodeUtil::getLibName(const char ** lib, const char ** optionalLib)
+{
+    LOGV("entry");
+    *lib = wrapperLibName;
+    *optionalLib = optionalWrapperLibName;
+    return C2_OK;
+}
+
+uint32_t Eac3DecodeUtil::getFrameHdrBufLen()
+{
+    LOGV("entry");
+    return EAC3_PUSH_MODE_LEN;
+}
+
+uint32_t Eac3DecodeUtil::getOutBufferLen()
+{
+    LOGV("entry");
+    return 36864;//8*6*256*24/8
+}
+
+c2_status_t Eac3DecodeUtil::parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info)
+{
+    LOGV("entry");
+    return C2_OK;
+}
+
+c2_status_t Eac3DecodeUtil::getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased)
+{
+    LOGV("entry");
+    if (formatType)
+        *formatType = DD_PLUS;
+    if (isHwBased)
+        *isHwBased = false;
+
+    return C2_OK;
+}
+
+c2_status_t Eac3DecodeUtil::handleBOS(uint32_t* offset, uint32_t length) {
+    return C2_OK;
+}
+
+c2_status_t Eac3DecodeUtil::handleEOS(uint8_t **ppBuffer, uint32_t* length)
+{
+    return C2_OK;
+}
+
+c2_status_t Eac3DecodeUtil::setParameter(UA_ParaType index,int32_t value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            LOGV("sample rate %d",value);
+            //mIntf->setSampleRate(value);
+            C2StreamSampleRateInfo::output sampleRateInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &sampleRateInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            LOGV("channel num %d",value);
+            //mIntf->setChannelCount(value);
+            C2StreamChannelCountInfo::output channelCountInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &channelCountInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            LOGV("bitrate %d",value);
+            mIntf->setBitrate(value);
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+}
+
+c2_status_t Eac3DecodeUtil::getParameter(UA_ParaType index,int32_t * value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    if(value == nullptr){
+        ret = C2_BAD_VALUE;
+        return ret;
+    }
+
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            *value = (int32_t)mIntf->getSampleRate();
+            LOGV("sample rate %d",*value);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            *value = (int32_t)mIntf->getChannelCount();
+            LOGV("channel num %d",*value);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            *value = (int32_t)mIntf->getBitrate();
+            LOGV("bitrate %d",*value);
+            break;
+        }
+        case UNIA_FRAMED:
+        {
+            *value = true;
+            LOGV("framed %d",*value);
+            break;
+        }
+        case UNIA_CHAN_MAP_TABLE:
+        {
+            CHAN_TABLE table;
+            memset(&table,0,sizeof(table));
+            table.size = EAC3_MAX_CHANNELS;
+            memcpy(&table.channel_table,eac3d_channel_layouts,sizeof(eac3d_channel_layouts));
+            memcpy(value,&table,sizeof(CHAN_TABLE));
+            LOGD("SET MAP TABLE");
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+
+}
+
+size_t Eac3DecodeUtil::getPushModeInputLen()
+{
+    return EAC3_PUSH_MODE_LEN;
+}
+
+
+class IMXC2Eac3DecFactory : public C2ComponentFactory {
+public:
+    IMXC2Eac3DecFactory(C2String name) : mHelper(std::static_pointer_cast<C2ReflectorHelper>(
+            GetImxC2Store()->getParamReflector()))
+    {
+            if(!name.empty())
+                mCodecName.assign(name);
+            else
+                mCodecName.assign("c2.imx.eac3.decoder.sw");
+    }
+
+    virtual c2_status_t createComponent(
+            c2_node_id_t id,
+            std::shared_ptr<C2Component>* const component,
+            std::function<void(C2Component*)> deleter) override {
+
+            auto impl = std::make_shared<Eac3DecodeUtil::IntfImpl>(mHelper, mCodecName.c_str());
+            Eac3DecodeUtil * pEac3Util = new Eac3DecodeUtil(mCodecName, impl);
+
+        *component = std::shared_ptr<C2Component>(
+                new UniaDecoder(std::make_shared<IMXC2Interface<Eac3DecodeUtil::IntfImpl>>(mCodecName.c_str(), id, impl),
+                                            pEac3Util),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual c2_status_t createInterface(
+            c2_node_id_t id, std::shared_ptr<C2ComponentInterface>* const interface,
+            std::function<void(C2ComponentInterface*)> deleter) override {
+        *interface = std::shared_ptr<C2ComponentInterface>(
+                new IMXInterface<Eac3DecodeUtil::IntfImpl>(
+                        mCodecName, id, std::make_shared<Eac3DecodeUtil::IntfImpl>(mHelper, mCodecName.c_str())),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual ~IMXC2Eac3DecFactory() override = default;
+
+private:
+    std::shared_ptr<C2ReflectorHelper> mHelper;
+    std::string mCodecName;
+};
+
+}  // namespace android
+
+extern "C" ::C2ComponentFactory* IMXCreateCodec2Factory(C2String name) {
+    LOGV("entry codecName %s", name.c_str());
+    return new ::android::IMXC2Eac3DecFactory(name);
+}
+
+extern "C" void IMXDestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+
diff --git a/codec2/audio_dec/eac3_dec/Eac3DecodeUtil.h b/codec2/audio_dec/eac3_dec/Eac3DecodeUtil.h
new file mode 100755
index 0000000..6966ce4
--- /dev/null
+++ b/codec2/audio_dec/eac3_dec/Eac3DecodeUtil.h
@@ -0,0 +1,42 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef EAC3_DECODE_UTIL_h
+#define EAC3_DECODE_UTIL_h
+
+#include <AudioDecodeUtil.h>
+
+namespace android {
+
+class Eac3DecodeUtil  : public AudioDecodeUtil {
+    public:
+        class IntfImpl;
+
+        Eac3DecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl);
+        virtual ~Eac3DecodeUtil();
+        virtual c2_status_t getLibName(const char ** lib, const char ** optionalLib) override;
+        virtual uint32_t getFrameHdrBufLen() override;
+        virtual uint32_t getOutBufferLen() override;
+        virtual c2_status_t parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info) override;
+        virtual c2_status_t getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased) override;
+        virtual c2_status_t handleBOS(uint32_t* offset, uint32_t length) override;
+        virtual c2_status_t handleEOS(uint8_t **ppBuffer, uint32_t* length) override;
+        virtual c2_status_t setParameter(UA_ParaType index,int32_t value) override;
+        virtual c2_status_t getParameter(UA_ParaType index,int32_t * value) override;
+        virtual size_t getPushModeInputLen() override;
+
+    private:
+        bool bFrameChecked;
+        std::shared_ptr<IntfImpl> mIntf;
+
+};
+
+}
+#endif
+
+
diff --git a/codec2/audio_dec/mp3_dec/Android.bp b/codec2/audio_dec/mp3_dec/Android.bp
new file mode 100644
index 0000000..bb05404
--- /dev/null
+++ b/codec2/audio_dec/mp3_dec/Android.bp
@@ -0,0 +1,45 @@
+cc_library_shared {
+    name: "lib_c2_imx_mp3_dec",
+
+    srcs: [
+        "Mp3DecodeUtil.cpp",
+    ],
+
+    include_dirs: [
+        "vendor/nxp/imx_android_mm/codec2/base/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/fsl-codec/ghdr/common",
+        "hardware/google/av/codec2/include",
+        "system/core/include",
+        "hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+    ],
+
+    local_include_dirs: [
+        ".",
+    ],
+
+    export_include_dirs: [
+        ".",
+    ],
+
+    header_libs: [
+        "libsystem_headers",
+    ],
+
+    shared_libs: [
+        "lib_c2_imx_audio_dec_common",
+        "lib_imx_c2_componentbase",
+        "liblog",
+        "libcodec2_vndk",
+        "libstagefright_foundation",
+        "lib_c2_imx_store",
+    ],
+
+    ldflags: ["-Wl,-Bsymbolic"],
+
+    defaults: [
+        "imx_defaults",
+    ],
+    //compile_multilib: "32",
+}
diff --git a/codec2/audio_dec/mp3_dec/Mp3DecodeUtil.cpp b/codec2/audio_dec/mp3_dec/Mp3DecodeUtil.cpp
new file mode 100755
index 0000000..cb85895
--- /dev/null
+++ b/codec2/audio_dec/mp3_dec/Mp3DecodeUtil.cpp
@@ -0,0 +1,410 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "Mp3DecUtil"
+#include <log/log.h>
+
+#include <Mp3FrameParser.h>
+#include <C2Config_imx.h>
+#include <IMXC2Interface.h>
+#include <media/stagefright/foundation/MediaDefs.h>
+#include <UniaDecoder.h>
+#include <C2ComponentFactory.h>
+#include <C2PlatformSupport.h>
+
+#include "Mp3DecodeUtil.h"
+
+namespace android {
+
+#define MP3D_FRAME_SIZE  1152
+#define MP3_PUSH_MODE_LEN   (2048*4)
+#define MP3_DECODER_DELAY 529 //samples
+
+#define DSP_WRAPPER_LIB_NAME "lib_dsp_wrap_arm12_android.so"
+
+class Mp3DecodeUtil::IntfImpl : public IMXInterface<void>::BaseParams  {
+public:
+    explicit IntfImpl(const std::shared_ptr<C2ReflectorHelper> &helper, C2String componentName)
+        : IMXInterface<void>::BaseParams(
+                helper,
+                componentName,
+                C2Component::KIND_DECODER,
+                C2Component::DOMAIN_AUDIO,
+                MEDIA_MIMETYPE_AUDIO_MPEG){
+        noPrivateBuffers(); // TODO: account for our buffers here
+        noInputReferences();
+        noOutputReferences();
+        noInputLatency();
+        noTimeStretch();
+
+        addParameter(
+                DefineParam(mAttrib, C2_PARAMKEY_COMPONENT_ATTRIBUTES)
+                .withConstValue(new C2ComponentAttributesSetting(
+                    C2Component::ATTRIB_IS_TEMPORAL))
+                .build());
+
+        addParameter(
+                DefineParam(mSampleRate, C2_NAME_STREAM_SAMPLE_RATE_SETTING)
+                .withDefault(new C2StreamSampleRateInfo::output(0u, 44100))
+                .withFields({C2F(mSampleRate, value).oneOf({
+                    8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000
+                })})
+                .withSetter(Setter<decltype(*mSampleRate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mChannelCount, C2_NAME_STREAM_CHANNEL_COUNT_SETTING)
+                .withDefault(new C2StreamChannelCountInfo::output(0u, 1))
+                .withFields({C2F(mChannelCount, value).inRange(1, 8)})
+                .withSetter(Setter<decltype(*mChannelCount)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mBitrate, C2_PARAMKEY_BITRATE)
+                .withDefault(new C2StreamBitrateInfo::input(0u, 64000))
+                .withFields({C2F(mBitrate, value).inRange(4000, 448000)})
+                .withSetter(Setter<decltype(*mBitrate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mInputMaxBufSize, C2_PARAMKEY_INPUT_MAX_BUFFER_SIZE)
+                .withConstValue(new C2StreamMaxBufferSizeInfo::input(0u, 8192))
+                .build());
+
+    }
+
+    uint32_t getSampleRate() const { return mSampleRate->value; };
+    uint32_t getChannelCount() const { return mChannelCount->value; };
+    uint32_t getBitrate() const { return mBitrate->value; };
+    void setSampleRate(uint32_t value) { mSampleRate->value = value; };
+    void setChannelCount(uint32_t value) { mChannelCount->value = value; };
+    void setBitrate(uint32_t value) { mBitrate->value = value; };
+
+private:
+    std::shared_ptr<C2StreamSampleRateInfo::output> mSampleRate;
+    std::shared_ptr<C2StreamChannelCountInfo::output> mChannelCount;
+    std::shared_ptr<C2StreamBitrateInfo::input> mBitrate;
+    std::shared_ptr<C2StreamMaxBufferSizeInfo::input> mInputMaxBufSize;
+};
+
+Mp3DecodeUtil::Mp3DecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl)
+    : AudioDecodeUtil(),
+    bFrameChecked(false),
+    mIntf(intfImpl),
+    nDelayLeft(0)
+{
+    LOGV("entry %p", this);
+    if(codecName.find("c2.imx.mp3.decoder.sw", 0) != std::string::npos){
+        wrapperLibName = "lib_mp3d_wrap_arm12_elinux_android.so";
+        optionalWrapperLibName = nullptr;
+    }
+    else if(codecName.find("c2.imx.mp3.decoder.hw", 0) != std::string::npos){
+        wrapperLibName = DSP_WRAPPER_LIB_NAME;
+        optionalWrapperLibName = nullptr;
+    }
+    else{
+        // error
+        LOGE("invalid codecName %s", codecName.c_str());
+        wrapperLibName = nullptr;
+        optionalWrapperLibName = nullptr;
+    }
+}
+
+Mp3DecodeUtil::~Mp3DecodeUtil()
+{
+    LOGV("entry");
+}
+
+c2_status_t Mp3DecodeUtil::getLibName(const char ** lib, const char ** optionalLib)
+{
+    LOGV("entry");
+    *lib = wrapperLibName;
+    *optionalLib = optionalWrapperLibName;
+    return C2_OK;
+}
+
+uint32_t Mp3DecodeUtil::getFrameHdrBufLen()
+{
+    LOGV("entry");
+    return MP3_PUSH_MODE_LEN;
+}
+
+uint32_t Mp3DecodeUtil::getOutBufferLen()
+{
+    LOGV("entry");
+    return MP3D_FRAME_SIZE* 2*2;
+}
+
+c2_status_t Mp3DecodeUtil::checkFrameHeader(unsigned char * pBuffer, size_t length, uint32_t *pOffset)
+{
+    LOGV("entry");
+    uint32_t nVal = 0;
+    AUDIO_FRAME_INFO FrameInfo;
+    bool bFound = false;
+    memset(&FrameInfo, 0, sizeof(AUDIO_FRAME_INFO));
+
+    if(bFrameChecked){
+        return C2_OK;
+    }
+
+    do{
+        LOGI("Get stream length: %zu
", length);
+
+        if(AFP_SUCCESS != Mp3CheckFrame(&FrameInfo, pBuffer, length)){
+            LOGD("check fail");
+            break;
+        }
+
+        if(FrameInfo.bGotOneFrame){
+            bFound = true;
+            LOGD("get one frame");
+        }
+
+        uint32_t nOffset = FrameInfo.nConsumedOffset;
+        LOGV("nOffset is %d", nOffset);
+
+        //if(nOffset < length)
+        //    LOGD("buffer=%02x%02x%02x%02x",pBuffer[nOffset],pBuffer[nOffset+1],pBuffer[nOffset+2],pBuffer[nOffset+1]);
+        *pOffset = nOffset;
+
+        if(bFound)
+            return C2_OK;
+    }while(0);
+
+    return C2_NOT_FOUND;
+
+}
+c2_status_t Mp3DecodeUtil::parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info)
+{
+    LOGV("entry");
+    AUDIO_FRAME_INFO FrameInfo;
+
+    if(pBuffer == nullptr || info == nullptr || len <= 0)
+        return C2_BAD_VALUE;
+
+    memset(&FrameInfo, 0, sizeof(AUDIO_FRAME_INFO));
+
+    if(AFP_SUCCESS == Mp3CheckFrame(&FrameInfo, pBuffer, len)){
+        info->bGotOneFrame = FrameInfo.bGotOneFrame;
+        info->nConsumedOffset = FrameInfo.nConsumedOffset;
+        info->nHeaderCount = FrameInfo.nHeaderCount;
+        info->nHeaderSize = FrameInfo.nHeaderSize;
+        info->nFrameSize = FrameInfo.nFrameSize;
+        info->nNextSize = FrameInfo.nNextFrameSize;
+    }
+
+    return C2_OK;
+}
+
+c2_status_t Mp3DecodeUtil::getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased)
+{
+    LOGV("entry");
+    if (formatType)
+        *formatType = MP3;
+    if (isHwBased)
+        *isHwBased = !strcmp(wrapperLibName, DSP_WRAPPER_LIB_NAME);
+
+    return C2_OK;
+}
+
+c2_status_t Mp3DecodeUtil::handleBOS(uint32_t* offset, uint32_t length)
+{
+    if (nDelayLeft == 0)
+        nDelayLeft = MP3_DECODER_DELAY * mIntf->getChannelCount() * sizeof(int16_t);
+
+    if (length - *offset > nDelayLeft) {
+        *offset += nDelayLeft;
+        nDelayLeft = 0;
+    } else {
+        nDelayLeft -= (length - *offset);
+        *offset = length;
+    }
+
+    if (0 == nDelayLeft)
+        return C2_OK;
+    else
+        return C2_BAD_VALUE;
+
+}
+
+c2_status_t Mp3DecodeUtil::handleEOS(uint8_t **ppBuffer, uint32_t* length)
+{
+    LOGV("entry");
+    uint32_t padding = 0;
+    uint8_t *pBuf = *ppBuffer;
+
+    // pad the end of the stream with 529 samples, since that many samples
+    // were trimmed off the beginning when decoding started
+    padding = MP3_DECODER_DELAY * mIntf->getChannelCount() * sizeof(int16_t);
+
+    pBuf = (uint8_t*)realloc(pBuf, *length + padding);
+    if (!pBuf)
+        return C2_NO_MEMORY;
+
+    memset(pBuf + *length, 0, padding);
+    *ppBuffer = pBuf;
+    *length += padding;
+
+    return C2_OK;
+}
+
+c2_status_t Mp3DecodeUtil::setParameter(UA_ParaType index,int32_t value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            LOGV("sample rate %d",value);
+            //mIntf->setSampleRate(value);
+            C2StreamSampleRateInfo::output sampleRateInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &sampleRateInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            LOGV("channel num %d",value);
+            //mIntf->setChannelCount(value);
+            C2StreamChannelCountInfo::output channelCountInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &channelCountInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            LOGV("bitrate %d",value);
+            mIntf->setBitrate(value);
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+}
+
+c2_status_t Mp3DecodeUtil::getParameter(UA_ParaType index,int32_t * value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    if(value == nullptr){
+        ret = C2_BAD_VALUE;
+        return ret;
+    }
+
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            *value = (int32_t)mIntf->getSampleRate();
+            LOGV("sample rate %d",*value);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            *value = (int32_t)mIntf->getChannelCount();
+            LOGV("channel num %d",*value);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            *value = (int32_t)mIntf->getBitrate();
+            LOGV("bitrate %d",*value);
+            break;
+        }
+        case UNIA_FRAMED:
+        {
+            *value = true;
+            LOGV("framed %d",*value);
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+
+}
+
+size_t Mp3DecodeUtil::getPushModeInputLen()
+{
+    return MP3_PUSH_MODE_LEN;
+}
+
+
+class IMXC2Mp3DecFactory : public C2ComponentFactory {
+public:
+    IMXC2Mp3DecFactory(C2String name) : mHelper(std::static_pointer_cast<C2ReflectorHelper>(
+            GetImxC2Store()->getParamReflector()))
+    {
+            if(!name.empty())
+                mCodecName.assign(name);
+            else
+                mCodecName.assign("c2.imx.mp3.decoder.sw");
+    }
+
+    virtual c2_status_t createComponent(
+            c2_node_id_t id,
+            std::shared_ptr<C2Component>* const component,
+            std::function<void(C2Component*)> deleter) override {
+
+            auto impl = std::make_shared<Mp3DecodeUtil::IntfImpl>(mHelper, mCodecName.c_str());
+            Mp3DecodeUtil * pMp3Util = new Mp3DecodeUtil(mCodecName, impl);
+
+        *component = std::shared_ptr<C2Component>(
+                new UniaDecoder(std::make_shared<IMXC2Interface<Mp3DecodeUtil::IntfImpl>>(mCodecName.c_str(), id, impl),
+                                            pMp3Util),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual c2_status_t createInterface(
+            c2_node_id_t id, std::shared_ptr<C2ComponentInterface>* const interface,
+            std::function<void(C2ComponentInterface*)> deleter) override {
+        *interface = std::shared_ptr<C2ComponentInterface>(
+                new IMXInterface<Mp3DecodeUtil::IntfImpl>(
+                        mCodecName, id, std::make_shared<Mp3DecodeUtil::IntfImpl>(mHelper, mCodecName.c_str())),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual ~IMXC2Mp3DecFactory() override = default;
+
+private:
+    std::shared_ptr<C2ReflectorHelper> mHelper;
+    std::string mCodecName;
+};
+
+}  // namespace android
+
+extern "C" ::C2ComponentFactory* IMXCreateCodec2Factory(C2String name) {
+    LOGV("entry codecName %s", name.c_str());
+    return new ::android::IMXC2Mp3DecFactory(name);
+}
+
+extern "C" void IMXDestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+/*
+extern "C" ::C2ComponentFactory* CreateCodec2Factory() {
+    LOGV("entry");
+    return new ::android::IMXC2AacDecFactory(nullptr);
+}
+
+extern "C" void DestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+*/
diff --git a/codec2/audio_dec/mp3_dec/Mp3DecodeUtil.h b/codec2/audio_dec/mp3_dec/Mp3DecodeUtil.h
new file mode 100755
index 0000000..e375a43
--- /dev/null
+++ b/codec2/audio_dec/mp3_dec/Mp3DecodeUtil.h
@@ -0,0 +1,44 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef MP3_DECODE_UTIL_h
+#define MP3_DECODE_UTIL_h
+
+#include <AudioDecodeUtil.h>
+
+namespace android {
+
+class Mp3DecodeUtil  : public AudioDecodeUtil {
+    public:
+        class IntfImpl;
+
+        Mp3DecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl);
+	virtual ~Mp3DecodeUtil();
+	virtual c2_status_t getLibName(const char ** lib, const char ** optionalLib) override;
+	virtual uint32_t getFrameHdrBufLen() override;
+        virtual uint32_t getOutBufferLen() override;
+	virtual c2_status_t checkFrameHeader(unsigned char * pBuffer, size_t length, uint32_t *pOffset) override;
+        virtual c2_status_t parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info) override;
+        virtual c2_status_t getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased) override;
+        virtual c2_status_t handleBOS(uint32_t* offset, uint32_t length) override;
+        virtual c2_status_t handleEOS(uint8_t **ppBuffer, uint32_t* length) override;
+        virtual c2_status_t setParameter(UA_ParaType index,int32_t value) override;
+        virtual c2_status_t getParameter(UA_ParaType index,int32_t * value) override;
+        virtual size_t getPushModeInputLen() override;
+
+    private:
+        bool bFrameChecked;
+        std::shared_ptr<IntfImpl> mIntf;
+        uint32_t nDelayLeft; // use for handleBos
+
+};
+
+}
+#endif
+
+
diff --git a/codec2/audio_dec/realaudio_dec/Android.bp b/codec2/audio_dec/realaudio_dec/Android.bp
new file mode 100644
index 0000000..e78f4fa
--- /dev/null
+++ b/codec2/audio_dec/realaudio_dec/Android.bp
@@ -0,0 +1,45 @@
+cc_library_shared {
+    name: "lib_c2_imx_ra_dec",
+
+    srcs: [
+        "RealAudioDecodeUtil.cpp",
+    ],
+
+    include_dirs: [
+        "vendor/nxp/imx_android_mm/codec2/base/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/fsl-codec/ghdr/common",
+        "hardware/google/av/codec2/include",
+        "system/core/include",
+        "hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+        "vendor/nxp/imx_android_mm/extractor",
+    ],
+
+    local_include_dirs: [
+        ".",
+    ],
+
+    export_include_dirs: [
+        ".",
+    ],
+
+    header_libs: [
+        "libsystem_headers",
+    ],
+
+    shared_libs: [
+        "lib_c2_imx_audio_dec_common",
+        "lib_imx_c2_componentbase",
+        "liblog",
+        "libcodec2_vndk",
+        "libstagefright_foundation",
+        "lib_c2_imx_store",
+    ],
+
+    ldflags: ["-Wl,-Bsymbolic"],
+
+    defaults: [
+        "imx_defaults",
+    ],
+}
diff --git a/codec2/audio_dec/realaudio_dec/RealAudioDecodeUtil.cpp b/codec2/audio_dec/realaudio_dec/RealAudioDecodeUtil.cpp
new file mode 100755
index 0000000..fb76bef
--- /dev/null
+++ b/codec2/audio_dec/realaudio_dec/RealAudioDecodeUtil.cpp
@@ -0,0 +1,298 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+#define LOG_NDEBUG 0
+#define LOG_TAG "RaDecUtil"
+#include <log/log.h>
+
+#include <C2Config_imx.h>
+#include <IMXC2Interface.h>
+#include <media/stagefright/foundation/MediaDefs.h>
+#include <UniaDecoder.h>
+#include <C2ComponentFactory.h>
+#include <C2PlatformSupport.h>
+#include <Imx_ext.h>
+
+#include "RealAudioDecodeUtil.h"
+
+namespace android {
+
+#define REAL_AUDIO_PUSH_MODE_LEN (2240/8)//max frame size
+
+class RealAudioDecodeUtil::IntfImpl : public IMXInterface<void>::BaseParams  {
+public:
+    explicit IntfImpl(const std::shared_ptr<C2ReflectorHelper> &helper, C2String componentName)
+        : IMXInterface<void>::BaseParams(
+                helper,
+                componentName,
+                C2Component::KIND_DECODER,
+                C2Component::DOMAIN_AUDIO,
+                MEDIA_MIMETYPE_AUDIO_REAL){
+        noPrivateBuffers(); // TODO: account for our buffers here
+        noInputReferences();
+        noOutputReferences();
+        noInputLatency();
+        noTimeStretch();
+
+        addParameter(
+                DefineParam(mAttrib, C2_PARAMKEY_COMPONENT_ATTRIBUTES)
+                .withConstValue(new C2ComponentAttributesSetting(
+                    C2Component::ATTRIB_IS_TEMPORAL))
+                .build());
+
+        addParameter(
+                DefineParam(mSampleRate, C2_NAME_STREAM_SAMPLE_RATE_SETTING)
+                .withDefault(new C2StreamSampleRateInfo::output(0u, 44100))
+                .withFields({C2F(mSampleRate, value).oneOf({
+                    32000, 44100, 48000
+                })})
+                .withSetter(Setter<decltype(*mSampleRate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mChannelCount, C2_NAME_STREAM_CHANNEL_COUNT_SETTING)
+                .withDefault(new C2StreamChannelCountInfo::output(0u, 1))
+                .withFields({C2F(mChannelCount, value).inRange(1, 8)})
+                .withSetter(Setter<decltype(*mChannelCount)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mInputMaxBufSize, C2_PARAMKEY_INPUT_MAX_BUFFER_SIZE)
+                .withConstValue(new C2StreamMaxBufferSizeInfo::input(0u, 8192))
+                .build());
+
+        addParameter(
+                DefineParam(mBitsPerFrame, C2_PARAMKEY_BITS_PER_FRAME)
+                .withDefault(new C2StreamBitsPerFrame::output(0u, 0))
+                .withFields({C2F(mBitsPerFrame, value).inRange(0, 10000)})
+                .withSetter(Setter<decltype(*mBitsPerFrame)>::NonStrictValueWithNoDeps)
+                .build());
+
+    }
+
+    uint32_t getSampleRate() const { return mSampleRate->value; };
+    uint32_t getChannelCount() const { return mChannelCount->value; };
+    uint32_t getBitsPerFrame() const { return mBitsPerFrame->value; };
+    void setSampleRate(uint32_t value) { mSampleRate->value = value; };
+    void setChannelCount(uint32_t value) { mChannelCount->value = value; };
+
+private:
+    std::shared_ptr<C2StreamSampleRateInfo::output> mSampleRate;
+    std::shared_ptr<C2StreamChannelCountInfo::output> mChannelCount;
+    std::shared_ptr<C2StreamMaxBufferSizeInfo::input> mInputMaxBufSize;
+    std::shared_ptr<C2StreamBitsPerFrame::output> mBitsPerFrame;
+};
+
+RealAudioDecodeUtil::RealAudioDecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl)
+    : AudioDecodeUtil(),
+    bFrameChecked(false),
+    mIntf(intfImpl)
+{
+    LOGV("entry %p", this);
+    if(codecName.find("c2.imx.ra.decoder.sw", 0) != std::string::npos){
+        wrapperLibName = "lib_realad_wrap_arm11_elinux_android.so";
+        optionalWrapperLibName = "lib_realad_wrap_arm_elinux_android.so"; // 64 bits
+    }
+    else{
+        // error
+        LOGE("invalid codecName %s", codecName.c_str());
+        wrapperLibName = nullptr;
+        optionalWrapperLibName = nullptr;
+    }
+}
+
+RealAudioDecodeUtil::~RealAudioDecodeUtil()
+{
+    LOGV("entry");
+}
+
+c2_status_t RealAudioDecodeUtil::getLibName(const char ** lib, const char ** optionalLib)
+{
+    LOGV("entry");
+    *lib = wrapperLibName;
+    *optionalLib = optionalWrapperLibName;
+    return C2_OK;
+}
+
+uint32_t RealAudioDecodeUtil::getFrameHdrBufLen()
+{
+    LOGV("entry");
+    return REAL_AUDIO_PUSH_MODE_LEN;
+}
+
+uint32_t RealAudioDecodeUtil::getOutBufferLen()
+{
+    LOGV("entry");
+    return 4096;
+}
+
+c2_status_t RealAudioDecodeUtil::parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info)
+{
+    LOGV("entry");
+    return C2_OK;
+}
+
+c2_status_t RealAudioDecodeUtil::getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased)
+{
+    LOGV("entry");
+    if (formatType)
+        *formatType = RA;
+    if (isHwBased)
+        *isHwBased = false;
+
+    return C2_OK;
+}
+
+c2_status_t RealAudioDecodeUtil::handleBOS(uint32_t* offset, uint32_t length) {
+    return C2_OK;
+}
+
+c2_status_t RealAudioDecodeUtil::handleEOS(uint8_t **ppBuffer, uint32_t* length)
+{
+    return C2_OK;
+}
+
+c2_status_t RealAudioDecodeUtil::setParameter(UA_ParaType index,int32_t value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            LOGV("sample rate %d",value);
+            //mIntf->setSampleRate(value);
+            C2StreamSampleRateInfo::output sampleRateInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &sampleRateInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            LOGV("channel num %d",value);
+            //mIntf->setChannelCount(value);
+            C2StreamChannelCountInfo::output channelCountInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &channelCountInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+}
+
+c2_status_t RealAudioDecodeUtil::getParameter(UA_ParaType index,int32_t * value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    if(value == nullptr){
+        ret = C2_BAD_VALUE;
+        return ret;
+    }
+
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            *value = (int32_t)mIntf->getSampleRate();
+            LOGV("sample rate %d",*value);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            *value = (int32_t)mIntf->getChannelCount();
+            LOGV("channel num %d",*value);
+            break;
+        }
+        case UNIA_FRAMED:
+        {
+            *value = false;
+            LOGV("framed %d",*value);
+            break;
+        }
+        case UNIA_RA_FRAME_BITS:
+        {
+            *value = (int32_t)mIntf->getBitsPerFrame();
+            LOGV("UNIA_RA_FRAME_BITS %d",*value);
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+
+}
+
+size_t RealAudioDecodeUtil::getPushModeInputLen()
+{
+    return REAL_AUDIO_PUSH_MODE_LEN;
+}
+
+
+class IMXC2RaDecFactory : public C2ComponentFactory {
+public:
+    IMXC2RaDecFactory(C2String name) : mHelper(std::static_pointer_cast<C2ReflectorHelper>(
+            GetImxC2Store()->getParamReflector()))
+    {
+            if(!name.empty())
+                mCodecName.assign(name);
+            else
+                mCodecName.assign("c2.imx.ra.decoder.sw");
+    }
+
+    virtual c2_status_t createComponent(
+            c2_node_id_t id,
+            std::shared_ptr<C2Component>* const component,
+            std::function<void(C2Component*)> deleter) override {
+
+            auto impl = std::make_shared<RealAudioDecodeUtil::IntfImpl>(mHelper, mCodecName.c_str());
+            RealAudioDecodeUtil * pUtil = new RealAudioDecodeUtil(mCodecName, impl);
+
+        *component = std::shared_ptr<C2Component>(
+                new UniaDecoder(std::make_shared<IMXC2Interface<RealAudioDecodeUtil::IntfImpl>>(mCodecName.c_str(), id, impl),
+                                            pUtil),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual c2_status_t createInterface(
+            c2_node_id_t id, std::shared_ptr<C2ComponentInterface>* const interface,
+            std::function<void(C2ComponentInterface*)> deleter) override {
+        *interface = std::shared_ptr<C2ComponentInterface>(
+                new IMXInterface<RealAudioDecodeUtil::IntfImpl>(
+                        mCodecName, id, std::make_shared<RealAudioDecodeUtil::IntfImpl>(mHelper, mCodecName.c_str())),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual ~IMXC2RaDecFactory() override = default;
+
+private:
+    std::shared_ptr<C2ReflectorHelper> mHelper;
+    std::string mCodecName;
+};
+
+}  // namespace android
+
+extern "C" ::C2ComponentFactory* IMXCreateCodec2Factory(C2String name) {
+    LOGV("entry codecName %s", name.c_str());
+    return new ::android::IMXC2RaDecFactory(name);
+}
+
+extern "C" void IMXDestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+
+
diff --git a/codec2/audio_dec/realaudio_dec/RealAudioDecodeUtil.h b/codec2/audio_dec/realaudio_dec/RealAudioDecodeUtil.h
new file mode 100755
index 0000000..af7596c
--- /dev/null
+++ b/codec2/audio_dec/realaudio_dec/RealAudioDecodeUtil.h
@@ -0,0 +1,42 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef AC3_DECODE_UTIL_h
+#define AC3_DECODE_UTIL_h
+
+#include <AudioDecodeUtil.h>
+
+namespace android {
+
+class RealAudioDecodeUtil  : public AudioDecodeUtil {
+    public:
+        class IntfImpl;
+
+        RealAudioDecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl);
+        virtual ~RealAudioDecodeUtil();
+        virtual c2_status_t getLibName(const char ** lib, const char ** optionalLib) override;
+        virtual uint32_t getFrameHdrBufLen() override;
+        virtual uint32_t getOutBufferLen() override;
+        virtual c2_status_t parseFrame(uint8_t * pBuffer, int len, UniaDecFrameInfo *info) override;
+        virtual c2_status_t getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased) override;
+        virtual c2_status_t handleBOS(uint32_t* offset, uint32_t length) override;
+        virtual c2_status_t handleEOS(uint8_t **ppBuffer, uint32_t* length) override;
+        virtual c2_status_t setParameter(UA_ParaType index,int32_t value) override;
+        virtual c2_status_t getParameter(UA_ParaType index,int32_t * value) override;
+        virtual size_t getPushModeInputLen() override;
+
+    private:
+        bool bFrameChecked;
+        std::shared_ptr<IntfImpl> mIntf;
+
+};
+
+}
+#endif
+
+
diff --git a/codec2/audio_dec/wma_dec/Android.bp b/codec2/audio_dec/wma_dec/Android.bp
new file mode 100644
index 0000000..ecec4f2
--- /dev/null
+++ b/codec2/audio_dec/wma_dec/Android.bp
@@ -0,0 +1,45 @@
+cc_library_shared {
+    name: "lib_c2_imx_wma_dec",
+
+    srcs: [
+        "WmaDecodeUtil.cpp",
+    ],
+
+    include_dirs: [
+        "vendor/nxp/imx_android_mm/codec2/base/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/fsl-codec/ghdr/common",
+        "hardware/google/av/codec2/include",
+        "system/core/include",
+        "hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+    ],
+
+    local_include_dirs: [
+        ".",
+    ],
+
+    export_include_dirs: [
+        ".",
+    ],
+
+    header_libs: [
+        "libsystem_headers",
+    ],
+
+    shared_libs: [
+        "lib_c2_imx_audio_dec_common",
+        "lib_imx_c2_componentbase",
+        "liblog",
+        "libcodec2_vndk",
+        "libstagefright_foundation",
+        "lib_c2_imx_store",
+    ],
+
+    ldflags: ["-Wl,-Bsymbolic"],
+
+    defaults: [
+        "imx_defaults",
+    ],
+    //compile_multilib: "32",
+}
diff --git a/codec2/audio_dec/wma_dec/WmaDecodeUtil.cpp b/codec2/audio_dec/wma_dec/WmaDecodeUtil.cpp
new file mode 100755
index 0000000..2ba21d2
--- /dev/null
+++ b/codec2/audio_dec/wma_dec/WmaDecodeUtil.cpp
@@ -0,0 +1,427 @@
+/**
+ *  Copyright 2019,2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+#define LOG_NDEBUG 0
+#define LOG_TAG "WmaDecUtil"
+#include <log/log.h>
+
+#include <C2Config_imx.h>
+#include <IMXC2Interface.h>
+#include <media/stagefright/foundation/MediaDefs.h>
+#include <UniaDecoder.h>
+#include <C2ComponentFactory.h>
+#include <C2PlatformSupport.h>
+
+#include "WmaDecodeUtil.h"
+
+
+namespace android {
+
+#define WMA_OUTPUT_PORT_SIZE 200000
+
+#define WMA_MAX_CHANNELS 8
+/* pcm channel mask for wma*/
+static uint32 wma10d_1channel_layout[] = {
+    /* FC */
+    UA_CHANNEL_FRONT_CENTER
+};
+static uint32 wma10d_2channel_layout[] = {
+    /* FL,FR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+};
+static uint32 wma10d_3channel_layout[] = {
+    /* FL,FR,FC */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER,
+    };
+static uint32 wma10d_4channel_layout[] = {
+    /* FL,FR,BL,BR */
+    UA_CHANNEL_FRONT_LEFT_CENTER,
+    UA_CHANNEL_FRONT_RIGHT_CENTER,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT
+};
+static uint32 wma10d_5channel_layout[] = {
+    /* FL,FR,FC,BL,BR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT
+    };
+static uint32 wma10d_6channel_layout[] = {
+    /* FL,FR,FC,LFE,BL,BR */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_LFE,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT
+};
+static uint32 wma10d_7channel_layout[] = {
+    /* FL,FR,FC,LFE,BL,BR,BC */
+    UA_CHANNEL_FRONT_LEFT,
+    UA_CHANNEL_FRONT_RIGHT,
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_LFE,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT,
+    UA_CHANNEL_REAR_CENTER
+};
+static uint32 wma10d_8channel_layout[] = {
+    /* FL,FR,FC,LFE,BL,BR,SL,SR  */
+    UA_CHANNEL_FRONT_LEFT_CENTER,
+    UA_CHANNEL_FRONT_RIGHT_CENTER,
+    UA_CHANNEL_FRONT_CENTER,
+    UA_CHANNEL_LFE,
+    UA_CHANNEL_REAR_LEFT,
+    UA_CHANNEL_REAR_RIGHT,
+    UA_CHANNEL_SIDE_LEFT,
+    UA_CHANNEL_SIDE_RIGHT
+};
+static uint32 * wma10d_channel_layouts[] = {
+    NULL,
+    wma10d_1channel_layout, // 1
+    wma10d_2channel_layout, // 2
+    wma10d_3channel_layout,
+    wma10d_4channel_layout,
+    wma10d_5channel_layout,
+    wma10d_6channel_layout,
+    wma10d_7channel_layout,
+    wma10d_8channel_layout
+};
+
+class WmaDecodeUtil::IntfImpl : public IMXInterface<void>::BaseParams  {
+public:
+    explicit IntfImpl(const std::shared_ptr<C2ReflectorHelper> &helper, C2String componentName)
+        : IMXInterface<void>::BaseParams(
+                helper,
+                componentName,
+                C2Component::KIND_DECODER,
+                C2Component::DOMAIN_AUDIO,
+                MEDIA_MIMETYPE_AUDIO_WMA){
+        noPrivateBuffers(); // TODO: account for our buffers here
+        noInputReferences();
+        noOutputReferences();
+        noInputLatency();
+        noTimeStretch();
+
+        addParameter(
+                DefineParam(mAttrib, C2_PARAMKEY_COMPONENT_ATTRIBUTES)
+                .withConstValue(new C2ComponentAttributesSetting(
+                    C2Component::ATTRIB_IS_TEMPORAL))
+                .build());
+
+        addParameter(
+                DefineParam(mSampleRate, C2_PARAMKEY_SAMPLE_RATE)
+                .withDefault(new C2StreamSampleRateInfo::output(0u, 44100))
+                .withFields({C2F(mSampleRate, value).oneOf({
+                    8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000
+                })})
+                .withSetter(Setter<decltype(*mSampleRate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mChannelCount, C2_PARAMKEY_CHANNEL_COUNT)
+                .withDefault(new C2StreamChannelCountInfo::output(0u, 1))
+                .withFields({C2F(mChannelCount, value).inRange(1, 8)})
+                .withSetter(Setter<decltype(*mChannelCount)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mBitrate, C2_PARAMKEY_BITRATE)
+                .withDefault(new C2StreamBitrateInfo::input(0u, 64000))
+                .withFields({C2F(mBitrate, value).inRange(1, 3000000)})
+                .withSetter(Setter<decltype(*mBitrate)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mInputMaxBufSize, C2_PARAMKEY_INPUT_MAX_BUFFER_SIZE)
+                .withConstValue(new C2StreamMaxBufferSizeInfo::input(0u, 8192))
+                .build());
+
+        addParameter(
+                DefineParam(mBlockAlign, C2_PARAMKEY_AUDIO_BLOCK_ALIGN)
+                .withDefault(new C2StreamAudioBlockAlign::input(0u, 0))
+                .withFields({C2F(mBlockAlign, value).inRange(0, 0x7fffffff)})
+                .withSetter(Setter<decltype(*mBlockAlign)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mSubFormat, C2_PARAMKEY_VENDOR_SUB_FORMAT)
+                .withDefault(new C2StreamVendorSubFormat::output(0))
+                .withFields({C2F(mSubFormat, value).inRange(0, 0x7fffffff)})
+                .withSetter(Setter<decltype(*mSubFormat)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mBitsPerSample, C2_PARAMKEY_BITS_PER_SAMPLE)
+                .withDefault(new C2StreamBitsPerSample::output(0u, 0))
+                .withFields({C2F(mBitsPerSample, value).inRange(0, 100)})
+                .withSetter(Setter<decltype(*mBitsPerSample)>::NonStrictValueWithNoDeps)
+                .build());
+
+    }
+
+    uint32_t getSampleRate() const { return mSampleRate->value; };
+    uint32_t getChannelCount() const { return mChannelCount->value; };
+    uint32_t getBitrate() const { return mBitrate->value; };
+    uint32_t getBlockAlign() const { return mBlockAlign->value; };
+    uint32_t getSubFormat() const { return mSubFormat->value; };
+    uint32_t getBitsPerSample() const { return mBitsPerSample->value; };
+
+    void setSampleRate(uint32_t value) { mSampleRate->value = value; };
+    void setChannelCount(uint32_t value) { mChannelCount->value = value; };
+    void setBitrate(uint32_t value) { mBitrate->value = value; };
+    void setBlockAlign(uint32_t value) { mBlockAlign->value = value; };
+    void setBitsPerSample(uint32_t value) { mBitsPerSample->value = value; };
+
+private:
+    std::shared_ptr<C2StreamSampleRateInfo::output> mSampleRate;
+    std::shared_ptr<C2StreamChannelCountInfo::output> mChannelCount;
+    std::shared_ptr<C2StreamBitrateInfo::input> mBitrate;
+    std::shared_ptr<C2StreamMaxBufferSizeInfo::input> mInputMaxBufSize;
+    std::shared_ptr<C2StreamAudioBlockAlign::input> mBlockAlign;
+    std::shared_ptr<C2StreamVendorSubFormat::output> mSubFormat;
+    std::shared_ptr<C2StreamBitsPerSample::output> mBitsPerSample;
+};
+
+WmaDecodeUtil::WmaDecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl)
+    : AudioDecodeUtil(),
+    bFrameChecked(false),
+    mIntf(intfImpl)
+{
+    LOGV("entry %p", this);
+    if(codecName.find("c2.imx.wma.decoder.sw", 0) != std::string::npos){
+        wrapperLibName = "lib_wma10d_wrap_arm12_elinux_android.so";
+        optionalWrapperLibName = nullptr;
+    }
+    else{
+        // error
+        LOGE("invalid codecName %s", codecName.c_str());
+        wrapperLibName = nullptr;
+        optionalWrapperLibName = nullptr;
+    }
+}
+
+WmaDecodeUtil::~WmaDecodeUtil()
+{
+    LOGV("entry");
+}
+
+c2_status_t WmaDecodeUtil::getLibName(const char ** lib, const char ** optionalLib)
+{
+    LOGV("entry");
+    *lib = wrapperLibName;
+    *optionalLib = optionalWrapperLibName;
+    return C2_OK;
+}
+
+uint32_t WmaDecodeUtil::getOutBufferLen()
+{
+    //LOGV("entry");
+    return WMA_OUTPUT_PORT_SIZE;
+}
+
+c2_status_t WmaDecodeUtil::getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased)
+{
+    LOGV("entry");
+    if (formatType)
+        *formatType = WMA;
+    return C2_OK;
+}
+
+c2_status_t WmaDecodeUtil::handleBOS(uint32_t* offset, uint32_t length) {
+    return C2_OK;
+}
+
+c2_status_t WmaDecodeUtil::handleEOS(uint8_t **ppBuffer, uint32_t* length)
+{
+    return C2_OK;
+}
+
+c2_status_t WmaDecodeUtil::setParameter(UA_ParaType index,int32_t value)
+{
+    LOGV("entry");
+    c2_status_t ret = C2_OK;
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            LOGV("sample rate %d",value);
+            //mIntf->setSampleRate(value);
+            C2StreamSampleRateInfo::output sampleRateInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &sampleRateInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            LOGV("channel num %d",value);
+            //mIntf->setChannelCount(value);
+            C2StreamChannelCountInfo::output channelCountInfo(0u, value);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            ret = mIntf->config({ &channelCountInfo }, C2_MAY_BLOCK, &failures);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            LOGV("bitrate %d",value);
+            mIntf->setBitrate(value);
+            break;
+        }
+        case UNIA_DEPTH:
+        {
+            LOGV("UNIA_DEPTH %d", value);
+            mIntf->setBitsPerSample(value);
+            break;
+        }
+        default:
+        {
+            LOGV("unknown index!");
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+}
+
+c2_status_t WmaDecodeUtil::getParameter(UA_ParaType index,int32_t * value)
+{
+    //LOGV("entry");
+    c2_status_t ret = C2_OK;
+    if(value == nullptr){
+        ret = C2_BAD_VALUE;
+        return ret;
+    }
+
+    switch(index){
+        case UNIA_SAMPLERATE:
+        {
+            *value = (int32_t)mIntf->getSampleRate();
+            LOGV("sample rate %d",*value);
+            break;
+        }
+        case UNIA_CHANNEL:
+        {
+            *value = (int32_t)mIntf->getChannelCount();
+            LOGV("channel num %d",*value);
+            break;
+        }
+        case UNIA_BITRATE:
+        {
+            *value = mIntf->getBitrate();
+            LOGV("bitrate %d",*value);
+            break;
+        }
+        case UNIA_FRAMED:
+        {
+            *value = true;
+            LOGV("framed %d",*value);
+            break;
+        }
+        case UNIA_WMA_BlOCKALIGN:
+        {
+            *value = mIntf->getBlockAlign();
+            LOGV("block align %d",*value);
+            break;
+        }
+        case UNIA_WMA_VERSION:
+            *value = mIntf->getSubFormat();
+            LOGV("subformat is %d", *value);
+            break;
+        case UNIA_DEPTH:
+            *value = (int32_t)mIntf->getBitsPerSample();
+            LOGV("get UNIA_DEPTH %d", *value);
+            break;
+        case UNIA_CHAN_MAP_TABLE:
+            CHAN_TABLE table;
+            memset(&table,0,sizeof(table));
+            table.size = WMA_MAX_CHANNELS;
+            memcpy(&table.channel_table,wma10d_channel_layouts,sizeof(wma10d_channel_layouts));
+            memcpy(value,&table,sizeof(CHAN_TABLE));
+            break;
+        default:
+        {
+            LOGV("unknown index 0x%x", index);
+            ret = C2_OMITTED;
+            break;
+        }
+    }
+    return ret;
+
+}
+
+
+class IMXC2WmaDecFactory : public C2ComponentFactory {
+public:
+    IMXC2WmaDecFactory(C2String name) : mHelper(std::static_pointer_cast<C2ReflectorHelper>(
+            GetImxC2Store()->getParamReflector()))
+    {
+            if(!name.empty())
+                mCodecName.assign(name);
+            else
+                mCodecName.assign("c2.imx.wma.decoder.sw");
+    }
+
+    virtual c2_status_t createComponent(
+            c2_node_id_t id,
+            std::shared_ptr<C2Component>* const component,
+            std::function<void(C2Component*)> deleter) override {
+
+            auto impl = std::make_shared<WmaDecodeUtil::IntfImpl>(mHelper, mCodecName.c_str());
+            WmaDecodeUtil * pUtil = new WmaDecodeUtil(mCodecName, impl);
+
+            std::shared_ptr<C2ComponentInterface> intf = std::make_shared<IMXC2Interface<WmaDecodeUtil::IntfImpl>>(mCodecName.c_str(), id, impl);
+            pUtil->mIntf2 = intf;
+
+        *component = std::shared_ptr<C2Component>(
+                new UniaDecoder(intf, pUtil),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual c2_status_t createInterface(
+            c2_node_id_t id, std::shared_ptr<C2ComponentInterface>* const interface,
+            std::function<void(C2ComponentInterface*)> deleter) override {
+        *interface = std::shared_ptr<C2ComponentInterface>(
+                new IMXInterface<WmaDecodeUtil::IntfImpl>(
+                        mCodecName, id, std::make_shared<WmaDecodeUtil::IntfImpl>(mHelper, mCodecName.c_str())),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual ~IMXC2WmaDecFactory() override = default;
+
+private:
+    std::shared_ptr<C2ReflectorHelper> mHelper;
+    std::string mCodecName;
+};
+
+}  // namespace android
+
+extern "C" ::C2ComponentFactory* IMXCreateCodec2Factory(C2String name) {
+    LOGV("entry codecName %s", name.c_str());
+    return new ::android::IMXC2WmaDecFactory(name);
+}
+
+extern "C" void IMXDestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+/*
+extern "C" ::C2ComponentFactory* CreateCodec2Factory() {
+    LOGV("entry");
+    return new ::android::IMXC2AacDecFactory(nullptr);
+}
+
+extern "C" void DestroyCodec2Factory(::C2ComponentFactory* factory) {
+    LOGV("entry");
+    delete factory;
+}
+*/
diff --git a/codec2/audio_dec/wma_dec/WmaDecodeUtil.h b/codec2/audio_dec/wma_dec/WmaDecodeUtil.h
new file mode 100755
index 0000000..c4ad208
--- /dev/null
+++ b/codec2/audio_dec/wma_dec/WmaDecodeUtil.h
@@ -0,0 +1,40 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef WMA_DECODE_UTIL_h
+#define WMA_DECODE_UTIL_h
+
+#include <AudioDecodeUtil.h>
+
+namespace android {
+
+class WmaDecodeUtil  : public AudioDecodeUtil {
+    public:
+        class IntfImpl;
+
+        WmaDecodeUtil(std::string & codecName, const std::shared_ptr<IntfImpl> &intfImpl);
+        virtual ~WmaDecodeUtil();
+        virtual c2_status_t getLibName(const char ** lib, const char ** optionalLib) override;
+        virtual uint32_t getOutBufferLen() override;
+        virtual c2_status_t getDecoderProp(AUDIOFORMAT *formatType, bool *isHwBased) override;
+        virtual c2_status_t handleBOS(uint32_t* offset, uint32_t length) override;
+        virtual c2_status_t handleEOS(uint8_t **ppBuffer, uint32_t* length) override;
+        virtual c2_status_t setParameter(UA_ParaType index,int32_t value) override;
+        virtual c2_status_t getParameter(UA_ParaType index,int32_t * value) override;
+        std::shared_ptr<C2ComponentInterface> mIntf2;
+
+    private:
+        bool bFrameChecked;
+        std::shared_ptr<IntfImpl> mIntf;
+
+};
+
+}
+#endif
+
+
diff --git a/codec2/base/Android.bp b/codec2/base/Android.bp
new file mode 100644
index 0000000..3f08818
--- /dev/null
+++ b/codec2/base/Android.bp
@@ -0,0 +1,43 @@
+cc_library_shared {
+    name: "lib_imx_c2_componentbase",
+
+    srcs: [
+        "IMXC2ComponentBase.cpp",
+        "IMXC2Interface.cpp",
+        "IMXUtils.cpp",
+    ],
+
+    include_dirs: [
+        "hardware/libhardware/include",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",    
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+        "vendor/nxp/imx_android_mm/extractor",
+        "system/core/include/system",
+    ],
+
+    header_libs: [
+        "media_plugin_headers",
+        "libcodec2_headers",
+    ],
+
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "libcodec2_vndk",
+    ],
+
+    export_include_dirs: [
+        "include",
+    ],
+
+
+    defaults: [
+        "imx_defaults",
+    ],
+}
diff --git a/codec2/base/IMXC2ComponentBase.cpp b/codec2/base/IMXC2ComponentBase.cpp
new file mode 100755
index 0000000..71c780f
--- /dev/null
+++ b/codec2/base/IMXC2ComponentBase.cpp
@@ -0,0 +1,785 @@
+/*
+ * Copyright (C) 2017 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "IMXC2ComponentBase"
+#include <log/log.h>
+
+#include <cutils/properties.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <inttypes.h>
+
+#include <C2Config.h>
+#include <C2Debug.h>
+#include <C2PlatformSupport.h>
+#include "IMXC2ComponentBase.h"
+
+namespace android {
+
+std::unique_ptr<C2Work> IMXC2ComponentBase::WorkQueue::pop_front() {
+    std::unique_ptr<C2Work> work = std::move(mQueue.front().work);
+    mQueue.pop_front();
+    return work;
+}
+
+void IMXC2ComponentBase::WorkQueue::push_back(std::unique_ptr<C2Work> work) {
+    mQueue.push_back({ std::move(work), NO_DRAIN });
+}
+
+bool IMXC2ComponentBase::WorkQueue::empty() const {
+    return mQueue.empty();
+}
+
+void IMXC2ComponentBase::WorkQueue::clear() {
+    mQueue.clear();
+}
+
+uint32_t IMXC2ComponentBase::WorkQueue::drainMode() const {
+    return mQueue.front().drainMode;
+}
+
+void IMXC2ComponentBase::WorkQueue::markDrain(uint32_t drainMode) {
+    mQueue.push_back({ nullptr, drainMode });
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+IMXC2ComponentBase::WorkHandler::WorkHandler() : mRunning(false) {}
+
+void IMXC2ComponentBase::WorkHandler::setComponent(
+        const std::shared_ptr<IMXC2ComponentBase> &thiz) {
+    mThiz = thiz;
+}
+
+static void Reply(const sp<AMessage> &msg, int32_t *err = nullptr) {
+    sp<AReplyToken> replyId;
+    CHECK(msg->senderAwaitsResponse(&replyId));
+    sp<AMessage> reply = new AMessage;
+    if (err) {
+        reply->setInt32("err", *err);
+    }
+    reply->postReply(replyId);
+}
+
+void IMXC2ComponentBase::WorkHandler::onMessageReceived(const sp<AMessage> &msg) {
+    std::shared_ptr<IMXC2ComponentBase> thiz = mThiz.lock();
+    if (!thiz) {
+        ALOGD("component not yet set; msg = %s", msg->debugString().c_str());
+        sp<AReplyToken> replyId;
+        if (msg->senderAwaitsResponse(&replyId)) {
+            sp<AMessage> reply = new AMessage;
+            reply->setInt32("err", C2_CORRUPTED);
+            reply->postReply(replyId);
+        }
+        return;
+    }
+
+    switch (msg->what()) {
+        case kWhatProcess: {
+            if (mRunning) {
+                if (thiz->processQueue()) {
+                    (new AMessage(kWhatProcess, this))->post();
+                }
+            } else {
+                ALOGV("Ignore process message as we're not running");
+            }
+            break;
+        }
+        case kWhatInit: {
+            int32_t err = thiz->onInit();
+            Reply(msg, &err);
+            [[fallthrough]];
+        }
+        case kWhatStart: {
+            mRunning = true;
+            break;
+        }
+        case kWhatStop: {
+            int32_t err = thiz->onStop();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatReset: {
+            thiz->onReset();
+            mRunning = false;
+            Reply(msg);
+            break;
+        }
+        case kWhatRelease: {
+            thiz->onRelease();
+            mRunning = false;
+            Reply(msg);
+            break;
+        }
+        default: {
+            ALOGD("Unrecognized msg: %d", msg->what());
+            break;
+        }
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+namespace {
+
+struct DummyReadView : public C2ReadView {
+    DummyReadView() : C2ReadView(C2_NO_INIT) {}
+};
+
+}  // namespace
+
+
+IMXC2ComponentBase::IMXC2ComponentBase(
+        const std::shared_ptr<C2ComponentInterface> &intf)
+    : mDummyReadView(DummyReadView()),
+      mIntf(intf),
+      mLooper(new ALooper),
+      mHandler(new WorkHandler) {
+
+    nCurFrameIndex = -1;
+    nUsedFrameIndex = -1;
+    bRecieveOutputEos = false;
+    mLooper->setName(intf->getName().c_str());
+    (void)mLooper->registerHandler(mHandler);
+    mLooper->start(false, false, ANDROID_PRIORITY_VIDEO);
+}
+
+IMXC2ComponentBase::~IMXC2ComponentBase() {
+    mLooper->unregisterHandler(mHandler->id());
+    (void)mLooper->stop();
+}
+
+c2_status_t IMXC2ComponentBase::setListener_vb(
+        const std::shared_ptr<C2Component::Listener> &listener, c2_blocking_t mayBlock) {
+    mHandler->setComponent(shared_from_this());
+
+    Mutexed<ExecState>::Locked state(mExecState);
+    if (state->mState == RUNNING) {
+        if (listener) {
+            return C2_BAD_STATE;
+        } else if (!mayBlock) {
+            return C2_BLOCKING;
+        }
+    }
+    state->mListener = listener;
+    // TODO: wait for listener change to have taken place before returning
+    // (e.g. if there is an ongoing listener callback)
+    return C2_OK;
+}
+
+c2_status_t IMXC2ComponentBase::queue_nb(std::list<std::unique_ptr<C2Work>> * const items) {
+    {
+        Mutexed<ExecState>::Locked state(mExecState);
+        if (state->mState != RUNNING) {
+            return C2_BAD_STATE;
+        }
+    }
+    bool queueWasEmpty = false;
+    {
+        Mutexed<WorkQueue>::Locked queue(mWorkQueue);
+        queueWasEmpty = queue->empty();
+        while (!items->empty()) {
+            queue->push_back(std::move(items->front()));
+            items->pop_front();
+        }
+    }
+    if (queueWasEmpty) {
+        (new AMessage(WorkHandler::kWhatProcess, mHandler))->post();
+    }
+    return C2_OK;
+}
+
+c2_status_t IMXC2ComponentBase::announce_nb(const std::vector<C2WorkOutline> &items) {
+    (void)items;
+    return C2_OMITTED;
+}
+
+c2_status_t IMXC2ComponentBase::flush_sm(
+        flush_mode_t flushMode, std::list<std::unique_ptr<C2Work>>* const flushedWork) {
+    (void)flushMode;
+    {
+        Mutexed<ExecState>::Locked state(mExecState);
+        if (state->mState != RUNNING) {
+            return C2_BAD_STATE;
+        }
+    }
+    {
+        Mutexed<WorkQueue>::Locked queue(mWorkQueue);
+        queue->incGeneration();
+        // TODO: queue->splicedBy(flushedWork, flushedWork->end());
+        while (!queue->empty()) {
+            std::unique_ptr<C2Work> work = queue->pop_front();
+            if (work) {
+                flushedWork->push_back(std::move(work));
+            }
+        }
+    }
+    {
+        Mutexed<PendingWork>::Locked pending(mPendingWork);
+        while (!pending->empty()) {
+            flushedWork->push_back(std::move(pending->front()));
+            pending->pop_front();
+        }
+    }
+
+    return C2_OK;
+}
+
+c2_status_t IMXC2ComponentBase::drain_nb(drain_mode_t drainMode) {
+    if (drainMode == DRAIN_CHAIN) {
+        return C2_OMITTED;
+    }
+    {
+        Mutexed<ExecState>::Locked state(mExecState);
+        if (state->mState != RUNNING) {
+            return C2_BAD_STATE;
+        }
+    }
+    bool queueWasEmpty = false;
+    {
+        Mutexed<WorkQueue>::Locked queue(mWorkQueue);
+        queueWasEmpty = queue->empty();
+        queue->markDrain(drainMode);
+    }
+    if (queueWasEmpty) {
+        (new AMessage(WorkHandler::kWhatProcess, mHandler))->post();
+    }
+
+    return C2_OK;
+}
+
+c2_status_t IMXC2ComponentBase::start() {
+    Mutexed<ExecState>::Locked state(mExecState);
+    if (state->mState == RUNNING) {
+        return C2_BAD_STATE;
+    }
+    bool needsInit = (state->mState == UNINITIALIZED);
+    state.unlock();
+    if (needsInit) {
+        sp<AMessage> reply;
+        (new AMessage(WorkHandler::kWhatInit, mHandler))->postAndAwaitResponse(&reply);
+        int32_t err;
+        CHECK(reply->findInt32("err", &err));
+        if (err != C2_OK) {
+            return (c2_status_t)err;
+        }
+    } else {
+        (new AMessage(WorkHandler::kWhatStart, mHandler))->post();
+    }
+    state.lock();
+    state->mState = RUNNING;
+    return C2_OK;
+}
+
+c2_status_t IMXC2ComponentBase::stop() {
+    ALOGV("stop");
+    {
+        Mutexed<ExecState>::Locked state(mExecState);
+        if (state->mState != RUNNING) {
+            return C2_BAD_STATE;
+        }
+        state->mState = STOPPED;
+    }
+    {
+        Mutexed<WorkQueue>::Locked queue(mWorkQueue);
+        queue->clear();
+    }
+    {
+        Mutexed<PendingWork>::Locked pending(mPendingWork);
+        pending->clear();
+    }
+    sp<AMessage> reply;
+    (new AMessage(WorkHandler::kWhatStop, mHandler))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    if (err != C2_OK) {
+        return (c2_status_t)err;
+    }
+    return C2_OK;
+}
+
+c2_status_t IMXC2ComponentBase::reset() {
+    ALOGV("reset");
+    {
+        Mutexed<ExecState>::Locked state(mExecState);
+        state->mState = UNINITIALIZED;
+    }
+    {
+        Mutexed<WorkQueue>::Locked queue(mWorkQueue);
+        queue->clear();
+    }
+    {
+        Mutexed<PendingWork>::Locked pending(mPendingWork);
+        pending->clear();
+    }
+    sp<AMessage> reply;
+    (new AMessage(WorkHandler::kWhatReset, mHandler))->postAndAwaitResponse(&reply);
+    return C2_OK;
+}
+
+c2_status_t IMXC2ComponentBase::release() {
+    ALOGV("release");
+
+    bool needCallStop = false;
+    {
+        Mutexed<ExecState>::Locked state(mExecState);
+        if (state->mState == RUNNING) {
+            state->mState = STOPPED;
+            needCallStop = true;
+        }
+    }
+
+    if (needCallStop) {
+        {
+            Mutexed<WorkQueue>::Locked queue(mWorkQueue);
+            queue->clear();
+        }
+        {
+            Mutexed<PendingWork>::Locked pending(mPendingWork);
+            pending->clear();
+        }
+        sp<AMessage> reply;
+        (new AMessage(WorkHandler::kWhatStop, mHandler))->postAndAwaitResponse(&reply);
+    }
+
+    sp<AMessage> reply;
+    (new AMessage(WorkHandler::kWhatRelease, mHandler))->postAndAwaitResponse(&reply);
+    return C2_OK;
+}
+
+std::shared_ptr<C2ComponentInterface> IMXC2ComponentBase::intf() {
+    return mIntf;
+}
+
+namespace {
+
+std::list<std::unique_ptr<C2Work>> vec(std::unique_ptr<C2Work> &work) {
+    std::list<std::unique_ptr<C2Work>> ret;
+    ret.push_back(std::move(work));
+    return ret;
+}
+
+}  // namespace
+
+c2_status_t IMXC2ComponentBase::finish(
+        uint64_t timestamp, std::function<void(const std::unique_ptr<C2Work> &)> fillWork) {
+
+    std::unique_ptr<C2Work> work;
+    {
+        // find one work : 1. input is used; 2. input ts match output ts
+        Mutexed<PendingWork>::Locked pending(mPendingWork);
+        ALOGV("finish, pending size=%d, ts=%lld", (int)pending->size(), (long long)timestamp);
+        auto workIter = std::find_if(pending->begin(), pending->end(),
+                                 [timestamp](const std::unique_ptr<C2Work>& w) {
+                                     return (w->input.ordinal.timestamp == timestamp);
+                                 });
+        if (workIter != pending->end()) {
+            work = std::move(*workIter);
+            workIter = pending->erase(workIter);
+        } else if (pending->size() > 0) {
+            workIter = pending->begin();
+            for (auto iter = pending->begin(); iter != pending->end(); ++iter) {
+                if ((*iter)->input.ordinal.timestamp < (*workIter)->input.ordinal.timestamp &&
+                        ((*iter)->input.flags & C2FrameData::FLAG_END_OF_STREAM) == 0)
+                    workIter = iter;
+            }
+
+            if (workIter != pending->end()) {
+                work = std::move(*workIter);
+                workIter = pending->erase(workIter);
+                ALOGV("pop the min timestamp used input #%lld, ts %lld, rest pending %zu",
+                    (long long)work->input.ordinal.frameIndex.peeku(),
+                    (long long)work->input.ordinal.timestamp.peeku(),
+                    pending->size());
+            }
+        }
+    }
+
+    if (work) {
+        ALOGV("returning pending work #%lld", (long long)work->input.ordinal.frameIndex.peeku());
+
+        fillWork(work);
+
+        if (work->worklets.front()->output.flags & C2FrameData::FLAG_END_OF_STREAM)
+            bRecieveOutputEos = true;
+
+        Mutexed<ExecState>::Locked state(mExecState);
+        std::shared_ptr<C2Component::Listener> listener = state->mListener;
+        state.unlock();
+        listener->onWorkDone_nb(shared_from_this(), vec(work));
+
+        if(0){
+            std::unique_ptr<C2Work> unexpected;
+            Mutexed<PendingWork>::Locked pending(mPendingWork);
+
+            auto iter = std::find_if(pending->begin(), pending->end(),
+                                 [timestamp](const std::unique_ptr<C2Work>& w) {
+                                     return (w->input.ordinal.timestamp.peeku() < timestamp &&
+                                             (w->input.flags & C2FrameData::FLAG_END_OF_STREAM) == 0);
+                                 });
+
+            if (iter != pending->end()) {
+                unexpected = std::move(*iter);
+                pending->erase(iter);
+            }
+
+            if (unexpected) {
+                ALOGD("unexpected pending work ts=%lld, frameIndex=%lld",
+                    (long long)unexpected->input.ordinal.timestamp.peeku(),
+                    (long long)unexpected->input.ordinal.frameIndex.peeku());
+                unexpected->result = C2_OK;
+                Mutexed<ExecState>::Locked state(mExecState);
+                std::shared_ptr<C2Component::Listener> listener = state->mListener;
+                state.unlock();
+                listener->onWorkDone_nb(shared_from_this(), vec(unexpected));
+            }
+        }
+
+        return C2_OK;
+    } else {
+        ALOGW("can't find related work (ts=%lld) in mPendingWork", (long long)timestamp);
+        //fillWork(work); // notice that work is null in this case
+        return C2_NOT_FOUND;
+    }
+}
+
+c2_status_t IMXC2ComponentBase::finishWithException(bool eos, bool force) {
+    // if exception is eos, then just return eos, otherwise decoder meet corrupted stream, need report it.
+    std::unique_ptr<C2Work> work;
+    Mutexed<PendingWork>::Locked pending(mPendingWork);
+
+    ALOGV("finishWithException, pending size=%d, force %d", (int)pending->size(), force);
+
+    if (pending->empty()) {
+
+        if (eos && force) {
+            ALOGI("no pending work when get eos");
+            std::unique_ptr<C2Work> work(new C2Work);
+            work->input.flags = C2FrameData::FLAG_END_OF_STREAM;
+            work->input.buffers.clear();
+
+            work->worklets.emplace_back(new C2Worklet);
+            work->worklets.front()->output.flags = C2FrameData::FLAG_END_OF_STREAM;
+            work->worklets.front()->output.buffers.clear();
+            work->workletsProcessed = 1u;
+            work->result = C2_OK;
+
+            Mutexed<ExecState>::Locked state(mExecState);
+            std::shared_ptr<C2Component::Listener> listener = state->mListener;
+            state.unlock();
+            listener->onWorkDone_nb(shared_from_this(), vec(work));
+            return C2_OK;
+        }
+
+        ALOGD("finishWithException(eos=%d): can't find c2work", eos);
+        Mutexed<ExecState>::Locked state(mExecState);
+        std::shared_ptr<C2Component::Listener> listener = state->mListener;
+        state.unlock();
+        listener->onError_nb(shared_from_this(), C2_NOT_FOUND);
+        return C2_NOT_FOUND;
+    }
+
+    while (!pending->empty()) {
+        auto workIter = pending->begin();
+        work = std::move(*workIter);
+        pending->erase(workIter);
+        work->worklets.front()->output.flags = work->input.flags;
+        work->worklets.front()->output.buffers.clear();
+        work->worklets.front()->output.ordinal = work->input.ordinal;
+        work->workletsProcessed = 1u;
+        work->result = eos ? C2_OK : C2_CORRUPTED;
+
+        ALOGV("finishWithException(eos=%d): frameIndex %d, result %d, flags 0x%x",
+            eos, (int)work->input.ordinal.frameIndex.peeku(), work->result, work->input.flags);
+
+        Mutexed<ExecState>::Locked state(mExecState);
+        std::shared_ptr<C2Component::Listener> listener = state->mListener;
+        state.unlock();
+        listener->onWorkDone_nb(shared_from_this(), vec(work));
+    }
+
+    return C2_OK;
+}
+
+C2Work* IMXC2ComponentBase::getPendingWorkByFrameIndex(uint64_t frameIndex) {
+    Mutexed<PendingWork>::Locked pending(mPendingWork);
+    auto workIter = std::find_if(pending->begin(), pending->end(),
+                                 [frameIndex](const std::unique_ptr<C2Work>& w) {
+                                     return w->input.ordinal.frameIndex == frameIndex;
+                                 });
+
+    if (workIter == pending->end()) {
+        ALOGV("Can't find pending work by bitstream ID: %llu", (unsigned long long)frameIndex);
+        return nullptr;
+    }
+    return workIter->get();
+}
+
+c2_status_t IMXC2ComponentBase::skipOnePendingWork(uint64_t frameIndex) {
+    std::unique_ptr<C2Work> work;
+    Mutexed<PendingWork>::Locked pending(mPendingWork);
+    auto workIter = pending->begin();
+
+    if (frameIndex != (uint64_t)(-1)) {
+        workIter = std::find_if(pending->begin(), pending->end(),
+                                 [frameIndex](const std::unique_ptr<C2Work>& w) {
+                                     return (w->input.ordinal.frameIndex == frameIndex);
+                                 });
+    }
+
+    if (workIter != pending->end()) {
+        work = std::move(*workIter);
+        workIter = pending->erase(workIter);
+        ALOGV("skip pending work #%lld", (long long)work->input.ordinal.frameIndex.peeku());
+        work->worklets.front()->output.flags = work->input.flags;
+        work->worklets.front()->output.buffers.clear();
+        work->worklets.front()->output.ordinal = work->input.ordinal;
+        work->workletsProcessed = 1u;
+        work->result = C2_OK;
+
+        Mutexed<ExecState>::Locked state(mExecState);
+        std::shared_ptr<C2Component::Listener> listener = state->mListener;
+        state.unlock();
+        listener->onWorkDone_nb(shared_from_this(), vec(work));
+        return C2_OK;
+    }
+
+    ALOGV("skip pending work but pending queue is empty");
+
+    return C2_BAD_VALUE;
+}
+
+c2_status_t IMXC2ComponentBase::initOutputBlockPool() {
+    c2_status_t err = C2_OK;
+    // TODO: don't use query_vb
+    C2StreamBufferTypeSetting::output outputFormat(0u);
+    std::vector<std::unique_ptr<C2Param>> params;
+    err = intf()->query_vb(
+            { &outputFormat },
+            { C2PortBlockPoolsTuning::output::PARAM_TYPE },
+            C2_DONT_BLOCK,
+            &params);
+    if (err != C2_OK && err != C2_BAD_INDEX) {
+        ALOGD("query err = %d", err);
+        return err;
+    }
+    C2BlockPool::local_id_t poolId =
+        outputFormat.value == C2BufferData::GRAPHIC
+                ? C2BlockPool::BASIC_GRAPHIC
+                : C2BlockPool::BASIC_LINEAR;
+    if (params.size()) {
+        C2PortBlockPoolsTuning::output *outputPools =
+            C2PortBlockPoolsTuning::output::From(params[0].get());
+        if (outputPools && outputPools->flexCount() >= 1) {
+            poolId = outputPools->m.values[0];
+        }
+    }
+
+    err = GetCodec2BlockPool(poolId, shared_from_this(), &mOutputBlockPool);
+    if (err == C2_OK && mOutputBlockPool->getLocalId() == C2BlockPool::BASIC_GRAPHIC) {
+        // can't C2BasicGraphicBlockPool because it doesn't have a pool manager
+        err = CreateCodec2BlockPool(C2PlatformAllocatorStore::GRALLOC, shared_from_this(), &mOutputBlockPool);
+        if (err) {
+            ALOGE("CreateCodec2BlockPool GRALLOC failed, err %d", err);
+            return err;
+        } else {
+            // Configure output block pool ID as parameter C2PortBlockPoolsTuning::output to component.
+            std::unique_ptr<C2PortBlockPoolsTuning::output> poolIdsTuning =
+                C2PortBlockPoolsTuning::output::AllocUnique({ mOutputBlockPool->getLocalId() });
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            err = intf()->config_vb({ poolIdsTuning.get() }, C2_MAY_BLOCK, &failures);
+            ALOGD("Configured output block pool ids %lld", (long long)poolIdsTuning->m.values[0]);
+        }
+    }
+
+    ALOGD("Using output block pool with poolID %llu => got %llu - %d",
+            (unsigned long long)poolId,
+            (unsigned long long)(
+                    mOutputBlockPool ? mOutputBlockPool->getLocalId() : 111000111),
+            err);
+
+    return C2_OK;
+
+}
+
+bool IMXC2ComponentBase::processQueue() {
+    std::unique_ptr<C2Work> work;
+    uint64_t generation;
+    int32_t drainMode;
+    bool isFlushPending = false;
+    bool hasQueuedWork = false;
+
+    {
+        Mutexed<WorkQueue>::Locked queue(mWorkQueue);
+        if (queue->empty()) {
+            return false;
+        }
+
+        generation = queue->generation();
+        drainMode = queue->drainMode();
+        isFlushPending = queue->popPendingFlush();
+        work = queue->pop_front();
+        hasQueuedWork = !queue->empty();
+    }
+    if (isFlushPending) {
+        ALOGV("processing pending flush");
+        c2_status_t err = onFlush_sm();
+        if (err != C2_OK) {
+            ALOGD("flush err: %d", err);
+            // TODO: error
+        }
+    }
+
+    if (!mOutputBlockPool) {
+        c2_status_t err = initOutputBlockPool();
+        if (err != C2_OK) {
+            ALOGE("GetCodec2BlockPool failed, err %d
", err);
+            Mutexed<ExecState>::Locked state(mExecState);
+            std::shared_ptr<C2Component::Listener> listener = state->mListener;
+            state.unlock();
+            listener->onError_nb(shared_from_this(), err);
+            return hasQueuedWork;
+        }
+    }
+
+    if (!work) {
+        ALOGV("work=null, call drainInternal, drainMode=%d", drainMode);
+        c2_status_t err = drainInternal(drainMode);
+        if (err != C2_OK) {
+            Mutexed<ExecState>::Locked state(mExecState);
+            std::shared_ptr<C2Component::Listener> listener = state->mListener;
+            state.unlock();
+            listener->onError_nb(shared_from_this(), err);
+        }
+        return hasQueuedWork;
+    }
+
+    {
+        std::vector<C2Param *> updates;
+        for (const std::unique_ptr<C2Param> &param: work->input.configUpdate) {
+            if (param) {
+                updates.emplace_back(param.get());
+            }
+        }
+        if (!updates.empty()) {
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            c2_status_t err = intf()->config_vb(updates, C2_MAY_BLOCK, &failures);
+            ALOGD("applied %zu configUpdates => %s (%d)", updates.size(), asString(err), err);
+        }
+    }
+
+    if (!work->input.buffers.empty() && !work->input.buffers[0]) {
+        ALOGD("Encountered null input buffer. Clearing the input buffer");
+        work->input.buffers.clear();
+    }
+
+    nCurFrameIndex = work->input.ordinal.frameIndex.peeku();
+
+    ALOGV("start processing frame #%lld ts %lld" ,
+        (long long)nCurFrameIndex, (long long)work->input.ordinal.timestamp.peeku());
+    processWork(work);
+    ALOGV("processed frame #%" PRIu64, nCurFrameIndex);
+    {
+        bool componentStopped = false;
+        {
+            Mutexed<ExecState>::Locked state(mExecState);
+            if (state->mState == STOPPED) {
+                componentStopped = true;
+                ALOGV("component is stopped, this work become unexpected");
+            }
+        }
+        Mutexed<WorkQueue>::Locked queue(mWorkQueue);
+        if (queue->generation() != generation || componentStopped) {
+            ALOGD("work form old generation: was %" PRIu64 " now %" PRIu64,
+                    queue->generation(), generation);
+            work->result = C2_NOT_FOUND;
+            queue.unlock();
+            {
+                Mutexed<ExecState>::Locked state(mExecState);
+                std::shared_ptr<C2Component::Listener> listener = state->mListener;
+                state.unlock();
+                listener->onWorkDone_nb(shared_from_this(), vec(work));
+            }
+            queue.lock();
+            return hasQueuedWork;
+        }
+    }
+    if (work->workletsProcessed != 0u) {
+        Mutexed<ExecState>::Locked state(mExecState);
+        ALOGV("returning this work");
+        std::shared_ptr<C2Component::Listener> listener = state->mListener;
+        state.unlock();
+        listener->onWorkDone_nb(shared_from_this(), vec(work));
+    } else {
+        ALOGV("queue pending work, ts=%" PRIu64 , work->input.ordinal.timestamp.peeku());
+        std::unique_ptr<C2Work> unexpected;
+        {
+            Mutexed<PendingWork>::Locked pending(mPendingWork);
+            uint64_t frameIndex = work->input.ordinal.frameIndex.peeku();
+
+            auto iter = std::find_if(pending->begin(), pending->end(),
+                                 [frameIndex](const std::unique_ptr<C2Work>& w) {
+                                     return w->input.ordinal.frameIndex == frameIndex;
+                                 });
+
+            if (iter != pending->end()) {
+                unexpected = std::move(*iter);
+                pending->erase(iter);
+            }
+            (void)pending->emplace_back(std::move(work));
+        }
+        if (unexpected) {
+            ALOGD("unexpected pending work");
+            unexpected->result = C2_CORRUPTED;
+            Mutexed<ExecState>::Locked state(mExecState);
+            std::shared_ptr<C2Component::Listener> listener = state->mListener;
+            state.unlock();
+            listener->onWorkDone_nb(shared_from_this(), vec(unexpected));
+        }
+    }
+
+    return hasQueuedWork;
+}
+
+std::shared_ptr<C2Buffer> IMXC2ComponentBase::createLinearBuffer(
+        const std::shared_ptr<C2LinearBlock> &block) {
+    return createLinearBuffer(block, block->offset(), block->size());
+}
+
+std::shared_ptr<C2Buffer> IMXC2ComponentBase::createLinearBuffer(
+        const std::shared_ptr<C2LinearBlock> &block, size_t offset, size_t size) {
+    return C2Buffer::CreateLinearBuffer(block->share(offset, size, ::C2Fence()));
+}
+
+std::shared_ptr<C2Buffer> IMXC2ComponentBase::createGraphicBuffer(
+        const std::shared_ptr<C2GraphicBlock> &block) {
+    return createGraphicBuffer(block, C2Rect(block->width(), block->height()));
+}
+
+std::shared_ptr<C2Buffer> IMXC2ComponentBase::createGraphicBuffer(
+        const std::shared_ptr<C2GraphicBlock> &block, const C2Rect &crop) {
+    return C2Buffer::CreateGraphicBuffer(block->share(crop, ::C2Fence()));
+}
+
+} // namespace android
diff --git a/codec2/base/IMXC2Interface.cpp b/codec2/base/IMXC2Interface.cpp
new file mode 100755
index 0000000..2083aae
--- /dev/null
+++ b/codec2/base/IMXC2Interface.cpp
@@ -0,0 +1,307 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#define LOG_TAG "IMXC2Interface"
+#include <utils/Log.h>
+
+// use MediaDefs here vs. MediaCodecConstants as this is not MediaCodec specific/dependent
+#include <media/stagefright/foundation/MediaDefs.h>
+
+#include <IMXC2Interface.h>
+
+namespace android {
+
+/* IMXInterface */
+
+IMXInterface<void>::BaseParams::BaseParams(
+        const std::shared_ptr<C2ReflectorHelper> &reflector,
+        C2String name,
+        C2Component::kind_t kind,
+        C2Component::domain_t domain,
+        C2String mediaType,
+        std::vector<C2String> aliases)
+    : C2InterfaceHelper(reflector) {
+    setDerivedInstance(this);
+
+    addParameter(
+            DefineParam(mName, C2_PARAMKEY_COMPONENT_NAME)
+            .withConstValue(AllocSharedString<C2ComponentNameSetting>(name.c_str()))
+            .build());
+
+    if (aliases.size()) {
+        C2String joined;
+        for (const C2String &alias : aliases) {
+            if (joined.length()) {
+                joined += ",";
+            }
+            joined += alias;
+        }
+        addParameter(
+                DefineParam(mAliases, C2_PARAMKEY_COMPONENT_ALIASES)
+                .withConstValue(AllocSharedString<C2ComponentAliasesSetting>(joined.c_str()))
+                .build());
+    }
+
+    addParameter(
+            DefineParam(mKind, C2_PARAMKEY_COMPONENT_KIND)
+            .withConstValue(new C2ComponentKindSetting(kind))
+            .build());
+
+    addParameter(
+            DefineParam(mDomain, C2_PARAMKEY_COMPONENT_DOMAIN)
+            .withConstValue(new C2ComponentDomainSetting(domain))
+            .build());
+
+    // simple interfaces have single streams
+    addParameter(
+            DefineParam(mInputStreamCount, C2_PARAMKEY_INPUT_STREAM_COUNT)
+            .withConstValue(new C2PortStreamCountTuning::input(1))
+            .build());
+
+    addParameter(
+            DefineParam(mOutputStreamCount, C2_PARAMKEY_OUTPUT_STREAM_COUNT)
+            .withConstValue(new C2PortStreamCountTuning::output(1))
+            .build());
+
+    // set up buffer formats and allocators
+
+    // default to linear buffers and no media type
+    C2BufferData::type_t rawBufferType = C2BufferData::LINEAR;
+    C2String rawMediaType;
+    C2Allocator::id_t rawAllocator = C2AllocatorStore::DEFAULT_LINEAR;
+    C2BlockPool::local_id_t rawPoolId = C2BlockPool::BASIC_LINEAR;
+    C2BufferData::type_t codedBufferType = C2BufferData::LINEAR;
+    C2Allocator::id_t codedAllocator = C2AllocatorStore::DEFAULT_LINEAR;
+    C2BlockPool::local_id_t codedPoolId = C2BlockPool::BASIC_LINEAR;
+
+    switch (domain) {
+        case C2Component::DOMAIN_IMAGE:
+        case C2Component::DOMAIN_VIDEO:
+            // TODO: should we define raw image? The only difference is timestamp handling
+            rawBufferType = C2BufferData::GRAPHIC;
+            rawMediaType = MEDIA_MIMETYPE_VIDEO_RAW;
+            rawAllocator = C2AllocatorStore::DEFAULT_GRAPHIC;
+            rawPoolId = C2BlockPool::BASIC_GRAPHIC;
+            break;
+        case C2Component::DOMAIN_AUDIO:
+            rawBufferType = C2BufferData::LINEAR;
+            rawMediaType = MEDIA_MIMETYPE_AUDIO_RAW;
+            rawAllocator = C2AllocatorStore::DEFAULT_LINEAR;
+            rawPoolId = C2BlockPool::BASIC_LINEAR;
+            break;
+        default:
+            break;
+    }
+    bool isEncoder = kind == C2Component::KIND_ENCODER;
+
+    // handle raw decoders
+    if (mediaType == rawMediaType) {
+        codedBufferType = rawBufferType;
+        codedAllocator = rawAllocator;
+        codedPoolId = rawPoolId;
+    }
+
+    addParameter(
+            DefineParam(mInputFormat, C2_PARAMKEY_INPUT_STREAM_BUFFER_TYPE)
+            .withConstValue(new C2StreamBufferTypeSetting::input(
+                    0u, isEncoder ? rawBufferType : codedBufferType))
+            .build());
+
+    addParameter(
+            DefineParam(mInputMediaType, C2_PARAMKEY_INPUT_MEDIA_TYPE)
+            .withConstValue(AllocSharedString<C2PortMediaTypeSetting::input>(
+                    isEncoder ? rawMediaType : mediaType))
+            .build());
+
+    addParameter(
+            DefineParam(mOutputFormat, C2_PARAMKEY_OUTPUT_STREAM_BUFFER_TYPE)
+            .withConstValue(new C2StreamBufferTypeSetting::output(
+                    0u, isEncoder ? codedBufferType : rawBufferType))
+            .build());
+
+    addParameter(
+            DefineParam(mOutputMediaType, C2_PARAMKEY_OUTPUT_MEDIA_TYPE)
+            .withConstValue(AllocSharedString<C2PortMediaTypeSetting::output>(
+                    isEncoder ? mediaType : rawMediaType))
+            .build());
+
+    C2Allocator::id_t inputAllocators[1] = { isEncoder ? rawAllocator : codedAllocator };
+    C2Allocator::id_t outputAllocators[1] = { isEncoder ? codedAllocator : rawAllocator };
+    C2BlockPool::local_id_t outputPoolIds[1] = { isEncoder ? codedPoolId : rawPoolId };
+
+    addParameter(
+            DefineParam(mInputAllocators, C2_PARAMKEY_INPUT_ALLOCATORS)
+            .withDefault(C2PortAllocatorsTuning::input::AllocShared(inputAllocators))
+            .withFields({ C2F(mInputAllocators, m.values[0]).any(),
+                          C2F(mInputAllocators, m.values).inRange(0, 1) })
+            .withSetter(Setter<C2PortAllocatorsTuning::input>::NonStrictValuesWithNoDeps)
+            .build());
+
+    addParameter(
+            DefineParam(mOutputAllocators, C2_PARAMKEY_OUTPUT_ALLOCATORS)
+            .withDefault(C2PortAllocatorsTuning::output::AllocShared(outputAllocators))
+            .withFields({ C2F(mOutputAllocators, m.values[0]).any(),
+                          C2F(mOutputAllocators, m.values).inRange(0, 1) })
+            .withSetter(Setter<C2PortAllocatorsTuning::output>::NonStrictValuesWithNoDeps)
+            .build());
+
+    addParameter(
+            DefineParam(mOutputPoolIds, C2_PARAMKEY_OUTPUT_BLOCK_POOLS)
+            .withDefault(C2PortBlockPoolsTuning::output::AllocShared(outputPoolIds))
+            .withFields({ C2F(mOutputPoolIds, m.values[0]).any(),
+                          C2F(mOutputPoolIds, m.values).inRange(0, 1) })
+            .withSetter(Setter<C2PortBlockPoolsTuning::output>::NonStrictValuesWithNoDeps)
+            .build());
+
+    // add stateless params
+    addParameter(
+            DefineParam(mSubscribedParamIndices, C2_PARAMKEY_SUBSCRIBED_PARAM_INDICES)
+            .withDefault(C2SubscribedParamIndicesTuning::AllocShared(0u))
+            .withFields({ C2F(mSubscribedParamIndices, m.values[0]).any(),
+                          C2F(mSubscribedParamIndices, m.values).any() })
+            .withSetter(Setter<C2SubscribedParamIndicesTuning>::NonStrictValuesWithNoDeps)
+            .build());
+
+    /* TODO
+
+    addParameter(
+            DefineParam(mCurrentWorkOrdinal, C2_PARAMKEY_CURRENT_WORK)
+            .withDefault(new C2CurrentWorkTuning())
+            .withFields({ C2F(mCurrentWorkOrdinal, m.timeStamp).any(),
+                          C2F(mCurrentWorkOrdinal, m.frameIndex).any(),
+                          C2F(mCurrentWorkOrdinal, m.customOrdinal).any() })
+            .withSetter(Setter<C2CurrentWorkTuning>::NonStrictValuesWithNoDeps)
+            .build());
+
+    addParameter(
+            DefineParam(mLastInputQueuedWorkOrdinal, C2_PARAMKEY_LAST_INPUT_QUEUED)
+            .withDefault(new C2LastWorkQueuedTuning::input())
+            .withFields({ C2F(mLastInputQueuedWorkOrdinal, m.timeStamp).any(),
+                          C2F(mLastInputQueuedWorkOrdinal, m.frameIndex).any(),
+                          C2F(mLastInputQueuedWorkOrdinal, m.customOrdinal).any() })
+            .withSetter(Setter<C2LastWorkQueuedTuning::input>::NonStrictValuesWithNoDeps)
+            .build());
+
+    addParameter(
+            DefineParam(mLastOutputQueuedWorkOrdinal, C2_PARAMKEY_LAST_OUTPUT_QUEUED)
+            .withDefault(new C2LastWorkQueuedTuning::output())
+            .withFields({ C2F(mLastOutputQueuedWorkOrdinal, m.timeStamp).any(),
+                          C2F(mLastOutputQueuedWorkOrdinal, m.frameIndex).any(),
+                          C2F(mLastOutputQueuedWorkOrdinal, m.customOrdinal).any() })
+            .withSetter(Setter<C2LastWorkQueuedTuning::output>::NonStrictValuesWithNoDeps)
+            .build());
+
+    std::shared_ptr<C2OutOfMemoryTuning> mOutOfMemory;
+
+    std::shared_ptr<C2PortConfigCounterTuning::input> mInputConfigCounter;
+    std::shared_ptr<C2PortConfigCounterTuning::output> mOutputConfigCounter;
+    std::shared_ptr<C2ConfigCounterTuning> mDirectConfigCounter;
+
+    */
+}
+
+void IMXInterface<void>::BaseParams::noInputLatency() {
+    addParameter(
+            DefineParam(mRequestedInputDelay, C2_PARAMKEY_INPUT_DELAY_REQUEST)
+            .withConstValue(new C2PortRequestedDelayTuning::input(0u))
+            .build());
+
+    addParameter(
+            DefineParam(mActualInputDelay, C2_PARAMKEY_INPUT_DELAY)
+            .withConstValue(new C2PortActualDelayTuning::input(0u))
+            .build());
+}
+
+void IMXInterface<void>::BaseParams::noOutputLatency() {
+    addParameter(
+            DefineParam(mRequestedOutputDelay, C2_PARAMKEY_OUTPUT_DELAY_REQUEST)
+            .withConstValue(new C2PortRequestedDelayTuning::output(0u))
+            .build());
+
+    addParameter(
+            DefineParam(mActualOutputDelay, C2_PARAMKEY_OUTPUT_DELAY)
+            .withConstValue(new C2PortActualDelayTuning::output(0u))
+            .build());
+}
+
+void IMXInterface<void>::BaseParams::noPipelineLatency() {
+    addParameter(
+            DefineParam(mRequestedPipelineDelay, C2_PARAMKEY_PIPELINE_DELAY_REQUEST)
+            .withConstValue(new C2RequestedPipelineDelayTuning(0u))
+            .build());
+
+    addParameter(
+            DefineParam(mActualPipelineDelay, C2_PARAMKEY_PIPELINE_DELAY)
+            .withConstValue(new C2ActualPipelineDelayTuning(0u))
+            .build());
+}
+
+void IMXInterface<void>::BaseParams::noPrivateBuffers() {
+    addParameter(
+            DefineParam(mPrivateAllocators, C2_PARAMKEY_PRIVATE_ALLOCATORS)
+            .withConstValue(C2PrivateAllocatorsTuning::AllocShared(0u))
+            .build());
+
+    addParameter(
+            DefineParam(mMaxPrivateBufferCount, C2_PARAMKEY_MAX_PRIVATE_BUFFER_COUNT)
+            .withConstValue(C2MaxPrivateBufferCountTuning::AllocShared(0u))
+            .build());
+
+    addParameter(
+            DefineParam(mPrivatePoolIds, C2_PARAMKEY_PRIVATE_BLOCK_POOLS)
+            .withConstValue(C2PrivateBlockPoolsTuning::AllocShared(0u))
+            .build());
+}
+
+void IMXInterface<void>::BaseParams::noInputReferences() {
+    addParameter(
+            DefineParam(mMaxInputReferenceAge, C2_PARAMKEY_INPUT_MAX_REFERENCE_AGE)
+            .withConstValue(new C2StreamMaxReferenceAgeTuning::input(0u))
+            .build());
+
+    addParameter(
+            DefineParam(mMaxInputReferenceCount, C2_PARAMKEY_INPUT_MAX_REFERENCE_COUNT)
+            .withConstValue(new C2StreamMaxReferenceCountTuning::input(0u))
+            .build());
+}
+
+void IMXInterface<void>::BaseParams::noOutputReferences() {
+    addParameter(
+            DefineParam(mMaxOutputReferenceAge, C2_PARAMKEY_OUTPUT_MAX_REFERENCE_AGE)
+            .withConstValue(new C2StreamMaxReferenceAgeTuning::output(0u))
+            .build());
+
+    addParameter(
+            DefineParam(mMaxOutputReferenceCount, C2_PARAMKEY_OUTPUT_MAX_REFERENCE_COUNT)
+            .withConstValue(new C2StreamMaxReferenceCountTuning::output(0u))
+            .build());
+}
+
+void IMXInterface<void>::BaseParams::noTimeStretch() {
+    addParameter(
+            DefineParam(mTimeStretch, C2_PARAMKEY_TIME_STRETCH)
+            .withConstValue(new C2ComponentTimeStretchTuning(1.f))
+            .build());
+}
+
+/*
+    Clients need to handle the following base params due to custom dependency.
+
+    std::shared_ptr<C2ApiLevelSetting> mApiLevel;
+    std::shared_ptr<C2ApiFeaturesSetting> mApiFeatures;
+    std::shared_ptr<C2ComponentAttributesSetting> mAttrib;
+
+    std::shared_ptr<C2PortSuggestedBufferCountTuning::input> mSuggestedInputBufferCount;
+    std::shared_ptr<C2PortSuggestedBufferCountTuning::output> mSuggestedOutputBufferCount;
+
+    std::shared_ptr<C2TrippedTuning> mTripped;
+
+*/
+
+} // namespace android
+
diff --git a/codec2/base/IMXUtils.cpp b/codec2/base/IMXUtils.cpp
new file mode 100644
index 0000000..a335146
--- /dev/null
+++ b/codec2/base/IMXUtils.cpp
@@ -0,0 +1,109 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <graphics.h>
+#include <media/stagefright/MediaDefs.h>
+#include "Imx_ext.h"
+#include "IMXUtils.h"
+#include "graphics_ext.h"
+
+
+namespace android {
+
+
+typedef struct {
+    const char* name;
+    const char* mime;
+} NameMime;
+
+static NameMime NameMimeMap[] = {
+        {"c2.imx.avc.decoder", MEDIA_MIMETYPE_VIDEO_AVC},
+        {"c2.imx.avc.encoder", MEDIA_MIMETYPE_VIDEO_AVC},
+        {"c2.imx.hevc.decoder", MEDIA_MIMETYPE_VIDEO_HEVC},
+        {"c2.imx.hevc.encoder", MEDIA_MIMETYPE_VIDEO_HEVC},
+        {"c2.imx.vp8.decoder", MEDIA_MIMETYPE_VIDEO_VP8},
+        {"c2.imx.vp8.encoder", MEDIA_MIMETYPE_VIDEO_VP8},
+        {"c2.imx.vp9.decoder", MEDIA_MIMETYPE_VIDEO_VP9},
+        {"c2.imx.mpeg2.decoder", MEDIA_MIMETYPE_VIDEO_MPEG2},
+        {"c2.imx.mpeg4.decoder", MEDIA_MIMETYPE_VIDEO_MPEG4},
+        {"c2.imx.h263.decoder", MEDIA_MIMETYPE_VIDEO_H263},
+        {"c2.imx.mjpeg.decoder", MEDIA_MIMETYPE_VIDEO_MJPEG},
+        {"c2.imx.xvid.decoder", MEDIA_MIMETYPE_VIDEO_XVID},
+        {"c2.imx.vc1.decoder", MEDIA_MIMETYPE_VIDEO_VC1},
+        {"c2.imx.rv.decoder", MEDIA_MIMETYPE_VIDEO_REAL},
+        {"c2.imx.sorenson.decoder", MEDIA_MIMETYPE_VIDEO_SORENSON},
+};
+
+const char* Name2MimeType(const char* name) {
+    int i;
+    for (i = 0; i < sizeof(NameMimeMap)/sizeof(NameMime); i++) {
+        if (strcmp(NameMimeMap[i].name, name) == 0) {
+            return NameMimeMap[i].mime;
+        }
+    }
+
+    return nullptr;
+}
+
+int pxlfmt2bpp(int pxlfmt) {
+    int bpp; // bit per pixel
+
+    switch(pxlfmt) {
+        case HAL_PIXEL_FORMAT_YCbCr_420_P:
+        case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+        case HAL_PIXEL_FORMAT_YCBCR_420_888:
+        case HAL_PIXEL_FORMAT_NV12_TILED:
+        case HAL_PIXEL_FORMAT_YV12:
+          bpp = 12;
+          break;
+        case HAL_PIXEL_FORMAT_P010:
+        case HAL_PIXEL_FORMAT_P010_TILED:
+        case HAL_PIXEL_FORMAT_P010_TILED_COMPRESSED:
+          bpp = 15;
+          break;
+        case HAL_PIXEL_FORMAT_RGB_565:
+        case HAL_PIXEL_FORMAT_YCbCr_422_P:
+        case HAL_PIXEL_FORMAT_YCbCr_422_SP:
+        case HAL_PIXEL_FORMAT_YCBCR_422_I:
+            bpp = 16;
+            break;
+
+        case HAL_PIXEL_FORMAT_RGBA_8888:
+        case HAL_PIXEL_FORMAT_RGBX_8888:
+        case HAL_PIXEL_FORMAT_BGRA_8888:
+            bpp = 32;
+            break;
+        default:
+          bpp = 0;
+          break;
+    }
+    return bpp;
+}
+
+int GetSocId(char* socId, int size) {
+    int ret = 1; // default set failed;
+
+    if ((socId == NULL) || (size < 10))
+        return false;
+
+    memset(socId, 0, size);
+
+    FILE *f = fopen("/sys/devices/soc0/soc_id", "r");
+    if (f != NULL) {
+        if (fgets(socId, size, f) != NULL) {
+            ret = 0; // success
+        }
+        fclose(f);
+    }
+
+    return ret;
+}
+
+} // namespace android
diff --git a/codec2/base/include/IMXC2ComponentBase.h b/codec2/base/include/IMXC2ComponentBase.h
new file mode 100755
index 0000000..d9531ff
--- /dev/null
+++ b/codec2/base/include/IMXC2ComponentBase.h
@@ -0,0 +1,251 @@
+/*
+ * Copyright (C) 2017 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef IMX_C2_COMPONENT_BASE_H_
+#define IMX_C2_COMPONENT_BASE_H_
+
+#include <list>
+#include <deque>
+#include <unordered_map>
+
+#include <C2Component.h>
+
+#include <media/stagefright/foundation/AHandler.h>
+#include <media/stagefright/foundation/ALooper.h>
+#include <media/stagefright/foundation/Mutexed.h>
+
+namespace android {
+
+
+class IMXC2ComponentBase
+        : public C2Component, public std::enable_shared_from_this<IMXC2ComponentBase> {
+public:
+    explicit IMXC2ComponentBase(
+            const std::shared_ptr<C2ComponentInterface> &intf);
+    virtual ~IMXC2ComponentBase();
+
+    // C2Component
+    // From C2Component
+    virtual c2_status_t setListener_vb(
+            const std::shared_ptr<Listener> &listener, c2_blocking_t mayBlock) override;
+    virtual c2_status_t queue_nb(std::list<std::unique_ptr<C2Work>>* const items) override;
+    virtual c2_status_t announce_nb(const std::vector<C2WorkOutline> &items) override;
+    virtual c2_status_t flush_sm(
+            flush_mode_t mode, std::list<std::unique_ptr<C2Work>>* const flushedWork) override;
+    virtual c2_status_t drain_nb(drain_mode_t mode) override;
+    virtual c2_status_t start() override;
+    virtual c2_status_t stop() override;
+    virtual c2_status_t reset() override;
+    virtual c2_status_t release() override;
+    virtual std::shared_ptr<C2ComponentInterface> intf() override;
+
+    // for handler
+    bool processQueue();
+
+protected:
+    /**
+     * Initialize internal states of the component according to the config set
+     * in the interface.
+     *
+     * This method is called during start(), but only at the first invocation or
+     * after reset().
+     */
+    virtual c2_status_t onInit() = 0;
+
+    /**
+     * Stop the component.
+     */
+    virtual c2_status_t onStop() = 0;
+
+    /**
+     * Reset the component.
+     */
+    virtual void onReset() = 0;
+
+    /**
+     * Release the component.
+     */
+    virtual void onRelease() = 0;
+
+    /**
+     * Flush the component.
+     */
+    virtual c2_status_t onFlush_sm() = 0;
+
+    /**
+     * Process the given work and finish pending work using finish().
+     *
+     * \param[in,out]   work    the work to process
+     * \param[in]       pool    the pool to use for allocating output blocks.
+     */
+    virtual void processWork(const std::unique_ptr<C2Work> &work) = 0;
+
+    /**
+     * Drain the component and finish pending work using finish().
+     *
+     * \param[in]   drainMode   mode of drain.
+     * \param[in]   pool        the pool to use for allocating output blocks.
+     *
+     * etval C2_OK            The component has drained all pending output
+     *                          work.
+     * etval C2_OMITTED       Unsupported mode (e.g. DRAIN_CHAIN)
+     */
+    virtual c2_status_t drainInternal(uint32_t drainMode) = 0;
+
+    // for derived classes
+    /**
+     * Finish pending work.
+     *
+     * This method will retrieve the pending work according to |frameIndex| and
+     * feed the work into |fillWork| function. |fillWork| must be
+     * "non-blocking". Once |fillWork| returns the filled work will be returned
+     * to the client.
+     *
+     * \param[in]   timestamp     the timestamp of the pending work
+     * \param[in]   fillWork      the function to fill the retrieved work.
+     */
+    c2_status_t finish(uint64_t timestamp, std::function<void(const std::unique_ptr<C2Work> &)> fillWork);
+
+    c2_status_t finishWithException(bool eos, bool force);
+
+    C2Work* getPendingWorkByTimestamp(uint64_t timestamp);
+
+    C2Work* getPendingWorkByFrameIndex(uint64_t frameIndex);
+
+    c2_status_t skipOnePendingWork(uint64_t frameIndex);
+
+    std::shared_ptr<C2Buffer> createLinearBuffer(
+            const std::shared_ptr<C2LinearBlock> &block);
+
+    std::shared_ptr<C2Buffer> createLinearBuffer(
+            const std::shared_ptr<C2LinearBlock> &block, size_t offset, size_t size);
+
+    std::shared_ptr<C2Buffer> createGraphicBuffer(
+            const std::shared_ptr<C2GraphicBlock> &block);
+
+    std::shared_ptr<C2Buffer> createGraphicBuffer(
+            const std::shared_ptr<C2GraphicBlock> &block,
+            const C2Rect &crop);
+
+    static constexpr uint32_t NO_DRAIN = ~0u;
+
+    C2ReadView mDummyReadView;
+
+    std::shared_ptr<C2BlockPool> mOutputBlockPool;
+
+    uint64_t nCurFrameIndex;
+    uint64_t nUsedFrameIndex;
+    bool bRecieveOutputEos;
+
+private:
+    c2_status_t initOutputBlockPool();
+
+
+    const std::shared_ptr<C2ComponentInterface> mIntf;
+
+    class WorkHandler : public AHandler {
+    public:
+        enum {
+            kWhatProcess,
+            kWhatInit,
+            kWhatStart,
+            kWhatStop,
+            kWhatReset,
+            kWhatRelease,
+        };
+
+        WorkHandler();
+        ~WorkHandler() override = default;
+
+        void setComponent(const std::shared_ptr<IMXC2ComponentBase> &thiz);
+
+    protected:
+        void onMessageReceived(const sp<AMessage> &msg) override;
+
+    private:
+        std::weak_ptr<IMXC2ComponentBase> mThiz;
+        bool mRunning;
+    };
+
+    enum {
+        UNINITIALIZED,
+        STOPPED,
+        RUNNING,
+    };
+
+    struct ExecState {
+        ExecState() : mState(UNINITIALIZED) {}
+
+        int mState;
+        std::shared_ptr<C2Component::Listener> mListener;
+    };
+    Mutexed<ExecState> mExecState;
+
+    sp<ALooper> mLooper;
+    sp<WorkHandler> mHandler;
+
+    class WorkQueue {
+    public:
+        inline WorkQueue() : mFlush(false), mGeneration(0ul) {}
+
+        inline uint64_t generation() const { return mGeneration; }
+        inline void incGeneration() { ++mGeneration; mFlush = true; }
+
+        std::unique_ptr<C2Work> pop_front();
+        void push_back(std::unique_ptr<C2Work> work);
+        bool empty() const;
+        uint32_t drainMode() const;
+        void markDrain(uint32_t drainMode);
+        inline bool popPendingFlush() {
+            bool flush = mFlush;
+            mFlush = false;
+            return flush;
+        }
+        void clear();
+
+    private:
+        struct Entry {
+            std::unique_ptr<C2Work> work;
+            uint32_t drainMode;
+        };
+
+        bool mFlush;
+        uint64_t mGeneration;
+        std::list<Entry> mQueue;
+    };
+    Mutexed<WorkQueue> mWorkQueue;
+
+    typedef std::deque<std::unique_ptr<C2Work>> PendingWork;
+
+    //typedef std::unordered_map<uint64_t, std::unique_ptr<C2Work>> PendingWork;
+    Mutexed<PendingWork> mPendingWork;
+
+    //std::shared_ptr<C2BlockPool> mOutputBlockPool;
+
+    IMXC2ComponentBase() = delete;
+};
+
+}  // namespace android
+
+#endif  // IMX_C2_COMPONENT_BASE_H_
diff --git a/codec2/base/include/IMXC2Interface.h b/codec2/base/include/IMXC2Interface.h
new file mode 100755
index 0000000..8ad400b
--- /dev/null
+++ b/codec2/base/include/IMXC2Interface.h
@@ -0,0 +1,229 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef IMX_C2_INTERFACE_H_
+#define IMX_C2_INTERFACE_H_
+
+#include <C2Component.h>
+#include <C2Config.h>
+#include <util/C2InterfaceHelper.h>
+
+namespace android {
+
+/**
+ * Wrap a common interface object (such as Codec2Client::Interface, or C2InterfaceHelper into
+ * a C2ComponentInterface.
+ *
+ * \param T common interface type
+ */
+template <typename T>
+class IMXC2Interface : public C2ComponentInterface {
+public:
+    IMXC2Interface(C2String name, c2_node_id_t id, const std::shared_ptr<T> &impl)
+        : mComponentName(name),
+          mId(id),
+          mImpl(impl) {
+    }
+
+    ~IMXC2Interface() override = default;
+
+    // From C2ComponentInterface
+    C2String getName() const override { return mComponentName; }
+    c2_node_id_t getId() const override { return mId; }
+    c2_status_t query_vb(
+            const std::vector<C2Param*> &stackParams,
+            const std::vector<C2Param::Index> &heapParamIndices,
+            c2_blocking_t mayBlock,
+            std::vector<std::unique_ptr<C2Param>>* const heapParams) const override {
+        return mImpl->query(stackParams, heapParamIndices, mayBlock, heapParams);
+    }
+    c2_status_t config_vb(
+            const std::vector<C2Param*> &params,
+            c2_blocking_t mayBlock,
+            std::vector<std::unique_ptr<C2SettingResult>>* const failures) override {
+        return mImpl->config(params, mayBlock, failures);
+    }
+    c2_status_t createTunnel_sm(c2_node_id_t) override { return C2_OMITTED; }
+    c2_status_t releaseTunnel_sm(c2_node_id_t) override { return C2_OMITTED; }
+    c2_status_t querySupportedParams_nb(
+            std::vector<std::shared_ptr<C2ParamDescriptor>> * const params) const override {
+        return mImpl->querySupportedParams(params);
+    }
+    c2_status_t querySupportedValues_vb(
+            std::vector<C2FieldSupportedValuesQuery> &fields,
+            c2_blocking_t mayBlock) const override {
+        return mImpl->querySupportedValues(fields, mayBlock);
+    }
+
+private:
+    C2String mComponentName;
+    const c2_node_id_t mId;
+    const std::shared_ptr<T> mImpl;
+};
+
+/**
+ * Utility classes for common interfaces.
+ */
+template<>
+class IMXC2Interface<void> {
+public:
+    /**
+     * Base Codec 2.0 parameters required for all components.
+     */
+    struct BaseParams : C2InterfaceHelper {
+        explicit BaseParams(
+                const std::shared_ptr<C2ReflectorHelper> &helper,
+                C2String name,
+                C2Component::kind_t kind,
+                C2Component::domain_t domain,
+                C2String mediaType,
+                std::vector<C2String> aliases = std::vector<C2String>());
+
+        /// Marks that this component has no input latency. Otherwise, component must
+        /// add support for C2PortRequestedDelayTuning::input and C2PortActualDelayTuning::input.
+        void noInputLatency();
+
+        /// Marks that this component has no output latency. Otherwise, component must
+        /// add support for C2PortRequestedDelayTuning::output and C2PortActualDelayTuning::output.
+        void noOutputLatency();
+
+        /// Marks that this component has no pipeline latency. Otherwise, component must
+        /// add support for C2RequestedPipelineDelayTuning and C2ActualPipelineDelayTuning.
+        void noPipelineLatency();
+
+        /// Marks that this component has no need for private buffers. Otherwise, component must
+        /// add support for C2MaxPrivateBufferCountTuning, C2PrivateAllocatorsTuning and
+        /// C2PrivateBlockPoolsTuning.
+        void noPrivateBuffers();
+
+        /// Marks that this component holds no references to input buffers. Otherwise, component
+        /// must add support for C2StreamMaxReferenceAgeTuning::input and
+        /// C2StreamMaxReferenceCountTuning::input.
+        void noInputReferences();
+
+        /// Marks that this component holds no references to output buffers. Otherwise, component
+        /// must add support for C2StreamMaxReferenceAgeTuning::output and
+        /// C2StreamMaxReferenceCountTuning::output.
+        void noOutputReferences();
+
+        /// Marks that this component does not stretch time. Otherwise, component
+        /// must add support for C2ComponentTimeStretchTuning.
+        void noTimeStretch();
+
+        std::shared_ptr<C2ApiLevelSetting> mApiLevel;
+        std::shared_ptr<C2ApiFeaturesSetting> mApiFeatures;
+
+        std::shared_ptr<C2PlatformLevelSetting> mPlatformLevel;
+        std::shared_ptr<C2PlatformFeaturesSetting> mPlatformFeatures;
+
+        std::shared_ptr<C2ComponentNameSetting> mName;
+        std::shared_ptr<C2ComponentAliasesSetting> mAliases;
+        std::shared_ptr<C2ComponentKindSetting> mKind;
+        std::shared_ptr<C2ComponentDomainSetting> mDomain;
+        std::shared_ptr<C2ComponentAttributesSetting> mAttrib;
+        std::shared_ptr<C2ComponentTimeStretchTuning> mTimeStretch;
+
+        std::shared_ptr<C2PortMediaTypeSetting::input> mInputMediaType;
+        std::shared_ptr<C2PortMediaTypeSetting::output> mOutputMediaType;
+        std::shared_ptr<C2StreamBufferTypeSetting::input> mInputFormat;
+        std::shared_ptr<C2StreamBufferTypeSetting::output> mOutputFormat;
+
+        std::shared_ptr<C2PortRequestedDelayTuning::input> mRequestedInputDelay;
+        std::shared_ptr<C2PortRequestedDelayTuning::output> mRequestedOutputDelay;
+        std::shared_ptr<C2RequestedPipelineDelayTuning> mRequestedPipelineDelay;
+
+        std::shared_ptr<C2PortActualDelayTuning::input> mActualInputDelay;
+        std::shared_ptr<C2PortActualDelayTuning::output> mActualOutputDelay;
+        std::shared_ptr<C2ActualPipelineDelayTuning> mActualPipelineDelay;
+
+        std::shared_ptr<C2StreamMaxReferenceAgeTuning::input> mMaxInputReferenceAge;
+        std::shared_ptr<C2StreamMaxReferenceCountTuning::input> mMaxInputReferenceCount;
+        std::shared_ptr<C2StreamMaxReferenceAgeTuning::output> mMaxOutputReferenceAge;
+        std::shared_ptr<C2StreamMaxReferenceCountTuning::output> mMaxOutputReferenceCount;
+        std::shared_ptr<C2MaxPrivateBufferCountTuning> mMaxPrivateBufferCount;
+
+        std::shared_ptr<C2PortStreamCountTuning::input> mInputStreamCount;
+        std::shared_ptr<C2PortStreamCountTuning::output> mOutputStreamCount;
+
+        std::shared_ptr<C2SubscribedParamIndicesTuning> mSubscribedParamIndices;
+        std::shared_ptr<C2PortSuggestedBufferCountTuning::input> mSuggestedInputBufferCount;
+        std::shared_ptr<C2PortSuggestedBufferCountTuning::output> mSuggestedOutputBufferCount;
+
+        std::shared_ptr<C2CurrentWorkTuning> mCurrentWorkOrdinal;
+        std::shared_ptr<C2LastWorkQueuedTuning::input> mLastInputQueuedWorkOrdinal;
+        std::shared_ptr<C2LastWorkQueuedTuning::output> mLastOutputQueuedWorkOrdinal;
+
+        std::shared_ptr<C2PortAllocatorsTuning::input> mInputAllocators;
+        std::shared_ptr<C2PortAllocatorsTuning::output> mOutputAllocators;
+        std::shared_ptr<C2PrivateAllocatorsTuning> mPrivateAllocators;
+        std::shared_ptr<C2PortBlockPoolsTuning::output> mOutputPoolIds;
+        std::shared_ptr<C2PrivateBlockPoolsTuning> mPrivatePoolIds;
+
+        std::shared_ptr<C2TrippedTuning> mTripped;
+        std::shared_ptr<C2OutOfMemoryTuning> mOutOfMemory;
+
+        std::shared_ptr<C2PortConfigCounterTuning::input> mInputConfigCounter;
+        std::shared_ptr<C2PortConfigCounterTuning::output> mOutputConfigCounter;
+        std::shared_ptr<C2ConfigCounterTuning> mDirectConfigCounter;
+    };
+};
+
+template<typename T>
+using IMXInterface = IMXC2Interface<T>;
+
+template<typename T, typename ...Args>
+std::shared_ptr<T> AllocSharedString(const Args(&... args), const char *str) {
+    size_t len = strlen(str) + 1;
+    std::shared_ptr<T> ret = T::AllocShared(len, args...);
+    strcpy(ret->m.value, str);
+    return ret;
+}
+
+template<typename T, typename ...Args>
+std::shared_ptr<T> AllocSharedString(const Args(&... args), const std::string &str) {
+    std::shared_ptr<T> ret = T::AllocShared(str.length() + 1, args...);
+    strcpy(ret->m.value, str.c_str());
+    return ret;
+}
+
+template <typename T>
+struct Setter {
+    typedef typename std::remove_reference<T>::type type;
+
+    static C2R NonStrictValueWithNoDeps(
+            bool mayBlock, C2InterfaceHelper::C2P<type> &me) {
+        (void)mayBlock;
+        return me.F(me.v.value).validatePossible(me.v.value);
+    }
+
+    static C2R NonStrictValuesWithNoDeps(
+            bool mayBlock, C2InterfaceHelper::C2P<type> &me) {
+        (void)mayBlock;
+        C2R res = C2R::Ok();
+        for (size_t ix = 0; ix < me.v.flexCount(); ++ix) {
+            res.plus(me.F(me.v.m.values[ix]).validatePossible(me.v.m.values[ix]));
+        }
+        return res;
+    }
+
+    static C2R StrictValueWithNoDeps(
+            bool mayBlock,
+            const C2InterfaceHelper::C2P<type> &old,
+            C2InterfaceHelper::C2P<type> &me) {
+        (void)mayBlock;
+        if (!me.F(me.v.value).supportsNow(me.v.value)) {
+            me.set().value = old.v.value;
+        }
+        return me.F(me.v.value).validatePossible(me.v.value);
+    }
+};
+
+}  // namespace android
+
+#endif  // IMX_C2_INTERFACE_H_
+
diff --git a/codec2/base/include/IMXUtils.h b/codec2/base/include/IMXUtils.h
new file mode 100755
index 0000000..2009568
--- /dev/null
+++ b/codec2/base/include/IMXUtils.h
@@ -0,0 +1,21 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef IMX_UUTILS_H_
+#define IMX_UUTILS_H_
+
+
+namespace android {
+
+const char* Name2MimeType(const char* name);
+int pxlfmt2bpp(int pxlfmt);
+
+int GetSocId(char* socId, int size);
+}
+
+#endif // IMX_UUTILS_H_
diff --git a/codec2/doc/Audio decoder class.png b/codec2/doc/Audio decoder class.png
new file mode 100755
index 0000000..8914c57
Binary files /dev/null and b/codec2/doc/Audio decoder class.png differ
diff --git a/codec2/doc/Component store.jpg b/codec2/doc/Component store.jpg
new file mode 100755
index 0000000..041a93d
Binary files /dev/null and b/codec2/doc/Component store.jpg differ
diff --git a/codec2/doc/Video decoder class.jpg b/codec2/doc/Video decoder class.jpg
new file mode 100755
index 0000000..a660e32
Binary files /dev/null and b/codec2/doc/Video decoder class.jpg differ
diff --git a/codec2/doc/video encoder class.png b/codec2/doc/video encoder class.png
new file mode 100755
index 0000000..fd167f6
Binary files /dev/null and b/codec2/doc/video encoder class.png differ
diff --git a/codec2/include/C2Config_imx.h b/codec2/include/C2Config_imx.h
new file mode 100755
index 0000000..df196de
--- /dev/null
+++ b/codec2/include/C2Config_imx.h
@@ -0,0 +1,47 @@
+/**
+ *  Copyright 2019,2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef C2CONFIG_IMX_H
+#define C2CONFIG_IMX_H
+
+#include <C2Config.h>
+
+enum imx_aac_packaging_t : uint32_t {
+    VENDOR_START = 10,
+    AAC_PACKAGING_ADIF,
+};
+
+constexpr imx_aac_packaging_t C2AacStreamFormatAdif = AAC_PACKAGING_ADIF;
+
+
+
+#define C2_PARAM_INDEX_VENDOR_START 0x8000 ///< vendor-defined parameters
+
+#define kParamIndexVendorSubFormat C2_PARAM_INDEX_VENDOR_START
+#define kParamIndexAudioBlockAlgin (C2_PARAM_INDEX_VENDOR_START + 1)
+#define kParamIndexBitsPerFrame (C2_PARAM_INDEX_VENDOR_START + 2)
+#define kParamIndexVendorHalPixelFormat (C2_PARAM_INDEX_VENDOR_START + 3)
+#define kParamIndexBitsPerSample (C2_PARAM_INDEX_VENDOR_START + 4)
+
+typedef C2StreamParam<C2Info, C2Uint32Value, kParamIndexVendorSubFormat> C2StreamVendorSubFormat;
+constexpr char C2_PARAMKEY_VENDOR_SUB_FORMAT[] = "vendor.sub-format";
+
+typedef C2StreamParam<C2Info, C2Uint32Value, kParamIndexVendorHalPixelFormat> C2StreamVendorHalPixelFormat;
+constexpr char C2_PARAMKEY_VENDOR_HAL_PIXEL_FORMAT[] = "vendor.hal-pixel-format";
+
+typedef C2StreamParam<C2Info, C2Uint32Value, kParamIndexAudioBlockAlgin> C2StreamAudioBlockAlign;
+constexpr char C2_PARAMKEY_AUDIO_BLOCK_ALIGN[] = "vendor.audio-block-align";
+
+typedef C2StreamParam<C2Info, C2Uint32Value, kParamIndexBitsPerFrame> C2StreamBitsPerFrame;
+constexpr char C2_PARAMKEY_BITS_PER_FRAME[] = "vendor.bits-per-frame";
+
+typedef C2StreamParam<C2Info, C2Uint32Value, kParamIndexBitsPerSample> C2StreamBitsPerSample;
+constexpr char C2_PARAMKEY_BITS_PER_SAMPLE[] = "vendor.bits-per-sample";
+
+#endif
+
diff --git a/codec2/include/C2_imx.h b/codec2/include/C2_imx.h
new file mode 100644
index 0000000..cbae91e
--- /dev/null
+++ b/codec2/include/C2_imx.h
@@ -0,0 +1,38 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef IMX_C2_H
+#define IMX_C2_H
+
+#include <C2Component.h>
+
+#include <memory>
+
+namespace android {
+
+enum decode_mode_t : uint32_t {
+    DEC_STREAM_MODE,
+    DEC_FILE_MODE,
+};
+
+#define LOGV(FMT, ...) ALOGV("%s " FMT, __FUNCTION__, ##__VA_ARGS__)
+#define LOGD(FMT, ...) ALOGD("%s " FMT, __FUNCTION__, ##__VA_ARGS__)
+#define LOGE(FMT, ...) ALOGE("%s " FMT, __FUNCTION__, ##__VA_ARGS__)
+#define LOGI(FMT, ...) ALOGI("%s " FMT, __FUNCTION__, ##__VA_ARGS__)
+#define LOGW(FMT, ...) ALOGW("%s " FMT, __FUNCTION__, ##__VA_ARGS__)
+
+std::shared_ptr<C2ComponentStore> GetImxC2Store();
+
+//add sync frame flag for C2FrameData::flags
+#define FLAG_SYNC_FRAME (1 << 4)
+#define FLAG_INTERLACED_FRAME (1 << 5)
+#define FLAG_RES_CHANGE (1 << 6)
+}
+
+#endif
+
diff --git a/codec2/process/Android.bp b/codec2/process/Android.bp
new file mode 100644
index 0000000..f6c6305
--- /dev/null
+++ b/codec2/process/Android.bp
@@ -0,0 +1,25 @@
+imx_c2_process_defaults {
+    name: "imx_c2_process_default",
+}
+
+
+bootstrap_go_package {
+    name: "soong-imx_process",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/process",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "imx_process.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+subdirs = [
+    "*",
+]
\ No newline at end of file
diff --git a/codec2/process/common/Android.bp b/codec2/process/common/Android.bp
new file mode 100644
index 0000000..8c1e997
--- /dev/null
+++ b/codec2/process/common/Android.bp
@@ -0,0 +1,55 @@
+cc_library_shared {
+    name: "lib_imx_c2_process",
+
+    soc_specific: true,
+    srcs: [
+        "ProcessBase.cpp",
+    ],
+
+    header_libs: [
+        "libcodec2_headers",
+        "media_plugin_headers",
+    ],
+
+    include_dirs: [
+        "hardware/libhardware/include",
+        "frameworks/av",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp/imx_android_mm/codec2/tsm",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+        "vendor/nxp/fsl-proprietary/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+		"vendor/nxp/imx_android_mm/codec2/process",
+	],
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "libion",
+        "lib_imx_c2_componentbase",
+        "libcodec2_vndk",
+        "lib_c2_imx_store",
+    ],
+
+    whole_static_libs: ["libionallocator"],
+
+    sanitize: {
+        cfi: true,
+        misc_undefined: [
+            "unsigned-integer-overflow",
+            "signed-integer-overflow",
+        ],
+        diag: {
+            cfi: true,
+        },
+    },
+
+//    compile_multilib: "32",
+}
+
diff --git a/codec2/process/common/ProcessBase.cpp b/codec2/process/common/ProcessBase.cpp
new file mode 100755
index 0000000..d806d90
--- /dev/null
+++ b/codec2/process/common/ProcessBase.cpp
@@ -0,0 +1,796 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "ProcessBase"
+
+#include <utils/Log.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <inttypes.h>
+#include <sys/mman.h>
+#include <cutils/properties.h>
+
+#include <C2Config.h>
+#include <C2Debug.h>
+#include <C2PlatformSupport.h>
+
+#include "graphics_ext.h"
+#include "Memory.h"
+#include "ProcessBase.h"
+#include "IonAllocator.h"
+
+#define PROCESS_BASE_API_TRACE
+#ifdef PROCESS_BASE_API_TRACE
+#define PP_BASE_API_TRACE ALOGV
+#else
+#define PP_BASE_API_TRACE(...)
+#endif
+
+#define PROCESS_BASE_DEBUG
+#ifdef PROCESS_BASE_DEBUG
+#define PP_BASE_LOG ALOGV
+#else
+#define PP_BASE_LOG(...)
+#endif
+
+#define PP_BASE_ERR_LOG ALOGE
+
+#if defined(__LP64__)
+#define G2DENGINE "/vendor/lib64/libg2d"
+#else
+#define G2DENGINE "/vendor/lib/libg2d"
+#endif
+
+namespace android {
+
+static void Reply(const sp<AMessage> &msg, int32_t *err = nullptr) {
+    sp<AReplyToken> replyId;
+    CHECK(msg->senderAwaitsResponse(&replyId));
+    sp<AMessage> reply = new AMessage;
+    if (err) {
+        reply->setInt32("err", *err);
+    }
+    reply->postReply(replyId);
+}
+
+ProcessBase::PPInputBuffer::PPInputBuffer(
+                    unsigned long phys,
+                    int id,
+                    uint32_t size,
+                    uint64_t ts,
+                    bool eos)
+    : physAddr(phys),
+      id(id),
+      size(size),
+      timestamp(ts),
+      eos(eos){
+}
+
+ProcessBase::ProcessBase()
+    : mLooper(new ALooper),
+      mClient(nullptr),
+      bInputEos(false){
+
+    mLooper->setName("ProcessBase");
+    mLooper->start(false, false, ANDROID_PRIORITY_VIDEO);
+
+    memset(&sInFormat, 0, sizeof(PROCESSBASE_FORMAT));
+    memset(&sOutFormat, 0, sizeof(PROCESSBASE_FORMAT));
+    memset(&sInMemInfo, 0, sizeof(PROCESS_MEM_INFO));
+    memset(&sOutMemInfo, 0, sizeof(PROCESS_MEM_INFO));
+    mState = UNINITIALIZED;
+    mAsync = false;
+    bResChanged = false;
+    nInputCnt = 0;
+    nOutputCnt = 0;
+}
+
+ProcessBase::~ProcessBase() {
+}
+
+bool ProcessBase::getDefaultG2DLib(char *libName, int size) {
+    char value[PROPERTY_VALUE_MAX];
+
+    if((libName == NULL)||(size < strlen(G2DENGINE) + strlen(".so")))
+        return false;
+
+    memset(libName, 0, size);
+    property_get("vendor.imx.default-g2d", value, "");
+    if(strcmp(value, "") == 0) {
+        PP_BASE_ERR_LOG("No g2d lib available to be used!");
+        return false;
+    } else {
+        strncpy(libName, G2DENGINE, strlen(G2DENGINE));
+        strcat(libName, "-");
+        strcat(libName, value);
+        strcat(libName, ".so");
+    }
+    PP_BASE_LOG("Default g2d lib: %s", libName);
+    return true;
+}
+
+status_t ProcessBase::init(Client* client, const std::shared_ptr<C2BlockPool>& pool) {
+    if (client == nullptr || pool.get() == nullptr) {
+        PP_BASE_ERR_LOG("init get nullptr ! 
");
+        return BAD_VALUE;
+    }
+
+    mBlockPool = pool;
+    mClient = client;
+    (void)mLooper->registerHandler(this);
+    nInputCnt = 0;
+    nOutputCnt = 0;
+
+    sp<AMessage> reply;
+    (new AMessage(kWhatInit, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+
+
+    if (err == OK)
+        mState = RUNNING;
+
+    return err;
+}
+
+status_t ProcessBase::setConfig(ProcessConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    status_t ret = OK;
+
+    switch (index) {
+        case PROCESS_CONFIG_INPUT_FORMAT: {
+            memcpy(&sInFormat, pConfig, sizeof(PROCESSBASE_FORMAT));
+            break;
+        }
+
+        default: {
+            ret = DoSetConfig(index, pConfig);
+            break;
+        }
+    }
+    return ret;
+}
+
+status_t ProcessBase::getConfig(ProcessConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    status_t ret = OK;
+
+    switch (index) {
+        case PROCESS_CONFIG_OUTPUT_FORMAT: {
+            memcpy(pConfig, &sOutFormat, sizeof(PROCESSBASE_FORMAT));
+            break;
+        }
+        default: {
+            ret = DoGetConfig(index, pConfig);
+            break;
+        }
+    }
+    return ret;
+}
+
+status_t ProcessBase::destroy() {
+    sp<AMessage> reply;
+    (new AMessage(kWhatDestroy, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t ProcessBase::queueInput(void* pVirt, void* pPhys, uint32_t size, uint64_t timestamp,
+                                        uint32_t flags, int fd, int id) {
+    Mutex::Autolock autoLock(mLock);
+    bool empty = mInputQueue.empty();
+    // if eos buffer is empty, notify eos right now, otherwise process data then notify eos.
+    bInputEos = ((flags & C2FrameData::FLAG_END_OF_STREAM) != 0);
+
+    int index;
+    ProcessFrameSet(&sInMemInfo, (unsigned long)pPhys, id, fd, flags, &index);
+    mInputQueue.push(index);
+    mTimestampQueue.push(timestamp);
+    ALOGV("mTimestampQueue.push %lld mInputQueue index=%d,fd=%d,size=%zu,id=%d",
+        (long long)timestamp,index,fd,mInputQueue.size(),id);
+    nInputCnt ++;
+
+    if(mState != RUNNING)
+        mState = RUNNING;
+
+    if(empty || bInputEos)
+        (new AMessage(kWhatProcess, this))->post();
+
+    return OK;
+}
+
+status_t ProcessBase::flush() {
+    sp<AMessage> reply;
+    (new AMessage(kWhatFlush, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t ProcessBase::stop() {
+    sp<AMessage> reply;
+    (new AMessage(kWhatStop, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+status_t ProcessBase::start() {
+    nInputCnt = 0;
+    nOutputCnt = 0;
+
+    sp<AMessage> reply;
+    (new AMessage(kWhatStart, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+status_t ProcessBase::reset() {
+    return OK;
+}
+
+status_t ProcessBase::importOutputBuffers() {
+    return OK;
+}
+
+status_t ProcessBase::outputBufferReturned(int outputId) {
+    sp<AMessage> msg = (new AMessage(kWhatReturnOutBuf, this));
+    msg->setInt32("output-id", outputId);
+    msg->post();
+    return OK;
+}
+
+ProcessBlockInfo* ProcessBase::getProcessBlockById(int blockId) {
+    if (blockId < 0) {
+        PP_BASE_ERR_LOG("%s line %d: invalid fd=%d", __FUNCTION__, __LINE__, blockId);
+        return nullptr;
+    }
+    auto blockIter = std::find_if(mProcessBlocks.begin(), mProcessBlocks.end(),
+                                  [blockId](const ProcessBlockInfo& pb) {
+                                      return pb.mBlockId == blockId;
+                                  });
+
+    if (blockIter == mProcessBlocks.end()) {
+        PP_BASE_ERR_LOG("%s line %d: failed: id=%d", __FUNCTION__, __LINE__, blockId);
+        return nullptr;
+    }
+    return &(*blockIter);
+}
+
+status_t ProcessBase::AllocateProcessBuffers(uint32_t num) {
+    uint32_t i;
+    C2MemoryUsage usage(C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE);
+
+    for (i = 0; i < num; i++) {
+        std::shared_ptr<C2LinearBlock> outBlock;
+        ALOGI("fetchLinearBlock: size %d", sOutFormat.bufferSize);
+        c2_status_t err = mBlockPool->fetchLinearBlock(sOutFormat.bufferSize, usage, &outBlock);
+        if (err != C2_OK) {
+            PP_BASE_ERR_LOG("fetchLinearBlock for Output failed with status %d", err);
+            return BAD_VALUE;
+        }
+
+        fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
+        int ret;
+        int fd = outBlock->handle()->data[0];
+        uint64_t pPhys = 0;
+        int index;
+
+        ret = pIonAllocator->getPhys(fd, sOutFormat.bufferSize, (uint64_t&)pPhys);
+        if (ret != 0) {
+            PP_BASE_ERR_LOG("Ion get physical address failed, fd %d", fd);
+            return BAD_VALUE;
+        }
+
+        ProcessBlockInfo info;
+        memset(&info, 0, sizeof(ProcessBlockInfo));
+        info.mBlockId = i;
+        info.mCapacity = sOutFormat.bufferSize;
+        info.mFd = fd;
+        info.mPhysAddr = pPhys;
+        info.mLinearBlock = std::move(outBlock);
+        ProcessFrameSet(&sOutMemInfo, pPhys, i, fd, 0, &index);
+        mOutputQueue.push(index);
+        mProcessBlocks.push_back(std::move(info));
+    }
+
+    return OK;
+}
+status_t ProcessBase::AllocateProcessBuffers(uint32_t num, uint32_t num_plane, uint32_t *buf_size) {
+    uint32_t i;
+    C2MemoryUsage usage(C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE);
+
+    if(num_plane != 2 || buf_size == NULL || buf_size[0] == 0 || buf_size[1] == 0)
+        return BAD_VALUE;
+    for (i = 0; i < num; i++) {
+        std::shared_ptr<C2LinearBlock> outBlock;
+        std::shared_ptr<C2LinearBlock> outBlock2;
+        ALOGI("fetchLinearBlock: size0=%d, size1=%d",buf_size[0], buf_size[1], sOutFormat.bufferSize);
+        c2_status_t err = mBlockPool->fetchLinearBlock(buf_size[0], usage, &outBlock);
+        if (err != C2_OK) {
+            PP_BASE_ERR_LOG("fetchLinearBlock for Output failed with status %d", err);
+            return BAD_VALUE;
+        }
+        int ret;
+        int fd;
+        uint64_t pPhys = (int)(outBlock->handle()->data[0]);
+        int index;
+
+        err = mBlockPool->fetchLinearBlock(buf_size[1], usage, &outBlock2);
+        if (err != C2_OK) {
+            PP_BASE_ERR_LOG("fetchLinearBlock for Output failed with status %d", err);
+            return BAD_VALUE;
+        }
+        fd = outBlock2->handle()->data[0];
+        ProcessBlockInfo info;
+        memset(&info, 0, sizeof(ProcessBlockInfo));
+        info.mBlockId = i;
+        info.mCapacity = sOutFormat.bufferSize;
+        info.mFd = fd;
+        info.mPhysAddr = pPhys;
+        info.mLinearBlock = std::move(outBlock);
+        info.mLinearBlock2 = std::move(outBlock2);
+        ProcessFrameSet(&sOutMemInfo, pPhys, i, fd, 0, &index);
+        mOutputQueue.push(index);
+        mProcessBlocks.push_back(std::move(info));
+        ALOGV("AllocateProcessBuffers fd0=%d,fd1=%d",(int)pPhys, fd);
+    }
+    return OK;
+}
+status_t ProcessBase::FreeProcessBuffers() {
+    for (auto& info : mProcessBlocks) {
+        //no need to close fd
+        #if 0
+        if (info.mVirtAddr > 0 && info.mCapacity > 0)
+            munmap((void*)info.mVirtAddr, info.mCapacity);
+        ALOGV("FreeProcessBuffers fd=%d,fd2=%d", info.mFd, (int)info.mPhysAddr);
+        if(info.mFd > 0)
+            close(info.mFd);
+        if(info.mPhysAddr > 0 && 0 == info.mVirtAddr){
+            int fd2 = (int)info.mPhysAddr;
+            close(fd2);
+        }
+        #endif
+
+        if(info.mLinearBlock != NULL){
+            info.mLinearBlock.reset();
+            ALOGV("mLinearBlock.reset");
+        }
+        if(info.mLinearBlock2 != NULL){
+            info.mLinearBlock2.reset();
+            ALOGV("mLinearBlock2.reset");
+        }
+        if(info.mGraphicBlock != NULL){
+            info.mGraphicBlock.reset();
+            ALOGV("mGraphicBlock.reset");
+        }
+
+    }
+
+    mProcessBlocks.clear();
+    return OK;
+}
+
+status_t ProcessBase::onFlush() {
+    ALOGV("ProcessBase::onFlush");
+
+    return OK;
+}
+
+status_t ProcessBase::onReset() {
+    return OK;
+}
+
+status_t ProcessBase::clearInputBuffers() {
+
+    int inIndex;
+    int inId;
+    int inFd;
+    unsigned long inPhys;
+    uint32_t inFlag= 0;
+    Mutex::Autolock autoLock(mLock);
+
+    while (!mInputQueue.empty()) {
+        inIndex = mInputQueue.front();
+        ProcessFrameGetNode(&sInMemInfo, inIndex, &inPhys, &inId, &inFd, &inFlag);
+        NotifyProcessInputUsed(inId);
+        ProcessFrameClear(&sInMemInfo,inIndex);
+        ALOGV("clearInputBuffers inIndex=%d",inIndex);
+        mInputQueue.pop();
+    }
+
+    while(!mTimestampQueue.empty()) {
+        uint64_t timestamp = mTimestampQueue.front();
+        mTimestampQueue.pop();
+        ALOGV("clear ts=%lld in kWhatFlush",(long long)timestamp);
+    }
+
+    return OK;
+}
+status_t ProcessBase::clearOutputBuffers() {
+
+    int outIndex;
+    int outId;
+    int outFd;
+    unsigned long outPhys;
+    uint32_t outFlag= 0;
+    Mutex::Autolock autoLock(mLock);
+
+    while (!mOutputQueue.empty()) {
+        outIndex = mOutputQueue.front();
+        ProcessFrameGetNode(&sOutMemInfo, outIndex, &outPhys, &outId, &outFd, &outFlag);
+
+        auto blockIter = std::find_if(mProcessBlocks.begin(), mProcessBlocks.end(),
+                                      [outPhys](const ProcessBlockInfo& pb) {
+                                          return pb.mPhysAddr == outPhys;
+                                      });
+        if (blockIter != mProcessBlocks.end()){
+            if(blockIter->mGraphicBlock != NULL)
+                (*blockIter).mGraphicBlock.reset();
+
+            if(blockIter->mLinearBlock != NULL)
+                (*blockIter).mLinearBlock.reset();
+            ALOGV("mLinearBlock.reset");
+
+            if(blockIter->mLinearBlock2 != NULL)
+                (*blockIter).mLinearBlock2.reset();
+
+        }
+        ProcessFrameClear(&sOutMemInfo,outIndex);
+        ALOGV("clearOutputBuffers outIndex=%d",outIndex);
+        mOutputQueue.pop();
+    }
+
+    return OK;
+}
+
+
+status_t ProcessBase::videoFormatChanged(PROCESSBASE_FORMAT *newFmt) {
+    if (sInFormat.width == newFmt->width && sInFormat.height == newFmt->height) {
+        ALOGV("videoFormatChanged do nothing return");
+        // resolution not changed, do nothing
+        //return OK;
+    }
+
+    sInFormat.width = newFmt->width;
+    sInFormat.height = newFmt->height;
+    sInFormat.stride = newFmt->stride;
+    sInFormat.interlaced = newFmt->interlaced;
+
+    int32_t err;
+    ALOGV("videoFormatChanged BEGIN");
+
+    do {
+        sp<AMessage> reply;
+        (new AMessage(kWhatResChanged, this))->postAndAwaitResponse(&reply);
+        CHECK(reply->findInt32("err", &err));
+    } while (err == WOULD_BLOCK);
+
+    bResChanged = false;
+    ALOGV("videoFormatChanged END");
+    return err;
+}
+
+status_t ProcessBase::onOutputBufferReturned(int outputId) {
+
+    if (!ProcessFrameValid(&sOutMemInfo, outputId)) {
+        PP_BASE_ERR_LOG("onOutputBufferReturned invalid outputId: %d", outputId);
+        return BAD_VALUE;
+    }
+
+    mOutputQueue.push(outputId);
+
+    Post_ProcessMessage();
+    return OK;
+}
+
+status_t ProcessBase::ProcessFrameSet(PROCESS_MEM_INFO* pMem, unsigned long nPhys, int id, int fd, uint32_t flag, int* pIndex) {
+    int i;
+    for (i = 0; i < MAX_PROCESS_BUFFER_NUM; i++) {
+        if (pMem->phyAddr[i] == 0) {
+            pMem->phyAddr[i] = nPhys;
+            pMem->id[i] = id;
+            pMem->fd[i] = fd;
+            pMem->flag[i] = flag;
+            *pIndex=i;
+            break;
+        }
+    }
+
+    if (i == MAX_PROCESS_BUFFER_NUM) {
+        PP_BASE_ERR_LOG("frame buffer is full ! 
");
+        *pIndex = -1;
+        return BAD_VALUE;
+    }
+
+    return OK;
+}
+
+status_t ProcessBase::ProcessFrameClear(PROCESS_MEM_INFO* pMem, int nIndex) {
+
+    if (nIndex >= MAX_PROCESS_BUFFER_NUM)
+        return BAD_VALUE;
+
+    pMem->phyAddr[nIndex] = 0;
+    pMem->virtAddr[nIndex] = 0;
+    pMem->fd[nIndex] = -1;
+    pMem->id[nIndex] = 0;
+    pMem->flag[nIndex] = 0;
+
+    return OK;
+}
+
+status_t ProcessBase::ProcessFrameGetNode(PROCESS_MEM_INFO* pMem, int nIndex, unsigned long* pPhys, int* nId, int * out_fd, uint32_t * flag) {
+
+    if (nIndex >= MAX_PROCESS_BUFFER_NUM)
+        return BAD_VALUE;
+
+    *pPhys = pMem->phyAddr[nIndex];
+    *nId = pMem->id[nIndex];
+    *out_fd = pMem->fd[nIndex];
+    *flag = pMem->flag[nIndex];
+    return OK;
+}
+
+bool ProcessBase::ProcessFrameValid(PROCESS_MEM_INFO* pMem, int nIndex) {
+    if(pMem->phyAddr[nIndex] == 0 && pMem->fd[nIndex] == -1){
+        return false;
+    }
+    else {
+        return true;
+    }
+}
+
+void ProcessBase::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatProcess: {
+            if (mState != RUNNING) {
+                break;
+            }
+            Mutex::Autolock autoLock(mLock);
+            ALOGV("kWhatProcess mInputQueue.size()=%d,mTimestampQueue=%d,mOutputQueue.size()=%d",
+                mInputQueue.size(),mTimestampQueue.size(),mOutputQueue.size());
+            //last buffer for eos frame, for g2d post process
+            if(bInputEos && mInputQueue.size() == 1 && mTimestampQueue.size() == 1){
+                ALOGV("mAsync=%d nOutputCnt=%d,nInputCnt=%d",mAsync,nOutputCnt,nInputCnt);
+                if(!mAsync){
+                    ALOGV("bInputEos call NotifyProcessEos directly");
+                    NotifyProcessEos();
+                    break;
+                }else if(mAsync && nOutputCnt > 0 && nInputCnt > 0 && nOutputCnt >= nInputCnt-1 ){
+                    ALOGV("bInputEos async call NotifyProcessEos");
+                    NotifyProcessEos();
+                    break;
+                }
+            }
+
+            uint64_t timestamp = 0;
+            if(!mTimestampQueue.empty())
+                timestamp = mTimestampQueue.front();
+
+            ALOGV("onProcess BEGIN mAsync=%d ts=%lld,size=%d",mAsync, (long long)timestamp, mInputQueue.size());
+            if(mInputQueue.size() > 0 || mOutputQueue.size() > 0){
+                if(OK == onProcess()){
+
+                    if(mAsync){
+                        //send kWhatProcess again only when mInputQueue has buffers for async component
+                        if(mInputQueue.size() > 0 || mOutputQueue.size() > 0)
+                            (new AMessage(kWhatProcess, this))->post();
+                    }
+                    else{
+                        //send kWhatProcess again only when both mInputQueue and mOutputQueue have buffers
+                        if (mInputQueue.size() > 0 && mOutputQueue.size() > 0)
+                            (new AMessage(kWhatProcess, this))->post();
+                    }
+                }
+            }
+            break;
+        }
+        case kWhatInit: {
+            mState = RUNNING;
+            int32_t err = onInit();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatStart: {
+            mState = RUNNING;
+            int32_t err = onStart();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatFlush: {
+            Mutexed<InputBufferQueue>::Locked queue(mInputBufferQueue);
+            int pre_state = mState;
+            mState = FLUSHING;
+
+            while (!queue->empty()) {
+                queue->pop_front();
+            }
+            clearInputBuffers();
+
+            clearOutputBuffers();
+
+            int32_t err = onFlush();
+            nInputCnt = 0;
+            nOutputCnt = 0;
+            Reply(msg, &err);
+            mState = pre_state;
+            break;
+        }
+        case kWhatResChanged: {
+            int32_t err;
+            if (!mTimestampQueue.empty()) {
+                ALOGV("process queue still have buffer not processed");
+                err = (int32_t)WOULD_BLOCK;
+                usleep(10000); // sleep 10ms because process may take at least 10ms
+                Reply(msg, &err);
+                break;
+            }
+            bResChanged = true;
+            err = onVideoResChanged();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatStop: {
+            Mutexed<InputBufferQueue>::Locked queue(mInputBufferQueue);
+            mState = STOPPING;
+            while (!queue->empty()) {
+                queue->pop_front();
+            }
+            clearInputBuffers();
+
+            clearOutputBuffers();
+
+            int32_t err = onStop();
+            mState = STOPPED;
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatDestroy: {
+            // release resources
+            Mutexed<InputBufferQueue>::Locked queue(mInputBufferQueue);
+
+            if(mState != STOPPED){
+                int32_t err = onStop();
+            }
+            mState = STOPPED;
+            while (!queue->empty()) {
+                queue->pop_front();
+            }
+
+            clearInputBuffers();
+            clearOutputBuffers();
+
+            int32_t err = onDestroy();
+            FreeProcessBuffers();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatReturnOutBuf: {
+            int outputId;
+            if (msg->findInt32("output-id", &outputId)) {
+                ALOGV("kWhatReturnOutBuf id=%d",outputId);
+                onOutputBufferReturned(outputId);
+            } else {
+                PP_BASE_ERR_LOG("kWhatReturnOutBuf can't find a valid output id
");
+            }
+            break;
+        }
+        default: {
+            PP_BASE_ERR_LOG("Unrecognized msg: %d", msg->what());
+            break;
+        }
+    }
+}
+
+status_t ProcessBase::NotifyProcessInputUsed(int inputId) {
+    mClient->notifyProcessInputUsed(inputId);
+    return OK;
+}
+
+status_t ProcessBase::NotifyProcessDone(int outputId, uint32_t flag) {
+
+    uint64_t timestamp = (uint64_t)(-1);
+    {
+        if (!mTimestampQueue.empty()) {
+            timestamp = mTimestampQueue.front();
+            mTimestampQueue.pop();
+            ALOGV("NotifyProcessDone timestamp=%lld",timestamp);
+        }else
+            ALOGE("NotifyProcessDone get no timestamp");
+    }
+    nOutputCnt ++;
+    mClient->notifyProcessDone(outputId, timestamp, flag);
+
+    //handle async process eos event, such as isi preprocess
+    if(bInputEos && mAsync && mInputQueue.size() == 1 && mTimestampQueue.size() == 1){
+        ALOGV("bInputEos async call NotifyProcessEos");
+        NotifyProcessEos();
+    }
+
+    return OK;
+}
+
+status_t ProcessBase::NotifyProcessEos() {
+
+    mInputQueue.pop();
+    mTimestampQueue.pop();
+    mClient->notifyProcessEos();
+    bInputEos = false;
+    mState = STOPPED;
+
+    return OK;
+}
+
+status_t ProcessBase::FetchProcessBuffer(int *bufferId, unsigned long *phys) {
+    //return mClient->fetchProcessBuffer(bufferId, phys);
+    uint32_t i;
+    C2MemoryUsage usage(C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE);
+    std::shared_ptr<C2GraphicBlock> outBlock;
+
+    ALOGV("%s, res(%d x %d), pixel fmt %d", __FUNCTION__, sOutFormat.width, sOutFormat.height, sOutFormat.format);
+
+    c2_status_t err = mBlockPool->fetchGraphicBlock(sOutFormat.width, sOutFormat.height,
+                                                        sOutFormat.format, usage, &outBlock);
+    if (err != C2_OK) {
+        PP_BASE_LOG("fetchGraphicBlock for Output failed with status %d", err);
+        return BAD_VALUE;
+    }
+    if(bResChanged){
+        ALOGI("drop C2GraphicBlock during resolution change");
+        outBlock.reset();
+        return BAD_VALUE;
+    }
+
+    fsl::Memory *prvHandle = (fsl::Memory*)outBlock->handle();
+    unsigned long physAddr = prvHandle->phys;
+
+    auto blockIter = std::find_if(mProcessBlocks.begin(), mProcessBlocks.end(),
+                                  [physAddr](const ProcessBlockInfo& pb) {
+                                      return pb.mPhysAddr == physAddr;
+                                  });
+
+    if (blockIter == mProcessBlocks.end()) {
+        // fetch a new graphic buffer
+        ProcessBlockInfo info;
+        memset(&info, 0, sizeof(ProcessBlockInfo));
+        info.mBlockId = static_cast<int32_t>(mProcessBlocks.size());
+        info.mCapacity = prvHandle->size;
+        info.mFd = prvHandle->fd;
+        info.mPhysAddr = prvHandle->phys;
+        info.mGraphicBlock = std::move(outBlock);
+        *bufferId = info.mBlockId;
+        *phys = prvHandle->phys;
+        mProcessBlocks.push_back(std::move(info));
+        ALOGV("fetch a new graphic buffer: id %d, phys %p,fd=%d", *bufferId, (void*)*phys, info.mFd);
+    } else {
+        // previous buffer fetch back
+        ALOGV("previous buffer fetch back, id %d", blockIter->mBlockId);
+        *bufferId = blockIter->mBlockId;
+        *phys = prvHandle->phys;
+        blockIter->mGraphicBlock = std::move(outBlock);
+    }
+
+    return OK;
+}
+status_t ProcessBase::Post_ProcessMessage()
+{
+
+    bool newOutput = (1 == mOutputQueue.size());
+
+    if(newOutput){
+        ALOGV("Post_ProcessMessage");
+        (new AMessage(kWhatProcess, this))->post();
+    }
+    return OK;
+}
+}
diff --git a/codec2/process/common/ProcessBase.h b/codec2/process/common/ProcessBase.h
new file mode 100644
index 0000000..4228b80
--- /dev/null
+++ b/codec2/process/common/ProcessBase.h
@@ -0,0 +1,210 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+
+#ifndef PROCESS_BASE_H
+#define PROCESS_BASE_H
+
+#include <queue>
+#include <C2Buffer.h>
+#include <C2Work.h>
+
+#include <media/stagefright/foundation/AHandler.h>
+#include <media/stagefright/foundation/ALooper.h>
+#include <media/stagefright/foundation/Mutexed.h>
+
+namespace android {
+
+#define DEFAULT_PROCESS_BUFFER_NUM 3
+#define MAX_PROCESS_BUFFER_NUM 32
+
+typedef struct {
+    int nNum;
+    int id[MAX_PROCESS_BUFFER_NUM];
+    unsigned long virtAddr[MAX_PROCESS_BUFFER_NUM];
+    unsigned long phyAddr[MAX_PROCESS_BUFFER_NUM];
+    unsigned long fd[MAX_PROCESS_BUFFER_NUM];
+    uint32_t size[MAX_PROCESS_BUFFER_NUM];
+    uint32_t flag[MAX_PROCESS_BUFFER_NUM];
+} PROCESS_MEM_INFO;
+
+typedef struct {
+    uint32_t width;
+    uint32_t height;
+    uint32_t format;
+    uint32_t stride;
+    uint32_t bufferSize;
+    bool interlaced;
+} PROCESSBASE_FORMAT;
+
+typedef struct {
+    int32_t mBlockId = -1;
+    int mFd;
+    unsigned long mPhysAddr;
+    unsigned long mVirtAddr;
+    uint32_t mCapacity;
+    uint64_t mTimestamp;
+    std::shared_ptr<C2LinearBlock> mLinearBlock;
+    std::shared_ptr<C2LinearBlock> mLinearBlock2;
+    std::shared_ptr<C2GraphicBlock> mGraphicBlock;
+
+} ProcessBlockInfo;
+
+typedef enum {
+    PROCESS_CONFIG_INPUT_FORMAT = 0,
+    PROCESS_CONFIG_OUTPUT_FORMAT,
+    PROCESS_CONFIG_INTRA_REFRESH,
+} ProcessConfig;
+
+class ProcessBase : public AHandler {
+public:
+    class Client{
+    public:
+        virtual status_t fetchProcessBuffer(int *bufferId, unsigned long *phys);
+        virtual status_t notifyProcessInputUsed(int inputId);
+        virtual status_t notifyProcessDone(int outputId, uint64_t timestamp, uint32_t flag);
+        virtual status_t notifyProcessOutputClear();
+        virtual status_t notifyProcessFlushDone();
+        virtual status_t notifyProcessResetDone();
+        virtual void notifyProcessError();
+        virtual void notifyProcessEos();
+    protected:
+            virtual ~Client() = default;
+    };
+
+
+    ProcessBase();
+    virtual ~ProcessBase();
+
+    status_t init(Client* client, const std::shared_ptr<C2BlockPool>& pool);
+    status_t destroy();
+    status_t queueInput(void* pVirt, void* pPhys, uint32_t size, uint64_t timestamp, uint32_t flags, int fd, int id);
+    status_t flush();
+    status_t reset();
+    status_t stop();
+    status_t start();
+    status_t importOutputBuffers();
+    status_t outputBufferReturned(int outputId);
+    ProcessBlockInfo* getProcessBlockById(int blockId);
+    status_t setConfig(ProcessConfig index, void* pConfig);
+    status_t getConfig(ProcessConfig index, void* pConfig);
+    status_t videoFormatChanged(PROCESSBASE_FORMAT *newFmt);
+
+protected:
+    struct PPInputBuffer{
+        unsigned long physAddr;
+        int id;
+        uint32_t size;
+        uint64_t timestamp;
+        bool eos;
+
+        PPInputBuffer() {}
+        PPInputBuffer(unsigned long phys, int id, uint32_t size, uint64_t ts, bool eos);
+    };
+
+    enum {
+        UNINITIALIZED,
+        STOPPED,
+        RUNNING,
+        STOPPING,
+        FLUSHING,
+    };
+
+    PROCESSBASE_FORMAT sInFormat;
+    PROCESSBASE_FORMAT sOutFormat;
+
+    PROCESS_MEM_INFO sInMemInfo;
+    PROCESS_MEM_INFO sOutMemInfo;
+
+    std::queue<int> mInputQueue;
+    std::queue<int> mOutputQueue;
+
+    std::shared_ptr<C2BlockPool> mBlockPool;
+
+    int mState;
+
+    bool mAsync;
+    bool bOutputEos;
+    uint64_t nInputCnt;
+    uint64_t nOutputCnt;
+
+    // preprocess use AllocateProcessBuffers to allocate linear buffer
+    status_t AllocateProcessBuffers(uint32_t num);
+    status_t AllocateProcessBuffers(uint32_t num, uint32_t num_plane, uint32_t *buf_size);
+    // postprocess use FetchProcessBuffer to fetch graphic buffer
+    status_t FetchProcessBuffer(int *bufferId, unsigned long *phys);
+    status_t FreeProcessBuffers();
+    status_t onFlush();
+    status_t onReset();
+    status_t clearInputBuffers();
+    status_t clearOutputBuffers();
+
+    status_t ProcessFrameSet(PROCESS_MEM_INFO* pMem, unsigned long nPhys, int id, int fd, uint32_t flag, int* pIndex);
+    status_t ProcessFrameClear(PROCESS_MEM_INFO* pMem, int nIndex);
+    status_t ProcessFrameGetNode(PROCESS_MEM_INFO* pMem, int nIndex, unsigned long* pPhys, int* nId, int * out_fd, uint32_t *flag );
+    bool ProcessFrameValid(PROCESS_MEM_INFO* pMem, int nIndex);
+
+    virtual status_t onInit() {return OK;}
+    virtual status_t onConfig() {return OK;}
+    virtual status_t onDestroy() {return OK;}
+    void onMessageReceived(const sp<AMessage> &msg) override;
+    virtual status_t onOutputBufferReturned(int outputId);
+    virtual status_t onProcess() {return OK;}
+    virtual status_t onVideoResChanged() {return OK;}
+    virtual status_t onStart() {return OK;}
+    virtual status_t onStop() {return OK;}
+
+    status_t NotifyProcessInputUsed(int inputId);
+    status_t NotifyProcessDone(int outputId, uint32_t flag);
+    status_t NotifyProcessEos();
+    virtual status_t DoSetConfig(ProcessConfig index, void* pConfig){return OK;}
+    virtual status_t DoGetConfig(ProcessConfig index, void* pConfig){return OK;}
+
+    bool getDefaultG2DLib(char *libName, int size);
+    status_t Post_ProcessMessage();
+    Mutex mLock;
+
+private:
+
+    enum {
+        kWhatInit,
+        kWhatProcess,
+        kWhatReturnOutBuf,
+        kWhatFlush,
+        kWhatResChanged,
+        kWhatStop,
+        kWhatDestroy,
+        kWhatStart,
+    };
+
+    sp<ALooper> mLooper;
+    Client* mClient;
+
+    bool bRunning;
+    bool bInputEos;
+    bool bResChanged;
+
+    typedef std::list<std::unique_ptr<PPInputBuffer>> InputBufferQueue;
+    Mutexed<InputBufferQueue> mInputBufferQueue;
+    std::queue<uint64_t> mTimestampQueue;
+
+
+    std::vector<ProcessBlockInfo> mProcessBlocks;
+    uint32_t nDebugFlag;
+
+    void ParseVpuLogLevel();
+    void dumpInputBuffer(void* buf, uint32_t size);
+    void dumpOutputBuffer(void* buf, uint32_t size);
+};
+
+ProcessBase * CreatePreProcessInstance();
+ProcessBase * CreatePostProcessInstance();
+
+}
+
+#endif    // PROCESS_BASE_H
diff --git a/codec2/process/dummy_post/Android.bp b/codec2/process/dummy_post/Android.bp
new file mode 100755
index 0000000..51aa128
--- /dev/null
+++ b/codec2/process/dummy_post/Android.bp
@@ -0,0 +1,79 @@
+imx_c2_process_dummy_post_defaults {
+    name: "imx_c2_process_dummy_post_default",
+}
+
+bootstrap_go_package {
+    name: "soong-imx_process_dummy_post",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/process/dummy_post",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "imx_process_dummy_post.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+cc_library_shared {
+    name: "lib_imx_c2_process_dummy_post",
+
+    defaults: ["imx_c2_process_dummy_post_default"],
+
+    soc_specific: true,
+    srcs: [
+        "DummyPostProcess.cpp",
+    ],
+
+    header_libs: [
+        "libcodec2_headers",
+        "media_plugin_headers",
+    ],
+
+    include_dirs: [
+        "hardware/libhardware/include",
+        "frameworks/av",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp/imx_android_mm/codec2/tsm",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+        "vendor/nxp/fsl-proprietary/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+		"vendor/nxp/imx_android_mm/codec2/process/common",
+	],
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "libion",
+        "lib_imx_c2_componentbase",
+        "libcodec2_vndk",
+        "lib_c2_imx_store",
+		"lib_imx_c2_process",
+    ],
+
+    whole_static_libs: ["libionallocator"],
+
+    sanitize: {
+        cfi: true,
+        misc_undefined: [
+            "unsigned-integer-overflow",
+            "signed-integer-overflow",
+        ],
+        diag: {
+            cfi: true,
+        },
+    },
+
+//    compile_multilib: "32",
+}
+
diff --git a/codec2/process/dummy_post/DummyPostProcess.cpp b/codec2/process/dummy_post/DummyPostProcess.cpp
new file mode 100644
index 0000000..7e5781f
--- /dev/null
+++ b/codec2/process/dummy_post/DummyPostProcess.cpp
@@ -0,0 +1,57 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "DummyPostProcess"
+
+#include <cutils/properties.h>
+#include <utils/Log.h>
+#include <dlfcn.h>
+
+#include "DummyPostProcess.h"
+
+namespace android {
+
+status_t DummyPostProcess::onProcess() {
+    return INVALID_OPERATION;
+}
+
+status_t DummyPostProcess::onVideoResChanged() {
+    return INVALID_OPERATION;
+
+}
+
+status_t DummyPostProcess::onInit() {
+    return INVALID_OPERATION;
+}
+
+status_t DummyPostProcess::onDestroy() {
+    return INVALID_OPERATION;
+}
+status_t DummyPostProcess::onStart() {
+    return INVALID_OPERATION;
+}
+
+status_t DummyPostProcess::onStop() {
+    return INVALID_OPERATION;
+}
+
+status_t DummyPostProcess::DoSetConfig(ProcessConfig index, void* pConfig) {
+    return INVALID_OPERATION; // not support any index yet
+}
+
+status_t DummyPostProcess::DoGetConfig(ProcessConfig index, void* pConfig) {
+    return INVALID_OPERATION; // not support any index yet
+}
+
+ProcessBase * CreatePostProcessInstance() {
+    return static_cast<ProcessBase *>(new DummyPostProcess());
+}
+
+
+} // namespcae android
diff --git a/codec2/process/dummy_post/DummyPostProcess.h b/codec2/process/dummy_post/DummyPostProcess.h
new file mode 100644
index 0000000..ef40d88
--- /dev/null
+++ b/codec2/process/dummy_post/DummyPostProcess.h
@@ -0,0 +1,33 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef DUMMY_POST_PROCESS_H
+#define DUMMY_POST_PROCESS_H
+
+#include "ProcessBase.h"
+
+namespace android {
+
+class DummyPostProcess : public ProcessBase {
+public:
+
+    status_t onInit() override;
+    status_t onDestroy() override;
+    status_t onStart() override;
+    status_t onStop() override;
+protected:
+    status_t onProcess() override;
+    status_t onVideoResChanged() override;
+    status_t DoSetConfig(ProcessConfig index, void* pConfig) override;
+    status_t DoGetConfig(ProcessConfig index, void* pConfig) override;
+
+};
+
+} // namespcae android
+
+#endif // G2D_POST_PROCESS_BASE_H
\ No newline at end of file
diff --git a/codec2/process/dummy_post/imx_process_dummy_post.go b/codec2/process/dummy_post/imx_process_dummy_post.go
new file mode 100755
index 0000000..86fc511
--- /dev/null
+++ b/codec2/process/dummy_post/imx_process_dummy_post.go
@@ -0,0 +1,55 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package imx_process_dummy_post
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_process_dummy_post_defaults", process_dummy_postDefaultsFactory)
+}
+
+
+func process_dummy_postDefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, process_dummy_postDefaults)
+    return module
+}
+
+func process_dummy_postDefaults(ctx android.LoadHookContext) {
+    var Cflags []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Cflags []string
+                }
+        }
+    }
+    p := &props{}
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8Q") {
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
+    } else {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    }
+
+    p.Target.Android.Cflags = Cflags
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/process/g2d_post/Android.bp b/codec2/process/g2d_post/Android.bp
new file mode 100644
index 0000000..4ad3695
--- /dev/null
+++ b/codec2/process/g2d_post/Android.bp
@@ -0,0 +1,79 @@
+imx_c2_process_g2d_post_defaults {
+    name: "imx_c2_process_g2d_post_default",
+}
+
+bootstrap_go_package {
+    name: "soong-imx_process_g2d_post",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/process/g2d_post",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "imx_process_g2d_post.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+cc_library_shared {
+    name: "lib_imx_c2_process_g2d_post",
+
+    defaults: ["imx_c2_process_g2d_post_default"],
+
+    soc_specific: true,
+    srcs: [
+        "G2dPostProcess.cpp",
+    ],
+
+    header_libs: [
+        "libcodec2_headers",
+        "media_plugin_headers",
+    ],
+
+    include_dirs: [
+        "hardware/libhardware/include",
+        "frameworks/av",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp/imx_android_mm/codec2/tsm",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+        "vendor/nxp/fsl-proprietary/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/imx_android_mm/codec2/process/common",
+	],
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "libion",
+        "lib_imx_c2_componentbase",
+        "libcodec2_vndk",
+        "lib_c2_imx_store",
+        "lib_imx_c2_process",
+    ],
+
+    whole_static_libs: ["libionallocator"],
+
+    sanitize: {
+        cfi: true,
+        misc_undefined: [
+            "unsigned-integer-overflow",
+            "signed-integer-overflow",
+        ],
+        diag: {
+            cfi: true,
+        },
+    },
+
+//    compile_multilib: "32",
+}
+
diff --git a/codec2/process/g2d_post/G2dPostProcess.cpp b/codec2/process/g2d_post/G2dPostProcess.cpp
new file mode 100755
index 0000000..b75bb06
--- /dev/null
+++ b/codec2/process/g2d_post/G2dPostProcess.cpp
@@ -0,0 +1,352 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "G2dPostProcess"
+
+#include <cutils/properties.h>
+#include <utils/Log.h>
+#include <dlfcn.h>
+
+#include "G2dPostProcess.h"
+#include "graphics_ext.h"
+
+
+#define G2D_POST_PROCESS_API_TRACE
+#ifdef G2D_POST_PROCESS_API_TRACE
+#define G2DPP_API_TRACE ALOGV
+#else
+#define G2DPP_API_TRACE(...)
+#endif
+
+#define G2D_PRE_PROCESS_DEBUG
+#ifdef G2D_PRE_PROCESS_DEBUG
+#define G2DPP_LOG ALOGV
+#else
+#define G2DPP_LOG(...)
+#endif
+
+#define G2DPP_ERR_LOG ALOGE
+
+namespace android {
+
+G2dPostProcess::G2dPostProcess() {
+    pPPHandle = nullptr;
+    mFetchThread = 0;
+    mAsync = false;
+
+    memset(&sG2dModule, 0, sizeof(G2D_MODULE));
+    memset(&sOutMemInfo, 0, sizeof(PROCESS_MEM_INFO));
+    memset(&sSrcSurface, 0, sizeof(G2DSurfaceEx));
+    memset(&sDstSurface, 0, sizeof(G2DSurfaceEx));
+    bFetchStarted = false;
+    bFetchStopped = true;
+}
+
+G2dPostProcess::~G2dPostProcess() {
+}
+
+status_t G2dPostProcess::createFetchThread() {
+    Mutex::Autolock autoLock(mLock);
+    if (!bFetchStarted) {
+        ALOGV("createFetchThread mFetchThread=%d",mFetchThread);
+        pthread_attr_t attr;
+        pthread_attr_init(&attr);
+        pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+
+        bFetchStarted = true;
+        bFetchStopped = false;
+
+        pthread_create(&mFetchThread, &attr, FetchThreadWrapper, this);
+        pthread_attr_destroy(&attr);
+    }
+    return OK;
+}
+
+status_t G2dPostProcess::destroyFetchThread() {
+
+    if (bFetchStarted) {
+        ALOGV("destroyFetchThread mFetchThread=%d",mFetchThread);
+        bFetchStarted = false;
+        do {
+            usleep(1000);
+        } while (!bFetchStopped);
+        Mutex::Autolock autoLock(mLock);
+        pthread_join(mFetchThread, NULL);
+    }
+    return OK;
+}
+
+void *G2dPostProcess::FetchThreadWrapper(void *me) {
+    return (void *)(uintptr_t)static_cast<G2dPostProcess *>(me)->HandleFetchThread();
+}
+
+status_t G2dPostProcess::HandleFetchThread() {
+    while(bFetchStarted){
+        ALOGV("HandleFetchThread loop begin mOutputQueue size=%d",mOutputQueue.size());
+
+        // only start fetching when process output buffer isn't enough
+        if (mOutputQueue.size() >= 3 || RUNNING != mState) {
+            usleep(5000);
+            continue;
+        }
+
+        int bufferId, index;
+        unsigned long phys;
+
+        if (OK != FetchProcessBuffer(&bufferId, &phys)) {
+            usleep(1000);
+            continue;
+        }
+
+        if(!bFetchStarted)
+            break;
+
+        Mutex::Autolock autoLock(mLock);
+
+        if(!bFetchStarted){
+            break;
+        }
+
+        ProcessFrameSet(&sOutMemInfo, phys, bufferId, -1, 0, &index);
+        mOutputQueue.push(index);
+        Post_ProcessMessage();
+    }
+    ALOGV("HandleFetchThread stopped");
+    bFetchStopped = true;
+    return OK;
+}
+
+status_t G2dPostProcess::onProcess() {
+    status_t ret = OK;
+    int inIndex, outIndex;
+    int inId, outId;
+    int inFd, outFd;
+    unsigned long inPhys, outPhys;
+    uint32_t inFlag= 0;
+    uint32_t outFlag= 0;
+
+    if (mInputQueue.size() == 0 || mOutputQueue.size() == 0) {
+        return BAD_VALUE;
+    }
+
+    // now we have input and output, post process can star
+    inIndex = mInputQueue.front();
+    ProcessFrameGetNode(&sInMemInfo, inIndex, &inPhys, &inId, &inFd, &inFlag);
+
+    outIndex = mOutputQueue.front();
+    ProcessFrameGetNode(&sOutMemInfo, outIndex, &outPhys, &outId, &outFd, &outFlag);
+
+    if(!inPhys && (inFlag & C2FrameData::FLAG_END_OF_STREAM)){
+        NotifyProcessEos();
+        ALOGE("G2dPostProcess NotifyProcessEos !");
+        return BAD_VALUE;
+    }
+
+    if (!inPhys || !outPhys) {
+        G2DPP_ERR_LOG("invalid address: inPhys %p outPhys %p inId %d, outId %d, inIndex %d, outIndex %d",
+            (void*)inPhys, (void*)outPhys, inId, outId, inIndex, outIndex);
+        return BAD_VALUE;
+    }
+
+    G2DPP_LOG("G2dPostProcess::doProcess inPhys: %p outPhys: %p, w*h(%d x %d), inId %d, outId %d inIndex %d, outIndex %d",
+        (void*)inPhys, (void*)outPhys, sInFormat.width, sInFormat.height, inId, outId, inIndex, outIndex);
+
+    //enable the macro can make workaround for g2d
+    #if 0
+    sSrcSurface.base.left = 0;
+    sSrcSurface.base.top = 0;
+    sSrcSurface.base.right = sInFormat.width;
+    sSrcSurface.base.bottom = sInFormat.height;
+    sSrcSurface.base.width = sInFormat.width;
+    sSrcSurface.base.height = sInFormat.height;
+    sSrcSurface.base.stride = sInFormat.stride;
+    #endif
+
+    sSrcSurface.base.planes[0] = (int)inPhys;
+    sSrcSurface.base.planes[1] = (int)inPhys + sSrcSurface.base.width * sSrcSurface.base.height;
+    ALOGV("G2dProcess::Process src w=%d,h=%d,right=%d,bottom=%d
",sSrcSurface.base.width,sSrcSurface.base.height,sSrcSurface.base.right, sSrcSurface.base.bottom);
+
+
+    sDstSurface.base.planes[0] = (int)outPhys;
+
+    if (sG2dModule.mG2dBlitEx(pPPHandle->g2dHandle, &sSrcSurface, &sDstSurface) != 0) {
+        G2DPP_ERR_LOG("g2d_blitEx failed
");
+        return BAD_VALUE;
+    }
+
+    if (sG2dModule.mG2dFinish(pPPHandle->g2dHandle) != 0) {
+        G2DPP_ERR_LOG("g2d_finish failed
");
+        return BAD_VALUE;
+    }
+
+    mInputQueue.pop();
+    ProcessFrameClear(&sInMemInfo, inIndex);
+
+    mOutputQueue.pop();
+    ProcessFrameClear(&sOutMemInfo, outIndex);
+
+    NotifyProcessInputUsed(inId);
+    NotifyProcessDone(outId,inFlag);
+    if(inFlag & C2FrameData::FLAG_END_OF_STREAM)
+        NotifyProcessEos();
+
+    return OK;
+}
+
+status_t G2dPostProcess::onVideoResChanged() {
+    if (bFetchStarted) {
+        destroyFetchThread();
+        FreeProcessBuffers();
+        Mutex::Autolock autoLock(mLock);
+        memset(&sOutMemInfo, 0, sizeof(PROCESS_MEM_INFO));
+        std::queue<int> empty;
+        std::swap(mOutputQueue, empty);
+    }
+
+    setPostProcessParameters();
+
+    if (!bFetchStarted) {
+        createFetchThread();
+    }
+
+    ALOGV("onVideoResChanged done");
+
+    return OK;
+}
+
+status_t G2dPostProcess::onInit() {
+    G2DPP_LOG("%s", __FUNCTION__);
+
+    char g2dlibName[PATH_MAX] = {0};
+
+    if(getDefaultG2DLib(g2dlibName, PATH_MAX)){
+        sG2dModule.hLibHandle = dlopen(g2dlibName, RTLD_NOW);
+    }
+
+    if (nullptr == sG2dModule.hLibHandle) {
+        G2DPP_ERR_LOG("dlopen %s failed, err: %s", g2dlibName, dlerror());
+        return BAD_VALUE;
+    }
+
+    sG2dModule.mG2dOpen = (g2d_func1)dlsym(sG2dModule.hLibHandle, "g2d_open");
+    sG2dModule.mG2dClose = (g2d_func1)dlsym(sG2dModule.hLibHandle, "g2d_close");
+    sG2dModule.mG2dFinish = (g2d_func1)dlsym(sG2dModule.hLibHandle, "g2d_finish");
+    sG2dModule.mG2dBlitEx = (g2d_func2)dlsym(sG2dModule.hLibHandle, "g2d_blitEx");
+
+    if (!sG2dModule.mG2dOpen || !sG2dModule.mG2dClose ||
+            !sG2dModule.mG2dFinish || !sG2dModule.mG2dBlitEx) {
+        G2DPP_ERR_LOG("dlsym failed, err: %s", dlerror());
+        return BAD_VALUE;
+    }
+
+    pPPHandle = (VpuDecoderGpuHandle*)malloc(sizeof(VpuDecoderGpuHandle));
+    if (!pPPHandle)
+        return BAD_VALUE;
+
+    if (sG2dModule.mG2dOpen(&pPPHandle->g2dHandle) == -1) {
+        G2DPP_ERR_LOG("g2d_open failed
");
+        return BAD_VALUE;
+    } else if (nullptr == pPPHandle->g2dHandle) {
+        G2DPP_ERR_LOG("g2d_open return null handle
");
+        return BAD_VALUE;
+    }
+
+    setPostProcessParameters();
+
+    createFetchThread();
+
+    return OK;
+}
+status_t G2dPostProcess::onStart()
+{
+    createFetchThread();
+    return OK;
+}
+status_t G2dPostProcess::onStop()
+{
+    destroyFetchThread();
+    return OK;
+}
+status_t G2dPostProcess::onDestroy() {
+    G2DPP_LOG("%s", __FUNCTION__);
+
+    onStop();
+
+    if (pPPHandle && pPPHandle->g2dHandle && sG2dModule.mG2dClose) {
+        if (sG2dModule.mG2dClose(pPPHandle->g2dHandle) != 0) {
+            G2DPP_ERR_LOG("g2d_close failed
");
+            return BAD_VALUE;
+        }
+        pPPHandle->g2dHandle = NULL;
+    }
+
+    if (pPPHandle) {
+        free(pPPHandle);
+        pPPHandle = nullptr;
+    }
+
+    if (sG2dModule.hLibHandle) {
+        dlclose(sG2dModule.hLibHandle);
+        memset(&sG2dModule, 0, sizeof(G2D_MODULE));
+    }
+
+    return OK;
+}
+
+void G2dPostProcess::setPostProcessParameters() {
+    sOutFormat.width = sInFormat.width;
+    sOutFormat.height = sInFormat.height;
+    sOutFormat.stride = sInFormat.stride;
+    sOutFormat.format = HAL_PIXEL_FORMAT_YCbCr_422_I;
+    sOutFormat.bufferSize = sOutFormat.width * sOutFormat.height * 2;
+
+    sSrcSurface.base.format = G2D_NV12;
+
+    sSrcSurface.base.left = 0;
+    sSrcSurface.base.top = 0;
+    sSrcSurface.base.right = sInFormat.width;
+    sSrcSurface.base.bottom = sInFormat.height;
+
+    sSrcSurface.base.width = sInFormat.width;
+    sSrcSurface.base.height = sInFormat.height;
+    sSrcSurface.base.stride = sInFormat.stride;
+    sSrcSurface.tiling = G2D_AMPHION_TILED;
+    if (sInFormat.interlaced) {
+        sSrcSurface.tiling = (enum g2d_tiling)(sSrcSurface.tiling | G2D_AMPHION_INTERLACED);
+        G2DPP_LOG("it is interlaced source");
+    }
+    ALOGV("setPostProcessParameters src w=%d,h=%d
",sSrcSurface.base.width,sSrcSurface.base.height);
+
+    sDstSurface.tiling = G2D_LINEAR;
+    sDstSurface.base.format = G2D_YUYV;
+
+    sDstSurface.base.left = 0;
+    sDstSurface.base.top = 0;
+    sDstSurface.base.right = sOutFormat.width;
+    sDstSurface.base.bottom = sOutFormat.height;
+
+    sDstSurface.base.stride = sOutFormat.stride;
+    sDstSurface.base.width = sOutFormat.width;
+    sDstSurface.base.height = sOutFormat.height;
+}
+
+status_t G2dPostProcess::DoSetConfig(ProcessConfig index, void* pConfig) {
+    return BAD_VALUE; // not support any index yet
+}
+
+status_t G2dPostProcess::DoGetConfig(ProcessConfig index, void* pConfig) {
+    return BAD_VALUE; // not support any index yet
+}
+
+ProcessBase * CreatePostProcessInstance() {
+    return static_cast<ProcessBase *>(new G2dPostProcess());
+}
+
+
+} // namespcae android
diff --git a/codec2/process/g2d_post/G2dPostProcess.h b/codec2/process/g2d_post/G2dPostProcess.h
new file mode 100644
index 0000000..249a746
--- /dev/null
+++ b/codec2/process/g2d_post/G2dPostProcess.h
@@ -0,0 +1,86 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef G2D_POST_PROCESS_H
+#define G2D_POST_PROCESS_H
+
+#include <queue>
+
+#include "ProcessBase.h"
+#include "g2d.h"
+#include "g2dExt.h"
+
+namespace android {
+
+typedef struct g2d_surfaceEx G2DSurfaceEx;
+
+typedef struct {
+    void * g2dHandle;
+} VpuDecoderGpuHandle;
+
+typedef int (*g2d_func1)(void* handle);
+typedef int (*g2d_func2)(void *handle, G2DSurfaceEx *srcEx, G2DSurfaceEx *dstEx);
+
+typedef struct {
+    void * hLibHandle;
+    g2d_func1 mG2dOpen;
+    g2d_func1 mG2dFinish;
+    g2d_func1 mG2dClose;
+    g2d_func2 mG2dBlitEx;
+} G2D_MODULE;
+
+
+
+class G2dPostProcess : public ProcessBase {
+public:
+    G2dPostProcess();
+    virtual ~G2dPostProcess();
+
+    status_t onInit() override;
+    status_t onDestroy() override;
+    status_t onStart() override;
+    status_t onStop() override;
+protected:
+    status_t onProcess() override;
+    status_t onVideoResChanged() override;
+    status_t DoSetConfig(ProcessConfig index, void* pConfig) override;
+    status_t DoGetConfig(ProcessConfig index, void* pConfig) override;
+
+private:
+    VpuDecoderGpuHandle* pPPHandle; // preprocess handle
+    G2D_MODULE sG2dModule;
+    G2DSurfaceEx sSrcSurface;
+    G2DSurfaceEx sDstSurface;
+
+    bool bFetchStarted;
+    bool bFetchStopped;
+/*
+    bool bProcessStarted;
+    bool bProcessStopped;
+*/
+    //Mutex mLock;
+    pthread_t mFetchThread;
+    //pthread_t mProcessThread;
+
+    status_t createFetchThread();
+    status_t destroyFetchThread();
+    static void *FetchThreadWrapper(void *);
+    status_t HandleFetchThread();
+/*
+    status_t createProcessThread();
+    status_t destroyProcessThread();
+    static void *ProcessThreadWrapper(void *);
+    status_t HandleProcessThread();
+    status_t DoProcess();*/
+
+    void setPostProcessParameters();
+};
+
+} // namespcae android
+
+#endif // G2D_POST_PROCESS_H
\ No newline at end of file
diff --git a/codec2/process/g2d_post/imx_process_g2d_post.go b/codec2/process/g2d_post/imx_process_g2d_post.go
new file mode 100644
index 0000000..088ce07
--- /dev/null
+++ b/codec2/process/g2d_post/imx_process_g2d_post.go
@@ -0,0 +1,55 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package imx_process_g2d_post
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_process_g2d_post_defaults", process_g2d_postDefaultsFactory)
+}
+
+
+func process_g2d_postDefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, process_g2d_postDefaults)
+    return module
+}
+
+func process_g2d_postDefaults(ctx android.LoadHookContext) {
+    var Cflags []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Cflags []string
+                }
+        }
+    }
+    p := &props{}
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8Q") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else {
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
+    }
+
+    p.Target.Android.Cflags = Cflags
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/process/g2d_pre/Android.bp b/codec2/process/g2d_pre/Android.bp
new file mode 100644
index 0000000..0e3131a
--- /dev/null
+++ b/codec2/process/g2d_pre/Android.bp
@@ -0,0 +1,79 @@
+imx_c2_process_g2d_pre_defaults {
+    name: "imx_c2_process_g2d_pre_default",
+}
+
+bootstrap_go_package {
+    name: "soong-imx_process_g2d_pre",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/process/g2d_pre",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "imx_process_g2d_pre.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+cc_library_shared {
+    name: "lib_imx_c2_process_g2d_pre",
+
+    defaults: ["imx_c2_process_g2d_pre_default"],
+
+    soc_specific: true,
+    srcs: [
+        "G2dPreProcess.cpp",
+    ],
+
+    header_libs: [
+        "libcodec2_headers",
+        "media_plugin_headers",
+    ],
+
+    include_dirs: [
+        "hardware/libhardware/include",
+        "frameworks/av",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp/imx_android_mm/codec2/tsm",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+        "vendor/nxp/fsl-proprietary/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/imx_android_mm/codec2/process/common",
+	],
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "libion",
+        "lib_imx_c2_componentbase",
+        "libcodec2_vndk",
+        "lib_c2_imx_store",
+        "lib_imx_c2_process",
+    ],
+
+    whole_static_libs: ["libionallocator"],
+
+    sanitize: {
+        cfi: true,
+        misc_undefined: [
+            "unsigned-integer-overflow",
+            "signed-integer-overflow",
+        ],
+        diag: {
+            cfi: true,
+        },
+    },
+
+//    compile_multilib: "32",
+}
+
diff --git a/codec2/process/g2d_pre/G2dPreProcess.cpp b/codec2/process/g2d_pre/G2dPreProcess.cpp
new file mode 100755
index 0000000..46e2eb6
--- /dev/null
+++ b/codec2/process/g2d_pre/G2dPreProcess.cpp
@@ -0,0 +1,307 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "G2dPreProcess"
+
+#include <cutils/properties.h>
+#include <utils/Log.h>
+#include <dlfcn.h>
+
+#include "G2dPreProcess.h"
+#include "graphics_ext.h"
+
+//#define DUMP_G2D_OUTPUT
+#ifdef DUMP_G2D_OUTPUT
+#include "IonAllocator.h"
+#include <sys/mman.h>
+#endif
+
+#define G2D_PRE_PROCESS_API_TRACE
+#ifdef G2D_PRE_PROCESS_API_TRACE
+#define G2DPP_API_TRACE ALOGV
+#else
+#define G2DPP_API_TRACE(...)
+#endif
+
+#define G2D_PRE_PROCESS_DEBUG
+#ifdef G2D_PRE_PROCESS_DEBUG
+#define G2DPP_LOG ALOGV
+#else
+#define G2DPP_LOG(...)
+#endif
+
+#define G2DPP_ERR_LOG ALOGE
+
+namespace android {
+
+g2d_format ConvertColorFmtPixel2G2D(int pixelColorFmt) {
+  g2d_format g2dColorFmt = G2D_YUYV;
+
+  switch(pixelColorFmt) {
+    case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+    case HAL_PIXEL_FORMAT_YCBCR_420_888:
+        g2dColorFmt = G2D_NV12;
+        break;
+    case HAL_PIXEL_FORMAT_YCbCr_420_P:
+        g2dColorFmt = G2D_I420;
+        break;
+    case HAL_PIXEL_FORMAT_YV12:
+        g2dColorFmt = G2D_YV12;
+        break;
+    case HAL_PIXEL_FORMAT_YCbCr_422_I:
+        g2dColorFmt = G2D_YUYV;
+        break;
+    case HAL_PIXEL_FORMAT_RGB_565:
+        g2dColorFmt = G2D_RGB565;
+        break;
+    case HAL_PIXEL_FORMAT_RGB_888:
+        g2dColorFmt = G2D_RGB888;
+        break;
+    case HAL_PIXEL_FORMAT_RGBA_8888:
+        g2dColorFmt = G2D_RGBA8888;
+        break;
+    case HAL_PIXEL_FORMAT_RGBX_8888:
+        g2dColorFmt = G2D_RGBX8888;
+        break;
+    case HAL_PIXEL_FORMAT_BGRA_8888:
+        g2dColorFmt = G2D_BGRA8888;
+        break;
+    default:
+      G2DPP_ERR_LOG("unknown pixelColorFmt %d
", pixelColorFmt);
+      break;
+  }
+
+  return g2dColorFmt;
+}
+
+#ifdef DUMP_G2D_OUTPUT
+void dumpOutput(int fd, uint32_t size) {
+    if (fd < 0 || size == 0)
+        return;
+
+    unsigned long virtAddr = 0;
+    bool needUnmap = false;
+    fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
+    int ret = pIonAllocator->getVaddrs(fd, size, (uint64_t&)virtAddr);
+
+    if (ret != 0) {
+        G2DPP_ERR_LOG("Ion get physical address failed, fd %d", fd);
+    } else
+        needUnmap = true;
+
+    if (virtAddr > 0) {
+        FILE * pfile;
+        pfile = fopen("/data/dumpG2DYUV","ab");
+        if(pfile) {
+            G2DPP_LOG("dump size %d", size);
+            fwrite((void*)virtAddr,1,size,pfile);
+            fclose(pfile);
+        } else {
+            G2DPP_ERR_LOG("open dumpfile failed
");
+        }
+    }
+    if (needUnmap && virtAddr > 0)
+        munmap((void*)virtAddr, size);
+}
+#endif
+
+G2dPreProcess::G2dPreProcess() {
+    pPPHandle = nullptr;
+    mAsync = false;
+    memset(&sG2dModule, 0, sizeof(G2D_MODULE));
+    memset(&sOutMemInfo, 0, sizeof(PROCESS_MEM_INFO));
+}
+
+G2dPreProcess::~G2dPreProcess() {
+}
+
+status_t G2dPreProcess::onProcess() {
+    if (mInputQueue.size() == 0 || mOutputQueue.size() == 0) {
+        return OK;
+    }
+
+    int inIndex, outIndex;
+    int inId, outId;
+    int inFd, outFd;
+    unsigned long inPhys, outPhys;
+    uint32_t inFlag = 0;
+    uint32_t outFlag = 0;
+
+    inIndex = mInputQueue.front();
+    outIndex = mOutputQueue.front();
+
+    ProcessFrameGetNode(&sInMemInfo, inIndex, &inPhys, &inId, &inFd, &inFlag);
+    ProcessFrameGetNode(&sOutMemInfo, outIndex, &outPhys, &outId, &outFd, &outFlag);
+
+    if (!inPhys || !outPhys) {
+        G2DPP_ERR_LOG("invalid address: inPhys %p outPhys %p", (void*)inPhys, (void*)outPhys);
+        return BAD_VALUE;
+    }
+
+    G2DPP_LOG("G2dPreProcess::doProcess inPhys: %p outPhys: %p", (void*)inPhys, (void*)outPhys);
+
+    if (sG2dModule.mG2dOpen(&pPPHandle->g2dHandle) == -1) {
+        G2DPP_ERR_LOG("g2d_open failed
");
+        return BAD_VALUE;
+    } else if (nullptr == pPPHandle->g2dHandle) {
+        G2DPP_ERR_LOG("g2d_open return null handle
");
+        return BAD_VALUE;
+    }
+
+
+    pPPHandle->sInput.planes[0] = (int)inPhys;
+    if (pPPHandle->sInput.format == G2D_YV12) {
+        int Ysize = pPPHandle->sInput.width * pPPHandle->sInput.height;
+        pPPHandle->sInput.planes[1] = pPPHandle->sInput.planes[0] + Ysize;
+        pPPHandle->sInput.planes[2] = pPPHandle->sInput.planes[0] + Ysize + Ysize / 4;
+    }
+    pPPHandle->sOutput.planes[0] = (int)outPhys;
+
+    if (sG2dModule.mG2dBlit(pPPHandle->g2dHandle, &pPPHandle->sInput, &pPPHandle->sOutput) != 0) {
+        G2DPP_ERR_LOG("g2d_blit failed
");
+        return BAD_VALUE;
+    }
+
+    if (sG2dModule.mG2dFinish(pPPHandle->g2dHandle) != 0) {
+        G2DPP_ERR_LOG("g2d_finish failed
");
+        return BAD_VALUE;
+    }
+    if (sG2dModule.mG2dClose(pPPHandle->g2dHandle) != 0) {
+        G2DPP_ERR_LOG("g2d_close failed
");
+        return BAD_VALUE;
+    }
+
+    #ifdef DUMP_G2D_OUTPUT
+    dumpOutput(outFd, sOutFormat.bufferSize);
+    #endif
+
+    pPPHandle->g2dHandle = NULL;
+    mInputQueue.pop();
+    mOutputQueue.pop();
+
+    ProcessFrameClear(&sInMemInfo, inIndex);
+
+    NotifyProcessInputUsed(inId);
+    NotifyProcessDone(outId, 0);
+
+    return OK;
+}
+
+status_t G2dPreProcess::onInit() {
+    char g2dlibName[PATH_MAX] = {0};
+    uint32_t alignedWidth = 0;
+    uint32_t alignedHeight = 0;
+
+    if(getDefaultG2DLib(g2dlibName, PATH_MAX)){
+        sG2dModule.hLibHandle = dlopen(g2dlibName, RTLD_NOW);
+    }
+
+    if (nullptr == sG2dModule.hLibHandle) {
+        G2DPP_ERR_LOG("dlopen %s failed, err: %s", g2dlibName, dlerror());
+        return BAD_VALUE;
+    }
+
+    sG2dModule.mG2dOpen = (g2d_func1)dlsym(sG2dModule.hLibHandle, "g2d_open");
+    sG2dModule.mG2dClose = (g2d_func1)dlsym(sG2dModule.hLibHandle, "g2d_close");
+    sG2dModule.mG2dFinish = (g2d_func1)dlsym(sG2dModule.hLibHandle, "g2d_finish");
+    sG2dModule.mG2dBlit = (g2d_func2)dlsym(sG2dModule.hLibHandle, "g2d_blit");
+
+    if (!sG2dModule.mG2dOpen || !sG2dModule.mG2dOpen ||
+            !sG2dModule.mG2dOpen || !sG2dModule.mG2dOpen) {
+        G2DPP_ERR_LOG("dlsym failed, err: %s", dlerror());
+        return BAD_VALUE;
+    }
+
+    pPPHandle = (VpuEncoderGpuHandle*)malloc(sizeof(VpuEncoderGpuHandle));
+    if (!pPPHandle)
+        return BAD_VALUE;
+
+    memset(&pPPHandle->sInput, 0, sizeof(G2DSurface));
+    memset(&pPPHandle->sOutput, 0, sizeof(G2DSurface));
+
+    // MA-16413 workaround: gralloc allocate YV12 buffer and align width with 32, as encoder still
+    // be configured with original width, need to use g2d to crop aligned width to original width
+    // vendor/nxp-opensource/imx/display/display/MemoryDesc.cpp#144, YV12 width is aligned with 32
+    if (sInFormat.format == HAL_PIXEL_FORMAT_YV12 && (sInFormat.width % 32) != 0) {
+        alignedWidth = ((sInFormat.width +31) & ~31);
+    } else
+        alignedWidth = sInFormat.width;
+
+    alignedHeight = sInFormat.height;
+
+    pPPHandle->sInput.format = ConvertColorFmtPixel2G2D(sInFormat.format);
+    pPPHandle->sInput.left = 0;
+    pPPHandle->sInput.top = 0;
+    pPPHandle->sInput.right = sInFormat.width;
+    pPPHandle->sInput.bottom = sInFormat.height;
+    pPPHandle->sInput.width = alignedWidth;
+    pPPHandle->sInput.height = alignedHeight;
+    pPPHandle->sInput.stride = alignedWidth;
+
+    pPPHandle->sOutput.format = G2D_YUYV;
+    pPPHandle->sOutput.left = 0;
+    pPPHandle->sOutput.top = 0;
+    pPPHandle->sOutput.right = sInFormat.width;
+    pPPHandle->sOutput.bottom = sInFormat.height;
+    pPPHandle->sOutput.width = sInFormat.width;
+    pPPHandle->sOutput.height = sInFormat.height;
+    pPPHandle->sOutput.stride = sInFormat.stride;
+
+    sOutFormat.width = pPPHandle->sOutput.width;
+    sOutFormat.height = pPPHandle->sOutput.height;
+    sOutFormat.stride = pPPHandle->sOutput.stride;
+    sOutFormat.format = HAL_PIXEL_FORMAT_YCbCr_422_I;
+    sOutFormat.bufferSize = sOutFormat.width * sOutFormat.height * 2;
+
+    G2DPP_LOG("input right %d bottom %d", pPPHandle->sInput.right, pPPHandle->sInput.bottom);
+    G2DPP_LOG("input aligned w h = %d x %d", alignedWidth, alignedHeight);
+
+    if (OK != AllocateProcessBuffers(DEFAULT_PROCESS_BUFFER_NUM))
+        return BAD_VALUE;
+
+    return OK;
+}
+
+status_t G2dPreProcess::onDestroy() {
+    if (pPPHandle) {
+        free(pPPHandle);
+        pPPHandle = nullptr;
+    }
+
+    if (sG2dModule.hLibHandle) {
+        // no need to close lib handle becuase it can be used for next instance.
+        // follow the usage as hwcomposer/camera.
+        //dlclose(sG2dModule.hLibHandle);
+        memset(&sG2dModule, 0, sizeof(G2D_MODULE));
+    }
+
+    return OK;
+}
+status_t G2dPreProcess::onStart()
+{
+    return OK;
+}
+status_t G2dPreProcess::onStop()
+{
+    return OK;
+}
+status_t G2dPreProcess::DoSetConfig(ProcessConfig index, void* pConfig) {
+    return BAD_VALUE; // not support any index yet
+}
+
+status_t G2dPreProcess::DoGetConfig(ProcessConfig index, void* pConfig) {
+    return BAD_VALUE; // not support any index yet
+}
+
+ProcessBase * CreatePreProcessInstance() {
+    return static_cast<ProcessBase *>(new G2dPreProcess());
+}
+
+
+} // namespcae android
diff --git a/codec2/process/g2d_pre/G2dPreProcess.h b/codec2/process/g2d_pre/G2dPreProcess.h
new file mode 100644
index 0000000..a65b6f6
--- /dev/null
+++ b/codec2/process/g2d_pre/G2dPreProcess.h
@@ -0,0 +1,61 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef G2D_PRE_PROCESS_BASE_H
+#define G2D_PRE_PROCESS_BASE_H
+
+#include <queue>
+
+#include "ProcessBase.h"
+#include "g2d.h"
+
+namespace android {
+
+typedef struct g2d_surface G2DSurface;
+
+typedef struct {
+    void * g2dHandle;
+    G2DSurface sInput;
+    G2DSurface sOutput;
+} VpuEncoderGpuHandle;
+
+typedef int (*g2d_func1)(void* handle);
+typedef int (*g2d_func2)(void* handle, void* arg1, void* arg2);
+
+typedef struct {
+    void * hLibHandle;
+    g2d_func1 mG2dOpen;
+    g2d_func1 mG2dFinish;
+    g2d_func1 mG2dClose;
+    g2d_func2 mG2dBlit;
+} G2D_MODULE;
+
+
+
+class G2dPreProcess : public ProcessBase {
+public:
+    G2dPreProcess();
+    virtual ~G2dPreProcess();
+
+    status_t onInit() override;
+    status_t onDestroy() override;
+    status_t onStart() override;
+    status_t onStop() override;
+protected:
+    status_t onProcess() override;
+    status_t DoSetConfig(ProcessConfig index, void* pConfig) override;
+    status_t DoGetConfig(ProcessConfig index, void* pConfig) override;
+
+private:
+    VpuEncoderGpuHandle* pPPHandle; // preprocess handle
+    G2D_MODULE sG2dModule;
+};
+
+} // namespcae android
+
+#endif // G2D_PRE_PROCESS_BASE_H
\ No newline at end of file
diff --git a/codec2/process/g2d_pre/imx_process_g2d_pre.go b/codec2/process/g2d_pre/imx_process_g2d_pre.go
new file mode 100644
index 0000000..bf85a83
--- /dev/null
+++ b/codec2/process/g2d_pre/imx_process_g2d_pre.go
@@ -0,0 +1,55 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package imx_process_g2d_pre
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_process_g2d_pre_defaults", process_g2d_preDefaultsFactory)
+}
+
+
+func process_g2d_preDefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, process_g2d_preDefaults)
+    return module
+}
+
+func process_g2d_preDefaults(ctx android.LoadHookContext) {
+    var Cflags []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Cflags []string
+                }
+        }
+    }
+    p := &props{}
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8MM") || strings.Contains(board, "IMX8MP"){
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else {
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
+    }
+
+    p.Target.Android.Cflags = Cflags
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/process/imx_process.go b/codec2/process/imx_process.go
new file mode 100755
index 0000000..805dbaa
--- /dev/null
+++ b/codec2/process/imx_process.go
@@ -0,0 +1,61 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package imx_process_g2d_post
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_process_defaults", imx_processDefaultsFactory)
+}
+
+func imx_processDefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, imx_processDefaults)
+    return module
+}
+
+func imx_processDefaults(ctx android.LoadHookContext) {
+    var Shared_libs []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Shared_libs []string
+                }
+        }
+    }
+    p := &props{}
+    p.Target.Android.Enabled = proptools.BoolPtr(false)
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8MM") || strings.Contains(board, "IMX8MP") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_process_g2d_pre")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_process_dummy_post")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    }else if strings.Contains(board, "IMX8Q") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_process_isi_pre")
+		Shared_libs = append(Shared_libs, "lib_imx_c2_process_g2d_post")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    }else if strings.Contains(board, "IMX8MQ") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_process_dummy_post")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    }
+    p.Target.Android.Shared_libs = Shared_libs
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/process/isi_pre/Android.bp b/codec2/process/isi_pre/Android.bp
new file mode 100755
index 0000000..ae72cd8
--- /dev/null
+++ b/codec2/process/isi_pre/Android.bp
@@ -0,0 +1,81 @@
+imx_c2_process_isi_pre_defaults {
+    name: "imx_c2_process_isi_pre_default",
+}
+
+bootstrap_go_package {
+    name: "soong-imx_process_isi_pre",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/process/isi_pre",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "imx_process_isi_pre.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+cc_library_shared {
+    name: "lib_imx_c2_process_isi_pre",
+
+    defaults: ["imx_c2_process_isi_pre_default"],
+
+    soc_specific: true,
+    srcs: [
+        "IsiPreProcess.cpp",
+    ],
+
+    header_libs: [
+        "libcodec2_headers",
+        "media_plugin_headers",
+    ],
+
+    include_dirs: [
+        "hardware/libhardware/include",
+        "frameworks/av",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp/imx_android_mm/codec2/tsm",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+        "vendor/nxp/fsl-proprietary/include",
+        "vendor/nxp/imx_android_mm/codec2/v4l2_dev",
+        "vendor/nxp/imx_android_mm/codec2/include",
+		"vendor/nxp/imx_android_mm/codec2/process/common",
+	],
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "libion",
+        "lib_imx_c2_componentbase",
+        "libcodec2_vndk",
+        "lib_c2_imx_store",
+        "lib_imx_c2_v4l2_dev",
+		"lib_imx_c2_process",
+    ],
+
+    whole_static_libs: ["libionallocator"],
+
+    sanitize: {
+        cfi: true,
+        misc_undefined: [
+            "unsigned-integer-overflow",
+            "signed-integer-overflow",
+        ],
+        diag: {
+            cfi: true,
+        },
+    },
+
+//    compile_multilib: "32",
+}
+
diff --git a/codec2/process/isi_pre/IsiPreProcess.cpp b/codec2/process/isi_pre/IsiPreProcess.cpp
new file mode 100644
index 0000000..2dd1330
--- /dev/null
+++ b/codec2/process/isi_pre/IsiPreProcess.cpp
@@ -0,0 +1,802 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "IsiPreProcess"
+
+#include "IsiPreProcess.h"
+#include <linux/videodev2.h>
+#include "graphics_ext.h"
+#include "C2_imx.h"
+
+namespace android {
+#define Align(ptr,align)    (((uint32_t)(ptr)+(align)-1)/(align)*(align))
+
+status_t IsiPreProcess::onInit(){
+    status_t ret = UNKNOWN_ERROR;
+
+    if(pDev == NULL){
+        pDev = new V4l2Dev();
+    }
+    if(pDev == NULL)
+        return ret;
+
+    mFd = pDev->Open(V4L2_DEV_ISI);
+    ALOGV("onInit pV4l2Dev->Open fd=%d",mFd);
+
+    if(mFd < 0)
+        return ret;
+
+    mInMemType = V4L2_MEMORY_DMABUF;
+    mOutMemType = V4L2_MEMORY_DMABUF;
+    mAddOutCnt = 0;
+
+    mWidthAlign = 1;
+    mHeightAlign = 1;
+
+    struct v4l2_frmsizeenum info;
+    memset(&info, 0, sizeof(v4l2_frmsizeenum));
+    if(OK == pDev->GetFormatFrameInfo(mOutFormat, &info)){
+        mWidthAlign = info.stepwise.step_width;
+        mHeightAlign = info.stepwise.step_height;
+    }
+    //align with v4l2 encoder
+    mWidthAlign = 16;
+
+    ret = prepareInputParams();
+    if(ret != OK){
+        ALOGE("prepareInputParams failed");
+        return ret;
+    }
+
+    ret = SetInputFormats();
+    if(ret != OK){
+        ALOGE("SetInputFormats failed");
+        return ret;
+    }
+
+    ret = prepareInputBuffers();
+    if(ret != OK){
+        ALOGE("prepareInputBuffers failed");
+        return ret;
+    }
+    
+    ret = prepareOutputParams();
+    if(ret != OK){
+        ALOGE("SetInputFormats failed");
+        return ret;
+    }
+
+    ret = SetOutputFormats();
+    if(ret != OK){
+        ALOGE("SetOutputFormats failed");
+        return ret;
+    }
+
+    if (OK != AllocateProcessBuffers(DEFAULT_PROCESS_BUFFER_NUM, kOutputBufferPlaneNum, &mOutputPlaneSize[0]))
+        return BAD_VALUE;
+
+    ret = prepareOutputBuffers();
+    if(ret != OK){
+        ALOGE("prepareInputBuffers failed");
+        return ret;
+    }
+
+    bPollStarted = false;
+    bInputStreamOn = false;
+    bOutputStreamOn = false;
+    bSyncFrame = false;
+    mAsync = true;
+
+    ret = createPollThread();
+
+    return ret;
+}
+
+typedef struct{
+    uint32_t v4l2_format;
+    int pixel_format;
+}V4L2_FORMAT_TABLE;
+
+static V4L2_FORMAT_TABLE color_format_table[]={
+{v4l2_fourcc('R', 'G', 'B', 'A'), HAL_PIXEL_FORMAT_RGBA_8888},
+{v4l2_fourcc('R', 'G', 'B', 'A'), HAL_PIXEL_FORMAT_RGBX_8888},
+{V4L2_PIX_FMT_RGB565, HAL_PIXEL_FORMAT_RGB_565},
+{V4L2_PIX_FMT_NV12, HAL_PIXEL_FORMAT_YCbCr_420_SP},
+};
+
+uint32_t IsiPreProcess::getV4l2Format(uint32_t color_format)
+{
+    uint32_t i=0;
+
+    for(i = 0; i < sizeof(color_format_table)/sizeof(V4L2_FORMAT_TABLE);i++){
+        if(color_format == color_format_table[i].pixel_format){
+            return color_format_table[i].v4l2_format;
+        }
+    }
+
+    return 0;
+}
+status_t IsiPreProcess::prepareInputParams()
+{
+    status_t ret = UNKNOWN_ERROR;
+    Mutex::Autolock autoLock(mLock);
+
+    sInFormat.width = Align(sInFormat.width, mWidthAlign);
+    sInFormat.height = sInFormat.height;
+    sInFormat.stride = Align(sInFormat.stride, mWidthAlign);
+
+    mInFormat = getV4l2Format(sInFormat.format);
+
+    ALOGV("prepareInputParams width=%d,height=%d,format=%x",sInFormat.width,sInFormat.height, mInFormat);
+
+    if(mInFormat == v4l2_fourcc('R', 'G', 'B', 'A')){
+        sInFormat.bufferSize = sInFormat.width * sInFormat.height * 4;
+    }else{
+        ALOGE("mInFormat is not RGBA");
+        return ret;
+    }
+
+    return OK;
+}
+
+status_t IsiPreProcess::prepareOutputParams()
+{
+    status_t ret = UNKNOWN_ERROR;
+    Mutex::Autolock autoLock(mLock);
+
+    sOutFormat.width = Align(sInFormat.width, mWidthAlign);
+    sOutFormat.height = sInFormat.height;
+    sOutFormat.stride = Align(sInFormat.stride, mWidthAlign);
+    sOutFormat.format = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+    mOutFormat = getV4l2Format(sOutFormat.format);
+
+    ALOGV("sOutFormat width=%d,height=%d,format=%x",sOutFormat.width,sOutFormat.height, mOutFormat);
+
+    if(mOutFormat == V4L2_PIX_FMT_NV12){
+        mOutputPlaneSize[0] = Align(sOutFormat.width, mWidthAlign) * Align(sOutFormat.height, mHeightAlign);
+        mOutputPlaneSize[1] = mOutputPlaneSize[0]/2;
+        sOutFormat.bufferSize = mOutputPlaneSize[0] + mOutputPlaneSize[1];
+    }else{
+        ALOGE("mOutFormat is not NV12");
+        return ret;
+    }
+
+    return OK;
+}
+status_t IsiPreProcess::SetInputFormats()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_format format;
+    memset(&format, 0, sizeof(format));
+
+    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    format.fmt.pix_mp.num_planes = kInputBufferPlaneNum;
+    format.fmt.pix_mp.pixelformat = mInFormat;
+    format.fmt.pix_mp.width = sInFormat.width;
+    format.fmt.pix_mp.height = sInFormat.height;
+    format.fmt.pix_mp.plane_fmt[0].sizeimage = sInFormat.bufferSize;
+    format.fmt.pix_mp.plane_fmt[0].bytesperline = sInFormat.stride;
+    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+
+    result = ioctl (mFd, VIDIOC_S_FMT, &format);
+    if(result != 0){
+        ALOGE("IsiPreProcess VIDIOC_S_FMT OUTPUT_MPLANE failed");
+        return UNKNOWN_ERROR;
+    }
+
+    memset(&format, 0, sizeof(struct v4l2_format));
+    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+
+    result = ioctl (mFd, VIDIOC_G_FMT, &format);
+    if(result < 0)
+        return UNKNOWN_ERROR;
+
+
+    if(format.fmt.pix_mp.pixelformat != mInFormat){
+        ALOGE("SetInputFormats mOutFormat mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.width != sInFormat.width ||
+        format.fmt.pix_mp.height != sInFormat.height){
+        ALOGE("SetInputFormats resolution mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].sizeimage != sInFormat.bufferSize){
+        ALOGE("SetInputFormats bufferSize mismatch sizeimage=%d,buffersize=%d", format.fmt.pix_mp.plane_fmt[0].sizeimage, sInFormat.bufferSize);
+        return UNKNOWN_ERROR;
+    }
+
+    ALOGV("SetInputFormats success mInFormat=%x,width=%d,height=%d",mInFormat, sInFormat.width, sInFormat.height);
+    return OK;
+}
+status_t IsiPreProcess::SetOutputFormats()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_format format;
+    memset(&format, 0, sizeof(format));
+    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    format.fmt.pix_mp.num_planes = kOutputBufferPlaneNum;
+    format.fmt.pix_mp.pixelformat = mOutFormat;
+    format.fmt.pix_mp.plane_fmt[0].sizeimage = mOutputPlaneSize[0];
+    format.fmt.pix_mp.plane_fmt[0].bytesperline = sOutFormat.stride;
+    format.fmt.pix_mp.plane_fmt[1].sizeimage = mOutputPlaneSize[1];
+    format.fmt.pix_mp.plane_fmt[1].bytesperline = sOutFormat.stride;
+    format.fmt.pix_mp.width = sOutFormat.width;
+    format.fmt.pix_mp.height = sOutFormat.height;
+    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+    ALOGV("SetOutputFormats mOutFormat=%x,w=%d,h=%d,stride=%d,size0=%d,size1=%d",
+        mOutFormat,sOutFormat.width,sOutFormat.height,sOutFormat.stride,mOutputPlaneSize[0],mOutputPlaneSize[1]);
+    result = ioctl (mFd, VIDIOC_S_FMT, &format);
+    if(result != 0){
+        ALOGE("IsiPreProcess VIDIOC_S_FMT CAPTURE_MPLANE failed err=%d",result);
+        return UNKNOWN_ERROR;
+    }
+
+    memset(&format, 0, sizeof(format));
+    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+
+    result = ioctl (mFd, VIDIOC_G_FMT, &format);
+    if(result != 0)
+        return UNKNOWN_ERROR;
+
+    if(format.fmt.pix_mp.pixelformat != mOutFormat){
+        ALOGE("SetOutputFormats mInFormat mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if( format.fmt.pix_mp.width != sOutFormat.width ||
+        format.fmt.pix_mp.height != sOutFormat.height){
+        ALOGE("SetOutputFormats resolution mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].bytesperline != sOutFormat.stride){
+        ALOGE("SetOutputFormats stride mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].sizeimage != mOutputPlaneSize[0] ||
+        format.fmt.pix_mp.plane_fmt[1].sizeimage != mOutputPlaneSize[1]){
+        ALOGE("SetOutputFormats bufferSize mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    return OK;
+}
+status_t IsiPreProcess::prepareInputBuffers()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = 16;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.memory = mInMemType;
+    ALOGV("prepareInputBuffers VIDIOC_REQBUFS bufferNum=%d",reqbufs.count);
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0){
+        ALOGE("VIDIOC_REQBUFS failed result=%d",result);
+        return UNKNOWN_ERROR;
+    }
+    ALOGV("prepareInputBuffers reqbufs.count=%d",reqbufs.count);
+
+    return OK;
+}
+status_t IsiPreProcess::prepareOutputBuffers()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = DEFAULT_PROCESS_BUFFER_NUM;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.memory = mOutMemType;
+    ALOGV("prepareOutputBuffers VIDIOC_REQBUFS bufferNum=%d",reqbufs.count);
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0){
+        ALOGE("VIDIOC_REQBUFS failed result=%d",result);
+        return UNKNOWN_ERROR;
+    }
+
+    ALOGV("prepareOutputBuffers reqbufs.count=%d",reqbufs.count);
+
+    return OK;
+}
+status_t IsiPreProcess::HandlePollThread()
+{
+    status_t ret = OK;
+    int32_t poll_ret = 0;
+
+    while(bPollStarted){
+        ALOGV("pollThreadHandler BEGIN");
+        poll_ret = pDev->Poll();
+        ALOGV("pollThreadHandler poll_ret=%x",poll_ret);
+
+        if(!bPollStarted)
+            break;
+
+        if(poll_ret & V4L2_DEV_POLL_OUTPUT){
+            ret = dequeueInputBuffer();
+        }
+        if(poll_ret & V4L2_DEV_POLL_CAPTURE){
+            ret = dequeueOutputBuffer();
+        }
+        ALOGV("pollThreadHandler END ret=%x",ret);
+    }
+    ALOGV("HandlePollThread return");
+    return OK;
+
+}
+status_t IsiPreProcess::createPollThread()
+{
+    Mutex::Autolock autoLock(mLock);
+
+    if(!bPollStarted){
+        pthread_attr_t attr;
+        pthread_attr_init(&attr);
+        pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+
+        bPollStarted = true;
+        pthread_create(&mPollThread, &attr, PollThreadWrapper, this);
+        pthread_attr_destroy(&attr);
+    }
+    return OK;
+}
+
+status_t IsiPreProcess::destroyPollThread()
+{
+    ALOGV("destroyPollThread BEGIN");
+
+    if(bPollStarted){
+        bPollStarted = false;
+        ALOGV("destroyPollThread bPollStarted FALSE");
+        usleep(1000);
+        mLock.lock();
+        pthread_join(mPollThread, NULL);
+        mLock.unlock();
+    }
+    return OK;
+}
+status_t IsiPreProcess::dequeueInputBuffer()
+{
+    int result = 0;
+    int input_id = -1;
+    Mutex::Autolock autoLock(mLock);
+    if(!bInputStreamOn)
+        return OK;
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane plane[kInputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(plane, 0, sizeof(v4l2_plane));
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    stV4lBuf.memory = mInMemType;
+    stV4lBuf.m.planes = plane;
+    stV4lBuf.length = kInputBufferPlaneNum;
+    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+    if(result < 0)
+        return UNKNOWN_ERROR;
+
+    ALOGV("OUTPUT_MPLANE VIDIOC_DQBUF index=%d
", stV4lBuf.index);
+
+    if(stV4lBuf.index >= 16)
+        return BAD_INDEX;
+
+    ALOGV("dequeueInputBuffer NotifyInputBufferUsed id=%d",stV4lBuf.index);
+
+
+    int inId = 0;
+    int inFd = -1;
+    uint32_t inFlag = 0;
+    unsigned long inPhys;
+
+    if(OK == ProcessFrameGetNode(&sInMemInfo, stV4lBuf.index, &inPhys, &inId, &inFd, &inFlag)){
+        ProcessFrameClear(&sInMemInfo, stV4lBuf.index);
+        NotifyProcessInputUsed(inId);
+    }
+
+    return OK;
+}
+status_t IsiPreProcess::dequeueOutputBuffer()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+    if(!bOutputStreamOn)
+        return OK;
+
+    uint64_t ts = 0;
+    uint32_t out_len = 0;
+    int keyFrame = 0;
+    uint32_t out_offset = 0;
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kOutputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(planes, 0, sizeof(planes));
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    stV4lBuf.memory = mOutMemType;
+    stV4lBuf.m.planes = planes;
+    stV4lBuf.length = kOutputBufferPlaneNum;
+    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+    if(result < 0)
+        return UNKNOWN_ERROR;
+
+    if(stV4lBuf.index >= DEFAULT_PROCESS_BUFFER_NUM)
+        return BAD_INDEX;
+
+    out_len = stV4lBuf.m.planes[0].bytesused;
+    ts = (uint64_t)stV4lBuf.timestamp.tv_sec *1000000;
+    ts += stV4lBuf.timestamp.tv_usec;
+    keyFrame = (stV4lBuf.flags & V4L2_BUF_FLAG_KEYFRAME)?1:0;
+
+    ALOGV("CAPTURE_MPLANE VIDIOC_DQBUF index=%d, len=%d,ts=%lld,flag=%x",stV4lBuf.index, out_len, (long long)ts, stV4lBuf.flags);
+
+
+    int outId = 0;
+    int outFd = -1;
+    uint32_t outFlag = 0;
+    unsigned long outPhys;
+
+    if(OK == ProcessFrameGetNode(&sOutMemInfo, stV4lBuf.index, &outPhys, &outId, &outFd, &outFlag)){
+        //ProcessFrameClear(&sOutMemInfo, stV4lBuf.index);
+        if(keyFrame)
+            outFlag = FLAG_SYNC_FRAME;
+        NotifyProcessDone(outId, outFlag);
+        ALOGV("NotifyProcessDone blockId=%d,len=%d,ts=%lld,keyFrame=%x,out_offset=%d",outId, out_len, (long long)ts, keyFrame,out_offset);
+
+    }
+
+    return OK;
+}
+status_t IsiPreProcess::queueInput()
+{
+    //return error for no more input
+    if (0 == mInputQueue.size()){
+        return OK;
+    }
+
+    status_t ret = OK;
+    int result = 0;
+    int inIndex = 0;;
+    int inId = 0;
+    int inFd = -1;
+    unsigned long inPhys;
+    uint32_t flag = 0;
+
+    inIndex = mInputQueue.front();
+
+    ret = ProcessFrameGetNode(&sInMemInfo, inIndex, &inPhys, &inId, &inFd, &flag);
+    if(ret != OK){
+        return ret;
+    }
+
+    uint32_t v4l2_flags = 0;
+
+    //TODO: handle eos, sync frame flag, timestamps
+    if(flag & C2FrameData::FLAG_END_OF_STREAM && inFd < 0){
+        return BAD_VALUE;
+    }
+
+    if(flag & C2FrameData::FLAG_END_OF_STREAM)
+        v4l2_flags |= V4L2_BUF_FLAG_LAST;
+
+    if(bSyncFrame/*flag & FLAG_SYNC_FRAME*/){
+        v4l2_flags |= V4L2_BUF_FLAG_KEYFRAME;
+        bSyncFrame = false;
+    }
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane plane[kInputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(&plane[0], 0, kInputBufferPlaneNum * sizeof(struct v4l2_plane));
+
+    plane[0].bytesused = sInFormat.bufferSize;
+    plane[0].length = sInFormat.bufferSize;
+    plane[0].data_offset = 0;
+
+    if(mInMemType == V4L2_MEMORY_DMABUF){
+        plane[0].m.fd = inFd;
+    }
+
+    stV4lBuf.index = inIndex;
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    //stV4lBuf.timestamp.tv_sec = input->timestamp/1000000;
+    //stV4lBuf.timestamp.tv_usec = input->timestamp - stV4lBuf.timestamp.tv_sec * 1000000;
+    stV4lBuf.memory = mInMemType;
+    stV4lBuf.m.planes = &plane[0];
+    stV4lBuf.length = kInputBufferPlaneNum;
+    stV4lBuf.flags = v4l2_flags;
+
+    ALOGV("OUTPUT_MPLANE VIDIOC_QBUF index=%d,len=%d,fd=%d, ts=%lld, v4l2_flags=%x
",
+        stV4lBuf.index, plane[0].bytesused, plane[0].m.fd, (long long)0, v4l2_flags);
+
+    result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
+    if(result < 0){
+        ALOGE("OUTPUT_MPLANE VIDIOC_QBUF failed, index=%d, result=%x",inIndex,result);
+        return UNKNOWN_ERROR;
+    }
+
+    mInputQueue.pop();
+
+    if(!bInputStreamOn)
+        startInputStream();
+
+    return OK;
+}
+status_t IsiPreProcess::queueOutput()
+{
+    //return error for no more input
+    if (0 == mOutputQueue.size()){
+        return OK;
+    }
+
+    status_t ret = OK;
+    int result = 0;
+    int outIndex = 0;
+    int outId = 0;
+    int outFd = -1;
+    uint32_t outFlag = 0;
+    unsigned long outPhys;
+    
+    outIndex = mOutputQueue.front();
+
+    ret = ProcessFrameGetNode(&sOutMemInfo, outIndex, &outPhys, &outId, &outFd, &outFlag);
+    if(ret != OK){
+        return ret;
+    }
+
+    uint32_t v4l2_flags = 0;
+
+    //TODO: handle eos, sync frame flag, timestamps
+    #if 0
+    bool eos = input->eos;
+
+    if(eos)
+        v4l2_flags |= V4L2_BUF_FLAG_LAST;
+
+    if((int64_t)input->timestamp >= 0)
+        v4l2_flags |= (V4L2_BUF_FLAG_TIMESTAMP_MASK | V4L2_BUF_FLAG_TIMESTAMP_COPY);
+
+    if(bSyncFrame){
+        v4l2_flags |= V4L2_BUF_FLAG_KEYFRAME;
+        bSyncFrame = false;
+    }
+    #endif
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kOutputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(&planes[0], 0, kOutputBufferPlaneNum * sizeof(struct v4l2_plane));
+
+    planes[0].bytesused = mOutputPlaneSize[0];
+    planes[0].length = mOutputPlaneSize[0];
+    planes[0].data_offset = 0;
+    
+    planes[1].bytesused = mOutputPlaneSize[1];
+    planes[1].length = mOutputPlaneSize[1];
+    planes[1].data_offset = 0;
+
+    if(mInMemType == V4L2_MEMORY_DMABUF){
+        planes[0].m.fd = (int)outPhys;
+        planes[1].m.fd = outFd;
+    }
+
+    stV4lBuf.index = outIndex;
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    //stV4lBuf.timestamp.tv_sec = input->timestamp/1000000;
+    //stV4lBuf.timestamp.tv_usec = input->timestamp - stV4lBuf.timestamp.tv_sec * 1000000;
+    stV4lBuf.memory = mOutMemType;
+    stV4lBuf.m.planes = &planes[0];
+    stV4lBuf.length = kOutputBufferPlaneNum;
+    stV4lBuf.flags = v4l2_flags;
+
+    ALOGV("CAPTURE_MPLANE VIDIOC_QBUF index=%d,len0=%d,len1=%d, fd0=%d,fd1=%d ts=%lld
",
+        stV4lBuf.index, planes[0].length, planes[1].length, planes[0].m.fd, planes[1].m.fd, (long long)0);
+
+    result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
+    if(result < 0){
+        ALOGE("CAPTURE_MPLANE VIDIOC_QBUF failed, index=%d, result=%x",outIndex,result);
+        return UNKNOWN_ERROR;
+    }
+
+    mAddOutCnt++;
+    mOutputQueue.pop();
+
+    if(!bOutputStreamOn && mAddOutCnt == DEFAULT_PROCESS_BUFFER_NUM)
+        startOutputStream();
+
+    return OK;
+}
+// static
+void *IsiPreProcess::PollThreadWrapper(void *me) {
+    return (void *)(uintptr_t)static_cast<IsiPreProcess *>(me)->HandlePollThread();
+}
+
+status_t IsiPreProcess::onProcess() {
+
+    status_t ret = OK;
+    ret = queueInput();
+    if(ret != OK)
+        ALOGE("queueInput failed ret=%x",ret);
+
+    while (mOutputQueue.size() > 0) {
+        ret = queueOutput();
+        if(ret != OK)
+            ALOGE("queueOutput failed ret=%x",ret);
+    }
+    return ret;
+}
+status_t IsiPreProcess::startInputStream()
+{
+    Mutex::Autolock autoLock(mLock);
+    if(!bInputStreamOn){
+        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
+            bInputStreamOn = true;
+            ALOGV("VIDIOC_STREAMON OUTPUT_MPLANE success");
+        }
+    }
+    return OK;
+}
+status_t IsiPreProcess::stopInputStream()
+{
+    Mutex::Autolock autoLock(mLock);
+    if(bInputStreamOn){
+        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        if(0 == ioctl(mFd, VIDIOC_STREAMOFF, &buf_type)){
+            bInputStreamOn = false;
+            ALOGV("VIDIOC_STREAMOFF OUTPUT_MPLANE success");
+        }
+    }
+
+    return OK;
+}
+status_t IsiPreProcess::startOutputStream()
+{
+    Mutex::Autolock autoLock(mLock);
+    if(!bOutputStreamOn){
+        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
+            bOutputStreamOn = true;
+            ALOGV("VIDIOC_STREAMON CAPTURE_MPLANE success");
+        }
+    }
+    return OK;
+}
+status_t IsiPreProcess::stopOutputStream()
+{
+    Mutex::Autolock autoLock(mLock);
+
+    //call VIDIOC_STREAMOFF and ignore the result
+    enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    ioctl(mFd, VIDIOC_STREAMOFF, &buf_type);
+    bOutputStreamOn = false;
+    ALOGV("VIDIOC_STREAMOFF CAPTURE_MPLANE success");
+
+    return OK;
+}
+status_t IsiPreProcess::destroyInputBuffers()
+{
+    Mutex::Autolock autoLock(mLock);
+
+    int result = 0;
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = 0;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
+
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0)
+        return UNKNOWN_ERROR;
+
+    ALOGV("destroyInputBuffers success");
+    return OK;
+}
+status_t IsiPreProcess::destroyOutputBuffers()
+{
+    Mutex::Autolock autoLock(mLock);
+
+    int result = 0;
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = 0;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
+
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0)
+        return UNKNOWN_ERROR;
+
+    ALOGV("destroyOutputBuffers success");
+    return OK;
+}
+status_t IsiPreProcess::onFlush()
+{
+    stopInputStream();
+    stopOutputStream();
+    mAddOutCnt = 0;
+    return OK;
+}
+status_t IsiPreProcess::onDestroy()
+{
+    if(mAddOutCnt != 0)
+        onFlush();
+
+    destroyPollThread();
+
+    Mutex::Autolock autoLock(mLock);
+
+    if(pDev == NULL)
+        return UNKNOWN_ERROR;
+
+    if(mFd > 0){
+        pDev->Close();
+        mFd = 0;
+    }
+
+    if(pDev != NULL)
+        delete pDev;
+    pDev = NULL;
+
+    return OK;
+}
+status_t IsiPreProcess::onStart()
+{
+    createPollThread();
+    return OK;
+}
+status_t IsiPreProcess::onStop()
+{
+    onFlush();
+    destroyPollThread();
+    return OK;
+}
+status_t IsiPreProcess::DoSetConfig(ProcessConfig index, void* pConfig) {
+
+    status_t ret = BAD_VALUE;
+
+    if (!pConfig)
+        return ret;
+    
+    switch (index) {
+        case PROCESS_CONFIG_INTRA_REFRESH: {
+            if(0 == (*(int*)pConfig))
+                bSyncFrame = false;
+            else
+                bSyncFrame = true;
+            ret = OK;
+            break;
+        }
+        default: {
+            break;
+        }
+    }
+
+    return ret;
+}
+
+status_t IsiPreProcess::DoGetConfig(ProcessConfig index, void* pConfig) {
+    return BAD_VALUE; // not support any index yet
+}
+ProcessBase * CreatePreProcessInstance() {
+    return static_cast<ProcessBase *>(new IsiPreProcess());
+}
+}
diff --git a/codec2/process/isi_pre/IsiPreProcess.h b/codec2/process/isi_pre/IsiPreProcess.h
new file mode 100644
index 0000000..21d69a1
--- /dev/null
+++ b/codec2/process/isi_pre/IsiPreProcess.h
@@ -0,0 +1,85 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef ISI_PRE_PROCESS_H
+#define ISI_PRE_PROCESS_H
+
+#include <queue>
+#include "V4l2Dev.h"
+#include "ProcessBase.h"
+
+namespace android {
+
+class IsiPreProcess : public ProcessBase{
+public:
+    status_t onInit() override;
+    status_t onDestroy() override;
+    status_t onStart() override;
+    status_t onStop() override;
+protected:
+    status_t onProcess() override;
+    status_t DoSetConfig(ProcessConfig index, void* pConfig) override;
+    status_t DoGetConfig(ProcessConfig index, void* pConfig) override;
+    status_t onFlush();
+
+private:
+    enum {
+        kInputBufferPlaneNum = 1,
+        kOutputBufferPlaneNum = 2,
+    };
+
+    int32_t mFd;
+    V4l2Dev* pDev;
+
+    pthread_t mPollThread;
+    
+    enum v4l2_memory mInMemType;//support userptr and dma
+    enum v4l2_memory mOutMemType;//support userptr and dma
+ 
+    uint32_t mInFormat;//v4l2 output format
+    uint32_t mOutFormat;//v4l2 capture format
+    uint32_t mOutputPlaneSize[kOutputBufferPlaneNum];
+
+    uint32_t mWidthAlign;
+    uint32_t mHeightAlign;
+
+    Mutex mLock;
+
+    uint64_t mAddOutCnt;
+    
+    bool bPollStarted;
+    bool bInputStreamOn;
+    bool bOutputStreamOn;
+    bool bSyncFrame;
+
+    uint32_t getV4l2Format(uint32_t color_format);
+    status_t prepareInputParams();
+    status_t prepareOutputParams();
+    status_t SetInputFormats();
+    status_t SetOutputFormats();
+    status_t prepareInputBuffers();
+    status_t prepareOutputBuffers();
+    status_t HandlePollThread();
+    status_t createPollThread();
+    static void *PollThreadWrapper(void *);
+    status_t destroyPollThread();
+    status_t dequeueInputBuffer();
+    status_t dequeueOutputBuffer();
+    status_t queueInput();
+    status_t queueOutput();
+    status_t startInputStream();
+    status_t stopInputStream();
+    status_t startOutputStream();
+    status_t stopOutputStream();
+    status_t destroyInputBuffers();
+    status_t destroyOutputBuffers();
+
+};
+
+}
+#endif
diff --git a/codec2/process/isi_pre/imx_process_isi_pre.go b/codec2/process/isi_pre/imx_process_isi_pre.go
new file mode 100644
index 0000000..b4c211a
--- /dev/null
+++ b/codec2/process/isi_pre/imx_process_isi_pre.go
@@ -0,0 +1,55 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package imx_process_isi_pre
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_process_isi_pre_defaults", process_isi_preDefaultsFactory)
+}
+
+
+func process_isi_preDefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, process_isi_preDefaults)
+    return module
+}
+
+func process_isi_preDefaults(ctx android.LoadHookContext) {
+    var Cflags []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Cflags []string
+                }
+        }
+    }
+    p := &props{}
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8Q") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else {
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
+    }
+
+    p.Target.Android.Cflags = Cflags
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/store/Android.bp b/codec2/store/Android.bp
new file mode 100644
index 0000000..15f373a
--- /dev/null
+++ b/codec2/store/Android.bp
@@ -0,0 +1,65 @@
+cc_library_shared {
+    name: "lib_c2_imx_store",
+
+    srcs: [
+        "RegistryParser.cpp",
+        "ImxC2Store.cpp",
+    ],
+
+    shared_libs: [
+        "libcutils",
+        "libcodec2_hidl@1.0",
+        "liblog",
+        "libcodec2_vndk",
+    ],
+
+    include_dirs: [
+        "vendor/nxp/imx_android_mm/codec2/include",
+    ],
+
+    defaults: [
+        "imx_defaults",
+    ],
+
+}
+
+cc_binary {
+    name: "android.hardware.media.c2@1.0-service",
+    defaults: ["hidl_defaults"],
+    soc_specific: true,
+    relative_install_path: "hw",
+    srcs: [
+        "ImxService.cpp",
+    ],
+
+    init_rc: ["android.hardware.media.c2@1.0-service.rc"],
+
+    shared_libs: [
+        "android.hardware.media.c2@1.0",
+        "android.hardware.media.omx@1.0",
+        "libavservices_minijail_vendor",
+        "libbinder",
+        "libcodec2_hidl@1.0",
+        "libhidlbase",
+        "libhidltransport",
+        "liblog",
+        "libstagefright_omx",
+        "libutils",
+        "lib_c2_imx_store",
+    ],
+
+    include_dirs: [
+        "vendor/nxp/imx_android_mm/codec2/include",
+    ],
+
+    arch: {
+        arm: {
+            required: ["codec2.vendor.base.policy"],
+        },
+        x86: {
+            required: ["codec2.vendor.base.policy"],
+        },
+    },
+
+    compile_multilib: "64",
+}
diff --git a/codec2/store/ImxC2Store.cpp b/codec2/store/ImxC2Store.cpp
new file mode 100755
index 0000000..7785ad5
--- /dev/null
+++ b/codec2/store/ImxC2Store.cpp
@@ -0,0 +1,478 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+#define LOG_NDEBUG 0
+#define LOG_TAG "ImxC2Store"
+#include <log/log.h>
+
+#include <cutils/properties.h>
+#include <C2ComponentFactory.h>
+#include <C2Config.h>
+#include <util/C2InterfaceHelper.h>
+#include <C2AllocatorGralloc.h>
+#include <C2AllocatorIon.h>
+#include <dlfcn.h>
+#include <C2_imx.h>
+#include "RegistryParser.h"
+
+namespace android {
+
+typedef ::C2ComponentFactory* (*IMXCreateCodec2FactoryFunc)(C2String name);
+typedef void (*IMXDestroyCodec2FactoryFunc)(::C2ComponentFactory*);
+
+class ImxC2Store : public C2ComponentStore {
+public:
+    ImxC2Store();
+
+    virtual ~ImxC2Store() override = default;
+
+    virtual C2String getName() const override;
+    virtual std::vector<std::shared_ptr<const C2Component::Traits>> listComponents() override;
+    virtual c2_status_t createComponent(
+            C2String name, std::shared_ptr<C2Component> *const component) override;
+    virtual c2_status_t createInterface(
+            C2String name, std::shared_ptr<C2ComponentInterface> *const interface) override;
+
+    virtual c2_status_t copyBuffer(
+            std::shared_ptr<C2GraphicBuffer>src,
+            std::shared_ptr<C2GraphicBuffer>dst ) override;
+
+    virtual c2_status_t query_sm(
+            const std::vector<C2Param*> &stackParams,
+            const std::vector<C2Param::Index> &heapParamIndices,
+            std::vector<std::unique_ptr<C2Param>> *const heapParams) const override;
+
+    virtual c2_status_t config_sm(
+            const std::vector<C2Param*> &params,
+            std::vector<std::unique_ptr<C2SettingResult>> *const failures) override;
+
+    virtual std::shared_ptr<C2ParamReflector> getParamReflector() const override;
+
+    virtual c2_status_t querySupportedParams_nb(
+            std::vector<std::shared_ptr<C2ParamDescriptor>> *const params) const override;
+
+    virtual c2_status_t querySupportedValues_sm(
+            std::vector<C2FieldSupportedValuesQuery> &fields) const override;
+
+private:
+    std::map<C2String, C2String> mRoleMap;
+
+    struct ComponentBox: public C2ComponentFactory, public std::enable_shared_from_this<ComponentBox>
+    {
+        ComponentBox(std::string alias, std::string libPath);
+
+        c2_status_t init();
+
+        ~ComponentBox() override;
+
+        c2_status_t createComponent(
+                c2_node_id_t id, std::shared_ptr<C2Component> *component,
+                ComponentDeleter deleter = std::default_delete<C2Component>()) override;
+
+        c2_status_t createInterface(
+                c2_node_id_t id, std::shared_ptr<C2ComponentInterface> *interface,
+                InterfaceDeleter deleter = std::default_delete<C2ComponentInterface>()) override;
+
+        std::shared_ptr<const C2Component::Traits> getTraits();
+
+    protected:
+
+        std::string mName;
+        std::string mLibPath;
+        c2_status_t mInit; ///< initialization result
+        void *mLibHandle; ///< loaded library handle
+
+        std::shared_ptr<C2Component::Traits> mTraits; ///< cached component traits
+        IMXCreateCodec2FactoryFunc createFactory; ///< loaded create function
+        C2ComponentFactory::DestroyCodec2FactoryFunc destroyFactory; ///< loaded destroy function
+        C2ComponentFactory *mComponentFactory; ///< loaded/created component factory
+
+        std::recursive_mutex mLock; ///< lock protecting mTraits
+    };
+
+    std::map<C2String, std::shared_ptr<android::ImxC2Store::ComponentBox>> mComponents; ///< map of name -> components
+    std::vector<C2String> mComponentsList; ///< list of components
+
+    std::shared_ptr<android::ImxC2Store::ComponentBox> findComponent(C2String name);
+
+    struct Interface : public C2InterfaceHelper {
+        std::shared_ptr<C2StoreIonUsageInfo> mIonUsageInfo;
+
+        Interface(std::shared_ptr<C2ReflectorHelper> reflector)
+            : C2InterfaceHelper(reflector) {
+            setDerivedInstance(this);
+            struct Setter {
+                static C2R setIonUsage(bool /* mayBlock */, C2P<C2StoreIonUsageInfo> &me) {
+                    me.set().heapMask = ~0;
+                    me.set().minAlignment = 0;
+                    if (me.set().usage & (C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE)) {
+                        me.set().allocFlags = 1;    //ION_FLAG_CACHED;
+                    } else {
+                        me.set().allocFlags = 0;
+                    }
+                    return C2R::Ok();
+                }
+            };
+
+            addParameter(
+                DefineParam(mIonUsageInfo, "ion-usage")
+                .withDefault(new C2StoreIonUsageInfo())
+                .withFields({
+                    C2F(mIonUsageInfo, usage).flags({C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE}),
+                    C2F(mIonUsageInfo, capacity).inRange(0, UINT32_MAX, 1024),
+                    C2F(mIonUsageInfo, heapMask).any(),
+                    C2F(mIonUsageInfo, allocFlags).flags({}),
+                    C2F(mIonUsageInfo, minAlignment).equalTo(0)
+                })
+                .withSetter(Setter::setIonUsage)
+                .build());
+        }
+    };
+    std::shared_ptr<C2ReflectorHelper> mReflector;
+    Interface mInterface;
+};
+
+
+ImxC2Store::ComponentBox::ComponentBox(std::string alias, std::string libPath)
+    : mName(alias),
+    mLibPath(libPath),
+    mInit(C2_NO_INIT),
+    mLibHandle(nullptr),
+    mTraits(nullptr),
+    createFactory(nullptr),
+    destroyFactory(nullptr),
+    mComponentFactory(nullptr)
+{
+}
+
+c2_status_t ImxC2Store::ComponentBox::init()
+{
+    if(mInit == C2_OK){
+        return C2_OK;
+    }
+
+    if(mInit == C2_NO_INIT){
+        //std::lock_guard<std::mutex> lock(mMutex);
+        std::unique_lock<std::recursive_mutex> lock(mLock);
+
+        mLibHandle = dlopen(mLibPath.c_str(), RTLD_NOW|RTLD_NODELETE);
+        ALOGV("ImxC2Store::ComponentBox init mLibHandle=%s mName=%s",mLibPath.c_str(),mName.c_str());
+        if (mLibHandle == nullptr) {
+            // could be access/symbol or simply not being there
+            ALOGE("could not dlopen %s: %s", mLibPath.c_str(), dlerror());
+            mInit = C2_CORRUPTED;
+        } else {
+            createFactory =
+                (IMXCreateCodec2FactoryFunc)dlsym(mLibHandle, "IMXCreateCodec2Factory");
+            destroyFactory =
+                (IMXDestroyCodec2FactoryFunc)dlsym(mLibHandle, "IMXDestroyCodec2Factory");
+
+            //TODO: add parameter in createFactory
+            //or to have more CreateCodec2FactoryFuncs
+            if(createFactory != nullptr){
+                ALOGV("CALL createFactory");
+                mComponentFactory = createFactory(mName);
+            }
+
+            if (mComponentFactory == nullptr) {
+                ALOGE("could not create factory in %s", mLibPath.c_str());
+                mInit = C2_NO_MEMORY;
+            } else {
+                mInit = C2_OK;
+            }
+        }
+
+        if (mInit != C2_OK) {
+            return mInit;
+        }
+
+        std::shared_ptr<C2ComponentInterface> intf;
+        c2_status_t res = createInterface(0, &intf);
+
+        if (res != C2_OK) {
+            ALOGD("failed to create interface: %d", res);
+            return mInit;
+        }
+
+        std::shared_ptr<C2Component::Traits> traits(new (std::nothrow) C2Component::Traits);
+        if (traits) {
+            if (mName != intf->getName()) {
+                ALOGV("%s is alias to %s", mName.c_str(), intf->getName().c_str());
+            }
+            traits->name = mName;
+            ALOGV("ImxC2Store::ComponentBox init mName=%s",mName.c_str());
+            // TODO: get this from interface properly.
+            bool encoder = (traits->name.find("encoder") != std::string::npos);
+            uint32_t mediaTypeIndex = encoder ? C2PortMediaTypeSetting::output::PARAM_TYPE
+                    : C2PortMediaTypeSetting::input::PARAM_TYPE;
+            std::vector<std::unique_ptr<C2Param>> params;
+            res = intf->query_vb({}, { mediaTypeIndex }, C2_MAY_BLOCK, &params);
+            if (res != C2_OK) {
+                ALOGD("failed to query interface: %d", res);
+                return mInit;
+            }
+            if (params.size() != 1u) {
+                ALOGD("failed to query interface: unexpected vector size: %zu", params.size());
+                return mInit;
+            }
+            C2PortMediaTypeSetting *mediaTypeConfig = (C2PortMediaTypeSetting *)(params[0].get());
+            if (mediaTypeConfig == nullptr) {
+                ALOGD("failed to query media type");
+                return mInit;
+            }
+            traits->mediaType = mediaTypeConfig->m.value;
+
+            // TODO: define these values properly
+            bool decoder = (traits->name.find("decoder") != std::string::npos);
+            traits->kind =
+                    decoder ? C2Component::KIND_DECODER :
+                    encoder ? C2Component::KIND_ENCODER :
+                    C2Component::KIND_OTHER;
+            if (strncmp(traits->mediaType.c_str(), "audio/", 6) == 0) {
+                traits->domain = C2Component::DOMAIN_AUDIO;
+            } else if (strncmp(traits->mediaType.c_str(), "video/", 6) == 0) {
+                traits->domain = C2Component::DOMAIN_VIDEO;
+            } else if (strncmp(traits->mediaType.c_str(), "image/", 6) == 0) {
+                traits->domain = C2Component::DOMAIN_IMAGE;
+            } else {
+                traits->domain = C2Component::DOMAIN_OTHER;
+            }
+
+            // set codec rank based on this prop, it is 0x111 as default
+            int flag = property_get_int32("media.fsl_codec.flag", 7);
+            bool useImxVideo = (flag & 0x2);
+            bool useImxAudio = (flag & 0x4);
+
+            if (traits->domain == C2Component::DOMAIN_VIDEO)
+                traits->rank = (useImxVideo ? 0x1 : 0x400);
+            else if (traits->domain == C2Component::DOMAIN_AUDIO)
+                traits->rank = (useImxAudio ? 0x1 : 0x400);
+            else
+                traits->rank = 0x200;
+        }
+        mTraits = traits;
+    }
+
+    return mInit;
+};
+ImxC2Store::ComponentBox::~ComponentBox() {
+    ALOGV("in %s", __func__);
+    if (destroyFactory && mComponentFactory) {
+        destroyFactory(mComponentFactory);
+    }
+    if (mLibHandle) {
+        ALOGV("unloading dll");
+        dlclose(mLibHandle);
+    }
+}
+
+c2_status_t ImxC2Store::ComponentBox::createComponent(
+        c2_node_id_t id, std::shared_ptr<C2Component> *component,
+        std::function<void(::C2Component*)> deleter) {
+    component->reset();
+    if (mInit != C2_OK) {
+        ALOGE("ImxC2Store::ComponentBox::createComponent failed ret=%d",mInit);
+        return mInit;
+    }
+    std::shared_ptr<ComponentBox> module = shared_from_this();
+    c2_status_t res = mComponentFactory->createComponent(
+            id, component, [module, deleter](C2Component *p) mutable {
+                // capture module so that we ensure we still have it while deleting component
+                deleter(p); // delete component first
+                module.reset(); // remove module ref (not technically needed)
+    });
+    return res;
+}
+
+c2_status_t ImxC2Store::ComponentBox::createInterface(
+        c2_node_id_t id, std::shared_ptr<C2ComponentInterface> *interface,
+        std::function<void(::C2ComponentInterface*)> deleter) {
+    interface->reset();
+    if (mInit != C2_OK) {
+        ALOGE("ImxC2Store::ComponentBox::createInterface failed ret=%d",mInit);
+        return mInit;
+    }
+    std::shared_ptr<ComponentBox> module = shared_from_this();
+    c2_status_t res = mComponentFactory->createInterface(
+            id, interface, [module, deleter](C2ComponentInterface *p) mutable {
+                // capture module so that we ensure we still have it while deleting interface
+                deleter(p); // delete interface first
+                module.reset(); // remove module ref (not technically needed)
+    });
+    return res;
+}
+
+std::shared_ptr<const C2Component::Traits> ImxC2Store::ComponentBox::getTraits() {
+    std::unique_lock<std::recursive_mutex> lock(mLock);
+    return mTraits;
+}
+
+ImxC2Store::ImxC2Store()
+    : mReflector(std::make_shared<C2ReflectorHelper>()),
+      mInterface(mReflector)
+{
+    ALOGV("ImxC2Store::ImxC2Store BEGIN");
+    auto emplace = [this](const char *alias, const char *libPath) {
+
+        // ComponentLoader is neither copiable nor movable, so it must be
+        // constructed in-place. Now ComponentLoader takes two arguments in
+        // constructor, so we need to use piecewise_construct to achieve this
+        // behavior.
+        mComponents.emplace(
+                std::piecewise_construct,
+                std::forward_as_tuple(alias),
+                std::forward_as_tuple(std::make_shared<ComponentBox>(alias, libPath)));
+        mComponentsList.emplace_back(alias);
+    };
+
+    RegistryParser localRegParser;
+    std::string register_file = "/vendor/etc/c2_component_register";
+    localRegParser.ParseRegList((char*)register_file.c_str());
+
+    int num = localRegParser.GetRegCompNum();
+    if (num <= 0) {
+        ALOGE("GetRegCompNum failed");
+        return;
+    }
+
+    int i;
+    REG_ENTRY * pReg;
+    for (i = 0; i < num; i++) {
+        pReg = localRegParser.QueryRegComp(i);
+        if (pReg && pReg->disable != true) {
+            ALOGV("emplace component %s lib %s", pReg->compName, pReg->libName);
+            emplace(pReg->compName, pReg->libName);
+        }
+    }
+
+    ALOGV("ImxC2Store::ImxC2Store END");
+}
+
+C2String ImxC2Store::getName() const {
+    return "ImxC2Store";
+}
+
+
+std::shared_ptr<android::ImxC2Store::ComponentBox> ImxC2Store::findComponent(C2String name) {
+
+    auto pos = mComponents.find(name);
+    if (pos == mComponents.end()) {
+        return nullptr;
+    }
+    return pos->second;
+}
+
+c2_status_t ImxC2Store::copyBuffer(
+        std::shared_ptr<C2GraphicBuffer> src, std::shared_ptr<C2GraphicBuffer> dst) {
+    (void)src;
+    (void)dst;
+    return C2_OMITTED;
+}
+
+c2_status_t ImxC2Store::createComponent(
+        C2String name, std::shared_ptr<C2Component> *const component) {
+
+    c2_status_t ret = C2_NOT_FOUND;
+
+    // This method SHALL return within 100ms.
+    component->reset();
+
+    std::shared_ptr<ComponentBox> box = findComponent(name);
+
+    if (box) {
+        ret = box->init();
+        if (ret == C2_OK) {
+            // TODO: get a unique node ID
+            ret = box->createComponent(0, component);
+        }
+    }
+
+    ALOGV("ImxC2Store::createComponent name=%s, ret=%d",name.c_str(), ret);
+    return ret;
+}
+
+c2_status_t ImxC2Store::createInterface(
+        C2String name, std::shared_ptr<C2ComponentInterface> *const interface) {
+
+    c2_status_t ret = C2_NOT_FOUND;
+
+    // This method SHALL return within 100ms.
+    interface->reset();
+
+    std::shared_ptr<ComponentBox> box = findComponent(name);
+
+    if (box) {
+        ret = box->init();
+        if (ret == C2_OK) {
+            // TODO: get a unique node ID
+            ret = box->createInterface(0, interface);
+        }
+    }
+
+    ALOGV("ImxC2Store::createInterface !!! name=%s, ret=%d",name.c_str(), ret);
+    return ret;
+}
+
+std::vector<std::shared_ptr<const C2Component::Traits>> ImxC2Store::listComponents() {
+    // This method SHALL return within 500ms.
+    std::vector<std::shared_ptr<const C2Component::Traits>> list;
+    for (const C2String &alias : mComponentsList) {
+        std::shared_ptr<ComponentBox> box = mComponents.at(alias);
+
+        c2_status_t ret = box->init();
+        if (ret == C2_OK) {
+            std::shared_ptr<const C2Component::Traits> traits = box->getTraits();
+            if (traits) {
+                list.push_back(traits);
+            }
+        }
+    }
+    return list;
+};
+
+c2_status_t ImxC2Store::query_sm(
+        const std::vector<C2Param*> &stackParams,
+        const std::vector<C2Param::Index> &heapParamIndices,
+        std::vector<std::unique_ptr<C2Param>> *const heapParams) const {
+    return mInterface.query(stackParams, heapParamIndices, C2_MAY_BLOCK, heapParams);
+}
+
+c2_status_t ImxC2Store::config_sm(
+        const std::vector<C2Param*> &params,
+        std::vector<std::unique_ptr<C2SettingResult>> *const failures) {
+    return mInterface.config(params, C2_MAY_BLOCK, failures);
+}
+
+std::shared_ptr<C2ParamReflector> ImxC2Store::getParamReflector() const {
+    return mReflector;
+}
+
+c2_status_t ImxC2Store::querySupportedParams_nb(
+        std::vector<std::shared_ptr<C2ParamDescriptor>> *const params) const {
+    return mInterface.querySupportedParams(params);
+}
+c2_status_t ImxC2Store::querySupportedValues_sm(
+        std::vector<C2FieldSupportedValuesQuery> &fields) const {
+    return mInterface.querySupportedValues(fields, C2_MAY_BLOCK);
+}
+
+std::shared_ptr<C2ComponentStore> GetImxC2Store() {
+    static std::mutex mutex;
+    static std::weak_ptr<C2ComponentStore> imxC2Store;
+    std::lock_guard<std::mutex> lock(mutex);
+    std::shared_ptr<C2ComponentStore> store = imxC2Store.lock();
+    if (store == nullptr) {
+        store = std::make_shared<android::ImxC2Store>();
+        imxC2Store = store;
+    }
+    return store;
+}
+
+
+}
+
diff --git a/codec2/store/ImxService.cpp b/codec2/store/ImxService.cpp
new file mode 100644
index 0000000..89b0b1c
--- /dev/null
+++ b/codec2/store/ImxService.cpp
@@ -0,0 +1,86 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "ImxService"
+#include <log/log.h>
+
+#include <C2Component.h>
+#include <codec2/hidl/1.0/ComponentStore.h>
+#include <hidl/HidlTransportSupport.h>
+#include <binder/ProcessState.h>
+#include <minijail.h>
+
+//#include <C2Component.h>
+//#include <C2ComponentFactory.h>
+//#include <C2Config.h>
+//#include <util/C2InterfaceHelper.h>
+//#include <C2AllocatorGralloc.h>
+//#include <C2AllocatorIon.h>
+//#include <dlfcn.h>
+
+#include <C2_imx.h>
+#include <media/stagefright/omx/1.0/OmxStore.h>
+
+// This is created by module "codec2.vendor.base.policy". This can be modified.
+static constexpr char kBaseSeccompPolicyPath[] =
+        "/vendor/etc/seccomp_policy/codec2.vendor.base.policy";
+
+// Additional device-specific seccomp permissions can be added in this file.
+static constexpr char kExtSeccompPolicyPath[] =
+        "/vendor/etc/seccomp_policy/codec2.vendor.ext.policy";
+
+int main(int /* argc */, char** /* argv */) {
+    ALOGD("android.hardware.media.c2@1.0-service starting...");
+
+    signal(SIGPIPE, SIG_IGN);
+    android::SetUpMinijail(kBaseSeccompPolicyPath, kExtSeccompPolicyPath);
+
+    // vndbinder is needed by BufferQueue.
+    android::ProcessState::initWithDriver("/dev/vndbinder");
+    android::ProcessState::self()->startThreadPool();
+
+    // Extra threads may be needed to handle a stacked IPC sequence that
+    // contains alternating binder and hwbinder calls. (See b/35283480.)
+    android::hardware::configureRpcThreadpool(16, true /* callerWillJoin */);
+
+    // Create IComponentStore service.
+    {
+        //using namespace android::hardware::google::media::c2::V1_0;
+        using ::android::hardware::media::c2::V1_0::IComponentStore;
+        using namespace ::android::hardware::media::c2::V1_0;
+        android::sp<IComponentStore> store;
+
+        ALOGD("Instantiating ImxC2Store service...");
+        store = new utils::ComponentStore(android::GetImxC2Store());
+        if (store == nullptr) {
+            ALOGE("Cannot create Codec2's IComponentStore service.");
+        } else {
+            if (store->registerAsService("default") != android::OK) {
+                ALOGE("Cannot register Codec2's ImxC2Store service.");
+            } else {
+                ALOGI("Codec2's ImxC2Store service created.");
+            }
+        }
+    }
+
+    // Register IOmxStore service.
+    {
+        using namespace ::android::hardware::media::omx::V1_0;
+        android::sp<IOmxStore> omxStore = new implementation::OmxStore();
+        if (omxStore == nullptr) {
+            ALOGE("Cannot create IOmxStore HAL service.");
+        } else if (omxStore->registerAsService() != android::OK) {
+            ALOGE("Cannot register IOmxStore HAL service.");
+        }
+    }
+    ALOGD("Register ImxC2Store service success");
+    android::hardware::joinRpcThreadpool();
+    return 0;
+}
+
diff --git a/codec2/store/RegistryParser.cpp b/codec2/store/RegistryParser.cpp
new file mode 100755
index 0000000..dc8d8a1
--- /dev/null
+++ b/codec2/store/RegistryParser.cpp
@@ -0,0 +1,212 @@
+/**
+ *  Copyright 2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "RegistryParser"
+#include <log/log.h>
+#include <utils/Log.h>
+#include <string.h>
+#include "RegistryParser.h"
+
+
+RegistryParser::RegistryParser()
+{
+    registerdCompNum = 0;
+    includeFilesNum = 0;
+    memset(RegList, 0, sizeof(REG_ENTRY)*ITEM_NUM);
+    memset(includeFiles, 0, sizeof(includeFiles));
+    ALOGV("RegistryParser");
+}
+
+RegistryParser::~RegistryParser()
+{
+}
+
+
+int RegistryParser::GetRegCompNum()
+{
+    return registerdCompNum;
+}
+
+REG_ENTRY * RegistryParser::QueryRegComp(int index)
+{
+    if (index >= registerdCompNum)
+        return NULL;
+
+    return &RegList[index];
+}
+
+REG_ERRORTYPE RegistryParser::ParseRegList(char *file_name) {
+
+    if (file_name == NULL)
+	{
+		ALOGE("Input file name is NULL.");
+		return REG_FAILURE;
+	}
+
+    DoParseRegList(file_name);
+
+    int i;
+    for (i=0; i< includeFilesNum; i++) {
+        DoParseRegList(includeFiles[i]);
+    }
+
+    int hwMp3Index = -1, hwAacIndex = -1;
+    int swMp3Index = -1, swAacIndex = -1;
+
+    for (i=0; i< registerdCompNum; i++) {
+        if (strstr(RegList[i].compName, "mp3.decoder.hw"))
+            hwMp3Index = i;
+        else if (strstr(RegList[i].compName, "mp3.decoder.sw"))
+            swMp3Index = i;
+        else if (strstr(RegList[i].compName, "aac.decoder.hw"))
+            hwAacIndex = i;
+        else if (strstr(RegList[i].compName, "aac.decoder.sw"))
+            swAacIndex = i;
+    }
+
+    ALOGV("hwMp3Index %d swMp3Index %d", hwMp3Index, swMp3Index);
+    ALOGV("hwAacIndex %d swAacIndex %d", hwAacIndex, swAacIndex);
+
+    if (hwMp3Index > 0 && swMp3Index > 0) {
+        RegList[swMp3Index].disable = true;
+    }
+
+    if (hwAacIndex > 0 && swAacIndex > 0) {
+        RegList[swAacIndex].disable = true;
+    }
+
+    return REG_SUCCESS;
+}
+
+REG_ERRORTYPE RegistryParser::DoParseRegList(char *file_name)
+{
+	char symbol;
+	bool bSkip = false;
+	char symbolBuffer[ITEM_NAME_LEN] = {0}, *pStrSeg;
+	bool EntryFounded = false;
+	int symbolCnt = 0;
+	REG_ENTRY *pRegEntry;
+    FILE *pfile = NULL;
+    int UseOffset = 0,  BufferDataLen = 0;
+    bool FileReadEnd = false;
+    bool getCompName = false, getLibName = false;
+    char readBuffer[FILE_READ_SIZE];
+
+    pfile = fopen(file_name, "r");
+	if (pfile == NULL)
+	{
+		ALOGE("open file %s failed.
", file_name);
+		return REG_FAILURE;
+	}
+
+    memset(readBuffer, 0, FILE_READ_SIZE);
+
+	while (BufferDataLen - UseOffset > 0 || FileReadEnd == false)
+	{
+	    if (BufferDataLen - UseOffset == 0)
+		{
+			BufferDataLen = fread(readBuffer, 1, FILE_READ_SIZE, pfile);
+			if (0 == BufferDataLen)
+			{
+			    break;
+			}
+
+			if (BufferDataLen < FILE_READ_SIZE)
+			{
+				FileReadEnd = true;
+			}
+
+			UseOffset = 0;
+		}
+
+		symbol = readBuffer[UseOffset];
+		UseOffset ++;
+        //ALOGD(" symbol %c", symbol);
+
+		if (bSkip == true)
+		{
+			if (symbol == '
')
+			{
+				bSkip = false;
+			}
+		}
+		else
+		{
+			if (symbol == '#')
+			{
+				bSkip = true;
+			}
+			else if (symbol == '	'
+					|| symbol == ' '
+					|| symbol == '
'
+					|| symbol == '')
+			{
+			}
+			else if (symbol == '@')
+			{
+				EntryFounded = true;
+			}
+			else if (symbol == '$')
+			{
+			    if (EntryFounded && getCompName && getLibName) {
+                    ALOGV("register comp index %d %s %s ", registerdCompNum, pRegEntry->compName, pRegEntry->libName);
+                    pRegEntry->disable = false;
+                    registerdCompNum++;
+                }
+                EntryFounded = false;
+                getCompName = false;
+                getLibName = false;
+				continue;
+			}
+			else if (symbol == ';')
+			{
+				char *pLast = NULL;
+				if (symbolCnt != 0 && ((pStrSeg = strtok_r(symbolBuffer, "=", &pLast)) != NULL))
+				{
+				    //ALOGD("pStrSeg=%s symbolBuffer %s", pStrSeg, symbolBuffer);
+                    pRegEntry = &RegList[registerdCompNum];
+                    if (!strncmp(pStrSeg, "component_name", strlen("component_name"))) {
+                        pStrSeg = strtok_r(NULL, "=", &pLast);
+                        strcpy(pRegEntry->compName, pStrSeg);
+                        getCompName = true;
+                        ALOGV("registerdCompNum %d compName=%s", registerdCompNum, pRegEntry->compName);
+                    } else if (!strncmp(pStrSeg, "library_path", strlen("library_path"))) {
+                        pStrSeg = strtok_r(NULL, "=", &pLast);
+                        strcpy(pRegEntry->libName, pStrSeg);
+                        getLibName = true;
+                        ALOGV("registerdCompNum %d libName=%s", registerdCompNum, pRegEntry->libName);
+                    } else if (!strncmp(pStrSeg, "include_file", strlen("include_file"))) {
+                        pStrSeg = strtok_r(NULL, "=", &pLast);
+                        strcpy(includeFiles[includeFilesNum], pStrSeg);
+                        ALOGV("include_file=%s", pStrSeg);
+                        includeFilesNum++;
+                    }
+					memset(symbolBuffer, 0, ITEM_NAME_LEN);
+					symbolCnt = 0;
+				}
+			}
+			else
+			{
+				if (EntryFounded == true)
+				{
+					symbolBuffer[symbolCnt] = symbol;
+					symbolCnt ++;
+				}
+			}
+		}
+	}
+
+    if (pfile) {
+        fclose(pfile);
+        pfile = NULL;
+    }
+	return REG_SUCCESS;
+}
+
+/* File EOF */
diff --git a/codec2/store/RegistryParser.h b/codec2/store/RegistryParser.h
new file mode 100755
index 0000000..b7bb96c
--- /dev/null
+++ b/codec2/store/RegistryParser.h
@@ -0,0 +1,58 @@
+/**
+ *  Copyright 2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+/**
+ *  @file RegistryParser.h
+ *  @brief Class definition of Regitsry file analyser
+ *  @ingroup RegistryParser
+ */
+
+
+#ifndef RegistryParser_h
+#define RegistryParser_h
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <stdbool.h>
+
+#define ITEM_NUM 32
+#define ITEM_NAME_LEN 128
+#define FILE_READ_SIZE (4096)
+
+typedef enum {
+    REG_SUCCESS,
+    REG_FAILURE,
+    REG_INSUFFICIENT_RESOURCES,
+    REG_INVALID_REG
+}REG_ERRORTYPE;
+
+typedef struct _REG_ENTRY {
+    char compName[ITEM_NAME_LEN];
+    char libName[ITEM_NAME_LEN];
+    bool disable;
+}REG_ENTRY;
+
+class RegistryParser {
+	public:
+		RegistryParser();
+		REG_ERRORTYPE ParseRegList(char *file_name);
+        int GetRegCompNum();
+        REG_ENTRY * QueryRegComp(int index);
+		~RegistryParser();
+	private:
+		REG_ENTRY RegList[ITEM_NUM];
+        int registerdCompNum;
+        int includeFilesNum;
+        char includeFiles[ITEM_NUM][ITEM_NAME_LEN];
+
+        REG_ERRORTYPE DoParseRegList(char *file_name);
+
+};
+
+#endif
+/* File EOF */
diff --git a/codec2/store/android.hardware.media.c2@1.0-service.rc b/codec2/store/android.hardware.media.c2@1.0-service.rc
new file mode 100644
index 0000000..8806bd1
--- /dev/null
+++ b/codec2/store/android.hardware.media.c2@1.0-service.rc
@@ -0,0 +1,7 @@
+service android-hardware-media-c2-hal-1-0 /vendor/bin/hw/android.hardware.media.c2@1.0-service
+    class hal
+    user mediacodec
+    group camera mediadrm drmrpc
+    ioprio rt 4
+    writepid /dev/cpuset/foreground/tasks
+
diff --git a/codec2/store/registry/Android.mk b/codec2/store/registry/Android.mk
new file mode 100644
index 0000000..50ee1e4
--- /dev/null
+++ b/codec2/store/registry/Android.mk
@@ -0,0 +1,23 @@
+LOCAL_PATH := $(call my-dir)
+
+include $(CLEAR_VARS)
+LOCAL_SRC_FILES := c2_component_register_8mm
+ifeq ($(BOARD_SOC_TYPE),IMX8MM)
+LOCAL_SRC_FILES := c2_component_register_8mm
+endif
+ifeq ($(BOARD_SOC_TYPE),IMX8MN)
+LOCAL_SRC_FILES := c2_component_register_8mn
+endif
+ifeq ($(BOARD_SOC_TYPE),IMX8MP)
+LOCAL_SRC_FILES := c2_component_register_8mp
+endif
+ifeq ($(BOARD_SOC_TYPE),IMX8MQ)
+LOCAL_SRC_FILES := c2_component_register_8mq
+endif
+ifeq ($(BOARD_SOC_TYPE),IMX8Q)
+LOCAL_SRC_FILES := c2_component_register_8q
+endif
+LOCAL_MODULE := c2_component_register
+LOCAL_MODULE_CLASS := ETC
+LOCAL_VENDOR_MODULE := true
+include $(BUILD_PREBUILT)
diff --git a/codec2/store/registry/c2_component_register_8mm b/codec2/store/registry/c2_component_register_8mm
new file mode 100644
index 0000000..d61cb84
--- /dev/null
+++ b/codec2/store/registry/c2_component_register_8mm
@@ -0,0 +1,53 @@
+# Register component to ImxC2Score.
+#
+# Usage:
+# @ means the begin of one component.
+# # means comments.
+# $ means the end of one component.
+# ; means finish of one tag value.
+# envirenment value should be set: COMPONENT_REGISTER_FILE=../registry/component_register
+
+@
+include_file=/vendor/etc/c2_component_register_ms;
+include_file=/vendor/etc/c2_component_register_ra;
+$
+
+@
+component_name=c2.imx.avc.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.hevc.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.vp8.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.vp9.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.avc.encoder;
+library_path=lib_imx_c2_videoenc.so;
+$
+
+@
+component_name=c2.imx.vp8.encoder;
+library_path=lib_imx_c2_videoenc.so;
+$
+
+@
+component_name=c2.imx.aac.decoder.sw;
+library_path=lib_c2_imx_aac_dec.so;
+$
+
+@
+component_name=c2.imx.mp3.decoder.sw;
+library_path=lib_c2_imx_mp3_dec.so;
+$
diff --git a/codec2/store/registry/c2_component_register_8mn b/codec2/store/registry/c2_component_register_8mn
new file mode 100644
index 0000000..bc5b7da
--- /dev/null
+++ b/codec2/store/registry/c2_component_register_8mn
@@ -0,0 +1,23 @@
+# Register component to ImxC2Score.
+#
+# Usage:
+# @ means the begin of one component.
+# # means comments.
+# $ means the end of one component.
+# ; means finish of one tag value.
+# envirenment value should be set: COMPONENT_REGISTER_FILE=../registry/component_register
+
+@
+include_file=/vendor/etc/c2_component_register_ms;
+include_file=/vendor/etc/c2_component_register_ra;
+$
+
+@
+component_name=c2.imx.aac.decoder.sw;
+library_path=lib_c2_imx_aac_dec.so;
+$
+
+@
+component_name=c2.imx.mp3.decoder.sw;
+library_path=lib_c2_imx_mp3_dec.so;
+$
diff --git a/codec2/store/registry/c2_component_register_8mp b/codec2/store/registry/c2_component_register_8mp
new file mode 100644
index 0000000..899c579
--- /dev/null
+++ b/codec2/store/registry/c2_component_register_8mp
@@ -0,0 +1,55 @@
+# Register component to ImxC2Score.
+#
+# Usage:
+# @ means the begin of one component.
+# # means comments.
+# $ means the end of one component.
+# ; means finish of one tag value.
+# envirenment value should be set: COMPONENT_REGISTER_FILE=../registry/component_register
+
+@
+include_file=/vendor/etc/c2_component_register_ms;
+include_file=/vendor/etc/c2_component_register_ra;
+include_file=/vendor/etc/c2_component_register_dsp;
+include_file=/vendor/etc/c2_component_register_dsp_aacp;
+$
+
+@
+component_name=c2.imx.avc.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.hevc.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.vp8.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.vp9.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.avc.encoder;
+library_path=lib_imx_c2_videoenc.so;
+$
+
+@
+component_name=c2.imx.hevc.encoder;
+library_path=lib_imx_c2_videoenc.so;
+$
+
+@
+component_name=c2.imx.aac.decoder.sw;
+library_path=lib_c2_imx_aac_dec.so;
+$
+
+@
+component_name=c2.imx.mp3.decoder.sw;
+library_path=lib_c2_imx_mp3_dec.so;
+$
diff --git a/codec2/store/registry/c2_component_register_8mq b/codec2/store/registry/c2_component_register_8mq
new file mode 100644
index 0000000..898f694
--- /dev/null
+++ b/codec2/store/registry/c2_component_register_8mq
@@ -0,0 +1,70 @@
+# Register component to ImxC2Score.
+#
+# Usage:
+# @ means the begin of one component.
+# # means comments.
+# $ means the end of one component.
+# ; means finish of one tag value.
+# envirenment value should be set: COMPONENT_REGISTER_FILE=../registry/component_register
+
+@
+include_file=/vendor/etc/c2_component_register_ms;
+include_file=/vendor/etc/c2_component_register_ra;
+include_file=/vendor/etc/c2_component_register_rv;
+include_file=/vendor/etc/c2_component_register_wmv9;
+$
+
+@
+component_name=c2.imx.avc.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.hevc.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.vp8.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.vp9.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.h263.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.mpeg2.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.mpeg4.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.mjpeg.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.xvid.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.aac.decoder.sw;
+library_path=lib_c2_imx_aac_dec.so;
+$
+
+@
+component_name=c2.imx.mp3.decoder.sw;
+library_path=lib_c2_imx_mp3_dec.so;
+$
diff --git a/codec2/store/registry/c2_component_register_8q b/codec2/store/registry/c2_component_register_8q
new file mode 100644
index 0000000..91cbc34
--- /dev/null
+++ b/codec2/store/registry/c2_component_register_8q
@@ -0,0 +1,77 @@
+# Register component to ImxC2Score.
+#
+# Usage:
+# @ means the begin of one component.
+# # means comments.
+# $ means the end of one component.
+# ; means finish of one tag value.
+# envirenment value should be set: COMPONENT_REGISTER_FILE=../registry/component_register
+
+@
+include_file=/vendor/etc/c2_component_register_ms;
+include_file=/vendor/etc/c2_component_register_ra;
+include_file=/vendor/etc/c2_component_register_rv;
+include_file=/vendor/etc/c2_component_register_wmv9;
+include_file=/vendor/etc/c2_component_register_dsp;
+include_file=/vendor/etc/c2_component_register_dsp_aacp;
+$
+
+@
+component_name=c2.imx.avc.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.hevc.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.vp8.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.h263.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.mpeg2.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.mpeg4.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.mjpeg.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.xvid.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.sorenson.decoder;
+library_path=lib_imx_c2_videodec.so;
+$
+
+@
+component_name=c2.imx.avc.encoder;
+library_path=lib_imx_c2_videoenc.so;
+$
+
+@
+component_name=c2.imx.aac.decoder.sw;
+library_path=lib_c2_imx_aac_dec.so;
+$
+
+@
+component_name=c2.imx.mp3.decoder.sw;
+library_path=lib_c2_imx_mp3_dec.so;
+$
diff --git a/codec2/store/seccomp_policy/codec2.software.base-arm.policy b/codec2/store/seccomp_policy/codec2.software.base-arm.policy
new file mode 100755
index 0000000..d5871d1
--- /dev/null
+++ b/codec2/store/seccomp_policy/codec2.software.base-arm.policy
@@ -0,0 +1,73 @@
+# Copyright (C) 2018 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# Organized by frequency of systemcall - in descending order for
+# best performance.
+futex: 1
+ioctl: 1
+write: 1
+prctl: 1
+clock_gettime: 1
+getpriority: 1
+read: 1
+close: 1
+writev: 1
+dup: 1
+ppoll: 1
+mmap2: 1
+getrandom: 1
+
+# mremap: Ensure |flags| are (MREMAP_MAYMOVE | MREMAP_FIXED) TODO: Once minijail
+# parser support for '<' is in this needs to be modified to also prevent
+# |old_address| and |new_address| from touching the exception vector page, which
+# on ARM is statically loaded at 0xffff 0000. See
+# http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0211h/Babfeega.html
+# for more details.
+mremap: arg3 == 3
+munmap: 1
+mprotect: 1
+madvise: 1
+openat: 1
+sigaltstack: 1
+clone: 1
+setpriority: 1
+getuid32: 1
+fstat64: 1
+fstatfs64: 1
+pread64: 1
+faccessat: 1
+readlinkat: 1
+exit: 1
+rt_sigprocmask: 1
+set_tid_address: 1
+restart_syscall: 1
+exit_group: 1
+rt_sigreturn: 1
+pipe2: 1
+gettimeofday: 1
+sched_yield: 1
+nanosleep: 1
+lseek: 1
+_llseek: 1
+sched_get_priority_max: 1
+sched_get_priority_min: 1
+statfs64: 1
+sched_setscheduler: 1
+fstatat64: 1
+ugetrlimit: 1
+getdents64: 1
+getrandom: 1
+
+@include /system/etc/seccomp_policy/crash_dump.arm.policy
+
diff --git a/codec2/store/seccomp_policy/codec2.software.base-x86.policy b/codec2/store/seccomp_policy/codec2.software.base-x86.policy
new file mode 100755
index 0000000..20c7625
--- /dev/null
+++ b/codec2/store/seccomp_policy/codec2.software.base-x86.policy
@@ -0,0 +1,57 @@
+# Copyright (C) 2018 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+read: 1
+mprotect: 1
+prctl: 1
+openat: 1
+getuid32: 1
+writev: 1
+ioctl: 1
+close: 1
+mmap2: 1
+fstat64: 1
+madvise: 1
+fstatat64: 1
+futex: 1
+munmap: 1
+faccessat: 1
+_llseek: 1
+lseek: 1
+clone: 1
+sigaltstack: 1
+setpriority: 1
+restart_syscall: 1
+exit: 1
+exit_group: 1
+rt_sigreturn: 1
+ugetrlimit: 1
+readlinkat: 1
+_llseek: 1
+fstatfs64: 1
+pread64: 1
+mremap: 1
+dup: 1
+set_tid_address: 1
+write: 1
+nanosleep: 1
+
+# Required by AddressSanitizer
+gettid: 1
+sched_yield: 1
+getpid: 1
+gettid: 1
+
+@include /system/etc/seccomp_policy/crash_dump.x86.policy
+
diff --git a/codec2/store/seccomp_policy/codec2.vendor.base-arm.policy b/codec2/store/seccomp_policy/codec2.vendor.base-arm.policy
new file mode 100755
index 0000000..d5871d1
--- /dev/null
+++ b/codec2/store/seccomp_policy/codec2.vendor.base-arm.policy
@@ -0,0 +1,73 @@
+# Copyright (C) 2018 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# Organized by frequency of systemcall - in descending order for
+# best performance.
+futex: 1
+ioctl: 1
+write: 1
+prctl: 1
+clock_gettime: 1
+getpriority: 1
+read: 1
+close: 1
+writev: 1
+dup: 1
+ppoll: 1
+mmap2: 1
+getrandom: 1
+
+# mremap: Ensure |flags| are (MREMAP_MAYMOVE | MREMAP_FIXED) TODO: Once minijail
+# parser support for '<' is in this needs to be modified to also prevent
+# |old_address| and |new_address| from touching the exception vector page, which
+# on ARM is statically loaded at 0xffff 0000. See
+# http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0211h/Babfeega.html
+# for more details.
+mremap: arg3 == 3
+munmap: 1
+mprotect: 1
+madvise: 1
+openat: 1
+sigaltstack: 1
+clone: 1
+setpriority: 1
+getuid32: 1
+fstat64: 1
+fstatfs64: 1
+pread64: 1
+faccessat: 1
+readlinkat: 1
+exit: 1
+rt_sigprocmask: 1
+set_tid_address: 1
+restart_syscall: 1
+exit_group: 1
+rt_sigreturn: 1
+pipe2: 1
+gettimeofday: 1
+sched_yield: 1
+nanosleep: 1
+lseek: 1
+_llseek: 1
+sched_get_priority_max: 1
+sched_get_priority_min: 1
+statfs64: 1
+sched_setscheduler: 1
+fstatat64: 1
+ugetrlimit: 1
+getdents64: 1
+getrandom: 1
+
+@include /system/etc/seccomp_policy/crash_dump.arm.policy
+
diff --git a/codec2/store/seccomp_policy/codec2.vendor.base-x86.policy b/codec2/store/seccomp_policy/codec2.vendor.base-x86.policy
new file mode 100755
index 0000000..20c7625
--- /dev/null
+++ b/codec2/store/seccomp_policy/codec2.vendor.base-x86.policy
@@ -0,0 +1,57 @@
+# Copyright (C) 2018 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+read: 1
+mprotect: 1
+prctl: 1
+openat: 1
+getuid32: 1
+writev: 1
+ioctl: 1
+close: 1
+mmap2: 1
+fstat64: 1
+madvise: 1
+fstatat64: 1
+futex: 1
+munmap: 1
+faccessat: 1
+_llseek: 1
+lseek: 1
+clone: 1
+sigaltstack: 1
+setpriority: 1
+restart_syscall: 1
+exit: 1
+exit_group: 1
+rt_sigreturn: 1
+ugetrlimit: 1
+readlinkat: 1
+_llseek: 1
+fstatfs64: 1
+pread64: 1
+mremap: 1
+dup: 1
+set_tid_address: 1
+write: 1
+nanosleep: 1
+
+# Required by AddressSanitizer
+gettid: 1
+sched_yield: 1
+getpid: 1
+gettid: 1
+
+@include /system/etc/seccomp_policy/crash_dump.x86.policy
+
diff --git a/codec2/tsm/Android.bp b/codec2/tsm/Android.bp
new file mode 100644
index 0000000..fe46fca
--- /dev/null
+++ b/codec2/tsm/Android.bp
@@ -0,0 +1,20 @@
+cc_library_shared {
+    name: "lib_imx_ts_manager",
+
+    shared_libs: [
+        "liblog",
+        "libutils",
+    ],
+
+    srcs: [
+        "Tsm_wrapper.c",
+        "mfw_gst_ts.c",
+    ],
+
+    include_dirs: ["."],
+
+    defaults: [
+        "imx_defaults",
+    ],
+
+}
diff --git a/codec2/tsm/Tsm_wrapper.c b/codec2/tsm/Tsm_wrapper.c
new file mode 100755
index 0000000..7a5841b
--- /dev/null
+++ b/codec2/tsm/Tsm_wrapper.c
@@ -0,0 +1,417 @@
+/**
+ *  Copyright (c) 2011-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "tsm_wrapper"
+#include <utils/Log.h>
+
+#include "stdio.h"
+#include "stdlib.h"
+#include "string.h"
+#include "Tsm_wrapper.h"
+
+//#define TS_DIS_ORI_TSMANAGER	//for debug: only use new ts mananger
+//#define TS_DIS_NEW_TSMANAGER	//for debug: only use original ts manager
+//#define TS_ENA_MULTI_STRATEGY	//for debug: run multi-strategy simultaneously
+#define TS_USE_QUERY_API		//the query value may be not matched with original method
+#define TS_LIST_LEN 128
+#define TS_LIST_FULL_THRESHOLD	(TS_LIST_LEN-5)
+#define TS_MAX_DIFF_US	90000
+#define TS_MAX_QUERY_DIFF_US	90000
+#define TS_INVALIDTS (-1)
+#define TS_SCALE	1000
+#define TS_ABS(t1,t2) (((t1)>=(t2))?((t1)-(t2)):((t2)-(t1)))
+#define TS_THRESHOLD_DURATION_INVALID (-1)
+#define TS_THRESHOLD_BLKCNT_INVALID (-1)
+
+#define LOG_PRINTF ALOGE
+
+//#define TS_DEBUG_ON
+#ifdef TS_DEBUG_ON
+#define TS_API	LOG_PRINTF
+#define TS_DEBUG LOG_PRINTF
+#define TS_ERROR LOG_PRINTF
+#else
+#define TS_API(...) //LOG_PRINTF
+#define TS_DEBUG(...) //LOG_PRINTF
+#define TS_ERROR LOG_PRINTF
+#endif
+
+#define ts_memset memset//fsl_osal_memset
+#define ts_memcpy memcpy//fsl_osal_memcpy
+#define ts_malloc malloc//FSL_MALLOC
+#define ts_free free//FSL_FREE
+#define TS_TRUE 1
+#define TS_FALSE 0
+
+typedef struct{
+	//new object
+	void* pHandle2;
+	int nInTsCnt2;
+	long long nInCurTs2;
+	int nIsActived2;	//accurate frame size is supported ?
+	signed long long nAccBlkOffset2;	//debug: accumulated bytes for blk
+	signed long long nAccFrmOffset2;	//debug: accumulated bytes for frame
+	long long nCurInputTs;     // input ts from parser(decode order)
+	long long nCurOutputTs;   // output ts from decoder(display order)
+
+	//global info
+	long long nLastTs;
+	long long nDeltaTs;
+
+	//data depth threshold: added for control the speed of feeding input, it is useful for rtsp/http application
+	long long nDurationMsThr;	/*threshold for timestamp duration cached in decoder:  <=0(default)-> no threshold*/
+	int nBlkCntThr;			/*threshold for blk(frame,field,...) count cached in decoder: <=0(default) -> no threshold*/
+}TSM_OBJ;
+
+static int DataDepthIsEnough(void* pHandle, void* pTsHandle)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+	int nBlkCnt;
+	int isEnough;
+	int isDurationEnough=0;
+	int isBlkEnough=0;
+	if((pObj->nDurationMsThr>0)
+		&& (TS_INVALIDTS!=pObj->nCurInputTs)&&(TS_INVALIDTS!=pObj->nCurOutputTs)
+		&& (pObj->nCurInputTs > pObj->nCurOutputTs+pObj->nDurationMsThr*1000)){
+		TS_DEBUG("input ts(us): %lld, output ts(us): %lld, duration threshold(ms): %lld 
",pObj->nCurInputTs,pObj->nCurOutputTs,pObj->nDurationMsThr);
+		isDurationEnough=1;
+	}
+	nBlkCnt=getTSManagerPreBufferCnt(pTsHandle);
+	if((pObj->nBlkCntThr>0)&&(nBlkCnt>pObj->nBlkCntThr)){
+		TS_DEBUG("cached blk cnt: %d, blkcnt threshold: %d 
",nBlkCnt,pObj->nBlkCntThr);
+		isBlkEnough=1;
+	}
+	isEnough = isDurationEnough & isBlkEnough;
+	return isEnough;
+}
+
+void* tsmCreate()
+{
+	TSM_OBJ* pObj=NULL;
+	void* ptr=NULL;
+
+	//malloc memory for object
+	pObj=(TSM_OBJ*)ts_malloc(sizeof(TSM_OBJ));
+	if(pObj==NULL){
+		TS_ERROR("%s: error: malloc %d bytes fail 
", __FUNCTION__, (int)sizeof(TSM_OBJ));
+		return NULL;
+	}
+	ts_memset((void*)pObj, 0, sizeof(TSM_OBJ));
+
+	//create new ts manager
+	TS_API("new:calling createTSManager(%d) 
",TS_LIST_LEN);
+	ptr=createTSManager(TS_LIST_LEN);
+	if(ptr){
+		pObj->pHandle2=ptr;
+		pObj->nInTsCnt2=0;
+		pObj->nInCurTs2=TS_INVALIDTS;
+		pObj->nCurInputTs=TS_INVALIDTS;
+		pObj->nCurOutputTs=TS_INVALIDTS;
+	}
+	else	{
+		goto TSM_Create_Fail;
+	}
+
+	//set default value
+	pObj->nLastTs=TS_INVALIDTS;
+	pObj->nDeltaTs=TS_INVALIDTS;
+	pObj->nDurationMsThr=TS_THRESHOLD_DURATION_INVALID;
+	pObj->nBlkCntThr=TS_THRESHOLD_BLKCNT_INVALID;
+	return (void*)pObj;
+
+TSM_Create_Fail:
+	if(pObj->pHandle2){
+		TS_API("new:calling destroyTSManager 
");
+		destroyTSManager(pObj->pHandle2);
+		pObj->pHandle2=NULL;
+	}
+	if(pObj){
+		ts_free(pObj);
+	}
+	return NULL;
+}
+
+int tsmDestroy(void* pHandle)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+	if(pObj->pHandle2){
+		TS_API("new:calling destroyTSManager 
");
+		destroyTSManager(pObj->pHandle2);
+		pObj->pHandle2=NULL;
+	}
+	ts_free(pObj);
+	return 1;
+}
+
+int tsmSetFrmRate(void* pHandle,int nFsN, int nFsD)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+	if(pObj->pHandle2){
+		TS_API("new:calling setTSManagerFrameRate: fps(%d/%d) 
",nFsN, nFsD);
+		setTSManagerFrameRate(pObj->pHandle2, nFsN, nFsD);
+	}
+	return 1;
+}
+
+
+int tsmSetBlkTs(void* pHandle,int nSize, TSM_TIMESTAMP Ts)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+	TSM_TIMESTAMP ts=TS_INVALIDTS;
+
+	if(pObj->pHandle2){
+		ts=Ts;
+		if(ts == TS_INVALIDTS){
+			ts = TSM_TIMESTAMP_NONE;
+			//pObj->nCurInputTs=TS_INVALIDTS;
+		}
+		else{
+			pObj->nCurInputTs=ts;
+			ts*= TS_SCALE;
+		}
+		TS_API("new:calling TSManagerReceive2: [%lld(0x%llX)] ts(ns): %lld, size: %d, total: %d
",pObj->nAccBlkOffset2,pObj->nAccBlkOffset2,ts, nSize,(int)pObj->nInTsCnt2);
+		TSManagerReceive2(pObj->pHandle2, ts,nSize);
+		pObj->nInTsCnt2++;
+		pObj->nAccBlkOffset2+=nSize;
+	}
+	return 1;
+}
+
+int tsmSetFrmBoundary(void* pHandle,int nStuffSize,int nFrmSize,void* pfrmHandle)
+{
+	/*pfrmHandle==NULL: the frame is skipped for skipmode/corrupt/... cases*/
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+
+	if(pObj->pHandle2){
+		if(pObj->nIsActived2==0){
+			pObj->nIsActived2=1;	//accurate frame size is reported by decoder
+		}
+		pObj->nAccFrmOffset2+=nStuffSize;
+#if 1	//consider special case: config data contain valid frames, as result, stuffsize < 0
+		if(pObj->nAccFrmOffset2+nFrmSize<=0)
+		{
+			TS_API("new:calling TSManagerValid2(0): [%lld(0x%llX)]: discarded frame size: %d 
",pObj->nAccFrmOffset2,pObj->nAccFrmOffset2,nFrmSize);
+			TSManagerValid2(pObj->pHandle2,0,pfrmHandle);
+		}
+		else if(pObj->nAccFrmOffset2<=0)
+		{
+			TS_API("new:calling TSManagerValid2(*): [%lld(0x%llX)]: discarded frame size: %d 
",pObj->nAccFrmOffset2,pObj->nAccFrmOffset2,nFrmSize);
+			TSManagerValid2(pObj->pHandle2,pObj->nAccFrmOffset2+nFrmSize,pfrmHandle);
+		}
+		else
+#endif
+		{
+			if(NULL==pfrmHandle){
+				TS_API("new:calling TSManagerValid2: [%lld(0x%llX)]: flush %d bytes, skipped frame size: %d 
",pObj->nAccFrmOffset2,pObj->nAccFrmOffset2,nStuffSize,nFrmSize);
+				TSManagerValid2(pObj->pHandle2,nStuffSize+nFrmSize,pfrmHandle);
+			}
+			else{
+				TS_API("new:calling TSManagerFlush2/TSManagerValid2: [%lld(0x%llX)]: flush %d bytes, frame size: %d, frm: %p 
",pObj->nAccFrmOffset2,pObj->nAccFrmOffset2,nStuffSize,nFrmSize,pfrmHandle);
+				TSManagerFlush2(pObj->pHandle2,nStuffSize);
+				TSManagerValid2(pObj->pHandle2,nFrmSize,pfrmHandle);
+			}
+		}
+		//In fact, nInTsCnt2 may be changed after calling TSManagerValid2(), so nInTsCnt2 become unmeaningful
+		pObj->nAccFrmOffset2+=nFrmSize;
+	}
+	return 1;
+}
+
+
+TSM_TIMESTAMP tsmGetFrmTs(void* pHandle,void* pfrmHandle)
+{
+	/*nfrmHandle==NULL:
+		(1) only need to pop one time stamp. (e.g. frame is not decoded at all by vpu for skipmode/corrupt/... cases);
+		(2) mosaic frame which is dropped by vpu for non-gop case
+	*/
+	TSM_TIMESTAMP ts=TS_INVALIDTS;
+	TSM_TIMESTAMP ts2=TS_INVALIDTS;
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+
+	if(pObj->pHandle2){
+		if(pObj->nIsActived2==0){
+			TS_DEBUG("new strategy isn't detected, it will be disabled automatically
");
+			TS_API("new: calling destroyTSManager
");
+			destroyTSManager(pObj->pHandle2);
+			pObj->pHandle2=NULL;
+		}
+		else{
+			if(pObj->nInCurTs2 != TS_INVALIDTS) {
+				ts2 = pObj->nInCurTs2;
+				pObj->nInCurTs2 = TS_INVALIDTS;
+			}
+			else{
+				if(NULL==pfrmHandle){
+					ts2=TSManagerSend2(pObj->pHandle2, NULL);
+					TS_API("new: calling TSManagerSend2(NULL): returned ts(ns): %lld, total: %d 
",ts2, (int)pObj->nInTsCnt2);
+				}
+				else{
+					ts2=TSManagerSend2(pObj->pHandle2, pfrmHandle);
+					TS_API("new: calling TSManagerSend2: frm: %p, returned ts(ns): %lld, total: %d 
",pfrmHandle,ts2, (int)pObj->nInTsCnt2);
+				}
+				ts2=(ts2==TS_INVALIDTS)?ts2:(ts2/TS_SCALE);
+				pObj->nInTsCnt2--;
+			}
+			//TS_DEBUG("new: get one ts: %lld, total: %d
", ts2, (int)pObj->nInTsCnt2);
+			ts=ts2;
+			pObj->nCurOutputTs=ts;
+		}
+	}
+
+
+	if(ts==TS_INVALIDTS){
+		TS_ERROR("%s: warning: can't get one valid ts 
",__FUNCTION__);
+	}
+#ifdef TS_DEBUG
+	if(pObj->nLastTs!=TS_INVALIDTS){
+		pObj->nDeltaTs=ts-pObj->nLastTs;
+	}
+	pObj->nLastTs=ts;
+	TS_DEBUG("%s: current ts(us): %lld, delta(us): %lld 
",__FUNCTION__,pObj->nLastTs,pObj->nDeltaTs);
+#endif
+	return ts;
+}
+
+int tsmReSync(void* pHandle, TSM_TIMESTAMP synctime, TSMGR_MODE mode)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+	TSM_TIMESTAMP ts;
+
+	if(pObj->pHandle2){
+		ts=synctime*TS_SCALE;
+		TS_API("new: calling resyncTSManager: synctime: %lld, mode: %d 
",ts,mode);
+		resyncTSManager(pObj->pHandle2, ts, mode);
+	}
+	return 1;
+}
+
+int tsmFlush(void* pHandle)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+
+	if(pObj->pHandle2){
+		pObj->nInTsCnt2=0;
+		pObj->nInCurTs2=TS_INVALIDTS;
+		pObj->nAccBlkOffset2=0;
+		pObj->nAccFrmOffset2=0;
+		pObj->nCurInputTs=TS_INVALIDTS;
+		pObj->nCurOutputTs=TS_INVALIDTS;
+	}
+	pObj->nLastTs=TS_INVALIDTS;
+	pObj->nDeltaTs=TS_INVALIDTS;
+	return 1;
+}
+
+int tsmHasEnoughSlot(void* pHandle)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+
+	if(pObj->pHandle2){
+		if(DataDepthIsEnough(pHandle,pObj->pHandle2))
+		{
+			return TS_FALSE;
+		}
+		else{
+			return TS_TRUE;
+		}
+	}
+	return TS_TRUE;
+}
+
+TSM_TIMESTAMP tsmQueryCurrTs(void* pHandle)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+	TSM_TIMESTAMP ts=TS_INVALIDTS;
+	TSM_TIMESTAMP tsOri=TS_INVALIDTS;
+	TSM_TIMESTAMP ts2=TS_INVALIDTS;
+	TSM_TIMESTAMP tsDiff;
+
+	if(pObj->pHandle2){
+#ifdef TS_USE_QUERY_API
+		if(pObj->nIsActived2==0){
+			//hasn't been enabled
+			ts2=TS_INVALIDTS;
+		}
+		else{
+			//FIXME: the ts may be not matched
+			ts2=TSManagerQuery2(pObj->pHandle2,NULL);
+			TS_API("new: calling TSManagerQuery2(NULL): returned ts(ns): %lld 
",ts2);
+			ts2=(ts2==TS_INVALIDTS)?ts2:(ts2/TS_SCALE);
+		}
+#else
+		if(pObj->nInTsCnt2 == 0){
+			ts2=TS_INVALIDTS;
+		}
+		else if(pObj->nInCurTs2 != TS_INVALIDTS){
+			ts2=pObj->nInCurTs2;
+		}
+		else{
+			//FIXME: the ts may be not matched without calling TSManagerValid2()
+			ts2 = TSManagerSend2(pObj->pHandle2,NULL);
+			TS_API("new: calling TSManagerSend2(NULL): returned(query) ts(ns): %lld 
",ts2);
+			if(ts2<0){
+				TS_ERROR("%s: error: one invalid ts(%lld) is queried: set it 0 manually
",__FUNCTION__,ts2);
+				//set one different value with TS_INVALIDTS to match the 'nInTsCntOri'
+				pObj->nInCurTs2=TS_INVALIDTS+1;
+			}
+			else{
+				ts2=(ts2==TS_INVALIDTS)?ts2:(ts2/TS_SCALE);
+				pObj->nInCurTs2 = ts2;
+			}
+			pObj->nInTsCnt2--;
+		}
+#endif
+		ts=ts2;
+		//TS_DEBUG("new: query one ts: %lld 
",ts2);
+	}
+
+	//double check the ts for different schema
+	//if(pObj->pHandleOri && pObj->pHandle2){
+	if((tsOri!=TS_INVALIDTS)&&(ts2!=TS_INVALIDTS)){
+		tsDiff=TS_ABS(tsOri,ts2);
+		if(tsDiff>=TS_MAX_QUERY_DIFF_US){
+			TS_ERROR("LEVEL: 1 %s: the time stamp is conflict: ori ts(us): %lld, new ts(us): %lld, diff(us): %lld 
",__FUNCTION__,tsOri,ts2,tsDiff);
+		}
+	}
+
+	return ts;
+}
+
+int tsmSetDataDepthThreshold(void* pHandle,int nDurationThr, int nBlkCntThr)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+	pObj->nDurationMsThr=nDurationThr;
+	pObj->nBlkCntThr=nBlkCntThr;
+	return 1;
+}
+
+int tsmClearCachedFrameTs(void* pHandle)
+{
+	TSM_OBJ* pObj=(TSM_OBJ*)pHandle;
+	int nBlkCnt;
+	TSM_TIMESTAMP ts;
+	/*in this function, we only clear those frame be decoded already*/
+
+	if(pObj->pHandle2){
+		/*in new design, only decoded frame is inserted the ready list, so we can clear them*/
+		nBlkCnt=getTSManagerPreBufferCnt(pObj->pHandle2);
+		TS_DEBUG("nBlkCnt: %d , nInTsCnt2: %d 
",nBlkCnt,pObj->nInTsCnt2);
+		while(nBlkCnt>0){
+			nBlkCnt--;
+			ts=TSManagerSend2(pObj->pHandle2, NULL);
+			TS_DEBUG("drop %lld 
",ts);
+			if(ts==TS_INVALIDTS){
+				break;
+			}
+		}
+	}
+	return 1;
+}
+
diff --git a/codec2/tsm/Tsm_wrapper.h b/codec2/tsm/Tsm_wrapper.h
new file mode 100755
index 0000000..1555fbf
--- /dev/null
+++ b/codec2/tsm/Tsm_wrapper.h
@@ -0,0 +1,36 @@
+/**
+ *  Copyright (c) 2011-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+#ifndef _TSM_WRAPPER_H_
+#define _TSM_WRAPPER_H_
+
+#include "mfw_gst_ts.h"
+#ifdef __cplusplus
+extern "C" {
+#endif /* __cplusplus */
+
+void* tsmCreate();
+int tsmDestroy(void * pHandle);
+int tsmSetFrmRate(void * pHandle,int nFsN, int nFsD);
+int tsmSetBlkTs(void * pHandle,int nSize, TSM_TIMESTAMP Ts);
+int tsmSetFrmBoundary(void * pHandle,int nStuffSize,int nFrmSize,void * pfrmHandle);
+TSM_TIMESTAMP tsmGetFrmTs(void * pHandle,void * pfrmHandle);
+int tsmReSync(void * pHandle, TSM_TIMESTAMP synctime, TSMGR_MODE mode);
+int tsmFlush(void * pHandle);
+int tsmHasEnoughSlot(void * pHandle);
+TSM_TIMESTAMP tsmQueryCurrTs(void * pHandle);
+int tsmSetDataDepthThreshold(void* pHandle,int nDurationThr, int nBlkCntThr);
+int tsmClearCachedFrameTs(void* pHandle);
+
+#ifdef __cplusplus
+}
+#endif /* __cplusplus */
+
+#endif  //_TSM_WRAPPER_H_
+
diff --git a/codec2/tsm/mfw_gst_ts.c b/codec2/tsm/mfw_gst_ts.c
new file mode 100644
index 0000000..8bbf8c1
--- /dev/null
+++ b/codec2/tsm/mfw_gst_ts.c
@@ -0,0 +1,750 @@
+/**
+ *  Copyright (c) 2010-2013, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+/*
+ * Module Name:    TimeStamp.c
+ *
+ * Description:    include TimeStamp stratege for VPU / SW video decoder plugin
+ *
+ * Portability:    This code is written for Linux OS and Gstreamer
+ */
+
+/*
+ * Changelog:
+  11/2/2010        draft version       Lyon Wang
+ *
+ */
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#include "mfw_gst_ts.h"
+
+const char *debug_env = "ME_DEBUG";
+char *debug = NULL;
+int debug_level = 0;
+
+
+enum
+{
+  DEBUG_LEVEL_ERROR = 1,
+  DEBUG_LEVEL_WARNING,
+  DEBUG_LEVEL_LOG,
+  DEBUG_LEVEL_VERBOSE,
+};
+
+
+#define TSM_MESSAGE(level, fmt, ...)\
+  do{\
+    if (debug_level>=(level)){\
+      printf("TSM:"fmt, ##__VA_ARGS__);\
+    }\
+  }while(0)
+
+#define TSM_ERROR(...) TSM_MESSAGE(DEBUG_LEVEL_ERROR, ##__VA_ARGS__)
+#define TSM_WARNING(...) TSM_MESSAGE(DEBUG_LEVEL_WARNING, ##__VA_ARGS__)
+#define TSM_LOG(...) TSM_MESSAGE(DEBUG_LEVEL_LOG, ##__VA_ARGS__)
+#define TSM_VERBOSE(...) TSM_MESSAGE(DEBUG_LEVEL_VERBOSE, ##__VA_ARGS__)
+
+#define TSM_HISTORY_POWER 5
+#define TSM_HISTORY_SIZE (1<<TSM_HISTORY_POWER)
+#define TSM_ADAPTIVE_INTERVAL(tsm) \
+    (tsm->dur_history_total>>TSM_HISTORY_POWER)
+
+#define TSM_SECOND ((TSM_TIMESTAMP)1000000000)
+#define TSM_DEFAULT_INTERVAL (TSM_SECOND/30)
+#define TSM_DEFAULT_TS_BUFFER_SIZE (128)
+
+#define TSM_TS_IS_VALID(ts)	\
+    ((ts) != TSM_TIMESTAMP_NONE)
+
+#define TSM_KEY_IS_VALID(key) \
+    ((key) != TSM_KEY_NONE)
+
+#define TSM_DISTANCE(tsm)\
+    (((tsm->rx)>=(tsm->tx))?((tsm->rx)-(tsm->tx)):(tsm->ts_buf_size-(tsm->tx)+(tsm->rx)))
+
+#define TSM_PLUS_AGE(tsm)\
+    (TSM_DISTANCE(tsm)+tsm->invalid_ts_count+2)
+
+#define TSM_ABS(ts0, ts1)\
+    (((ts0)>(ts1))?((ts0)-(ts1)):((ts1)-(ts0)))
+
+#define TSM_TIME_FORMAT "u:%02u:%02u.%09u"
+
+#define TSM_TIME_ARGS(t) \
+        TSM_TS_IS_VALID (t) ? \
+        (unsigned int) (((TSM_TIMESTAMP)(t)) / (TSM_SECOND * 60 * 60)) : 99, \
+        TSM_TS_IS_VALID (t) ? \
+        (unsigned int) ((((TSM_TIMESTAMP)(t)) / (TSM_SECOND * 60)) % 60) : 99, \
+        TSM_TS_IS_VALID (t) ? \
+        (unsigned int) ((((TSM_TIMESTAMP)(t)) / TSM_SECOND) % 60) : 99, \
+        TSM_TS_IS_VALID (t) ? \
+        (unsigned int) (((TSM_TIMESTAMP)(t)) % TSM_SECOND) : 999999999
+
+#define TSM_BUFFER_SET(buf, value, size) \
+    do {\
+        int i;\
+        for (i=0;i<(size);i++){\
+            (buf)[i] = (value);\
+        }\
+    }while(0)
+
+#define TSM_RECEIVED_NUNBER 512
+
+
+typedef struct
+{
+  TSM_TIMESTAMP ts;
+  unsigned long long age;
+  void *key;
+} TSMControl;
+
+typedef struct _TSMReceivedEntry
+{
+  TSM_TIMESTAMP ts;
+  struct _TSMReceivedEntry *next;
+  unsigned int used:1;
+  unsigned int subentry:1;
+  int size;
+} TSMReceivedEntry;
+
+typedef struct _TSMReceivedEntryMemory
+{
+  struct _TSMReceivedEntryMemory *next;
+  TSMReceivedEntry entrys[TSM_RECEIVED_NUNBER];
+} TSMReceivedEntryMemory;
+
+typedef struct
+{
+  TSMReceivedEntry *head;
+  TSMReceivedEntry *tail;
+  TSMReceivedEntry *free;
+  TSMReceivedEntryMemory *memory;
+  int cnt;
+} TSMRecivedCtl;
+
+typedef struct _TSManager
+{
+  int first_tx;
+  int first_rx;
+  int rx;                       //timestamps received
+  int tx;                       //timestamps transfered
+  TSM_TIMESTAMP last_ts_sent;   //last time stamp sent
+  TSM_TIMESTAMP last_ts_received;
+  TSM_TIMESTAMP suspicious_ts;
+
+  TSM_TIMESTAMP discont_threshold;
+
+  unsigned int invalid_ts_count;
+  TSMGR_MODE mode;
+  int ts_buf_size;
+  int dur_history_tx;
+  TSM_TIMESTAMP dur_history_total;
+  TSM_TIMESTAMP dur_history_buf[TSM_HISTORY_SIZE];
+  TSMControl *ts_buf;
+  unsigned long long age;
+  int tx_cnt;
+  int rx_cnt;
+  int cnt;
+  int valid_ts_received:1;
+  int big_cnt;
+
+  TSMRecivedCtl rctl;
+} TSManager;
+
+
+static void
+tsm_free_received_entry (TSMRecivedCtl * rctl, TSMReceivedEntry * entry)
+{
+  entry->next = rctl->free;
+  rctl->free = entry;
+}
+
+
+static TSMReceivedEntry *
+tsm_new_received_entry (TSMRecivedCtl * rctl)
+{
+  TSMReceivedEntry *ret = NULL;
+  if (rctl->free) {
+    ret = rctl->free;
+    rctl->free = ret->next;
+  } else {
+    TSMReceivedEntryMemory *p = malloc (sizeof (TSMReceivedEntryMemory));
+    if (p) {
+      int i;
+      for (i = 1; i < TSM_RECEIVED_NUNBER; i++) {
+        TSMReceivedEntry *e = &p->entrys[i];
+        tsm_free_received_entry (rctl, e);
+      };
+
+      p->next = rctl->memory;
+      rctl->memory = p;
+
+      ret = p->entrys;
+    }
+  }
+  return ret;
+}
+
+
+void
+TSManagerReceive2 (void *handle, TSM_TIMESTAMP timestamp, int size)
+{
+#define CLEAR_TSM_RENTRY(entry)\
+  do { \
+    (entry)->used = 0; \
+    (entry)->subentry = 0; \
+    (entry)->next = NULL; \
+  } while (0)
+  TSManager *tsm = (TSManager *) handle;
+
+  TSM_VERBOSE ("receive2 %" TSM_TIME_FORMAT " size %d
",
+      TSM_TIME_ARGS (timestamp), size);
+
+  if (tsm) {
+    if (size > 0) {
+      TSMRecivedCtl *rctl = &tsm->rctl;
+      TSMReceivedEntry *e = tsm_new_received_entry (rctl);
+      if (e) {
+        CLEAR_TSM_RENTRY (e);
+        if ((rctl->tail) && (rctl->tail->ts == timestamp)) {
+          e->subentry = 1;
+        }
+        e->ts = timestamp;
+        e->size = size;
+        if (rctl->tail) {
+          rctl->tail->next = e;
+          rctl->tail = e;
+        } else {
+          rctl->head = rctl->tail = e;
+        }
+      }
+      rctl->cnt++;
+    } else {
+      TSManagerReceive (handle, timestamp);
+    }
+  }
+}
+
+
+static TSM_TIMESTAMP
+TSManagerGetLastTimeStamp (TSMRecivedCtl * rctl, int size, int use)
+{
+  TSM_TIMESTAMP ts = TSM_TIMESTAMP_NONE;
+  TSMReceivedEntry *e;
+  while ((size > 0) && (e = rctl->head)) {
+    ts = ((e->used) ? (TSM_TIMESTAMP_NONE) : (e->ts));
+    if (use)
+      e->used = 1;
+    if (size >= e->size) {
+      rctl->head = e->next;
+      if (rctl->head == NULL) {
+        rctl->tail = NULL;
+      } else {
+        if (rctl->head->subentry) {
+          rctl->head->used = e->used;
+        }
+      }
+      size -= e->size;
+      rctl->cnt--;
+      tsm_free_received_entry (rctl, e);
+    } else {
+      e->size -= size;
+      size = 0;
+    }
+  }
+  return ts;
+}
+
+
+void
+TSManagerFlush2 (void *handle, int size)
+{
+  TSManager *tsm = (TSManager *) handle;
+  if (tsm) {
+    TSManagerGetLastTimeStamp (&tsm->rctl, size, 0);
+  }
+
+}
+
+
+/*======================================================================================
+FUNCTION:           mfw_gst_receive_ts
+
+DESCRIPTION:        Check timestamp and do frame dropping if enabled
+
+ARGUMENTS PASSED:   pTimeStamp_Object  - TimeStamp Manager to handle related timestamp
+                    timestamp - time stamp of the input buffer which has video data.
+
+RETURN VALUE:       None
+PRE-CONDITIONS:     None
+POST-CONDITIONS:    None
+IMPORTANT NOTES:    None
+=======================================================================================*/
+static void
+_TSManagerReceive (void *handle, TSM_TIMESTAMP timestamp, void *key)
+{
+  TSManager *tsm = (TSManager *) handle;
+
+  if (tsm) {
+    if (TSM_TS_IS_VALID (timestamp) && (tsm->rx_cnt))
+      tsm->valid_ts_received = 1;
+    tsm->rx_cnt++;
+    if (tsm->cnt < tsm->ts_buf_size - 1) {
+      tsm->cnt++;
+      if (tsm->mode == MODE_AI) {
+
+        if (TSM_TS_IS_VALID (timestamp)) {
+          if (tsm->first_rx) {
+            tsm->last_ts_received = timestamp;
+            tsm->first_rx = 0;
+          } else {
+            if (tsm->suspicious_ts) {
+              if (timestamp >= tsm->suspicious_ts) {
+                tsm->last_ts_received = timestamp;
+              }
+              tsm->suspicious_ts = 0;
+            }
+            if ((timestamp > tsm->last_ts_received)
+                && (timestamp - tsm->last_ts_received > tsm->discont_threshold)) {
+              tsm->suspicious_ts = timestamp;
+              timestamp = TSM_TIMESTAMP_NONE;
+            }
+          }
+        }
+
+        if (TSM_TS_IS_VALID (timestamp))        // && (TSM_ABS(timestamp, tsm->last_ts_sent)<TSM_SECOND*10))
+        {
+          tsm->ts_buf[tsm->rx].ts = timestamp;
+          tsm->ts_buf[tsm->rx].age = tsm->age + TSM_PLUS_AGE (tsm);
+          tsm->ts_buf[tsm->rx].key = key;
+          tsm->last_ts_received = timestamp;
+#ifdef DEBUG
+          //printf("age should %lld %lld
", tsm->age, tsm->ts_buf[tsm->rx].age);
+          //printf("++++++ distance = %d  tx=%d, rx=%d, invalid count=%d
", TSM_DISTANCE(tsm), tsm->tx, tsm->rx,tsm->invalid_ts_count);
+#endif
+          tsm->rx = ((tsm->rx + 1) % tsm->ts_buf_size);
+        } else {
+          tsm->invalid_ts_count++;
+        }
+      } else if (tsm->mode == MODE_FIFO) {
+        tsm->ts_buf[tsm->rx].ts = timestamp;
+        tsm->rx = ((tsm->rx + 1) % tsm->ts_buf_size);
+      }
+      TSM_LOG ("++Receive %d:%" TSM_TIME_FORMAT
+          ", invalid:%d, size:%d key %p
", tsm->rx_cnt,
+          TSM_TIME_ARGS (timestamp), tsm->invalid_ts_count, tsm->cnt, key);
+    } else {
+      TSM_ERROR ("Too many timestamps recieved!! (cnt=%d)
", tsm->cnt);
+    }
+  }
+}
+
+
+void
+TSManagerValid2 (void *handle, int size, void *key)
+{
+  TSManager *tsm = (TSManager *) handle;
+
+  TSM_VERBOSE ("valid2 size %d
", size);
+
+  if (tsm) {
+    TSM_TIMESTAMP ts;
+    ts = TSManagerGetLastTimeStamp (&tsm->rctl, size, 1);
+    _TSManagerReceive (tsm, ts, key);
+  }
+}
+
+
+void
+TSManagerReceive (void *handle, TSM_TIMESTAMP timestamp)
+{
+  _TSManagerReceive (handle, timestamp, TSM_KEY_NONE);
+}
+
+
+/*======================================================================================
+FUNCTION:           TSManagerSend
+
+DESCRIPTION:        Check timestamp and do frame dropping if enabled
+
+ARGUMENTS PASSED:   pTimeStamp_Object  - TimeStamp Manager to handle related timestamp
+                    ptimestamp - returned timestamp to use at render
+
+RETURN VALUE:       None
+PRE-CONDITIONS:     None
+POST-CONDITIONS:    None
+IMPORTANT NOTES:    None
+=======================================================================================*/
+static TSM_TIMESTAMP
+_TSManagerSend2 (void *handle, void *key, int send)
+{
+  TSManager *tsm = (TSManager *) handle;
+  int index = -1;
+  int isValidTs=0;
+  TSM_TIMESTAMP ts0 = 0, tstmp = TSM_TIMESTAMP_NONE;
+  unsigned long long age = 0;
+
+  if(tsm == NULL)
+    return tstmp;
+
+  int i = tsm->tx;
+  TSM_TIMESTAMP half_interval = TSM_ADAPTIVE_INTERVAL (tsm) >> 1;
+
+
+  if (tsm) {
+    if (send) {
+      tsm->tx_cnt++;
+    } else {
+      tsm->cnt++;
+      tsm->invalid_ts_count++;
+    }
+    if (tsm->cnt > 0) {
+      if (send) {
+        tsm->cnt--;
+      }
+      if (tsm->mode == MODE_AI) {
+
+        if (tsm->first_tx == 0) {
+          tstmp = tsm->last_ts_sent + TSM_ADAPTIVE_INTERVAL (tsm);
+        } else {
+          tstmp = tsm->last_ts_sent;
+        }
+
+        while (i != tsm->rx) {
+          if (index >= 0) {
+            if (tsm->ts_buf[i].ts < ts0) {
+              ts0 = tsm->ts_buf[i].ts;
+              age = tsm->ts_buf[i].age;
+              index = i;
+            }
+          } else {
+            ts0 = tsm->ts_buf[i].ts;
+            age = tsm->ts_buf[i].age;
+            index = i;
+          }
+          if ((TSM_KEY_IS_VALID (key)) && (key == tsm->ts_buf[i].key))
+            break;
+          i = ((i + 1) % tsm->ts_buf_size);
+        }
+        if (index >= 0) {
+          if ((tsm->invalid_ts_count) && (ts0 >= ((tstmp) + half_interval))
+              && (age > tsm->age)) {
+            /* use calculated ts0 */
+            if (send) {
+              tsm->invalid_ts_count--;
+            }
+          } else {
+
+            if (send) {
+              if (index != tsm->tx) {
+                tsm->ts_buf[index] = tsm->ts_buf[tsm->tx];
+              }
+              tsm->tx = ((tsm->tx + 1) % tsm->ts_buf_size);
+
+            }
+#if 0
+            if (ts0 >= ((tstmp) + half_interval))
+              tstmp = tstmp;
+            else
+              tstmp = ts0;
+#else
+            tstmp = ts0;
+#endif
+            isValidTs=1;
+          }
+
+        } else {
+          if (send) {
+            tsm->invalid_ts_count--;
+          }
+        }
+
+        if (tsm->first_tx == 0) {
+
+          if (tstmp > tsm->last_ts_sent) {
+            ts0 = (tstmp - tsm->last_ts_sent);
+          } else {
+            ts0 = 0;
+            //reset the timestamp to last frame only when new frames's timestamp is earlier than one frame.
+            if(tstmp + TSM_ADAPTIVE_INTERVAL (tsm) * 3 / 2 < tsm->last_ts_sent )
+              tstmp = tsm->last_ts_sent;
+          }
+
+          if (ts0 > TSM_ADAPTIVE_INTERVAL (tsm) * 3 / 2) {
+            TSM_WARNING ("Jitter1:%" TSM_TIME_FORMAT " %" TSM_TIME_FORMAT "
",
+                TSM_TIME_ARGS (ts0),
+                TSM_TIME_ARGS (TSM_ADAPTIVE_INTERVAL (tsm) * 3 / 2));
+          } else if (ts0 == 0) {
+            TSM_WARNING ("Jitter:%" TSM_TIME_FORMAT "
", TSM_TIME_ARGS (ts0));
+          }
+
+          if (send) {
+            if(isValidTs && ts0 > TSM_ADAPTIVE_INTERVAL (tsm) * 2)
+                ts0 = TSM_ADAPTIVE_INTERVAL (tsm) * 2;
+            //printf("tstmp: %lld, ts0 %lld, interv %lld, big_cnt %d, is Valid %d
", tstmp, ts0, TSM_ADAPTIVE_INTERVAL (tsm),tsm->big_cnt, isValidTs);
+            if ((ts0 <= TSM_ADAPTIVE_INTERVAL (tsm) * 2) || (tsm->big_cnt > 3)) {
+              tsm->big_cnt = 0;
+              tsm->dur_history_total -=
+                  tsm->dur_history_buf[tsm->dur_history_tx];
+              tsm->dur_history_buf[tsm->dur_history_tx] = ts0;
+              tsm->dur_history_tx =
+                  ((tsm->dur_history_tx + 1) % TSM_HISTORY_SIZE);
+              tsm->dur_history_total += ts0;
+            } else {
+              tsm->big_cnt++;
+            }
+          }
+        }
+
+        if (send) {
+          tsm->last_ts_sent = tstmp;
+          tsm->age++;
+          tsm->first_tx = 0;
+        }
+
+      } else if (tsm->mode == MODE_FIFO) {
+        tstmp = tsm->ts_buf[tsm->tx].ts;
+        if (send) {
+          tsm->tx = ((tsm->tx + 1) % tsm->ts_buf_size);
+        }
+        ts0 = tstmp - tsm->last_ts_sent;
+        if (send) {
+          tsm->last_ts_sent = tstmp;
+        }
+      }
+
+      if (send) {
+        TSM_LOG ("--Send %d:%" TSM_TIME_FORMAT ", int:%" TSM_TIME_FORMAT
+            ", avg:%" TSM_TIME_FORMAT " inkey %p
", tsm->tx_cnt,
+            TSM_TIME_ARGS (tstmp), TSM_TIME_ARGS (ts0),
+            TSM_TIME_ARGS (TSM_ADAPTIVE_INTERVAL (tsm)), key);
+      }
+
+    } else {
+      if (tsm->valid_ts_received == 0) {
+        if (tsm->first_tx) {
+          tstmp = tsm->last_ts_sent;
+        } else {
+          tstmp = tsm->last_ts_sent + TSM_ADAPTIVE_INTERVAL (tsm);
+        }
+        if (send) {
+          tsm->first_tx = 0;
+          tsm->last_ts_sent = tstmp;
+        }
+      }
+      TSM_ERROR ("Too many timestamps send!!
");
+    }
+
+    if (send == 0) {
+      tsm->cnt--;
+      tsm->invalid_ts_count--;
+    }
+
+  }
+
+  return tstmp;
+}
+
+
+TSM_TIMESTAMP
+TSManagerSend2 (void *handle, void *key)
+{
+  return _TSManagerSend2 (handle, key, 1);
+}
+
+
+TSM_TIMESTAMP
+TSManagerQuery2 (void *handle, void *key)
+{
+  return _TSManagerSend2 (handle, key, 0);
+}
+
+
+TSM_TIMESTAMP
+TSManagerSend (void *handle)
+{
+  return TSManagerSend2 (handle, TSM_KEY_NONE);
+}
+
+
+TSM_TIMESTAMP
+TSManagerQuery (void *handle)
+{
+  return TSManagerQuery2 (handle, TSM_KEY_NONE);
+}
+
+
+void
+resyncTSManager (void *handle, TSM_TIMESTAMP synctime, TSMGR_MODE mode)
+{
+  TSManager *tsm = (TSManager *) handle;
+  if (tsm) {
+    TSMRecivedCtl *rctl = &tsm->rctl;
+    TSMReceivedEntry *e = rctl->head;
+
+    while ((e = rctl->head)) {
+      rctl->head = e->next;
+      tsm_free_received_entry (rctl, e);
+    };
+    rctl->cnt = 0;
+
+    rctl->tail = NULL;
+
+    tsm->first_tx = 1;
+    tsm->first_rx = 1;
+    tsm->suspicious_ts = 0;
+
+    if (TSM_TS_IS_VALID (synctime))
+      tsm->last_ts_sent = synctime;
+
+    tsm->tx = tsm->rx = 0;
+    tsm->invalid_ts_count = 0;
+    tsm->mode = mode;
+    tsm->age = 0;
+    tsm->rx_cnt = tsm->tx_cnt = tsm->cnt = 0;
+    tsm->valid_ts_received = 0;
+
+    tsm->big_cnt = 0;
+  }
+}
+
+
+/*======================================================================================
+FUNCTION:           mfw_gst_init_ts
+
+DESCRIPTION:        malloc and initialize timestamp strcture
+
+ARGUMENTS PASSED:   ppTimeStamp_Object  - pointer of TimeStamp Manager to handle related timestamp
+
+RETURN VALUE:       TimeStamp structure pointer
+PRE-CONDITIONS:     None
+POST-CONDITIONS:    None
+IMPORTANT NOTES:    None
+=======================================================================================*/
+void *
+createTSManager (int ts_buf_size)
+{
+  TSManager *tsm = (TSManager *) malloc (sizeof (TSManager));
+  debug = getenv (debug_env);
+  if (debug) {
+    debug_level = atoi (debug);
+  }
+  // printf("debug = %s 
 ++++++++++++++++++++++++++++",debug);
+  if (tsm) {
+    memset (tsm, 0, sizeof (TSManager));
+    if (ts_buf_size <= 0) {
+      ts_buf_size = TSM_DEFAULT_TS_BUFFER_SIZE;
+    }
+    tsm->ts_buf_size = ts_buf_size;
+    tsm->ts_buf = malloc (sizeof (TSMControl) * ts_buf_size);
+
+    if (tsm->ts_buf == NULL) {
+      goto fail;
+    }
+
+    resyncTSManager (tsm, (TSM_TIMESTAMP) 0, MODE_AI);
+
+    tsm->dur_history_tx = 0;
+    TSM_BUFFER_SET (tsm->dur_history_buf, TSM_DEFAULT_INTERVAL,
+        TSM_HISTORY_SIZE);
+    tsm->dur_history_total = TSM_DEFAULT_INTERVAL << TSM_HISTORY_POWER;
+
+    tsm->discont_threshold = 10000000000LL;     // 10s
+  }
+  return tsm;
+fail:
+  if (tsm) {
+    if (tsm->ts_buf) {
+      free (tsm->ts_buf);
+    }
+    free (tsm);
+    tsm = NULL;
+  }
+  return tsm;
+}
+
+
+void
+destroyTSManager (void *handle)
+{
+  TSManager *tsm = (TSManager *) handle;
+  if (tsm) {
+    TSMRecivedCtl *rctl = &tsm->rctl;
+    TSMReceivedEntryMemory *rmem;
+    if (tsm->ts_buf) {
+      free (tsm->ts_buf);
+    }
+
+    while ((rmem = rctl->memory)) {
+      rctl->memory = rmem->next;
+      free (rmem);
+    }
+    free (tsm);
+    tsm = NULL;
+  }
+}
+
+
+void
+setTSManagerFrameRate (void *handle, int fps_n, int fps_d)
+//void setTSManagerFrameRate(void * handle, float framerate)
+{
+  TSManager *tsm = (TSManager *) handle;
+  TSM_TIMESTAMP ts;
+  if ((fps_n > 0) && (fps_d > 0) && (fps_n / fps_d <= 80))
+    ts = TSM_SECOND * fps_d / fps_n;
+  else
+    ts = TSM_DEFAULT_INTERVAL;
+  // TSM_TIMESTAMP ts = TSM_SECOND / framerate;
+
+  if (tsm) {
+    TSM_BUFFER_SET (tsm->dur_history_buf, ts, TSM_HISTORY_SIZE);
+    tsm->dur_history_total = (ts << TSM_HISTORY_POWER);
+    if (debug)
+      TSM_LOG ("Set frame intrval:%" TSM_TIME_FORMAT "
", TSM_TIME_ARGS (ts));
+  }
+}
+
+
+TSM_TIMESTAMP
+getTSManagerFrameInterval (void *handle)
+{
+  TSManager *tsm = (TSManager *) handle;
+  TSM_TIMESTAMP ts = 0;
+  if (tsm) {
+    ts = TSM_ADAPTIVE_INTERVAL (tsm);
+  }
+  return ts;
+}
+
+
+TSM_TIMESTAMP
+getTSManagerPosition (void *handle)
+{
+  TSManager *tsm = (TSManager *) handle;
+  TSM_TIMESTAMP ts = 0;
+  if (tsm) {
+    ts = tsm->last_ts_sent;
+  }
+  return ts;
+}
+
+
+int
+getTSManagerPreBufferCnt (void *handle)
+{
+  int i = 0;
+  TSManager *tsm = (TSManager *) handle;
+  if (tsm) {
+    i = tsm->rctl.cnt;
+  }
+  return i;
+}
diff --git a/codec2/tsm/mfw_gst_ts.h b/codec2/tsm/mfw_gst_ts.h
new file mode 100755
index 0000000..1301010
--- /dev/null
+++ b/codec2/tsm/mfw_gst_ts.h
@@ -0,0 +1,157 @@
+/**
+ *  Copyright (c) 2010-2012, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+
+/*
+ * Module Name:    TimeStamp.h
+ *
+ * Description:    include TimeStamp stratege for VPU / SW video decoder plugin
+ *
+ * Portability:    This code is written for Linux OS and Gstreamer
+ */
+
+/*
+ * Changelog:
+  11/2/2010        draft version       Lyon Wang
+ *
+ */
+
+#ifndef _TIMESTAMP_H_
+#define _TIMESTAMP_H_
+
+
+/**
+ * GST_CLOCK_TIME_NONE:
+ *
+ * Constant to define an undefined clock time.
+ */
+
+typedef long long TSM_TIMESTAMP;
+
+typedef enum
+{
+  MODE_AI,
+  MODE_FIFO,
+} TSMGR_MODE;
+
+#define TSM_TIMESTAMP_NONE ((long long)(-1))
+#define TSM_KEY_NONE ((void *)0)
+
+/**
+ * GST_CLOCK_TIME_IS_VALID:
+ * @time: clock time to validate
+ *
+ * Tests if a given #GstClockTime represents a valid defined time.
+ */
+
+#ifdef __cplusplus
+#define EXTERN
+#else
+#define EXTERN extern
+#endif
+
+#ifdef __cplusplus
+extern "C"
+{
+#endif
+
+/*!
+ * This function receive timestamp into timestamp manager.
+ *
+ * @param	handle		handle of timestamp manager.
+ *
+ * @param	timestamp	timestamp received
+ *
+ * @return
+ */
+  EXTERN void TSManagerReceive (void *handle, TSM_TIMESTAMP timestamp);
+
+  EXTERN void TSManagerReceive2 (void *handle, TSM_TIMESTAMP timestamp,
+      int size);
+
+  EXTERN void TSManagerFlush2 (void *handle, int size);
+
+  EXTERN void TSManagerValid2 (void *handle, int size, void *key);
+
+/*!
+ * This function send the timestamp for next output frame.
+ *
+ * @param	handle		handle of timestamp manager.
+ *
+ * @return	timestamp for next output frame.
+ */
+  EXTERN TSM_TIMESTAMP TSManagerSend (void *handle);
+
+  EXTERN TSM_TIMESTAMP TSManagerSend2 (void *handle, void *key);
+
+  EXTERN TSM_TIMESTAMP TSManagerQuery2 (void *handle, void *key);
+
+  EXTERN TSM_TIMESTAMP TSManagerQuery (void *handle);
+/*!
+ * This function resync timestamp handler when reset and seek
+ *
+ * @param	handle		handle of timestamp manager.
+ *
+ * @param	synctime    the postion time needed to set, if value invalid, position keeps original
+ *
+ * @param	mode		playing mode (AI or FIFO)
+ *
+ * @return
+ */
+  EXTERN void resyncTSManager (void *handle, TSM_TIMESTAMP synctime,
+      TSMGR_MODE mode);
+/*!
+ * This function create and reset timestamp handler
+ *
+ * @param	ts_buf_size	 time stamp queue buffer size
+ *
+ * @return
+ */
+  EXTERN void *createTSManager (int ts_buf_size);
+/*!
+ * This function destory timestamp handler
+ *
+ * @param	handle		handle of timestamp manager.
+ *
+ * @return
+ */
+  EXTERN void destroyTSManager (void *handle);
+/*!
+ * This function set  history buffer frame interval by fps_n and fps_d
+ *
+ * @param	handle		handle of timestamp manager.
+ *
+ * @param	framerate       the framerate to be set
+ *
+ * @return
+ */
+  EXTERN void setTSManagerFrameRate (void *handle, int fps_n, int fps_d);
+//EXTERN void setTSManagerFrameRate(void * handle, float framerate);
+/*!
+ * This function set the current calculated Frame Interval
+ *
+ * @param	handle		handle of timestamp manager.
+ *
+ * @return
+ */
+  EXTERN TSM_TIMESTAMP getTSManagerFrameInterval (void *handle);
+/*!
+ * This function get  the current time stamp postion
+ *
+ * @param	handle		handle of timestamp manager.
+ *
+ * @return
+ */
+  EXTERN TSM_TIMESTAMP getTSManagerPosition (void *handle);
+  EXTERN int getTSManagerPreBufferCnt (void *handle);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /*_TIMESTAMP_H_ */
diff --git a/codec2/v4l2_dev/Android.bp b/codec2/v4l2_dev/Android.bp
new file mode 100644
index 0000000..bafa332
--- /dev/null
+++ b/codec2/v4l2_dev/Android.bp
@@ -0,0 +1,68 @@
+imx_c2_v4l2_dev_defaults {
+    name: "imx_c2_v4l2_dev_default",
+}
+
+bootstrap_go_package {
+    name: "soong-v4l2_dev",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/v4l2_dev",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "v4l2_dev.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+
+cc_library_shared {
+    name: "lib_imx_c2_v4l2_dev",
+    defaults: ["imx_c2_v4l2_dev_default"],
+    soc_specific: true,
+    srcs: [
+        "V4l2Dev.cpp",
+    ],
+
+    header_libs: [
+        "media_plugin_headers",
+        "libcodec2_headers",
+    ],
+
+    include_dirs: [
+        "hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",    
+        "vendor/nxp/imx_android_mm/codec2/video_dec/common",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp/imx_android_mm/extractor",
+    ],
+
+    shared_libs: [
+        "liblog",
+        "libstagefright_bufferqueue_helper",
+        "libstagefright_foundation",
+        "libcodec2_vndk",
+	    "libutils",
+        "libcutils",
+    ],
+
+    sanitize: {
+        cfi: true,
+        misc_undefined: [
+            "unsigned-integer-overflow",
+            "signed-integer-overflow",
+        ],
+        diag: {
+            cfi: true,
+        },
+    },
+
+ //  compile_multilib: "32",
+}
diff --git a/codec2/v4l2_dev/V4l2Dev.cpp b/codec2/v4l2_dev/V4l2Dev.cpp
new file mode 100644
index 0000000..c15084d
--- /dev/null
+++ b/codec2/v4l2_dev/V4l2Dev.cpp
@@ -0,0 +1,669 @@
+/**
+ *  Copyright 2018-2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4l2Dev"
+#include "V4l2Dev.h"
+
+#include <linux/videodev2.h>
+#include <sys/eventfd.h>
+#include <sys/ioctl.h>
+#include <stdio.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <poll.h>
+#include <string.h>
+
+#include <media/stagefright/MediaDefs.h>
+#include <media/stagefright/MediaErrors.h>
+#include "graphics_ext.h"
+#include "Imx_ext.h"
+
+namespace android {
+
+#define VPU_DEC_NODE "/dev/video12"
+#define VPU_ENC_NODE "/dev/video13"
+
+#define V4L2_CID_USER_FRAME_DEPTH (V4L2_CID_USER_BASE + 0x1200)
+#define V4L2_CID_USER_TS_THRESHOLD     (V4L2_CID_USER_BASE + 0x1101)
+#define V4L2_CID_USER_BS_L_THRESHOLD	(V4L2_CID_USER_BASE + 0x1102)
+#define V4L2_CID_USER_BS_H_THRESHOLD	(V4L2_CID_USER_BASE + 0x1103)
+#define V4L2_CID_USER_FRAME_COLORDESC   (V4L2_CID_USER_BASE + 0x1104)
+#define V4L2_CID_USER_FRAME_TRANSFERCHARS   (V4L2_CID_USER_BASE + 0x1105)
+#define V4L2_CID_USER_FRAME_MATRIXCOEFFS    (V4L2_CID_USER_BASE + 0x1106)
+#define V4L2_CID_USER_FRAME_FULLRANGE       (V4L2_CID_USER_BASE + 0x1107)
+#define V4L2_CID_USER_FRAME_VUIPRESENT      (V4L2_CID_USER_BASE + 0x1108)
+
+#define MAX_VIDEO_SEARCH_NODE (20)
+
+V4l2Dev::V4l2Dev()
+{
+    memset((char*)sDevName, 0, MAX_DEV_NAME_LEN);
+    nFd = -1;
+    nEventFd = -1;
+}
+int32_t V4l2Dev::Open(V4l2DEV_TYPE type){
+
+    if(OK != SearchName(type))
+        return -1;
+    
+    nFd = open ((char*)sDevName, O_RDWR | O_NONBLOCK);
+
+    if(nFd > 0){
+        struct v4l2_event_subscription  sub;
+        memset(&sub, 0, sizeof(struct v4l2_event_subscription));
+
+        sub.type = V4L2_EVENT_SOURCE_CHANGE;
+        ioctl(nFd, VIDIOC_SUBSCRIBE_EVENT, &sub);
+
+        sub.type = V4L2_EVENT_EOS;
+        ioctl(nFd, VIDIOC_SUBSCRIBE_EVENT, &sub);
+
+        if(type == V4L2_DEV_DECODER){
+            sub.type = V4L2_EVENT_SKIP;
+            ioctl(nFd, VIDIOC_SUBSCRIBE_EVENT, &sub);
+
+            sub.type = V4L2_EVENT_DECODE_ERROR;
+            ioctl(nFd, VIDIOC_SUBSCRIBE_EVENT, &sub);
+        }
+
+    }
+
+    //nEventFd = eventfd(0, EFD_CLOEXEC | EFD_NONBLOCK );
+
+    return nFd;
+}
+status_t V4l2Dev::Close()
+{
+    if(nFd >= 0){
+        close(nFd);
+        nFd = -1;
+    }
+
+    if(nEventFd >= 0){
+        close(nEventFd);
+        nEventFd = -1;
+    }
+    return OK;
+}
+status_t V4l2Dev::SearchName(V4l2DEV_TYPE type)
+{
+    //open device node directly to save search time.
+    if(type == V4L2_DEV_DECODER){
+         strcpy((char *)sDevName, VPU_DEC_NODE );
+         return OK;
+    }else if(type == V4L2_DEV_ENCODER){
+         strcpy((char *)sDevName, VPU_ENC_NODE );
+         return OK;
+    }
+
+    int32_t index = 0;
+    //isi node is /dev/video4 on board with due camera
+    const int32_t index_map[MAX_VIDEO_SEARCH_NODE]={4,3,2,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,0,1};
+    int32_t fd = -1;
+    char name[MAX_DEV_NAME_LEN];
+    bool bGet = false;
+    struct v4l2_capability cap;
+
+    while(index < MAX_VIDEO_SEARCH_NODE){
+
+        sprintf((char*)name, "/dev/video%d", index_map[index]);
+
+        fd = open ((char*)name, O_RDWR);
+        if(fd < 0){
+            ALOGV("open index %d failed
",index);
+            index ++;
+            continue;
+        }
+        if (ioctl (fd, VIDIOC_QUERYCAP, &cap) < 0) {
+            close(fd);
+            ALOGV("VIDIOC_QUERYCAP %d failed
",index);
+            index ++;
+            continue;
+        }
+        ALOGV("index %d name=%s
",index,(char*)cap.driver);
+
+        if(type == V4L2_DEV_DECODER || type == V4L2_DEV_ENCODER){
+            if(NULL == strstr((char*)cap.driver, "vpu")){
+                close(fd);
+                index ++;
+                continue;
+            }
+        }
+        if(type == V4L2_DEV_ISI){
+            if(NULL == strstr((char*)cap.driver, "mxc-isi")){
+                close(fd);
+                index ++;
+                continue;
+            }
+        }
+
+        if (!((cap.capabilities & (V4L2_CAP_VIDEO_M2M |
+                        V4L2_CAP_VIDEO_M2M_MPLANE)) ||
+                ((cap.capabilities &
+                        (V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_VIDEO_CAPTURE_MPLANE)) &&
+                    (cap.capabilities &
+                        (V4L2_CAP_VIDEO_OUTPUT | V4L2_CAP_VIDEO_OUTPUT_MPLANE))))){
+            close(fd);
+            index ++;
+            continue;
+        }
+        ALOGV("index %d 
",index);
+        if((isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_OUTPUT)||
+            isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE)) &&
+            (isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_CAPTURE)||
+            isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE))){
+            bGet = true;
+            close(fd);
+            ALOGV("get device %s 
",name);
+            strcpy((char *)sDevName, name);
+            break;
+        }
+        close(fd);
+        index ++;
+    }
+
+    if(bGet)
+        return OK;
+    else
+        return UNKNOWN_ERROR;
+}
+bool V4l2Dev::isV4lBufferTypeSupported(int32_t fd,V4l2DEV_TYPE dec_type, uint32_t v4l2_buf_type )
+{
+    uint32_t i = 0;
+    bool bGot = false;
+    struct v4l2_fmtdesc sFmt;
+
+    while(true){
+        sFmt.index = i;
+        sFmt.type = v4l2_buf_type;
+        if(ioctl(fd,VIDIOC_ENUM_FMT,&sFmt) < 0)
+            break;
+
+        i++;
+        if(v4l2_buf_type == V4L2_BUF_TYPE_VIDEO_OUTPUT || v4l2_buf_type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE){
+            if(dec_type == V4L2_DEV_DECODER && (sFmt.flags & V4L2_FMT_FLAG_COMPRESSED)){
+                bGot = true;
+                break;
+            }else if(dec_type == V4L2_DEV_ENCODER && !(sFmt.flags & V4L2_FMT_FLAG_COMPRESSED)){
+                bGot = true;
+                break;
+            }else if(dec_type == V4L2_DEV_ISI && !(sFmt.flags & V4L2_FMT_FLAG_COMPRESSED)){
+                bGot = true;
+                break;
+            }
+        }else if(v4l2_buf_type == V4L2_BUF_TYPE_VIDEO_CAPTURE || v4l2_buf_type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE){
+            if(dec_type == V4L2_DEV_DECODER && !(sFmt.flags & V4L2_FMT_FLAG_COMPRESSED)){
+                bGot = true;
+                break;
+            }else if(dec_type == V4L2_DEV_ENCODER && (sFmt.flags & V4L2_FMT_FLAG_COMPRESSED)){
+                bGot = true;
+                break;
+            }else if(dec_type == V4L2_DEV_ISI && !(sFmt.flags & V4L2_FMT_FLAG_COMPRESSED)){
+                bGot = true;
+                break;
+            }
+        }
+    }
+
+    return bGot;
+
+}
+status_t V4l2Dev::QueryFormats(uint32_t format_type)
+{
+    struct v4l2_fmtdesc fmt;
+    int32_t i = 0;
+    if(format_type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE){
+        output_formats.clear();
+        while(true){
+            fmt.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+            fmt.index = i;
+            if(ioctl(nFd,VIDIOC_ENUM_FMT,&fmt) < 0)
+                break;
+ 
+            output_formats.push_back(fmt.pixelformat);
+            ALOGV("QueryFormat add output format %x
",fmt.pixelformat);
+            i++;
+        }
+        if(output_formats.size() > 0)
+            return OK;
+        else
+            return UNKNOWN_ERROR;
+    }
+    else if(format_type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE){
+        capture_formats.clear();
+        while(true){
+            fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+            fmt.index = i;
+            if(ioctl(nFd,VIDIOC_ENUM_FMT,&fmt) < 0)
+                break;
+
+            capture_formats.push_back(fmt.pixelformat);
+            ALOGV("QueryFormat add capture format %x
",fmt.pixelformat);
+            i++;
+        }
+
+        if(capture_formats.size() > 0)
+            return OK;
+        else
+            return UNKNOWN_ERROR;
+    }
+    return BAD_TYPE;
+}
+bool V4l2Dev::IsOutputFormatSupported(uint32_t format)
+{
+    if(output_formats.empty()){
+        status_t ret = QueryFormats(V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE);
+        if(ret != OK)
+            return false;
+    }
+    
+    for (uint32_t i = 0; i < output_formats.size(); i++) {
+        if(format == output_formats.at(i)){
+            return true;
+        }
+    }
+
+    return false;
+}
+bool V4l2Dev::IsCaptureFormatSupported(uint32_t format)
+{
+    if(capture_formats.empty()){
+        status_t ret = QueryFormats(V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
+        if(ret != OK)
+            return false;
+    }
+    
+    for (uint32_t i = 0; i < capture_formats.size(); i++) {
+        if(format == capture_formats.at(i)){
+            return true;
+        }
+    }
+    return false;
+}
+
+typedef struct{
+    const char * mime;
+    uint32_t v4l2_format;
+}V4L2_FORMAT_TABLE;
+
+static const V4L2_FORMAT_TABLE v4l2_format_table[]={
+    { MEDIA_MIMETYPE_VIDEO_AVC, V4L2_PIX_FMT_H264 },
+    { MEDIA_MIMETYPE_VIDEO_HEVC, v4l2_fourcc('H', 'E', 'V', 'C') },
+    { MEDIA_MIMETYPE_VIDEO_H263, V4L2_PIX_FMT_H263 },
+    { MEDIA_MIMETYPE_VIDEO_MPEG4, V4L2_PIX_FMT_MPEG4 },
+    { MEDIA_MIMETYPE_VIDEO_MPEG2, V4L2_PIX_FMT_MPEG2 },
+    { MEDIA_MIMETYPE_VIDEO_VP8, V4L2_PIX_FMT_VP8 },
+    { MEDIA_MIMETYPE_VIDEO_VC1, V4L2_PIX_FMT_VC1_ANNEX_G },
+    { MEDIA_MIMETYPE_VIDEO_XVID, V4L2_PIX_FMT_XVID },
+    { MEDIA_MIMETYPE_VIDEO_REAL, v4l2_fourcc('R', 'V', '0', '0')},
+    { MEDIA_MIMETYPE_VIDEO_MJPEG, V4L2_PIX_FMT_JPEG },
+    { MEDIA_MIMETYPE_VIDEO_SORENSON, v4l2_fourcc('S', 'P', 'K', '0')},
+#if 0//TODO: add extended format
+    { MEDIA_MIMETYPE_VIDEO_DIV3, v4l2_fourcc('D', 'I', 'V', '3') },
+    { MEDIA_MIMETYPE_VIDEO_DIV4, v4l2_fourcc('D', 'I', 'V', 'X') },
+    { MEDIA_MIMETYPE_VIDEO_DIVX, v4l2_fourcc('D', 'I', 'V', 'X') },
+#endif
+};
+
+typedef struct{
+    uint32_t color_format;
+    uint32_t v4l2_format;
+}COLOR_FORMAT_TABLE;
+
+//TODO: add android pixel format
+static const COLOR_FORMAT_TABLE color_format_table[]={
+    { HAL_PIXEL_FORMAT_NV12_TILED, V4L2_PIX_FMT_NV12 },
+    { HAL_PIXEL_FORMAT_YCbCr_420_SP, V4L2_PIX_FMT_NV12 },
+    { HAL_PIXEL_FORMAT_YCbCr_420_888, V4L2_PIX_FMT_NV12 },
+    //{ 2, v4l2_fourcc('N', 'T', '1', '2')}
+};
+status_t V4l2Dev::GetStreamTypeByMime(const char * mime, uint32_t * format_type)
+{
+    
+    for( size_t i = 0; i < sizeof(v4l2_format_table)/sizeof(V4L2_FORMAT_TABLE); i++){
+        if (!strcmp(mime, v4l2_format_table[i].mime)) {
+            *format_type = v4l2_format_table[i].v4l2_format;
+            return OK;
+        }
+    }
+
+    *format_type = 0x0;
+    return ERROR_UNSUPPORTED;
+}
+
+status_t V4l2Dev::GetMimeByStreamType(uint32_t format_type, const char ** mime)
+{
+    for( size_t i = 0; i < sizeof(v4l2_format_table)/sizeof(V4L2_FORMAT_TABLE); i++){
+        if (format_type == v4l2_format_table[i].v4l2_format) {
+            *mime = v4l2_format_table[i].mime;
+            return OK;
+        }
+    }
+
+    *mime = NULL;
+    return ERROR_UNSUPPORTED;
+}
+
+status_t V4l2Dev::GetColorFormatByV4l2(uint32_t v4l2_format, uint32_t * color_format)
+{
+    for( size_t i = 0; i < sizeof(color_format_table)/sizeof(COLOR_FORMAT_TABLE); i++){
+        if (v4l2_format == color_format_table[i].v4l2_format) {
+            *color_format = color_format_table[i].color_format;
+            return OK;
+        }
+    }
+    *color_format = 0;
+    return ERROR_UNSUPPORTED;
+}
+status_t V4l2Dev::GetV4l2FormatByColor(uint32_t color_format, uint32_t * v4l2_format)
+{
+    for( size_t i = 0; i < sizeof(color_format_table)/sizeof(COLOR_FORMAT_TABLE); i++){
+        if (color_format == color_format_table[i].color_format) {
+            *v4l2_format = color_format_table[i].v4l2_format;
+            return OK;
+        }
+    }
+    *v4l2_format = 0;
+    return ERROR_UNSUPPORTED;
+}
+
+status_t V4l2Dev::GetFormatFrameInfo(uint32_t format, struct v4l2_frmsizeenum * info)
+{
+    if(info == NULL)
+        return BAD_TYPE;
+
+    info->index = 0;
+    info->type = V4L2_FRMSIZE_TYPE_STEPWISE;
+    info->pixel_format = format;
+
+    if(0 == ioctl(nFd, VIDIOC_ENUM_FRAMESIZES, info)){
+        return OK;
+    }
+
+    return UNKNOWN_ERROR;
+}
+uint32_t V4l2Dev::Poll()
+{
+    uint32_t ret = V4L2_DEV_POLL_NONE;
+    int r;
+    struct pollfd pfd[2];
+    struct timespec ts;
+    ts.tv_sec = 1;//default timeout 1 seconds
+    ts.tv_nsec = 0;
+
+    pfd[0].fd = nFd;
+    pfd[0].events = POLLERR | POLLNVAL | POLLHUP;
+    pfd[0].revents = 0;
+
+    pfd[0].events |= POLLOUT | POLLPRI | POLLWRNORM;
+    pfd[0].events |= POLLIN | POLLRDNORM;
+
+    pfd[1].fd = nEventFd;
+    pfd[1].events = POLLIN | POLLERR;
+
+    ALOGV("Poll BEGIN %p
",this);
+    r = ppoll (&pfd[0], 2, &ts, NULL);
+
+    if(r <= 0){
+        ret = V4L2_DEV_POLL_NONE;
+    }else{
+        if(pfd[1].revents & POLLERR){
+            ret = V4L2_DEV_POLL_NONE;
+            return ret;
+        }
+
+        if(pfd[0].revents & POLLPRI){
+            ALOGV("[%p]POLLPRI 
",this);
+            ret = V4L2_DEV_POLL_EVENT;
+            return ret;
+        }
+
+        if(pfd[0].revents & POLLERR){
+            //char tembuf[1];
+            //read (mFd, tembuf, 1);
+            ret = V4L2_DEV_POLL_NONE;
+            usleep(2000);
+            return ret;
+        }
+
+        if((pfd[0].revents & POLLIN) || (pfd[0].revents & POLLRDNORM)){
+            ret |= V4L2_DEV_POLL_CAPTURE;
+        }
+        if((pfd[0].revents & POLLOUT) || (pfd[0].revents & POLLWRNORM)){
+            ret |= V4L2_DEV_POLL_OUTPUT;
+        }
+    }
+
+    ALOGV("Poll END,ret=%x
",ret);
+    return ret;
+}
+status_t V4l2Dev::SetPollInterrupt()
+{
+    if(nEventFd > 0){
+        const uint64_t buf = EFD_CLOEXEC|EFD_NONBLOCK;
+        eventfd_write(nEventFd, buf);
+    }
+    return OK;
+}
+status_t V4l2Dev::ClearPollInterrupt()
+{
+    if(nEventFd > 0){
+        uint64_t buf;
+        eventfd_read(nEventFd, &buf);
+    }
+    return OK;
+}
+status_t V4l2Dev::ResetDecoder()
+{
+    int ret = 0;
+    struct v4l2_decoder_cmd cmd;
+    memset(&cmd, 0, sizeof(struct v4l2_decoder_cmd));
+
+    cmd.cmd = IMX_V4L2_DEC_CMD_RESET;
+    cmd.flags = V4L2_DEC_CMD_STOP_IMMEDIATELY;
+
+    ret = ioctl(nFd, VIDIOC_DECODER_CMD, &cmd);
+    if(ret < 0){
+        ALOGE("V4l2Dev::ResetDecoder ret=%x
",ret);
+        return UNKNOWN_ERROR;
+    }
+
+    ALOGV("V4l2Dev::ResetDecoder SUCCESS
");
+    return OK;
+
+}
+
+status_t V4l2Dev::StopDecoder()
+{
+    int ret = 0;
+    struct v4l2_decoder_cmd cmd;
+    memset(&cmd, 0, sizeof(struct v4l2_decoder_cmd));
+
+    cmd.cmd = V4L2_DEC_CMD_STOP;
+    cmd.flags = V4L2_DEC_CMD_STOP_IMMEDIATELY;
+
+    ret = ioctl(nFd, VIDIOC_DECODER_CMD, &cmd);
+    if(ret < 0){
+        ALOGV("V4l2Dev::StopDecoder ret=%x
",ret);
+        return UNKNOWN_ERROR;
+    }
+
+    ALOGV("V4l2Dev::StopDecoder SUCCESS
");
+    return OK;
+}
+
+status_t V4l2Dev::StopEncoder()
+{
+    int ret = 0;
+
+    struct v4l2_encoder_cmd cmd;
+    memset(&cmd, 0, sizeof(struct v4l2_encoder_cmd));
+
+    cmd.cmd = V4L2_ENC_CMD_STOP;
+    cmd.flags = V4L2_ENC_CMD_STOP_AT_GOP_END;
+    ret = ioctl(nFd, VIDIOC_ENCODER_CMD, &cmd);
+
+    if(ret < 0){
+        ALOGV("V4l2Dev::StopEncoder FAILED
");
+        return UNKNOWN_ERROR;
+    }
+
+    ALOGV("V4l2Dev::StopEncoder SUCCESS
");
+    return OK;
+}
+status_t V4l2Dev::GetColorDesc(VideoColorAspect * desc)
+{
+    int ret = 0;
+    struct v4l2_control control;
+
+    if (nFd < 0 || desc == NULL)
+        return UNKNOWN_ERROR;
+
+    control.id =  V4L2_CID_USER_FRAME_FULLRANGE;
+    control.value = 0;
+
+    ret = ioctl(nFd, VIDIOC_G_CTRL, &control);
+    if (ret) {
+        ALOGE("GetColourDesc V4L2_CID_USER_FRAME_FULLRANGE OMX_ErrorUndefined
");
+        return UNKNOWN_ERROR;
+    }
+
+    desc->fullRange = control.value;
+
+
+    control.id =  V4L2_CID_USER_FRAME_COLORDESC;
+    control.value = 0;
+
+    ret = ioctl(nFd, VIDIOC_G_CTRL, &control);
+    if (ret) {
+        ALOGE("GetColourDesc V4L2_CID_USER_FRAME_COLORDESC OMX_ErrorUndefined
");
+        return UNKNOWN_ERROR;
+    }
+    desc->colourPrimaries = control.value;
+
+
+    control.id =  V4L2_CID_USER_FRAME_TRANSFERCHARS;
+    control.value = 0;
+    ret = ioctl(nFd, VIDIOC_G_CTRL, &control);
+    if (ret) {
+        ALOGE("GetColourDesc V4L2_CID_USER_FRAME_TRANSFERCHARS OMX_ErrorUndefined
");
+        return UNKNOWN_ERROR;
+    }
+    desc->transferCharacteristics = control.value;
+
+
+    control.id =  V4L2_CID_USER_FRAME_MATRIXCOEFFS;
+    control.value = 0;
+    ret = ioctl(nFd, VIDIOC_G_CTRL, &control);
+    if (ret) {
+        ALOGE("GetColourDesc V4L2_CID_USER_FRAME_MATRIXCOEFFS OMX_ErrorUndefined
");
+        return UNKNOWN_ERROR;
+    }
+    desc->matrixCoeffs = control.value;
+
+    ALOGV("GetColourDesc success, p=%d,t=%d,m=%d,r=%d
",
+        desc->colourPrimaries,desc->transferCharacteristics,desc->matrixCoeffs,desc->fullRange);
+
+    return OK;
+}
+status_t V4l2Dev::SetEncoderParam(V4l2EncInputParam *param)
+{
+    int ret = 0;
+    if(param == NULL)
+        return UNKNOWN_ERROR;
+
+    ALOGV("SetEncoderParam nBitRate=%d
",param->nBitRate);
+    ALOGV("SetEncoderParam nGOPSize=%d
",param->nGOPSize);
+    ALOGV("SetEncoderParam nIntraFreshNum=%d
",param->nIntraFreshNum);
+    if(param->nBitRate > 0){
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_BITRATE_MODE,param->nBitRateMode);
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_BITRATE,param->nBitRate);
+        ALOGV("V4L2_CID_MPEG_VIDEO_BITRATE 1 ret=%x
",ret);
+
+    }
+
+    if(param->nGOPSize > 0)
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_GOP_SIZE,param->nGOPSize);
+
+    ALOGV("SetEncoderParam V4L2_CID_MPEG_VIDEO_GOP_SIZE ret=%x
",ret);
+    
+    if(param->nH264_i_qp > 0)
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_I_FRAME_QP,param->nH264_i_qp);
+    if(param->nH264_p_qp > 0)
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_P_FRAME_QP,param->nH264_p_qp);
+    if(param->nH264_min_qp > 0)
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_MIN_QP,param->nH264_min_qp);
+    if(param->nH264_max_qp > 0)
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_MAX_QP,param->nH264_max_qp);
+    if(param->nMpeg4_i_qp > 0)
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_MPEG4_I_FRAME_QP,param->nMpeg4_i_qp);
+    if(param->nMpeg4_p_qp > 0)
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_MPEG4_P_FRAME_QP,param->nMpeg4_p_qp);
+    if(param->nIntraFreshNum > 0)
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_CYCLIC_INTRA_REFRESH_MB,param->nIntraFreshNum);
+
+    ALOGV("SetEncoderParam 1 ret=%x
",ret);
+
+    //ignore result
+    int32_t value= 1;
+    if(90 == param->nRotAngle || 270 == param->nRotAngle)
+        SetCtrl(V4L2_CID_HFLIP,value);
+    else if(0 == param->nRotAngle || 180 == param->nRotAngle)
+        SetCtrl(V4L2_CID_VFLIP,value);
+
+    ret = SetH264EncoderProfileAndLevel(param->nProfile, param->nLevel);
+    
+    ALOGV("SetH264EncoderProfileAndLevel ret=%x
",ret);
+    return ret;
+}
+status_t V4l2Dev::SetH264EncoderProfileAndLevel(uint32_t profile, uint32_t level)
+{
+    int ret = 0;
+    int32_t v4l2_profile = V4L2_MPEG_VIDEO_H264_PROFILE_MAIN;
+    int32_t v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_4_1;
+
+
+    ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_PROFILE, v4l2_profile);
+    ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_LEVEL, v4l2_level);
+    ALOGV("set profile=%d,level=%d,ret=%d",v4l2_profile,v4l2_level,ret);
+    return OK;
+}
+
+status_t V4l2Dev::SetFrameRate(uint32_t framerate)
+{
+    struct v4l2_streamparm parm;
+    int ret = 0;
+
+    if (0 == framerate)
+        return UNKNOWN_ERROR;
+
+    memset(&parm, 0, sizeof(parm));
+    parm.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    parm.parm.capture.timeperframe.numerator = 0x1000;
+    parm.parm.capture.timeperframe.denominator = framerate * 0x1000;
+    ALOGV("set frame rate =%d",framerate);
+    ret = ioctl(nFd, VIDIOC_S_PARM, &parm);
+    if (ret) {
+        ALOGE("SetFrameRate fail
");
+        return UNKNOWN_ERROR;
+    }
+    return OK;
+}
+status_t V4l2Dev::SetCtrl(uint32_t id, int32_t value)
+{
+    int ret = 0;
+    struct v4l2_control ctl = { 0,0 };
+    ctl.id = id;
+    ctl.value = value;
+    ret = ioctl(nFd, VIDIOC_S_CTRL, &ctl);
+
+    return (status_t)ret;
+}
+
+}
diff --git a/codec2/v4l2_dev/V4l2Dev.h b/codec2/v4l2_dev/V4l2Dev.h
new file mode 100644
index 0000000..7739235
--- /dev/null
+++ b/codec2/v4l2_dev/V4l2Dev.h
@@ -0,0 +1,104 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+#ifndef V4L2_DEV_H
+#define V4L2_DEV_H
+#include <stdint.h>
+#include <sys/types.h>
+#include <linux/videodev2.h>
+#include <media/stagefright/foundation/AHandler.h>
+#include <vector>
+
+namespace android {
+
+typedef enum{
+V4L2_DEV_DECODER = 0,
+V4L2_DEV_ENCODER,
+V4L2_DEV_ISI,
+}V4l2DEV_TYPE;
+
+
+#define V4L2_DEV_POLL_NONE 0
+#define V4L2_DEV_POLL_EVENT 1
+#define V4L2_DEV_POLL_OUTPUT 2
+#define V4L2_DEV_POLL_CAPTURE 4
+
+#define IMX_V4L2_DEC_CMD_START         (0x09000000)
+#define IMX_V4L2_DEC_CMD_RESET         (IMX_V4L2_DEC_CMD_START + 1)
+
+#define V4L2_EVENT_DECODE_ERROR                (V4L2_EVENT_PRIVATE_START + 1)
+#define V4L2_EVENT_SKIP                        (V4L2_EVENT_PRIVATE_START + 2)
+
+#define MAX_DEV_NAME_LEN (16)
+typedef struct {
+    uint32_t colourPrimaries;
+    uint32_t transferCharacteristics;
+    uint32_t matrixCoeffs;
+    uint32_t fullRange;
+} VideoColorAspect;
+
+typedef struct {
+    int32_t nBitRate;/*unit: bps*/
+    int32_t nBitRateMode;
+    int32_t nGOPSize;
+    int32_t nH264_i_qp;
+    int32_t nH264_p_qp;
+    int32_t nH264_min_qp;
+    int32_t nH264_max_qp;
+    int32_t nMpeg4_i_qp;
+    int32_t nMpeg4_p_qp;
+    int32_t nIntraFreshNum;//V4L2_CID_MPEG_VIDEO_CYCLIC_INTRA_REFRESH_MB
+    int32_t nProfile;
+    int32_t nLevel;
+    int32_t nRotAngle;
+} V4l2EncInputParam;
+    
+class V4l2Dev{
+public:
+    explicit V4l2Dev();
+    int32_t Open(V4l2DEV_TYPE type);
+    status_t Close();
+    bool IsOutputFormatSupported(uint32_t format);
+    bool IsCaptureFormatSupported(uint32_t format);
+    status_t GetFormatFrameInfo(uint32_t format, struct v4l2_frmsizeenum * info);
+
+    status_t GetStreamTypeByMime(const char * mime, uint32_t * format_type);
+    status_t GetMimeByStreamType(uint32_t format_type, const char ** mime);
+
+    status_t GetColorFormatByV4l2(uint32_t v4l2_format, uint32_t * color_format);
+    status_t GetV4l2FormatByColor(uint32_t color_format, uint32_t * v4l2_format);
+    
+    uint32_t Poll();
+    status_t SetPollInterrupt();
+    status_t ClearPollInterrupt();
+    status_t ResetDecoder();
+    status_t StopDecoder();
+
+    status_t GetColorDesc(VideoColorAspect * desc);
+
+
+    //encoder functions
+    status_t StopEncoder();
+    status_t SetEncoderParam(V4l2EncInputParam *param);
+    status_t SetH264EncoderProfileAndLevel(uint32_t profile, uint32_t level);
+    status_t SetFrameRate(uint32_t framerate);
+    
+private:
+    status_t SearchName(V4l2DEV_TYPE type);
+    bool isV4lBufferTypeSupported(int32_t fd, V4l2DEV_TYPE dec_type, uint32_t v4l2_buf_type);
+    status_t QueryFormats(uint32_t format_type);
+
+    status_t SetCtrl(uint32_t id, int32_t value);
+
+    char sDevName[MAX_DEV_NAME_LEN];
+    int32_t nFd;
+    int32_t nEventFd;
+    std::vector<uint32_t> output_formats;
+    std::vector<uint32_t> capture_formats;
+};
+}
+#endif
diff --git a/codec2/v4l2_dev/v4l2_dev.go b/codec2/v4l2_dev/v4l2_dev.go
new file mode 100644
index 0000000..ab14dca
--- /dev/null
+++ b/codec2/v4l2_dev/v4l2_dev.go
@@ -0,0 +1,54 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package v4l2_dev
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_v4l2_dev_defaults", v4l2DefaultsFactory)
+}
+
+
+func v4l2DefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, v4l2Defaults)
+    return module
+}
+
+func v4l2Defaults(ctx android.LoadHookContext) {
+    var Cflags []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Cflags []string
+                }
+        }
+    }
+    p := &props{}
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8Q") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else {
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
+    }
+    p.Target.Android.Cflags = Cflags
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/video_dec/Android.bp b/codec2/video_dec/Android.bp
new file mode 100644
index 0000000..6d0b0f5
--- /dev/null
+++ b/codec2/video_dec/Android.bp
@@ -0,0 +1,25 @@
+imx_c2_video_dec_defaults {
+    name: "imx_c2_video_dec_default",
+}
+
+
+bootstrap_go_package {
+    name: "soong-video_dec",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/video_dec",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "video_dec.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+subdirs = [
+    "*",
+]
diff --git a/codec2/video_dec/common/Android.bp b/codec2/video_dec/common/Android.bp
new file mode 100644
index 0000000..f5512e1
--- /dev/null
+++ b/codec2/video_dec/common/Android.bp
@@ -0,0 +1,91 @@
+cc_library_shared {
+    name: "lib_imx_c2_videodec_common",
+
+    srcs: [
+        "VideoDecoderBase.cpp",
+    ],
+
+    include_dirs: [
+	"hardware/libhardware/include",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",    
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+    ],
+
+    header_libs: [
+        "media_plugin_headers",
+        "libcodec2_headers",
+    ],
+
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "lib_imx_c2_componentbase",
+        "libion",
+        "libcodec2_vndk",
+    ],
+
+    whole_static_libs: ["libionallocator"],
+
+    export_include_dirs: ["."],
+
+    defaults: [
+        "imx_defaults",
+    ],
+}
+
+
+cc_library_shared {
+    name: "lib_imx_c2_videodec",
+
+    srcs: [
+        "IMXC2VideoDecoder.cpp",
+    ],
+
+    include_dirs: [
+        "frameworks/av",
+        "hardware/libhardware/include",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",    
+        "vendor/nxp/imx_android_mm/codec2/video_dec/common",
+        "frameworks/av/media/codec2/components/base/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/imx_android_mm/codec2/base/include",
+        "vendor/nxp/imx_android_mm/codec2/process/common",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+    ],
+
+    header_libs: [
+        "media_plugin_headers",
+        "libcodec2_headers",
+    ],
+
+
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "lib_imx_c2_componentbase",
+        "lib_imx_c2_videodec_common",
+        "libcodec2_vndk",
+        "lib_c2_imx_store",
+        "lib_imx_c2_process",
+    ],
+
+
+    export_include_dirs: ["."],
+
+    defaults: [
+        "imx_defaults",
+        "imx_c2_video_dec_default",
+    ],
+}
diff --git a/codec2/video_dec/common/IMXC2ComponentFactory.h b/codec2/video_dec/common/IMXC2ComponentFactory.h
new file mode 100644
index 0000000..f9ae1fc
--- /dev/null
+++ b/codec2/video_dec/common/IMXC2ComponentFactory.h
@@ -0,0 +1,21 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef IMX_CODEC2_COMPONENT_FACTORY_H_
+#define IMX_CODEC2_COMPONENT_FACTORY_H_
+
+#include <C2ComponentFactory.h>
+
+class IMXC2ComponentFactory : public C2ComponentFactory {
+public:
+    typedef ::C2ComponentFactory* (*IMXCreateCodec2FactoryFunc)(C2String name);
+    typedef void (*IMXDestroyCodec2FactoryFunc)(::C2ComponentFactory*);
+};
+
+
+#endif // IMX_CODEC2_COMPONENT_FACTORY_H_
diff --git a/codec2/video_dec/common/IMXC2VideoDecoder.cpp b/codec2/video_dec/common/IMXC2VideoDecoder.cpp
new file mode 100755
index 0000000..d25579b
--- /dev/null
+++ b/codec2/video_dec/common/IMXC2VideoDecoder.cpp
@@ -0,0 +1,1292 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "IMXC2VideoDecoder"
+#include <utils/Log.h>
+
+#include <media/stagefright/MediaDefs.h>
+#include <string.h>
+
+#include "IMXC2VideoDecoder.h"
+#include "C2_imx.h"
+#include "C2Config_imx.h"
+#include "IMXUtils.h"
+#include "graphics_ext.h"
+
+namespace android {
+
+#define CHECK_AND_RETURN_C2_ERR(err) if((err) != OK) {ALOGE("%s, line %d", __FUNCTION__, __LINE__); return (((err) == OK) ? C2_OK : C2_CORRUPTED);}
+#define C2ERR(err) ((err) == OK ? C2_OK : C2_CORRUPTED)
+
+#define DEFAULT_ACTUAL_OUTPUT_DELAY_VALUE 16
+#define DEFAULT_OUTPUT_BUFFER_CNT_IN_POST_PROCESS 3
+
+#ifdef IMX_VIDEO_DEC_API_TRACE
+#define IMX_VIDEO_DEC_API_TRACE ALOGD
+#else
+#define IMX_VIDEO_DEC_API_TRACE
+#endif
+
+class IMXC2VideoDecoder::IntfImpl : public IMXInterface<void>::BaseParams {
+public:
+    explicit IntfImpl(const std::shared_ptr<C2ReflectorHelper> &helper, C2String componentName)
+        : IMXInterface<void>::BaseParams(
+                helper,
+                componentName,
+                C2Component::KIND_DECODER,
+                C2Component::DOMAIN_VIDEO,
+                Name2MimeType(componentName.c_str())),
+                mComponentName(componentName) {
+
+        C2String mimeType(Name2MimeType(mComponentName.c_str()));
+
+        noPrivateBuffers(); // TODO: account for our buffers here
+        noInputReferences();
+        noOutputReferences();
+        noInputLatency();
+        noTimeStretch();
+
+        // TODO: Proper support for reorder depth.
+        /*addParameter(
+                DefineParam(mActualInputDelay, C2_PARAMKEY_INPUT_DELAY)
+                .withDefault(new C2PortActualDelayTuning::input(3u))
+                .withFields({C2F(mActualInputDelay, value).inRange(0, 32)})
+                .withSetter(Setter<decltype(*mActualInputDelay)>::StrictValueWithNoDeps)
+                .build());*/
+
+        addParameter(
+                DefineParam(mActualOutputDelay, C2_PARAMKEY_OUTPUT_DELAY)
+                .withDefault(new C2PortActualDelayTuning::output(DEFAULT_ACTUAL_OUTPUT_DELAY_VALUE))
+                .withFields({C2F(mActualOutputDelay, value).inRange(0, 32)})
+                .withSetter(Setter<decltype(*mActualOutputDelay)>::StrictValueWithNoDeps)
+                .build());
+
+        // TODO: output latency and reordering
+
+        addParameter(
+                DefineParam(mAttrib, C2_PARAMKEY_COMPONENT_ATTRIBUTES)
+                .withConstValue(new C2ComponentAttributesSetting(C2Component::ATTRIB_IS_TEMPORAL))
+                .build());
+
+        // coded and output picture size is the same for this codec
+        addParameter(
+                DefineParam(mSize, C2_PARAMKEY_PICTURE_SIZE)
+                .withDefault(new C2StreamPictureSizeInfo::output(0u, 320, 240))
+                .withFields({
+                    C2F(mSize, width).inRange(2, 4096, 2),
+                    C2F(mSize, height).inRange(2, 2160, 2),
+                })
+                .withSetter(SizeSetter)
+                .build());
+
+        // coded and output picture size is the same for this codec
+        addParameter(
+                DefineParam(mCrop, C2_PARAMKEY_CROP_RECT)
+                .withDefault(new C2StreamCropRectInfo::output(0u, C2Rect(320, 240)))
+                .withFields({
+                    C2F(mCrop, width).inRange(2, 4096, 2),
+                    C2F(mCrop, height).inRange(2, 2160, 2),
+                })
+                .withSetter(CropSetter)
+                .build());
+
+        addParameter(
+                DefineParam(mMaxSize, C2_PARAMKEY_MAX_PICTURE_SIZE)
+                .withDefault(new C2StreamMaxPictureSizeTuning::output(0u, 320, 240))
+                .withFields({
+                    C2F(mSize, width).inRange(2, 4096, 2),
+                    C2F(mSize, height).inRange(2, 2160, 2),
+                })
+                .withSetter(MaxPictureSizeSetter, mSize)
+                .build());
+
+        if (mimeType == MEDIA_MIMETYPE_VIDEO_AVC) {
+            addParameter(
+                    DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+                    .withDefault(new C2StreamProfileLevelInfo::input(0u,
+                            C2Config::PROFILE_AVC_CONSTRAINED_BASELINE, C2Config::LEVEL_AVC_5_2))
+                    .withFields({
+                        C2F(mProfileLevel, profile).oneOf({
+                                C2Config::PROFILE_AVC_CONSTRAINED_BASELINE,
+                                C2Config::PROFILE_AVC_BASELINE,
+                                C2Config::PROFILE_AVC_MAIN,
+                                C2Config::PROFILE_AVC_CONSTRAINED_HIGH,
+                                C2Config::PROFILE_AVC_PROGRESSIVE_HIGH,
+                                C2Config::PROFILE_AVC_HIGH}),
+                        C2F(mProfileLevel, level).oneOf({
+                                C2Config::LEVEL_AVC_1, C2Config::LEVEL_AVC_1B, C2Config::LEVEL_AVC_1_1,
+                                C2Config::LEVEL_AVC_1_2, C2Config::LEVEL_AVC_1_3,
+                                C2Config::LEVEL_AVC_2, C2Config::LEVEL_AVC_2_1, C2Config::LEVEL_AVC_2_2,
+                                C2Config::LEVEL_AVC_3, C2Config::LEVEL_AVC_3_1, C2Config::LEVEL_AVC_3_2,
+                                C2Config::LEVEL_AVC_4, C2Config::LEVEL_AVC_4_1, C2Config::LEVEL_AVC_4_2,
+                                C2Config::LEVEL_AVC_5, C2Config::LEVEL_AVC_5_1, C2Config::LEVEL_AVC_5_2
+                        })
+                    })
+                    .withSetter(ProfileLevelSetter, mSize)
+                    .build());
+        }else if (mimeType == MEDIA_MIMETYPE_VIDEO_HEVC) {
+            addParameter(
+                    DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+                    .withDefault(new C2StreamProfileLevelInfo::input(0u,
+                            C2Config::PROFILE_HEVC_MAIN, C2Config::LEVEL_HEVC_MAIN_5_1))
+                    .withFields({
+                        C2F(mProfileLevel, profile).oneOf({
+                                C2Config::PROFILE_HEVC_MAIN,
+                                C2Config::PROFILE_HEVC_MAIN_STILL}),
+                        C2F(mProfileLevel, level).oneOf({
+                                C2Config::LEVEL_HEVC_MAIN_1,
+                                C2Config::LEVEL_HEVC_MAIN_2, C2Config::LEVEL_HEVC_MAIN_2_1,
+                                C2Config::LEVEL_HEVC_MAIN_3, C2Config::LEVEL_HEVC_MAIN_3_1,
+                                C2Config::LEVEL_HEVC_MAIN_4, C2Config::LEVEL_HEVC_MAIN_4_1,
+                                C2Config::LEVEL_HEVC_MAIN_5, C2Config::LEVEL_HEVC_MAIN_5_1,
+                                C2Config::LEVEL_HEVC_MAIN_5_2, C2Config::LEVEL_HEVC_HIGH_4,
+                                C2Config::LEVEL_HEVC_HIGH_4_1, C2Config::LEVEL_HEVC_HIGH_5,
+                                C2Config::LEVEL_HEVC_HIGH_5_1, C2Config::LEVEL_HEVC_HIGH_5_2
+                        })
+                    })
+                    .withSetter(ProfileLevelSetter, mSize)
+                    .build());
+        } else if (mimeType ==  MEDIA_MIMETYPE_VIDEO_MPEG4) {
+            addParameter(
+                    DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+                    .withDefault(new C2StreamProfileLevelInfo::input(0u,
+                            C2Config::PROFILE_MP4V_SIMPLE, C2Config::LEVEL_MP4V_3))
+                    .withFields({
+                        C2F(mProfileLevel, profile).oneOf({
+                                C2Config::PROFILE_MP4V_SIMPLE,
+                                C2Config::PROFILE_MP4V_ADVANCED_SIMPLE}),
+                        C2F(mProfileLevel, level).oneOf({
+                                C2Config::LEVEL_MP4V_0,
+                                C2Config::LEVEL_MP4V_0B,
+                                C2Config::LEVEL_MP4V_1,
+                                C2Config::LEVEL_MP4V_2,
+                                C2Config::LEVEL_MP4V_3,
+                                C2Config::LEVEL_MP4V_3B,
+                                C2Config::LEVEL_MP4V_4,
+                                C2Config::LEVEL_MP4V_4A,
+                                C2Config::LEVEL_MP4V_5,
+                                C2Config::LEVEL_MP4V_6})
+                    })
+                    .withSetter(ProfileLevelSetter, mSize)
+                    .build());
+        } else if (mimeType ==  MEDIA_MIMETYPE_VIDEO_MPEG2) {
+            addParameter(
+                    DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+                    .withDefault(new C2StreamProfileLevelInfo::input(0u,
+                            C2Config::PROFILE_MP2V_SIMPLE, C2Config::LEVEL_MP2V_HIGH))
+                    .withFields({
+                        C2F(mProfileLevel, profile).oneOf({
+                                C2Config::PROFILE_MP2V_SIMPLE,
+                                C2Config::PROFILE_MP2V_MAIN}),
+                        C2F(mProfileLevel, level).oneOf({
+                                C2Config::LEVEL_MP2V_LOW,
+                                C2Config::LEVEL_MP2V_MAIN,
+                                C2Config::LEVEL_MP2V_HIGH_1440,
+                                C2Config::LEVEL_MP2V_HIGH})
+                    })
+                    .withSetter(ProfileLevelSetter, mSize)
+                    .build());
+
+        } else if (mimeType ==  MEDIA_MIMETYPE_VIDEO_H263) {
+            addParameter(
+                    DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+                    .withDefault(new C2StreamProfileLevelInfo::input(0u,
+                            C2Config::PROFILE_H263_BASELINE, C2Config::LEVEL_H263_30))
+                    .withFields({
+                        C2F(mProfileLevel, profile).oneOf({
+                                C2Config::PROFILE_H263_BASELINE,
+                                C2Config::PROFILE_H263_ISWV2}),
+                        C2F(mProfileLevel, level).oneOf({
+                                C2Config::LEVEL_H263_10,
+                                C2Config::LEVEL_H263_20,
+                                C2Config::LEVEL_H263_30,
+                                C2Config::LEVEL_H263_40,
+                                C2Config::LEVEL_H263_45,
+                                C2Config::LEVEL_H263_50,
+                                C2Config::LEVEL_H263_60,
+                                C2Config::LEVEL_H263_70})
+                    })
+                    .withSetter(ProfileLevelSetter, mSize)
+                    .build());
+        } else if (mimeType ==  MEDIA_MIMETYPE_VIDEO_VP8) {
+            addParameter(
+                    DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+                    .withConstValue(new C2StreamProfileLevelInfo::input(0u,
+                            C2Config::PROFILE_UNUSED, C2Config::LEVEL_UNUSED))
+                    .build());
+        } else if (mimeType ==  MEDIA_MIMETYPE_VIDEO_VP9) {
+            // TODO: Add C2Config::PROFILE_VP9_2HDR ??
+            addParameter(
+                    DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+                    .withDefault(new C2StreamProfileLevelInfo::input(0u,
+                            C2Config::PROFILE_VP9_0, C2Config::LEVEL_VP9_5))
+                    .withFields({
+                        C2F(mProfileLevel, profile).oneOf({
+                                C2Config::PROFILE_VP9_0,
+                                C2Config::PROFILE_VP9_2}),
+                        C2F(mProfileLevel, level).oneOf({
+                                C2Config::LEVEL_VP9_1,
+                                C2Config::LEVEL_VP9_1_1,
+                                C2Config::LEVEL_VP9_2,
+                                C2Config::LEVEL_VP9_2_1,
+                                C2Config::LEVEL_VP9_3,
+                                C2Config::LEVEL_VP9_3_1,
+                                C2Config::LEVEL_VP9_4,
+                                C2Config::LEVEL_VP9_4_1,
+                                C2Config::LEVEL_VP9_5,
+                        })
+                    })
+                    .withSetter(ProfileLevelSetter, mSize)
+                    .build());
+
+            mHdr10PlusInfoInput = C2StreamHdr10PlusInfo::input::AllocShared(0);
+            addParameter(
+                    DefineParam(mHdr10PlusInfoInput, C2_PARAMKEY_INPUT_HDR10_PLUS_INFO)
+                    .withDefault(mHdr10PlusInfoInput)
+                    .withFields({
+                        C2F(mHdr10PlusInfoInput, m.value).any(),
+                    })
+                    .withSetter(Hdr10PlusInfoInputSetter)
+                    .build());
+
+            mHdr10PlusInfoOutput = C2StreamHdr10PlusInfo::output::AllocShared(0);
+            addParameter(
+                    DefineParam(mHdr10PlusInfoOutput, C2_PARAMKEY_OUTPUT_HDR10_PLUS_INFO)
+                    .withDefault(mHdr10PlusInfoOutput)
+                    .withFields({
+                        C2F(mHdr10PlusInfoOutput, m.value).any(),
+                    })
+                    .withSetter(Hdr10PlusInfoOutputSetter)
+                    .build());
+        }
+
+        addParameter(
+                DefineParam(mMaxInputSize, C2_PARAMKEY_INPUT_MAX_BUFFER_SIZE)
+                .withDefault(new C2StreamMaxBufferSizeInfo::input(0u, 320 * 240 * 3 / 4))
+                .withFields({
+                    C2F(mMaxInputSize, value).any(),
+                })
+                .calculatedAs(MaxInputSizeSetter, mMaxSize)
+                .build());
+
+        C2ChromaOffsetStruct locations[1] = { C2ChromaOffsetStruct::ITU_YUV_420_0() };
+        std::shared_ptr<C2StreamColorInfo::output> defaultColorInfo =
+            C2StreamColorInfo::output::AllocShared(
+                    1u, 0u, 8u /* bitDepth */, C2Color::YUV_420);
+        memcpy(defaultColorInfo->m.locations, locations, sizeof(locations));
+
+        defaultColorInfo =
+            C2StreamColorInfo::output::AllocShared(
+                    { C2ChromaOffsetStruct::ITU_YUV_420_0() },
+                    0u, 8u /* bitDepth */, C2Color::YUV_420);
+        helper->addStructDescriptors<C2ChromaOffsetStruct>();
+
+        addParameter(
+                DefineParam(mColorInfo, C2_PARAMKEY_CODED_COLOR_INFO)
+                .withConstValue(defaultColorInfo)
+                .build());
+
+        addParameter(
+                DefineParam(mDefaultColorAspects, C2_PARAMKEY_DEFAULT_COLOR_ASPECTS)
+                .withDefault(new C2StreamColorAspectsTuning::output(
+                        0u, C2Color::RANGE_UNSPECIFIED, C2Color::PRIMARIES_UNSPECIFIED,
+                        C2Color::TRANSFER_UNSPECIFIED, C2Color::MATRIX_UNSPECIFIED))
+                .withFields({
+                    C2F(mDefaultColorAspects, range).inRange(
+                                C2Color::RANGE_UNSPECIFIED,     C2Color::RANGE_OTHER),
+                    C2F(mDefaultColorAspects, primaries).inRange(
+                                C2Color::PRIMARIES_UNSPECIFIED, C2Color::PRIMARIES_OTHER),
+                    C2F(mDefaultColorAspects, transfer).inRange(
+                                C2Color::TRANSFER_UNSPECIFIED,  C2Color::TRANSFER_OTHER),
+                    C2F(mDefaultColorAspects, matrix).inRange(
+                                C2Color::MATRIX_UNSPECIFIED,    C2Color::MATRIX_OTHER)
+                })
+                .withSetter(DefaultColorAspectsSetter)
+                .build());
+
+        addParameter(
+                DefineParam(mCodedColorAspects, C2_PARAMKEY_VUI_COLOR_ASPECTS)
+                .withDefault(new C2StreamColorAspectsInfo::input(
+                        0u, C2Color::RANGE_LIMITED, C2Color::PRIMARIES_UNSPECIFIED,
+                        C2Color::TRANSFER_UNSPECIFIED, C2Color::MATRIX_UNSPECIFIED))
+                .withFields({
+                    C2F(mCodedColorAspects, range).inRange(
+                                C2Color::RANGE_UNSPECIFIED,     C2Color::RANGE_OTHER),
+                    C2F(mCodedColorAspects, primaries).inRange(
+                                C2Color::PRIMARIES_UNSPECIFIED, C2Color::PRIMARIES_OTHER),
+                    C2F(mCodedColorAspects, transfer).inRange(
+                                C2Color::TRANSFER_UNSPECIFIED,  C2Color::TRANSFER_OTHER),
+                    C2F(mCodedColorAspects, matrix).inRange(
+                                C2Color::MATRIX_UNSPECIFIED,    C2Color::MATRIX_OTHER)
+                })
+                .withSetter(CodedColorAspectsSetter)
+                .build());
+
+        addParameter(
+                DefineParam(mColorAspects, C2_PARAMKEY_COLOR_ASPECTS)
+                .withDefault(new C2StreamColorAspectsInfo::output(
+                        0u, C2Color::RANGE_UNSPECIFIED, C2Color::PRIMARIES_UNSPECIFIED,
+                        C2Color::TRANSFER_UNSPECIFIED, C2Color::MATRIX_UNSPECIFIED))
+                .withFields({
+                    C2F(mColorAspects, range).inRange(
+                                C2Color::RANGE_UNSPECIFIED,     C2Color::RANGE_OTHER),
+                    C2F(mColorAspects, primaries).inRange(
+                                C2Color::PRIMARIES_UNSPECIFIED, C2Color::PRIMARIES_OTHER),
+                    C2F(mColorAspects, transfer).inRange(
+                                C2Color::TRANSFER_UNSPECIFIED,  C2Color::TRANSFER_OTHER),
+                    C2F(mColorAspects, matrix).inRange(
+                                C2Color::MATRIX_UNSPECIFIED,    C2Color::MATRIX_OTHER)
+                })
+                .withSetter(ColorAspectsSetter, mDefaultColorAspects, mCodedColorAspects)
+                .build());
+
+        // TODO: support more formats?
+        addParameter(
+                DefineParam(mPixelFormat, C2_PARAMKEY_PIXEL_FORMAT)
+                .withDefault(new C2StreamPixelFormatInfo::output(
+                            0u, HAL_PIXEL_FORMAT_YCBCR_420_888))
+                .withFields({C2F(mPixelFormat, value).inRange(0, 0xffffffff)})
+                .withSetter(Setter<decltype(*mPixelFormat)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mSurfaceAllocator, C2_PARAMKEY_OUTPUT_SURFACE_ALLOCATOR)
+                .withConstValue(new C2PortSurfaceAllocatorTuning::output(C2PlatformAllocatorStore::BUFFERQUEUE))
+                .build());
+
+        addParameter(
+                DefineParam(mVideoSubFormat, C2_PARAMKEY_VENDOR_SUB_FORMAT)
+                .withDefault(new C2StreamVendorSubFormat::output(0))
+                .withFields({C2F(mVideoSubFormat, value).inRange(0, 0x7fffffff)})
+                .withSetter(Setter<decltype(*mVideoSubFormat)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mVendorHalPixelFormat, C2_PARAMKEY_VENDOR_HAL_PIXEL_FORMAT)
+                .withDefault(new C2StreamVendorHalPixelFormat::output(0))
+                .withFields({C2F(mVendorHalPixelFormat, value).inRange(0, 0xffffffff)})
+                .withSetter(Setter<decltype(*mVendorHalPixelFormat)>::StrictValueWithNoDeps)
+                .build());
+    }
+
+    static C2R SizeSetter(bool mayBlock, const C2P<C2StreamPictureSizeInfo::output> &oldMe,
+                          C2P<C2StreamPictureSizeInfo::output> &me) {
+        (void)mayBlock;
+        C2R res = C2R::Ok();
+        if (!me.F(me.v.width).supportsAtAll(me.v.width)) {
+            me.set().width = ((me.v.width+1)*2/2);
+            ALOGI("invalid width = %d", me.v.width);
+        }
+        if (!me.F(me.v.height).supportsAtAll(me.v.height)) {
+            me.set().height = ((me.v.height+1)*2/2);
+            ALOGI("invalid height = %d", me.v.height);
+        }
+        return res;
+    }
+
+    static C2R CropSetter(bool mayBlock, const C2P<C2StreamCropRectInfo::output> &oldMe,
+                          C2P<C2StreamCropRectInfo::output> &me) {
+        (void)mayBlock;
+        C2R res = C2R::Ok();
+        if (!me.F(me.v.width).supportsAtAll(me.v.width)) {
+            me.set().width = ((me.v.width+1)*2/2);
+            ALOGI("invalid crop width = %d", me.v.width);
+        }
+        if (!me.F(me.v.height).supportsAtAll(me.v.height)) {
+            me.set().height = ((me.v.height+1)*2/2);
+            ALOGI("invalid crop height = %d", me.v.height);
+        }
+        return res;
+    }
+
+    static C2R MaxPictureSizeSetter(bool mayBlock, C2P<C2StreamMaxPictureSizeTuning::output> &me,
+                                    const C2P<C2StreamPictureSizeInfo::output> &size) {
+        (void)mayBlock;
+        // TODO: get max width/height from the size's field helpers vs. hardcoding
+        me.set().width = c2_min(c2_max(me.v.width, size.v.width), 4080u);
+        me.set().height = c2_min(c2_max(me.v.height, size.v.height), 4080u);
+        return C2R::Ok();
+    }
+
+    static C2R MaxInputSizeSetter(bool mayBlock, C2P<C2StreamMaxBufferSizeInfo::input> &me,
+                                  const C2P<C2StreamMaxPictureSizeTuning::output> &maxSize) {
+        (void)mayBlock;
+        // assume compression ratio of 2
+        me.set().value = (((maxSize.v.width + 15) / 16) * ((maxSize.v.height + 15) / 16) * 192);
+        return C2R::Ok();
+    }
+
+    static C2R ProfileLevelSetter(bool mayBlock, C2P<C2StreamProfileLevelInfo::input> &me,
+                                  const C2P<C2StreamPictureSizeInfo::output> &size) {
+        (void)mayBlock;
+        (void)size;
+        (void)me;  // TODO: validate
+        return C2R::Ok();
+    }
+
+    static C2R DefaultColorAspectsSetter(bool mayBlock, C2P<C2StreamColorAspectsTuning::output> &me) {
+        (void)mayBlock;
+        if (me.v.range > C2Color::RANGE_OTHER) {
+                me.set().range = C2Color::RANGE_OTHER;
+        }
+        if (me.v.primaries > C2Color::PRIMARIES_OTHER) {
+                me.set().primaries = C2Color::PRIMARIES_OTHER;
+        }
+        if (me.v.transfer > C2Color::TRANSFER_OTHER) {
+                me.set().transfer = C2Color::TRANSFER_OTHER;
+        }
+        if (me.v.matrix > C2Color::MATRIX_OTHER) {
+                me.set().matrix = C2Color::MATRIX_OTHER;
+        }
+        return C2R::Ok();
+    }
+
+    static C2R CodedColorAspectsSetter(bool mayBlock, C2P<C2StreamColorAspectsInfo::input> &me) {
+        (void)mayBlock;
+        if (me.v.range > C2Color::RANGE_OTHER) {
+                me.set().range = C2Color::RANGE_OTHER;
+        }
+        if (me.v.primaries > C2Color::PRIMARIES_OTHER) {
+                me.set().primaries = C2Color::PRIMARIES_OTHER;
+        }
+        if (me.v.transfer > C2Color::TRANSFER_OTHER) {
+                me.set().transfer = C2Color::TRANSFER_OTHER;
+        }
+        if (me.v.matrix > C2Color::MATRIX_OTHER) {
+                me.set().matrix = C2Color::MATRIX_OTHER;
+        }
+        return C2R::Ok();
+    }
+
+    static C2R ColorAspectsSetter(bool mayBlock, C2P<C2StreamColorAspectsInfo::output> &me,
+                                  const C2P<C2StreamColorAspectsTuning::output> &def,
+                                  const C2P<C2StreamColorAspectsInfo::input> &coded) {
+        (void)mayBlock;
+        // take default values for all unspecified fields, and coded values for specified ones
+        me.set().range = coded.v.range == RANGE_UNSPECIFIED ? def.v.range : coded.v.range;
+        me.set().primaries = coded.v.primaries == PRIMARIES_UNSPECIFIED
+                ? def.v.primaries : coded.v.primaries;
+        me.set().transfer = coded.v.transfer == TRANSFER_UNSPECIFIED
+                ? def.v.transfer : coded.v.transfer;
+        me.set().matrix = coded.v.matrix == MATRIX_UNSPECIFIED ? def.v.matrix : coded.v.matrix;
+        return C2R::Ok();
+    }
+
+    std::shared_ptr<C2StreamColorAspectsInfo::output> getColorAspects_l() {
+        return mColorAspects;
+    }
+
+    std::shared_ptr<C2StreamColorAspectsTuning::output> getDefaultColorAspects_l() {
+        return mDefaultColorAspects;
+    }
+
+
+    uint32_t getVenderHalFormat() const { return mVendorHalPixelFormat->value; }
+
+    static C2R Hdr10PlusInfoInputSetter(bool mayBlock, C2P<C2StreamHdr10PlusInfo::input> &me) {
+        (void)mayBlock;
+        (void)me;  // TODO: validate
+        return C2R::Ok();
+    }
+
+    static C2R Hdr10PlusInfoOutputSetter(bool mayBlock, C2P<C2StreamHdr10PlusInfo::output> &me) {
+        (void)mayBlock;
+        (void)me;  // TODO: validate
+        return C2R::Ok();
+    }
+
+private:
+    C2String mComponentName;
+    std::shared_ptr<C2StreamProfileLevelInfo::input> mProfileLevel;
+    std::shared_ptr<C2StreamPictureSizeInfo::output> mSize;
+    std::shared_ptr<C2StreamCropRectInfo::output> mCrop;
+    std::shared_ptr<C2StreamMaxPictureSizeTuning::output> mMaxSize;
+    std::shared_ptr<C2StreamMaxBufferSizeInfo::input> mMaxInputSize;
+    std::shared_ptr<C2StreamColorInfo::output> mColorInfo;
+    std::shared_ptr<C2StreamColorAspectsInfo::input> mCodedColorAspects;
+    std::shared_ptr<C2StreamColorAspectsTuning::output> mDefaultColorAspects;
+    std::shared_ptr<C2StreamColorAspectsInfo::output> mColorAspects;
+    std::shared_ptr<C2StreamPixelFormatInfo::output> mPixelFormat;
+    std::shared_ptr<C2PortSurfaceAllocatorTuning::output> mSurfaceAllocator;
+    std::shared_ptr<C2StreamHdr10PlusInfo::input> mHdr10PlusInfoInput;
+    std::shared_ptr<C2StreamHdr10PlusInfo::output> mHdr10PlusInfoOutput;
+    std::shared_ptr<C2StreamVendorSubFormat::output> mVideoSubFormat;
+    std::shared_ptr<C2StreamVendorHalPixelFormat::output> mVendorHalPixelFormat;
+};
+
+static void convertCodecColorAspectsToCodec2Aspects(
+                DecColorAspects * pCodecAspects,
+                C2StreamColorAspectsInfo::input * pCodec2Aspects) {
+
+    std::unordered_map<int, C2Color::primaries_t> sColorPrimariesSf = {
+        { 0/*ColorAspects::PrimariesUnspecified*/, C2Color::PRIMARIES_UNSPECIFIED },
+        { 1/*ColorAspects::PrimariesBT709_5*/,     C2Color::PRIMARIES_BT709 },
+        { 2/*ColorAspects::PrimariesBT470_6M*/,    C2Color::PRIMARIES_BT470_M },
+        { 3/*ColorAspects::PrimariesBT601_6_625*/, C2Color::PRIMARIES_BT601_625 },
+        { 4/*ColorAspects::PrimariesBT601_6_525*/, C2Color::PRIMARIES_BT601_525 },
+        { 5/*ColorAspects::PrimariesGenericFilm*/, C2Color::PRIMARIES_GENERIC_FILM },
+        { 6/*ColorAspects::PrimariesBT2020*/,      C2Color::PRIMARIES_BT2020 },
+        { 0xff/*ColorAspects::PrimariesOther*/,    C2Color::PRIMARIES_OTHER },
+    };
+
+    std::unordered_map<int, C2Color::range_t> sColorRangesSf = {
+        { 0/*ColorAspects::RangeUnspecified*/, C2Color::RANGE_UNSPECIFIED },
+        { 1/*ColorAspects::RangeFull*/,        C2Color::RANGE_FULL },
+        { 2/*ColorAspects::RangeLimited*/,     C2Color::RANGE_LIMITED },
+        { 0xff/*ColorAspects::RangeOther*/,    C2Color::RANGE_OTHER },
+    };
+
+    std::unordered_map<int, C2Color::matrix_t> sColorMatricesSf = {
+        { 0/*ColorAspects::MatrixUnspecified*/,    C2Color::MATRIX_UNSPECIFIED },
+        { 1/*ColorAspects::MatrixBT709_5*/,        C2Color::MATRIX_BT709 },
+        { 2/*ColorAspects::MatrixBT470_6M*/,       C2Color::MATRIX_FCC47_73_682 },
+        { 3/*ColorAspects::MatrixBT601_6*/,        C2Color::MATRIX_BT601 },
+        { 4/*ColorAspects::MatrixSMPTE240M*/,      C2Color::MATRIX_240M },
+        { 5/*ColorAspects::MatrixBT2020*/,         C2Color::MATRIX_BT2020 },
+        { 6/*ColorAspects::MatrixBT2020Constant*/, C2Color::MATRIX_BT2020_CONSTANT },
+        { 0xff/*ColorAspects::MatrixOther*/,       C2Color::MATRIX_OTHER },
+    };
+
+    std::unordered_map<int, C2Color::transfer_t> sColorTransfersSf = {
+        { 0/*ColorAspects::TransferUnspecified*/,  C2Color::TRANSFER_UNSPECIFIED },
+        { 1/*ColorAspects::TransferLinear*/,       C2Color::TRANSFER_LINEAR },
+        { 2/*ColorAspects::TransferSRGB*/,         C2Color::TRANSFER_SRGB },
+        { 3/*ColorAspects::TransferSMPTE170M*/,    C2Color::TRANSFER_170M },
+        { 4/*ColorAspects::TransferGamma22*/,      C2Color::TRANSFER_GAMMA22 },
+        { 5/*ColorAspects::TransferGamma28*/,      C2Color::TRANSFER_GAMMA28 },
+        { 6/*ColorAspects::TransferST2084*/,       C2Color::TRANSFER_ST2084 },
+        { 7/*ColorAspects::TransferHLG*/,          C2Color::TRANSFER_HLG },
+        { 0x40/*ColorAspects::TransferSMPTE240M*/, C2Color::TRANSFER_240M },
+        { 0x41/*ColorAspects::TransferXvYCC*/,     C2Color::TRANSFER_XVYCC },
+        { 0x42/*ColorAspects::TransferBT1361*/,    C2Color::TRANSFER_BT1361 },
+        { 0x43/*ColorAspects::TransferST428*/,     C2Color::TRANSFER_ST428 },
+        { 0xff/*ColorAspects::TransferOther*/,     C2Color::TRANSFER_OTHER },
+    };
+
+    pCodec2Aspects->primaries = sColorPrimariesSf.at(pCodecAspects->colourPrimaries);
+    pCodec2Aspects->range = sColorRangesSf.at(pCodecAspects->fullRange);
+    pCodec2Aspects->matrix = sColorMatricesSf.at(pCodecAspects->matrixCoeffs);
+    pCodec2Aspects->transfer = sColorTransfersSf.at(pCodecAspects->transferCharacteristics);
+};
+
+
+IMXC2VideoDecoder::IMXC2VideoDecoder(const char* name, c2_node_id_t id, const std::shared_ptr<IntfImpl> &intfImpl)
+    : IMXC2ComponentBase(std::make_shared<IMXInterface<IntfImpl>>(name, id, intfImpl)),
+      mIntf(intfImpl),
+      mWidth(320),
+      mHeight(240),
+      mCropWidth(320),
+      mCropHeight(240),
+      nOutBufferNum(8),
+      mName(name),
+      bPendingFmtChanged(false),
+      bGetGraphicBlockPool(false),
+      bSignalOutputEos(false),
+      bSignalledError(false),
+      bFlushDone(false),
+      bPPEnabled(false){
+}
+
+IMXC2VideoDecoder::~IMXC2VideoDecoder() {
+}
+
+// From IMXC2ComponentBase
+c2_status_t IMXC2VideoDecoder::onInit() {
+    status_t err;
+
+    const char* mime = Name2MimeType((const char*)mName.c_str());
+    if (mime == nullptr) {
+        ALOGE("Unsupported component name: %s", mName.c_str());
+        return C2_BAD_VALUE;
+    }
+    ALOGV("onInit mime=%s",mime);
+    mDecoder = CreateVideoDecoderInstance(mime);
+    if (!mDecoder) {
+        ALOGE("CreateVideoDecoderInstance for mime(%s) failed 
", mime);
+        return C2_CORRUPTED;
+    }
+
+    err = mDecoder->init((VideoDecoderBase::Client*)this);
+    if (err) {
+        goto RELEASE_DECODER;
+    }
+
+    err = initInternalParam();
+    if (err)
+        goto RELEASE_DECODER;
+
+    err = mDecoder->start();
+    if (err)
+        goto RELEASE_DECODER;
+
+    return C2_OK;
+
+RELEASE_DECODER:
+    // release decoder if init failed, in case of upper layer don't call release
+    releaseDecoder();
+    return C2_NO_MEMORY;
+}
+
+c2_status_t IMXC2VideoDecoder::onStop() {
+    status_t err;
+
+
+    ALOGV("onStop");
+    err = mDecoder->stop();
+    if (err != OK)
+        ALOGE("decoder stop return err %d", err);
+
+    if (mPostProcess) {
+        ALOGV("onStop mPostProcess->stop");
+        err = mPostProcess->stop();
+        if (err != OK)
+            ALOGE("post process stop return err %d", err);
+    }
+
+    err = initInternalParam();
+    return C2ERR(err);
+}
+
+c2_status_t IMXC2VideoDecoder::onFlush_sm() {
+    status_t err = OK;
+    ALOGV("onFlush_sm");
+
+
+    err = mDecoder->flush();
+    CHECK_AND_RETURN_C2_ERR(err);
+
+    if (bPPEnabled) {
+        err = mPostProcess->flush();
+        CHECK_AND_RETURN_C2_ERR(err);
+    }
+
+
+    bPendingFmtChanged = false;
+    bSignalledError = false;
+    bSignalOutputEos = false;
+    bRecieveOutputEos = false;
+    bFlushDone = true;
+
+    nCurFrameIndex = 0;
+    nUsedFrameIndex = 0;
+
+    return C2ERR(err);
+}
+
+void IMXC2VideoDecoder::onReset() {
+    ALOGV("onReset");
+    (void) releaseDecoder();
+}
+
+void IMXC2VideoDecoder::onRelease() {
+    ALOGV("onRelease");
+    (void) releaseDecoder();
+}
+
+static void fillEmptyWork(const std::unique_ptr<C2Work> &work) {
+    uint32_t flags = 0;
+    if (work->input.flags & C2FrameData::FLAG_END_OF_STREAM) {
+        flags |= C2FrameData::FLAG_END_OF_STREAM;
+        ALOGV("signalling eos");
+    }
+    work->worklets.front()->output.flags = (C2FrameData::flags_t)flags;
+    work->worklets.front()->output.buffers.clear();
+    work->worklets.front()->output.ordinal = work->input.ordinal;
+    work->workletsProcessed = 1u;
+}
+
+void IMXC2VideoDecoder::processWork(const std::unique_ptr<C2Work> &work) {
+    int32_t fd, inputId;
+    uint8_t* inputBuffer;
+    uint64_t timestamp;
+
+    if (!bGetGraphicBlockPool) {
+        status_t err = mDecoder->setGraphicBlockPool(mOutputBlockPool);
+        if (err != OK)
+            return;
+        bGetGraphicBlockPool = true;
+    }
+
+    work->result = C2_OK;
+    work->workletsProcessed = 0u;
+    work->worklets.front()->output.configUpdate.clear();
+    work->worklets.front()->output.flags = work->input.flags;
+
+    if (bSignalledError | bSignalOutputEos) {
+        work->result = C2_BAD_VALUE;
+        return fillEmptyWork(work);
+    }
+
+    C2ReadView view = mDummyReadView;
+    uint32_t size = 0;
+    uint32_t flags = work->input.flags;
+    bool eos = ((work->input.flags & C2FrameData::FLAG_END_OF_STREAM) != 0);
+    if(eos)
+        flags &= ~(work->input.flags & C2FrameData::FLAG_END_OF_STREAM);
+
+    if (!work->input.buffers.empty()) {
+        view = work->input.buffers[0]->data().linearBlocks().front().map().get();
+        size = view.capacity();
+        if (size && view.error()) {
+            ALOGE("read view map failed %d", view.error());
+            work->result = view.error();
+            return;
+        }
+    }
+
+    if (eos && size == 0) {
+        ALOGI("input eos, size=0,ts=%d",(int)work->input.ordinal.timestamp.peeku());
+        drain_nb(DRAIN_COMPONENT_WITH_EOS);
+        bSignalOutputEos = true;
+        return;
+    } else if (work->input.buffers.empty()) {
+        fillEmptyWork(work);
+        return;
+    }
+
+    const C2ConstLinearBlock block = work->input.buffers[0]->data().linearBlocks().front();
+    fd = block.handle()->data[0];
+    inputBuffer = const_cast<uint8_t *>(view.data());
+    timestamp = work->input.ordinal.timestamp.peeku();
+    inputId = static_cast<int32_t>(work->input.ordinal.frameIndex.peeku() & 0x3FFFFFFF);
+
+    ALOGV("in buffer fd %d addr %p size %d timestamp %d frameindex %d, flags %x",
+          fd, inputBuffer, (int)view.capacity(), (int)timestamp,
+          (int)work->input.ordinal.frameIndex.peeku(), flags);
+
+    mDecoder->queueInput(inputBuffer, size, timestamp, flags, fd, inputId);
+
+    if (nUsedFrameIndex == nCurFrameIndex) {
+        work->input.buffers.front().reset();
+        ALOGV("input id %d is used 
", inputId);
+    }
+
+    // codec data won't have a picture out, mark c2work as processed directly
+    if (flags & C2FrameData::FLAG_CODEC_CONFIG) {
+        work->workletsProcessed = 1u;
+        work->result = C2_OK;
+    }
+
+    if (eos && size > 0) {
+        ALOGI("input eos, size=%d,ts=%d",size,(int)work->input.ordinal.timestamp.peeku());
+
+        drain_nb(DRAIN_COMPONENT_WITH_EOS);
+        bSignalOutputEos = true;
+        return;
+    }
+}
+
+c2_status_t IMXC2VideoDecoder::drainInternal(uint32_t drainMode) {
+    // trigger decoding to drain internel input buffers
+    if (drainMode == NO_DRAIN) {
+        ALOGW("drain with NO_DRAIN: no-op");
+        return C2_OK;
+    }
+    if (drainMode == DRAIN_CHAIN) {
+        ALOGW("DRAIN_CHAIN not supported");
+        return C2_OMITTED;
+
+    }
+    // DRAIN_COMPONENT_WITH_EOS
+    mDecoder->queueInput(nullptr, 0, 0, C2FrameData::FLAG_END_OF_STREAM, -1, -1);
+    return C2_OK;
+}
+
+status_t IMXC2VideoDecoder::initInternalParam() {
+    c2_status_t err = C2_OK;
+    ALOGV("initInternalParam BEGIN");
+
+    C2StreamPictureSizeInfo::output size(0u, mWidth, mHeight);
+    intf()->query_vb({&size,}, {}, C2_DONT_BLOCK, nullptr);
+    if (err == C2_OK) {
+        mWidth = size.width;
+        mHeight = size.height;
+
+        VideoFormat vFormat;
+        mDecoder->getConfig(DEC_CONFIG_INPUT_FORMAT, &vFormat);
+        vFormat.width = mWidth;
+        vFormat.height = mHeight;
+        mDecoder->setConfig(DEC_CONFIG_INPUT_FORMAT, &vFormat);
+
+        memset(&vFormat, 0, sizeof(VideoFormat));
+        mDecoder->getConfig(DEC_CONFIG_OUTPUT_FORMAT, &vFormat);
+        vFormat.width = mWidth;
+        vFormat.height = mHeight;
+        mDecoder->setConfig(DEC_CONFIG_OUTPUT_FORMAT, &vFormat);
+    }
+
+    C2StreamVendorSubFormat::output subFormat(0);
+    err = intf()->query_vb({&subFormat,}, {}, C2_DONT_BLOCK, nullptr);
+    if (err == C2_OK && subFormat.value != 0) {
+        int32_t vc1SubFormat = subFormat.value;
+        ALOGV("SET DEC_CONFIG_VC1_SUB_FORMAT vc1SubFormat=%x",vc1SubFormat);
+        mDecoder->setConfig(DEC_CONFIG_VC1_SUB_FORMAT, &vc1SubFormat);
+    }
+
+    int outputDelayValue;
+    if (OK == mDecoder->getConfig(DEC_CONFIG_OUTPUT_DELAY, &outputDelayValue)) {
+        C2PortActualDelayTuning::output outputDelay(outputDelayValue);
+        std::vector<std::unique_ptr<C2SettingResult>> failures;
+        (void)mIntf->config({&outputDelay}, C2_MAY_BLOCK, &failures);
+    }
+
+    C2StreamVendorHalPixelFormat::output output_fmt(0);
+    intf()->query_vb({&output_fmt,}, {}, C2_DONT_BLOCK, nullptr);
+    if (err == C2_OK && output_fmt.value != 0) {
+        uint32_t fmt = output_fmt.value;
+        ALOGV("SET DEC_CONFIG_HAL_PIXEL_FORMAT fmt=%x",fmt);
+        (void)mDecoder->setConfig(DEC_CONFIG_HAL_PIXEL_FORMAT, &fmt);
+    }
+
+    return OK;
+}
+
+void IMXC2VideoDecoder::releaseDecoder() {
+
+    if (mDecoder) {
+        mDecoder->destroy();
+        mDecoder.clear();
+    }
+
+    if (mPostProcess) {
+        ALOGV("releaseDecoder mPostProcess->destroy");
+        mPostProcess->destroy();
+        mPostProcess.clear();
+    }
+
+}
+
+void IMXC2VideoDecoder::handleOutputPicture(GraphicBlockInfo* info, uint64_t timestamp, uint32_t flag) {
+    C2ConstGraphicBlock constBlock = info->mGraphicBlock->share(C2Rect(mCropWidth, mCropHeight), C2Fence());
+    std::shared_ptr<C2Buffer> buffer = C2Buffer::CreateGraphicBuffer(std::move(constBlock));
+    if(bPPEnabled){
+        bPendingFmtChanged = false;
+        if(flag & FLAG_RES_CHANGE)
+            bPendingFmtChanged = true;
+    }
+
+    bool configUpdate = (bPendingFmtChanged || bFlushDone);
+    uint32_t outputDelayValue = 0;
+    C2PortActualDelayTuning::output outputDelay(0);
+    C2StreamPictureSizeInfo::output size(0u, mWidth, mHeight);
+    C2StreamPixelFormatInfo::output fmt(0u, HAL_PIXEL_FORMAT_YCBCR_420_888);
+    if(bPPEnabled){
+        fmt.value = HAL_PIXEL_FORMAT_YCBCR_422_I;//0x14;
+        ALOGV("handleOutputPicture bPPEnabled");
+    }
+
+    {
+        IntfImpl::Lock lock = mIntf->lock();
+        buffer->setInfo(mIntf->getColorAspects_l());
+    }
+
+    if (bPendingFmtChanged) {
+        DecStaticHDRInfo hdrInfo;
+        if (OK == mDecoder->getConfig(DEC_CONFIG_HDR10_STATIC_INFO, &hdrInfo)) {
+            std::shared_ptr<C2StreamHdrStaticInfo::output> hdrStaticInfo =
+                std::make_shared<C2StreamHdrStaticInfo::output>();
+            hdrStaticInfo->mastering = {
+                .red   = { .x = (float)(hdrInfo.mR[0]*0.00002),  .y = (float)(hdrInfo.mR[1]*0.00002) },
+                .green = { .x = (float)(hdrInfo.mG[0]*0.00002),  .y = (float)(hdrInfo.mG[1]*0.00002) },
+                .blue  = { .x = (float)(hdrInfo.mB[0]*0.00002),  .y = (float)(hdrInfo.mB[1]*0.00002) },
+                .white = { .x = (float)(hdrInfo.mW[0]*0.00002),  .y = (float)(hdrInfo.mW[1]*0.00002) },
+                .maxLuminance = (float)(hdrInfo.mMaxDisplayLuminance*1.0),
+                .minLuminance = (float)(hdrInfo.mMinDisplayLuminance*0.0001),
+            };
+            hdrStaticInfo->maxCll = (float)(hdrInfo.mMaxContentLightLevel*1.0);
+            hdrStaticInfo->maxFall = (float)(hdrInfo.mMaxFrameAverageLightLevel*1.0);
+            buffer->setInfo(hdrStaticInfo);
+
+            ALOGI("HdrStaticInfo: red(%0.5f, %0.5f) green(%0.5f, %0.5f) blue(%0.5f, %0.5f) white(%0.5f, %0.5f)",
+                hdrStaticInfo->mastering.red.x, hdrStaticInfo->mastering.red.y,
+                hdrStaticInfo->mastering.green.x, hdrStaticInfo->mastering.green.y,
+                hdrStaticInfo->mastering.blue.x, hdrStaticInfo->mastering.blue.y,
+                hdrStaticInfo->mastering.white.x, hdrStaticInfo->mastering.white.y);
+            ALOGI("HdrStaticInfo: maxLuminance(%0.1f) minLuminance(%0.4f) maxCll(%0.1f) maxFall(%0.1f)",
+                hdrStaticInfo->mastering.maxLuminance, hdrStaticInfo->mastering.minLuminance,
+                hdrStaticInfo->maxCll, hdrStaticInfo->maxFall);
+        }
+    }
+
+    if (configUpdate) {
+        c2_status_t err = intf()->query_vb(
+            {
+                &outputDelay,
+            },
+            {},
+            C2_DONT_BLOCK,
+            nullptr);
+        if (err == C2_OK) {
+            outputDelayValue = outputDelay.value;
+        }
+
+        if (bPendingFmtChanged) {
+            // align with c2, add 4 (kSmoothnessFactor) buffers.
+            outputDelayValue = nOutBufferNum + 4;
+
+            if (outputDelay.value < outputDelayValue) {
+                outputDelay.value = outputDelayValue;
+                std::vector<std::unique_ptr<C2SettingResult>> failures;
+                (void)mIntf->config({&outputDelay}, C2_MAY_BLOCK, &failures);
+            }
+        }
+
+        ALOGV("configUpdate outputDelay.value=%d", outputDelay.value);
+
+    }
+
+    auto fillWork = [buffer, timestamp, configUpdate, size, outputDelay, fmt]
+                    (const std::unique_ptr<C2Work> &work) mutable {
+
+        uint32_t flags = 0;
+        if ((work->input.flags & C2FrameData::FLAG_END_OF_STREAM) &&
+                (c2_cntr64_t(timestamp) == work->input.ordinal.timestamp)) {
+            flags |= C2FrameData::FLAG_END_OF_STREAM;
+            ALOGV("signalling eos");
+        }
+        if (configUpdate) {
+            work->worklets.front()->output.configUpdate.push_back(C2Param::Copy(size));
+            work->worklets.front()->output.configUpdate.push_back(C2Param::Copy(outputDelay));
+            work->worklets.front()->output.configUpdate.push_back(C2Param::Copy(fmt));
+        }
+
+        work->worklets.front()->output.flags = (C2FrameData::flags_t)flags;
+        work->worklets.front()->output.buffers.clear();
+        work->worklets.front()->output.buffers.push_back(buffer);
+        work->worklets.front()->output.ordinal = work->input.ordinal;
+
+        // if original timestamp is -1, use ts manager adjusted timestamp instead,
+        // or frame with ts=-1 will be dropped by display, video become influent.
+        if (-1 == work->input.ordinal.timestamp.peeku()) {
+            work->worklets.front()->output.ordinal.timestamp = timestamp;
+        }
+
+        work->workletsProcessed = 1u;
+    };
+
+    c2_status_t err = finish(timestamp, fillWork);
+
+    info->mState = GraphicBlockInfo::State::OWNED_BY_CLIENT;
+    bPendingFmtChanged = false;
+    bFlushDone = false;
+
+    if (C2_NOT_FOUND == err && !bPPEnabled) {
+        // no need to return buffer to post processor because its reference is clear.
+        mDecoder->returnOutputBufferToDecoder(info->mBlockId);
+    } else {
+        info->mGraphicBlock.reset();
+    }
+}
+
+
+// callbacks for VideoDecoderBase
+
+// update intf configure
+void IMXC2VideoDecoder::notifyVideoInfo(VideoFormat *pFormat) {
+    status_t err = OK;
+
+    bPPEnabled = mDecoder->checkIfPostProcessNeeded();
+
+    if (bPPEnabled) {
+        ALOGI("post process is enabled");
+
+        PROCESSBASE_FORMAT inFmt, outFmt;
+        inFmt.width = pFormat->width;
+        inFmt.height = pFormat->height;
+        inFmt.stride = pFormat->width;
+        inFmt.interlaced = pFormat->interlaced;
+
+        // receive the first format change event, post process is created and configured.
+        // later post process just need to call videoFormatChanged to handle this event.
+        if (!mPostProcess) {
+            mPostProcess = CreatePostProcessInstance();
+            if (!mPostProcess) {
+                bSignalledError = true;
+                return;
+            }
+
+            ALOGV("config process input format: %d x %d, stride %d", pFormat->width, pFormat->height, pFormat->width);
+
+            err = mPostProcess->setConfig(PROCESS_CONFIG_INPUT_FORMAT, &inFmt);
+            if (err) {
+                bSignalledError = true;
+                return;
+            }
+
+            err = mPostProcess->init((ProcessBase::Client*)this, mOutputBlockPool);
+            if (err) {
+                bSignalledError = true;
+                return;
+            }
+
+            err = mPostProcess->getConfig(PROCESS_CONFIG_OUTPUT_FORMAT, &outFmt);
+            if (err) {
+                bSignalledError = true;
+                return;
+            }
+        } else {
+            ALOGV("notifyVideoInfo call mPostProcess->videoFormatChanged");
+            // need reconfigure post processor to handle resolution change.
+            mPostProcess->videoFormatChanged(&inFmt);
+            mPostProcess->start();
+        }
+        nOutBufferNum = DEFAULT_OUTPUT_BUFFER_CNT_IN_POST_PROCESS;
+    }
+    else
+        nOutBufferNum = pFormat->bufferNum;
+
+    mWidth = pFormat->width;
+    mHeight = pFormat->height;
+    mCropWidth = pFormat->rect.right - pFormat->rect.left;
+    mCropHeight = pFormat->rect.bottom- pFormat->rect.top;
+
+    ALOGV("notifyVideoInfo mWidth=%d,mHeight=%d, mCropWidth=%d,mCropHeight=%d,nOutBufferNum=%d",mWidth,mHeight,mCropWidth, mCropHeight,nOutBufferNum);
+
+    std::vector<std::unique_ptr<C2SettingResult>> failures;
+
+    C2StreamPictureSizeInfo::output size(0u, mWidth, mHeight);
+
+    C2StreamCropRectInfo::output crop(0u, C2Rect(mCropWidth, mCropHeight));
+
+    (void)mIntf->config({&size}, C2_MAY_BLOCK, &failures);
+
+    (void)mIntf->config({&crop}, C2_MAY_BLOCK, &failures);
+
+    //update C2StreamVendorHalPixelFormat when enable post process for malone decoder
+    if(0 == mIntf->getVenderHalFormat() && bPPEnabled){
+        C2StreamVendorHalPixelFormat::output fmt(0u, HAL_PIXEL_FORMAT_YCBCR_422_I);//FORMAT_YUYV 0x14
+        (void)mIntf->config({&fmt}, C2_MAY_BLOCK, &failures);
+        ALOGV("config C2StreamVendorHalPixelFormat HAL_PIXEL_FORMAT_YCBCR_422_I");
+    }
+
+    DecColorAspects colorAspects;
+    if (OK == mDecoder->getConfig(DEC_CONFIG_COLOR_ASPECTS, &colorAspects)) {
+        C2StreamColorAspectsInfo::input codedAspects = { 0u };
+        convertCodecColorAspectsToCodec2Aspects(&colorAspects, &codedAspects);
+        ALOGD("C2 color aspect p %d t %d m %d r %d",
+            codedAspects.primaries, codedAspects.range,
+            codedAspects.matrix, codedAspects.transfer);
+        std::vector<std::unique_ptr<C2SettingResult>> failures;
+        (void)mIntf->config({&codedAspects}, C2_MAY_BLOCK, &failures);
+    }
+
+    bPendingFmtChanged = true;
+}
+
+void IMXC2VideoDecoder::clearPictureBuffer() {
+}
+
+void IMXC2VideoDecoder::notifyPictureReady(int32_t pictureId, uint64_t timestamp) {
+    ALOGV("notifyPictureReady picture id=%d, ts=%lld", (int)pictureId, (long long)timestamp);
+
+    GraphicBlockInfo* info = mDecoder->getGraphicBlockById(pictureId);
+    if (!info) {
+        /* notify error */
+        ALOGE("%s line %d: wrong pictureId %d", __FUNCTION__, __LINE__, pictureId);
+        return;
+    }
+
+    if (info->mState != GraphicBlockInfo::State::OWNED_BY_VPU) {
+        ALOGE("%s line %d: error graphic block state, expect OWNED_BY_VPU but get %d", __FUNCTION__, __LINE__, info->mState);
+        return;
+    }
+
+    if (bPPEnabled) {
+        uint32_t flag = 0;
+        if(bPendingFmtChanged){
+            flag = FLAG_RES_CHANGE;
+            bPendingFmtChanged = false;
+        }
+        ALOGV("queueInput input pictureId=%d,id=%d",(int)pictureId,(int)info->mBlockId);
+        mPostProcess->queueInput((void*)info->mVirtAddr, (void*)info->mPhysAddr, info->mCapacity,
+                                    timestamp, flag, info->mDMABufFd, info->mBlockId);
+        return;
+    }
+
+    handleOutputPicture(info, timestamp, 0);
+
+}
+
+void IMXC2VideoDecoder::notifyInputBufferUsed(int32_t input_id) {
+    nUsedFrameIndex = static_cast<uint64_t>(input_id);
+
+    C2Work* work = getPendingWorkByFrameIndex(nUsedFrameIndex);
+    if (!work) {
+        return;
+    }
+
+    // When the work is done, the input buffer shall be reset by component.
+    work->input.buffers.front().reset();
+    ALOGV("input id %d is used 
", (int)input_id);
+}
+
+void IMXC2VideoDecoder::notifySkipInputBuffer(int32_t input_id) {
+    skipOnePendingWork((uint64_t)input_id);
+}
+
+void IMXC2VideoDecoder::notifyFlushDone() {
+    if (bPPEnabled) {
+        // wait post process notify flush done
+        return;
+    }
+    bFlushDone = true;
+}
+
+void IMXC2VideoDecoder::notifyResetDone() {
+}
+
+void IMXC2VideoDecoder::notifyError(status_t err) {
+    bSignalledError = true;
+    finishWithException(false/*eos*/, false/*force*/);
+    ALOGE("video decoder notify with error %d", err);
+}
+
+void IMXC2VideoDecoder::notifyEos() {
+    if (bPPEnabled) {
+        // queue an empty input with eos flag
+        mPostProcess->queueInput(0, 0, 0, 0, C2FrameData::FLAG_END_OF_STREAM, -1, -1);
+        return;
+    } else {
+        finishWithException(true/*eos*/, !bRecieveOutputEos);
+    }
+
+    // fill empty work and sigal eos
+    bRecieveOutputEos = true;
+}
+
+status_t IMXC2VideoDecoder::fetchProcessBuffer(int *bufferId, unsigned long *phys) {
+    status_t ret = OK;
+
+    GraphicBlockInfo *gbInfo = mDecoder->getFreeGraphicBlock();
+    if (!gbInfo) {
+        if (OK == mDecoder->fetchOutputBuffer()) {
+            gbInfo = mDecoder->getFreeGraphicBlock();
+        } else
+            ret = BAD_VALUE;
+    }
+
+    if (ret == OK) {
+        *bufferId = gbInfo->mBlockId;
+        *phys = gbInfo->mPhysAddr;
+    }
+
+    return ret;
+}
+
+status_t IMXC2VideoDecoder::notifyProcessInputUsed(int inputId) {
+    ALOGV("%s inputId %d", __FUNCTION__, inputId);
+    if(mDecoder == NULL)
+        return OK;
+
+    if(bPPEnabled && mPostProcess != NULL)
+        return mDecoder->queueOutput(inputId);
+    else
+        mDecoder->returnOutputBufferToDecoder(inputId);
+    return OK;
+}
+
+status_t IMXC2VideoDecoder::notifyProcessDone(int outputId, uint64_t timestamp, uint32_t flag) {
+    ALOGV("%s, outputId %d, timestamp %lld
", __FUNCTION__, outputId, (long long)timestamp);
+
+    ProcessBlockInfo* pInfo = mPostProcess->getProcessBlockById(outputId);
+    if (!pInfo) {
+        ALOGE("notifyProcessDone get invalid outputId: %d", outputId);
+        return BAD_VALUE;
+    }
+
+    GraphicBlockInfo graphicInfo;
+
+    memset(&graphicInfo, 0, sizeof(GraphicBlockInfo));
+    graphicInfo.mBlockId = pInfo->mBlockId;
+    graphicInfo.mGraphicBlock = std::move(pInfo->mGraphicBlock);
+    //(void)flag;
+    handleOutputPicture(&graphicInfo, timestamp,flag);
+
+    return OK;
+}
+
+status_t IMXC2VideoDecoder::notifyProcessOutputClear() {
+    return OK;
+}
+
+status_t IMXC2VideoDecoder::notifyProcessFlushDone() {
+    bFlushDone = true;
+    return OK;
+}
+
+status_t IMXC2VideoDecoder::notifyProcessResetDone() {
+    return OK;
+}
+
+void IMXC2VideoDecoder::notifyProcessError() {
+    bSignalledError = true;
+    finishWithException(false/*eos*/, false/*force*/);
+    ALOGE("post process notify with error");
+}
+
+void IMXC2VideoDecoder::notifyProcessEos() {
+    ALOGV("get notifyProcessEos");
+    // fill empty work and sigal eos
+    finishWithException(true/*eos*/, !bRecieveOutputEos);
+    bRecieveOutputEos = true;
+}
+
+class IMXC2VideoDecoderFactory : public C2ComponentFactory {
+public:
+    IMXC2VideoDecoderFactory(C2String name)
+        : mHelper(std::static_pointer_cast<C2ReflectorHelper>(GetImxC2Store()->getParamReflector())),
+          mComponentName(name) {
+    }
+
+    virtual c2_status_t createComponent(
+            c2_node_id_t id,
+            std::shared_ptr<C2Component>* const component,
+            std::function<void(C2Component*)> deleter) override {
+        *component = std::shared_ptr<C2Component>(
+                new IMXC2VideoDecoder(mComponentName.c_str(),
+                                 id,
+                                 std::make_shared<IMXC2VideoDecoder::IntfImpl>(mHelper, mComponentName.c_str())),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual c2_status_t createInterface(
+            c2_node_id_t id,
+            std::shared_ptr<C2ComponentInterface>* const interface,
+            std::function<void(C2ComponentInterface*)> deleter) override {
+        *interface = std::shared_ptr<C2ComponentInterface>(
+                new IMXInterface<IMXC2VideoDecoder::IntfImpl>(
+                        mComponentName, id, std::make_shared<IMXC2VideoDecoder::IntfImpl>(mHelper, mComponentName)),
+                deleter);
+        return C2_OK;
+    }
+
+    //typedef ::C2ComponentFactory* (*IMXCreateCodec2FactoryFunc)(C2String name);
+
+    virtual ~IMXC2VideoDecoderFactory() override = default;
+
+private:
+    std::shared_ptr<C2ReflectorHelper> mHelper;
+    C2String mComponentName;
+};
+
+extern "C" ::C2ComponentFactory* IMXCreateCodec2Factory(C2String name) {
+    ALOGV("in %s", __func__);
+    return new ::android::IMXC2VideoDecoderFactory(name);
+}
+
+extern "C" void IMXDestroyCodec2Factory(::C2ComponentFactory* factory) {
+    ALOGV("in %s", __func__);
+    delete factory;
+}
+
+
+} // namespcae android
+
+/* end of file */
diff --git a/codec2/video_dec/common/IMXC2VideoDecoder.h b/codec2/video_dec/common/IMXC2VideoDecoder.h
new file mode 100755
index 0000000..a559954
--- /dev/null
+++ b/codec2/video_dec/common/IMXC2VideoDecoder.h
@@ -0,0 +1,101 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef IMX_VIDEO_DECODER_H_
+#define IMX_VIDEO_DECODER_H_
+
+#include <log/log.h>
+
+#include <media/stagefright/foundation/MediaDefs.h>
+
+#include <C2Debug.h>
+#include <C2PlatformSupport.h>
+#include <IMXC2Interface.h>
+
+#include "IMXC2ComponentBase.h"
+#include "ProcessBase.h"
+#include "VideoDecoderBase.h"
+
+namespace android {
+
+class IMXC2VideoDecoder : public IMXC2ComponentBase,
+						        public ProcessBase::Client,
+						        public VideoDecoderBase::Client {
+public:
+
+	class IntfImpl;
+
+    IMXC2VideoDecoder(const char* name, c2_node_id_t id, const std::shared_ptr<IntfImpl> &intfImpl);
+    virtual ~IMXC2VideoDecoder();
+
+	// from VideoDecoderBase
+	void notifyVideoInfo(VideoFormat *pformat) override;
+	void clearPictureBuffer() override;
+    void notifyPictureReady(int32_t pictureId, uint64_t timestamp) override;
+    void notifyInputBufferUsed(int32_t input_id) override;
+    void notifySkipInputBuffer(int32_t input_id) override;
+    void notifyFlushDone() override;
+    void notifyResetDone() override;
+    void notifyError(status_t err) override;
+    void notifyEos() override;
+
+	// from ProcessBase
+    status_t fetchProcessBuffer(int *bufferId, unsigned long *phys) override;
+    status_t notifyProcessInputUsed(int inputId) override;
+    status_t notifyProcessDone(int outputId, uint64_t timestamp, uint32_t flag) override;
+    status_t notifyProcessOutputClear() override;
+    status_t notifyProcessFlushDone() override;
+    status_t notifyProcessResetDone() override;
+    void notifyProcessError() override;
+    void notifyProcessEos() override;
+
+    void outputBufferReturned(int32_t pictureId);
+
+protected:
+
+	// From IMXC2Component
+    c2_status_t onInit() override;
+    c2_status_t onStop() override;
+    c2_status_t onFlush_sm() override;
+    void onReset() override;
+    void onRelease() override;
+    void processWork(const std::unique_ptr<C2Work> &work) override;
+    c2_status_t drainInternal(uint32_t drainMode) override;
+
+
+private:
+	sp<ProcessBase> mPostProcess;
+	sp<VideoDecoderBase> mDecoder;
+	std::shared_ptr<IntfImpl> mIntf;
+	// The vector of storing allocated output graphic block information.
+    std::vector<std::shared_ptr<C2GraphicBlock>> mOutputBufferMap;
+    uint32_t mWidth;
+    uint32_t mHeight;
+    uint32_t mCropWidth;
+    uint32_t mCropHeight;
+    uint32_t nOutBufferNum;
+
+	C2String mName; //component name or role name ?
+    bool bPendingFmtChanged;
+    bool bGetGraphicBlockPool;
+    bool bSignalOutputEos;
+    bool bSignalledError;
+    bool bFlushDone;
+    bool bPPEnabled;
+    bool bReleasingDecoder;
+
+    status_t initInternalParam();    // init internel paramters
+    void releaseDecoder();    // release decoder instance
+
+    void handleOutputPicture(GraphicBlockInfo* info, uint64_t timestamp, uint32_t flag);
+};
+
+
+} // namespace android
+
+#endif  // IMX_VIDEO_DECODER_H_
diff --git a/codec2/video_dec/common/VideoDecoderBase.cpp b/codec2/video_dec/common/VideoDecoderBase.cpp
new file mode 100755
index 0000000..e270ca6
--- /dev/null
+++ b/codec2/video_dec/common/VideoDecoderBase.cpp
@@ -0,0 +1,691 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "VideoDecoderBase"
+
+//#define API_TRACE
+#ifdef API_TRACE
+#define VDB_API_TRACE ALOGV
+#else
+#define VDB_API_TRACE(...)
+#endif
+
+//#define VDB_INFO_TRACE
+#ifdef VDB_INFO_TRACE
+#define VDB_INFO ALOGV
+#else
+#define VDB_INFO(...)
+#endif
+
+#include <utils/Log.h>
+//#include <cutils/properties.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <inttypes.h>
+#include <sys/mman.h>
+
+#include <C2Config.h>
+#include <C2Debug.h>
+#include <C2PlatformSupport.h>
+
+#include "graphics_ext.h"
+#include "Memory.h"
+#include "IonAllocator.h"
+
+#include "VideoDecoderBase.h"
+
+namespace android {
+
+static void Reply(const sp<AMessage> &msg, int32_t *err = nullptr) {
+    sp<AReplyToken> replyId;
+    CHECK(msg->senderAwaitsResponse(&replyId));
+    sp<AMessage> reply = new AMessage;
+    if (err) {
+        reply->setInt32("err", *err);
+    }
+    reply->postReply(replyId);
+}
+
+VideoRect::VideoRect(VideoRect &rect) {
+    left = rect.left;
+    right = rect.right;
+    top = rect.top;
+    bottom = rect.bottom;
+}
+
+VideoRect::VideoRect(uint32_t left, uint32_t right, uint32_t top, uint32_t bottom)
+    : left(left),
+      top(top),
+      right(right),
+      bottom(bottom) {
+}
+
+VideoFormat::VideoFormat(
+                    int format,
+                    uint32_t minNumBuffers,
+                    uint32_t width,
+                    uint32_t height,
+                    VideoRect &rect,
+                    bool interlaced)
+    : pixelFormat(format),
+      minBufferNum(minNumBuffers),
+      width(width),
+      height(height),
+      rect(rect),
+      interlaced(interlaced) {
+}
+
+VideoDecoderBase::IMXInputBuffer::IMXInputBuffer(
+                    void* pBuffer,
+                    int fd,
+                    int id,
+                    uint32_t size,
+                    uint64_t ts,
+                    bool eos,
+                    bool codecdata)
+    : pInBuffer(pBuffer),
+      fd(fd),
+      id(id),
+      size(size),
+      timestamp(ts),
+      eos(eos),
+      csd(codecdata){
+}
+
+VideoDecoderBase::VideoDecoderBase()
+    : bInputEos(false),
+      bOutputEos(false),
+      bAdaptiveMode(false),
+      bSecureMode(false),
+      bReceiveError(false),
+      mLooper(new ALooper) {
+
+    bOutputFmtChangedPending = false;
+    bReleasingDecoder = false;
+
+    nOutBufferUsage = (uint64_t)(GRALLOC_USAGE_PRIVATE_2);
+
+    pCodecDataBuf = nullptr;
+    nCodecDataLen = 0;
+
+    mLooper->setName("VideoDecoderBase");
+    mLooper->start(false, false, ANDROID_PRIORITY_VIDEO);
+}
+
+VideoDecoderBase::~VideoDecoderBase() {
+}
+
+status_t VideoDecoderBase::init(Client* client/*const std::shared_ptr<C2BlockPool> &pool*/) {
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    (void)mLooper->registerHandler(this);
+    mClient = client;
+
+    sp<AMessage> reply;
+    (new AMessage(kWhatInit, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t VideoDecoderBase::start() {
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+    sp<AMessage> reply;
+    (new AMessage(kWhatStart, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t VideoDecoderBase::stop() {
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+    sp<AMessage> reply;
+    (new AMessage(kWhatStop, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t VideoDecoderBase::flush() {
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+    sp<AMessage> reply;
+    (new AMessage(kWhatFlush, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t VideoDecoderBase::destroy() {
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+    sp<AMessage> reply;
+    (new AMessage(kWhatDestroy, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t VideoDecoderBase::queueInput(
+        uint8_t *pInBuf, uint32_t size, uint64_t timestamp, uint32_t flags, int fd, int id) {
+
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    bool codecdata = ((flags & C2FrameData::FLAG_CODEC_CONFIG) != 0);
+
+    if (codecdata) {
+        if (!pCodecDataBuf) {
+            pCodecDataBuf = (uint8_t*)malloc(size);
+        } else {
+            pCodecDataBuf = (uint8_t*)realloc(pCodecDataBuf, nCodecDataLen + size);
+        }
+
+        if (!pCodecDataBuf) {
+            ALOGE("malloc pCodecDataBuf falied, size=%d", size);
+            return BAD_VALUE;
+        }
+
+        memcpy(pCodecDataBuf + nCodecDataLen, pInBuf, size);
+        nCodecDataLen += size;
+        return OK;
+    }
+
+    bInputEos = ((flags & C2FrameData::FLAG_END_OF_STREAM) != 0);
+
+    {
+        Mutexed<InputBufferQueue>::Locked queue(mInputQueue);
+        queue->push_back(std::make_unique<IMXInputBuffer>(pInBuf, fd, id, size, timestamp, bInputEos, codecdata));
+    }
+
+    sp<AMessage> reply;
+    (new AMessage(kWhatDecode, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+status_t VideoDecoderBase::queueOutput(int32_t blockId){
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    sp<AMessage> msg = new AMessage(kWhatQueueOutput, this);
+    msg->setInt32("blockId", blockId);
+    msg->post();
+
+    return OK;
+}
+
+status_t VideoDecoderBase::setConfig(DecConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    switch (index) {
+        case DEC_CONFIG_OUTPUT_FORMAT:
+            memcpy(&mOutputFormat, pConfig, sizeof(VideoFormat));
+            break;
+        case DEC_CONFIG_INPUT_FORMAT:
+            memcpy(&mInputFormat, pConfig, sizeof(VideoFormat));
+            break;
+        default:
+            return DoSetConfig(index, pConfig);
+    }
+    return OK;
+}
+
+status_t VideoDecoderBase::getConfig(DecConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    switch (index) {
+        case DEC_CONFIG_OUTPUT_FORMAT:
+            memcpy(pConfig, &mOutputFormat, sizeof(VideoFormat));
+            break;
+        case DEC_CONFIG_INPUT_FORMAT:
+            memcpy(pConfig, &mInputFormat, sizeof(VideoFormat));
+            break;
+        default:
+            return DoGetConfig(index, pConfig);
+    }
+    return OK;
+}
+
+status_t VideoDecoderBase::setGraphicBlockPool(const std::shared_ptr<C2BlockPool> &pool) {
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    if (pool.get() == nullptr) {
+        ALOGE("setGraphicBlockPool get nullptr ! 
");
+        return BAD_VALUE;
+    }
+
+    mBlockPool = pool;
+    return OK;
+}
+
+status_t VideoDecoderBase::onInit() {
+    /* implement by sub class */
+    return OK;
+}
+
+status_t VideoDecoderBase::onStart() {
+    /* implement by sub class */
+    return OK;
+}
+
+status_t VideoDecoderBase::onStop() {
+    /* implement by sub class */
+    return OK;
+}
+
+status_t VideoDecoderBase::onFlush() {
+    /* implement by sub class */
+    return OK;
+}
+
+status_t VideoDecoderBase::onDestroy() {
+    /* implement by sub class */
+    return OK;
+}
+
+// input == nullptr, drain output
+status_t VideoDecoderBase::decodeInternal(std::unique_ptr<IMXInputBuffer> input) {
+    /* implement by sub class */
+    (void)input;
+    return OK;
+}
+
+GraphicBlockInfo* VideoDecoderBase::getGraphicBlockById(int32_t blockId) {
+    if (blockId < 0 || blockId >= static_cast<int32_t>(mGraphicBlocks.size())) {
+        ALOGE("getGraphicBlockById failed: id=%d", blockId);
+        return nullptr;
+    }
+    auto blockIter = std::find_if(mGraphicBlocks.begin(), mGraphicBlocks.end(),
+                                  [blockId](const GraphicBlockInfo& gb) {
+                                      return gb.mBlockId == blockId;
+                                  });
+
+    if (blockIter == mGraphicBlocks.end()) {
+        ALOGV("%s line %d: failed: blockId=%d", __FUNCTION__, __LINE__, blockId);
+        return nullptr;
+    }
+    return &(*blockIter);
+}
+
+GraphicBlockInfo* VideoDecoderBase::getGraphicBlockByPhysAddr(unsigned long physAddr) {
+    if (physAddr == 0) {
+        ALOGE("%s line %d: invalid physical address=%p", __FUNCTION__, __LINE__, (void*)physAddr);
+        return nullptr;
+    }
+    auto blockIter = std::find_if(mGraphicBlocks.begin(), mGraphicBlocks.end(),
+                                  [physAddr](const GraphicBlockInfo& gb) {
+                                      return gb.mPhysAddr == physAddr;
+                                  });
+
+    if (blockIter == mGraphicBlocks.end()) {
+        ALOGV("%s line %d: failed: physical address=%p", __FUNCTION__, __LINE__, (void*)physAddr);
+        return nullptr;
+    }
+    return &(*blockIter);
+}
+
+GraphicBlockInfo* VideoDecoderBase::getFreeGraphicBlock() {
+    auto blockIter = std::find_if(mGraphicBlocks.begin(), mGraphicBlocks.end(),
+                                  [](const GraphicBlockInfo& gb) {
+                                      return gb.mState == GraphicBlockInfo::State::OWNED_BY_COMPONENT;;
+                                  });
+
+    if (blockIter == mGraphicBlocks.end()) {
+        ALOGV("%s line %d: failed: no free Graphic Block",  __FUNCTION__, __LINE__);
+        return nullptr;
+    }
+
+    ALOGV("getFreeGraphicBlock blockId %d", blockIter->mBlockId);
+    return &(*blockIter);
+}
+
+status_t VideoDecoderBase::removeGraphicBlockById(int32_t blockId) {
+    if (blockId < 0 || blockId >= static_cast<int32_t>(mGraphicBlocks.size())) {
+        ALOGE("getGraphicBlockById failed: id=%d", blockId);
+        return BAD_INDEX;
+    }
+    auto blockIter = std::find_if(mGraphicBlocks.begin(), mGraphicBlocks.end(),
+                                  [blockId](const GraphicBlockInfo& gb) {
+                                      return gb.mBlockId == blockId;
+                                  });
+
+    if (blockIter == mGraphicBlocks.end()) {
+        ALOGV("%s line %d: failed: blockId=%d", __FUNCTION__, __LINE__, blockId);
+        return BAD_INDEX;
+    }
+
+    if ((*blockIter).mVirtAddr > 0 && (*blockIter).mCapacity > 0)
+        munmap((void*)(*blockIter).mVirtAddr, (*blockIter).mCapacity);
+
+    (*blockIter).mGraphicBlock.reset();
+    mGraphicBlocks.erase(blockIter);
+    return OK;
+}
+
+status_t VideoDecoderBase::outputFormatChanged() {
+
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    bOutputFmtChangedPending = true;
+    status_t err = onOutputFormatChanged();
+    if (err == OK)
+        bOutputFmtChangedPending = false;
+
+    return err;
+}
+
+status_t VideoDecoderBase::fetchOutputBuffer() {
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    C2MemoryUsage usage(nOutBufferUsage);
+
+    std::shared_ptr<C2GraphicBlock> outBlock;
+    c2_status_t c2_err = mBlockPool->fetchGraphicBlock(mOutputFormat.width, mOutputFormat.height,
+                                                    mOutputFormat.pixelFormat, usage, &outBlock);
+
+    if (c2_err == C2_BLOCKING)
+        return WOULD_BLOCK;
+    else if (c2_err != C2_OK) {
+        ALOGE("fetchGraphicBlock for Output failed with status %d", c2_err);
+        return UNKNOWN_ERROR;
+    }
+
+    int32_t blockId;
+    status_t err = appendOutputBuffer(outBlock, &blockId);
+    if (err == NO_MEMORY) {
+        // sleep 5ms to wait graphic buffer return from display
+        usleep(5000);
+        err = WOULD_BLOCK;
+    }
+
+    return err;
+}
+
+void VideoDecoderBase::returnOutputBufferToDecoder(int32_t blockId) {
+    GraphicBlockInfo *gbInfo = getGraphicBlockById(blockId);
+    if (gbInfo) {
+        ALOGV("%s: blockId %d", __FUNCTION__, blockId);
+        gbInfo->mState = GraphicBlockInfo::State::OWNED_BY_COMPONENT;
+    } else {
+        ALOGE("%s: invalid blockId %d", __FUNCTION__, blockId);
+    }
+}
+
+void VideoDecoderBase::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatDecode: {
+            std::unique_ptr<IMXInputBuffer> input;
+            {
+                Mutexed<InputBufferQueue>::Locked queue(mInputQueue);
+                // there is always have at least one input
+                input = std::move(queue->front());
+                queue->pop_front(); // pop in NotifyInputBufferUsed ?
+            }
+            status_t err = decodeInternal(std::move(input));
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatInit: {
+            int32_t err = onInit();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatStart: {
+            int32_t err = onStart();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatStop: {
+            int32_t err = onStop();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatFlush: {
+            Mutexed<InputBufferQueue>::Locked queue(mInputQueue);
+            while (!queue->empty()) {
+                queue->pop_front();
+            }
+
+            // flush codec data
+            //memset(pCodecDataBuf, 0, sizeof(nCodecDataLen));
+            nCodecDataLen = 0;
+            bReleasingDecoder = false;
+
+            int32_t err = onFlush();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatDestroy: {
+            // release resources
+            Mutexed<InputBufferQueue>::Locked queue(mInputQueue);
+            while (!queue->empty()) {
+                queue->pop_front();
+            }
+
+            if (pCodecDataBuf) {
+                free(pCodecDataBuf);
+                pCodecDataBuf = nullptr;
+                nCodecDataLen = 0;
+            }
+
+            bReleasingDecoder = true;
+
+            int32_t err = onDestroy();
+            freeOutputBuffers();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatQueueOutput:
+            int32_t blockId;
+            CHECK(msg->findInt32("blockId", &blockId));
+            returnOutputBufferToDecoder(blockId);
+            break;
+
+        default: {
+            ALOGW("Unrecognized msg: %d", msg->what());
+            break;
+        }
+    }
+}
+
+status_t VideoDecoderBase::appendOutputBuffer(std::shared_ptr<C2GraphicBlock> block, int32_t* blockId) {
+    fsl::Memory *prvHandle = (fsl::Memory*)block->handle();
+
+    ALOGV("appendOutputBuffer handle %p, fd %d virt %p, phys %p, format 0x%x, size %d",
+        prvHandle, prvHandle->fd, (void*)prvHandle->base, (void*)prvHandle->phys, prvHandle->format, prvHandle->size);
+
+    GraphicBlockInfo* pInfo = getGraphicBlockByPhysAddr(prvHandle->phys);
+    if (pInfo) {
+        // previous output buffer returned to decoder
+        ALOGV("previous output buffer returned to decoder, blockId %d", pInfo->mBlockId);
+        pInfo->mDMABufFd = prvHandle->fd;
+        pInfo->mGraphicBlock = std::move(block);
+        pInfo->mState = GraphicBlockInfo::State::OWNED_BY_COMPONENT;
+        *blockId = pInfo->mBlockId;
+    } else {
+        if (true == OutputBufferFull()) {
+            return NO_MEMORY;
+        }
+        GraphicBlockInfo info;
+
+        fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
+        int ret = pIonAllocator->getVaddrs(prvHandle->fd, prvHandle->size, (uint64_t&)info.mVirtAddr);
+        if (ret != 0) {
+            ALOGE("Ion get virtual address failed, fd %d", info.mDMABufFd);
+            return BAD_VALUE;
+        }
+
+        info.mDMABufFd = prvHandle->fd;
+        info.mCapacity = prvHandle->size;
+        info.mPhysAddr = prvHandle->phys;
+        info.mPixelFormat = prvHandle->format;
+        info.mState = GraphicBlockInfo::State::OWNED_BY_COMPONENT;
+        info.mBlockId = static_cast<int32_t>(mGraphicBlocks.size());
+        info.mGraphicBlock = std::move(block);
+        *blockId = info.mBlockId;
+        ALOGI("fetch a new buffer, blockId %d phys %p virt %p", info.mBlockId, (void*)info.mPhysAddr, (void*)info.mVirtAddr);
+
+        Mutex::Autolock autoLock(mGBLock);
+        mGraphicBlocks.push_back(std::move(info));
+    }
+
+    return OK;
+}
+
+status_t VideoDecoderBase::importOutputBuffers(std::vector<GraphicBlockInfo> buffers)
+{
+    return OK;
+}
+
+status_t VideoDecoderBase::onOutputFormatChanged() {
+    VDB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    ALOGI("New format(pixelfmt=0x%x, min buffers=%u, request buffers %d, w*h=%d x %d, crop=(%d %d %d %d), interlaced %d)",
+          static_cast<uint32_t>(mOutputFormat.pixelFormat), mOutputFormat.minBufferNum, mOutputFormat.bufferNum,
+          mOutputFormat.width, mOutputFormat.height,
+          mOutputFormat.rect.left, mOutputFormat.rect.top,
+          mOutputFormat.rect.right, mOutputFormat.rect.bottom, mOutputFormat.interlaced);
+
+    status_t err;
+
+    mClient->notifyVideoInfo(&mOutputFormat);
+
+    for (auto& info : mGraphicBlocks) {
+        if (info.mState == GraphicBlockInfo::State::OWNED_BY_VPU)
+            info.mState = GraphicBlockInfo::State::OWNED_BY_COMPONENT;
+    }
+
+    for (const auto& info : mGraphicBlocks) {
+        CHECK(info.mState != GraphicBlockInfo::State::OWNED_BY_VPU);
+    }
+
+    err = freeOutputBuffers();
+    if (err) {
+        NotifyError(err);
+        return err;
+    }
+
+    err = allocateOutputBuffers();
+    if (err) {
+        NotifyError(err);
+        return err;
+    }
+
+    importOutputBuffers(mGraphicBlocks);
+
+    return OK;
+}
+
+void VideoDecoderBase::ClearPictureBuffer() {
+    mClient->clearPictureBuffer();
+}
+
+void VideoDecoderBase::NotifyFlushDone () {
+    mClient->notifyFlushDone();
+}
+
+void VideoDecoderBase::NotifyInputBufferUsed(int32_t input_id) {
+    mClient->notifyInputBufferUsed(input_id);
+}
+
+void VideoDecoderBase::NotifySkipInputBuffer(int32_t input_id) {
+    mClient->notifySkipInputBuffer(input_id);
+}
+
+void VideoDecoderBase::NotifyPictureReady(int32_t pictureId, uint64_t timestamp) {
+    if (bReleasingDecoder)
+        returnOutputBufferToDecoder(pictureId);
+    else {
+        Mutex::Autolock autoLock(mGBLock);
+        mClient->notifyPictureReady(pictureId, timestamp);
+    }
+}
+
+void VideoDecoderBase::NotifyEOS() {
+    mClient->notifyEos();
+}
+
+void VideoDecoderBase::NotifyError(status_t err) {
+    mClient->notifyError(err);
+}
+status_t VideoDecoderBase::convertIsoColorAspectsToCodecAspects(DecColorAspects * pIsoColorAspects, DecColorAspects * pCodecAspects)
+{
+
+    static const int sPrimariesMap[] = {
+        0/* ColorAspects::PrimariesUnspecified */,
+        1/* ColorAspects::PrimariesBT709_5 */,
+        0/* ColorAspects::PrimariesUnspecified */,
+        0/* ColorAspects::PrimariesUnspecified */,
+        2/* ColorAspects::PrimariesBT470_6M */,
+        3/* ColorAspects::PrimariesBT601_6_625 */,
+        4/* ColorAspects::PrimariesBT601_6_525 main */,
+        4/* ColorAspects::PrimariesBT601_6_525 */,
+        // ITU T.832 201201 ends here
+        5/* ColorAspects::PrimariesGenericFilm */,
+        6/* ColorAspects::PrimariesBT2020 */,
+        0xff/* ColorAspects::PrimariesOther XYZ */,
+    };
+
+    static const int sTransfersMap[] = {
+        0/* ColorAspects::TransferUnspecified */,
+        3/* ColorAspects::TransferSMPTE170M main */,
+        0/* ColorAspects::TransferUnspecified */,
+        0/* ColorAspects::TransferUnspecified */,
+        4/* ColorAspects::TransferGamma22 */,
+        5/* ColorAspects::TransferGamma28 */,
+        3/* ColorAspects::TransferSMPTE170M */,
+        0x40/* ColorAspects::TransferSMPTE240M */,
+        1/* ColorAspects::TransferLinear */,
+        0xff/* ColorAspects::TransferOther log 100:1 */,
+        0xff/* ColorAspects::TransferOther log 316:1 */,
+        0x41/* ColorAspects::TransferXvYCC */,
+        0x42/* ColorAspects::TransferBT1361 */,
+        2/* ColorAspects::TransferSRGB */,
+        // ITU T.832 201201 ends here
+        3/* ColorAspects::TransferSMPTE170M */,
+        3/* ColorAspects::TransferSMPTE170M */,
+        6/* ColorAspects::TransferST2084 */,
+        0x43/* ColorAspects::TransferST428 */,
+        7/* ColorAspects::TransferHLG */,
+    };
+
+    static const int sMatrixCoeffsMap[] = {
+        //change the first value from 0xff to 0
+        0/* ColorAspects::MatrixOther */,
+        1/* ColorAspects::MatrixBT709_5 */,
+        0/* ColorAspects::MatrixUnspecified */,
+        0/* ColorAspects::MatrixUnspecified */,
+        2/* ColorAspects::MatrixBT470_6M */,
+        3/* ColorAspects::MatrixBT601_6 */,
+        3/* ColorAspects::MatrixBT601_6 main */,
+        4/* ColorAspects::MatrixSMPTE240M */,
+        0xff/* ColorAspects::MatrixOther YCgCo */,
+        // -- ITU T.832 201201 ends here
+        5/* ColorAspects::MatrixBT2020 */,
+        6/* ColorAspects::MatrixBT2020Constant */,
+    };
+
+    if(pIsoColorAspects->colourPrimaries < sizeof(sPrimariesMap))
+        pCodecAspects->colourPrimaries = sPrimariesMap[pIsoColorAspects->colourPrimaries];
+    if(pIsoColorAspects->transferCharacteristics < sizeof(sTransfersMap))
+        pCodecAspects->transferCharacteristics = sTransfersMap[pIsoColorAspects->transferCharacteristics];
+    if(pIsoColorAspects->matrixCoeffs < sizeof(sMatrixCoeffsMap))
+        pCodecAspects->matrixCoeffs = sMatrixCoeffsMap[pIsoColorAspects->matrixCoeffs];
+    pCodecAspects->fullRange = (pIsoColorAspects->fullRange ? 1 /* RangeFull */: 2 /* RangeLimited */);
+
+    return OK;
+}
+int VideoDecoderBase::getBlockPoolAllocatorId()
+{
+    if(mBlockPool != nullptr)
+        return mBlockPool->getAllocatorId();
+
+    return -1;
+}
+} // namespace android
+
+/* end of file */
diff --git a/codec2/video_dec/common/VideoDecoderBase.h b/codec2/video_dec/common/VideoDecoderBase.h
new file mode 100755
index 0000000..9c525b2
--- /dev/null
+++ b/codec2/video_dec/common/VideoDecoderBase.h
@@ -0,0 +1,261 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef VIDEO_DECODER_BASE_H
+#define VIDEO_DECODER_BASE_H
+
+#include <C2Buffer.h>
+#include <C2Work.h>
+
+#include <media/stagefright/foundation/AHandler.h>
+#include <media/stagefright/foundation/ALooper.h>
+#include <media/stagefright/foundation/Mutexed.h>
+
+namespace android {
+
+#define DEFAULT_FRM_WIDTH   176
+#define DEFAULT_FRM_HEIGHT  144
+
+typedef enum {
+    DEC_CONFIG_INPUT_FORMAT = 0,
+    DEC_CONFIG_OUTPUT_FORMAT,
+    DEC_CONFIG_OUTPUT_DELAY,
+    DEC_CONFIG_VC1_SUB_FORMAT,
+    DEC_CONFIG_HAL_PIXEL_FORMAT,
+    DEC_CONFIG_HDR10_STATIC_INFO,
+    DEC_CONFIG_COLOR_ASPECTS,
+} DecConfig;
+
+typedef struct {
+    uint32_t nSize;
+    uint16_t mR[2]; // display primary 0
+    uint16_t mG[2]; // display primary 1
+    uint16_t mB[2]; // display primary 2
+    uint16_t mW[2]; // white point
+    uint16_t mMaxDisplayLuminance; // in cd/m^2
+    uint16_t mMinDisplayLuminance; // in 0.0001 cd/m^2
+    uint16_t mMaxContentLightLevel; // in cd/m^2
+    uint16_t mMaxFrameAverageLightLevel; // in cd/m^2
+} DecStaticHDRInfo;
+
+typedef struct {
+    unsigned int colourPrimaries;
+    unsigned int transferCharacteristics;
+    unsigned int matrixCoeffs;
+    unsigned int fullRange;
+} DecColorAspects;
+
+struct GraphicBlockInfo {
+    enum class State {
+        OWNED_BY_COMPONENT = 0,    // Owned by this component.
+        OWNED_BY_CLIENT,       // Owned by client.
+        OWNED_BY_VPU,          // Owned by vpu
+    };
+
+    // The ID of this block used for VPU.
+    int32_t mBlockId = -1;
+    // The ID of this block used in block pool. It indicates slot index for bufferqueue-backed
+    // block pool, and buffer ID of BufferPoolData for bufferpool block pool.
+    uint32_t mPoolId = 0;
+    State mState = State::OWNED_BY_COMPONENT;
+    // Graphic block buffer allocated from allocator. The graphic block should be owned until
+    // it is passed to client.
+    std::shared_ptr<C2GraphicBlock> mGraphicBlock;
+    // HAL pixel format used while importing to VPU.
+    int mPixelFormat; //HalPixelFormat mPixelFormat;
+    uint64_t mTimestamp;
+    int mDMABufFd;
+    unsigned long mPhysAddr;
+    unsigned long mVirtAddr;
+    uint32_t mCapacity;
+};
+
+struct VideoRect {
+	uint32_t left;
+	uint32_t top;
+	uint32_t right;
+	uint32_t bottom;
+    VideoRect() {}
+    VideoRect(VideoRect &rect);
+    VideoRect(uint32_t left, uint32_t right, uint32_t top, uint32_t bottom);
+};
+
+struct VideoFormat {
+    int pixelFormat = 0;//HalPixelFormat::UNKNOWN;
+    uint32_t minBufferNum = 0;
+    uint32_t width;
+    uint32_t height;
+    uint32_t bufferNum;
+    uint32_t bufferSize;
+    VideoRect rect;
+    bool interlaced;
+
+    VideoFormat() {}
+    VideoFormat(int format, uint32_t minNumBuffers, uint32_t width, uint32_t height,
+                VideoRect &rect, bool interlaced);
+};
+
+
+class VideoDecoderBase
+    : public AHandler, public std::enable_shared_from_this<VideoDecoderBase> {
+public:
+    // The adaptor client interface. This interface should be implemented in the component side.
+    class Client {
+    public:
+        // Callback to tell client how many and what size of buffers to provide.
+        virtual void notifyVideoInfo(VideoFormat *pFormat) {(void)pFormat;}
+
+        // CallBack to tell client to free picture buffers.
+        virtual void clearPictureBuffer() {}
+
+        // Callback to deliver decoded pictures ready to be displayed.
+        virtual void notifyPictureReady(int32_t pictureId, uint64_t timestamp) {(void)pictureId; (void)timestamp;}
+
+        // Callback to notify that decoder has decoded the end of the bitstream buffer with specified ID.
+        virtual void notifyInputBufferUsed(int32_t input_id) {(void)input_id;}
+
+        // Callback to notify that decode skip this buffer
+        virtual void notifySkipInputBuffer(int32_t input_id) {(void)input_id;}
+
+        // Flush completion callback.
+        virtual void notifyFlushDone() {}
+
+        // Reset completion callback.
+        virtual void notifyResetDone() {}
+
+        // Callback to notify about errors. Note that errors in initialize() will not be reported
+        // here, instead of by its returned value.
+        virtual void notifyError(status_t err) {(void)err;}
+
+        virtual void notifyEos() {}
+    protected:
+        virtual ~Client() = default;
+    };
+
+    VideoDecoderBase();
+    virtual ~VideoDecoderBase();
+
+    status_t init(Client* client/*const std::shared_ptr<C2BlockPool> &pool*/);//load componnent and init parameters
+    status_t start();//loaded to idle
+    status_t stop();//idle to loaded
+    status_t flush();//flush
+    status_t destroy();//free Buffers
+    status_t setConfig(DecConfig index, void* pConfig);
+    status_t getConfig(DecConfig index, void* pConfig);
+    virtual bool checkIfPostProcessNeeded() {return false;}
+
+    status_t setGraphicBlockPool(const std::shared_ptr<C2BlockPool> &pool);
+    status_t queueInput(uint8_t *pInBuf, uint32_t size, uint64_t timestamp, uint32_t flags, int fd, int id);
+    status_t fetchOutputBuffer();
+    virtual status_t importOutputBuffers(std::vector<GraphicBlockInfo> buffers);
+    GraphicBlockInfo* getGraphicBlockById(int32_t blockId);
+    GraphicBlockInfo* getGraphicBlockByPhysAddr(unsigned long physAddr);
+    GraphicBlockInfo* getFreeGraphicBlock();
+    status_t removeGraphicBlockById(int32_t blockId);
+    void returnOutputBufferToDecoder(int32_t blockId);
+    status_t queueOutput(int32_t blockId);
+protected:
+
+    enum {
+        kInputBufferCount = 8,
+        kInputBufferSizeFor1080p = 1024 * 1024,
+        // Input bitstream buffer size for up to 4k streams.
+        kInputBufferSizeFor4k = 4 * kInputBufferSizeFor1080p,
+        kDefaultOutputBufferCount = 8,
+    };
+
+    struct IMXInputBuffer{
+        void* pInBuffer;
+        int fd;
+        int id;
+        uint32_t size;
+        uint64_t timestamp;
+        bool eos;
+        bool csd;
+
+        IMXInputBuffer() {}
+        IMXInputBuffer(void* pBuffer, int fd, int id, uint32_t size, uint64_t ts, bool eos, bool codecdata);
+    };
+
+    bool bInputEos;
+    bool bOutputEos;
+    bool bAdaptiveMode;
+    bool bSecureMode;
+    bool bReceiveError;
+
+    VideoFormat mInputFormat;
+    VideoFormat mOutputFormat;
+
+    uint64_t nOutBufferUsage;
+
+    uint8_t* pCodecDataBuf;
+    uint32_t nCodecDataLen;
+
+    std::vector<GraphicBlockInfo> mGraphicBlocks;
+
+    void onMessageReceived(const sp<AMessage> &msg) override;
+    virtual status_t onInit();
+    virtual status_t onStart();//loaded to idle
+    virtual status_t onStop();//idle to loaded
+    virtual status_t onFlush();//flush
+    virtual status_t onDestroy();//free Buffers
+    virtual status_t decodeInternal(std::unique_ptr<IMXInputBuffer> input);
+
+    virtual status_t DoSetConfig(DecConfig index, void* pConfig) {return OK;}
+    virtual status_t DoGetConfig(DecConfig index, void* pConfig) {return OK;}
+
+    virtual status_t allocateOutputBuffers() {return OK;}
+    virtual status_t freeOutputBuffers() {return OK;}
+
+    virtual bool OutputBufferFull() {return false;}
+
+    status_t outputFormatChanged();
+    int getBlockPoolAllocatorId();
+
+    void ClearPictureBuffer();
+    void NotifyPictureReady(int32_t pictureId, uint64_t timestamp);
+    void NotifyInputBufferUsed(int32_t input_id);
+    void NotifySkipInputBuffer(int32_t input_id);
+    void NotifyFlushDone();
+    void NotifyResetDone();
+    void NotifyEOS();
+    void NotifyError(status_t err);
+    status_t convertIsoColorAspectsToCodecAspects(DecColorAspects * pIsoColorAspects, DecColorAspects * pCodecAspects);
+
+private:
+    enum {
+        kWhatDecode,
+        kWhatInit,
+        kWhatStart,
+        kWhatFlush,
+        kWhatStop,
+        kWhatReset,
+        kWhatDestroy,
+        kWhatQueueOutput,
+    };
+
+    sp<ALooper> mLooper;
+
+    Client* mClient;
+
+    Mutex mGBLock; // graphic buffer lock
+
+    typedef std::list<std::unique_ptr<IMXInputBuffer>> InputBufferQueue;
+    Mutexed<InputBufferQueue> mInputQueue;
+    std::shared_ptr<C2BlockPool> mBlockPool;
+
+    bool bOutputFmtChangedPending;
+    bool bReleasingDecoder;
+
+    status_t onOutputFormatChanged();
+    status_t appendOutputBuffer(std::shared_ptr<C2GraphicBlock> block, int32_t* blockId);
+};
+
+VideoDecoderBase * CreateVideoDecoderInstance(const char* mime);
+}
+#endif // VIDEO_DECODER_BASE_H
diff --git a/codec2/video_dec/v4l2_dec/Android.bp b/codec2/video_dec/v4l2_dec/Android.bp
new file mode 100644
index 0000000..f10f27b
--- /dev/null
+++ b/codec2/video_dec/v4l2_dec/Android.bp
@@ -0,0 +1,76 @@
+imx_c2_v4l2_dec_defaults {
+    name: "imx_c2_v4l2_dec_default",
+}
+
+bootstrap_go_package {
+    name: "soong-v4l2_dec",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/video_dec/v4l2_dec",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "v4l2_dec.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+cc_library_shared {
+    name: "lib_imx_c2_v4l2_dec",
+
+    defaults: ["imx_c2_v4l2_dec_default"],
+
+    soc_specific: true,
+    srcs: [
+        "V4l2Dec.cpp",
+    ],
+
+    header_libs: [
+        "libcodec2_headers",
+        "media_plugin_headers",
+    ],
+
+    include_dirs: [
+	"hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",    
+        "vendor/nxp/imx_android_mm/codec2/video_dec/common",
+        "vendor/nxp/imx_android_mm/codec2/v4l2_dev",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+        "vendor/nxp/imx_android_mm/extractor",
+	],
+    shared_libs: [
+        "liblog",
+		"libstagefright_bufferqueue_helper",
+		"libstagefright_foundation",
+        "libcodec2_vndk",
+		"libutils",
+        "libcutils",
+        "libion",
+        "lib_imx_c2_v4l2_dev",
+        "lib_imx_c2_videodec_common",
+    ],
+
+    whole_static_libs: ["libionallocator"],
+
+    sanitize: {
+        cfi: true,
+        misc_undefined: [
+            "unsigned-integer-overflow",
+            "signed-integer-overflow",
+        ],
+        diag: {
+            cfi: true,
+        },
+    },
+
+//    compile_multilib: "32",
+}
+
diff --git a/codec2/video_dec/v4l2_dec/V4l2Dec.cpp b/codec2/video_dec/v4l2_dec/V4l2Dec.cpp
new file mode 100755
index 0000000..a54c44e
--- /dev/null
+++ b/codec2/video_dec/v4l2_dec/V4l2Dec.cpp
@@ -0,0 +1,1591 @@
+/**
+ *  Copyright 2018-2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4l2Dec"
+
+#include "V4l2Dec.h"
+#include <media/stagefright/MediaErrors.h>
+#include <C2PlatformSupport.h>
+#include "graphics_ext.h"
+#include "Imx_ext.h"
+#include "Memory.h"
+#include "IonAllocator.h"
+#include <sys/mman.h>
+
+namespace android {
+
+#define IMX_V4L2_BUF_FLAG_CODECCONFIG      0x00200000
+#define IMX_V4L2_BUF_FLAG_TIMESTAMP_INVALID    0x00400000
+
+#define Align(ptr,align)    (((uint32_t)(ptr)+(align)-1)/(align)*(align))
+#define FRAME_ALIGN     (512)
+#define DEFAULT_OUTPUT_BUFFER_COUNT 6
+
+V4l2Dec::V4l2Dec(const char* mime):
+    mMime(mime),
+    mPollThread(0),
+    mFetchThread(0),
+    pDev(NULL),
+    mFd(-1){
+
+    bPollStarted = false;
+    bPollStopped = false;
+    bFetchStarted = false;
+    bFetchStopped = false;
+
+    bInputStreamOn = false;
+    bOutputStreamOn = false;
+
+    bCodecDataQueued = false;
+
+    bNeedPostProcess = true;
+
+    mState = UNINITIALIZED;
+
+    mVpuOwnedOutputBufferNum = 0;
+
+    mInputFormat.bufferNum = kInputBufferCount;
+    mInputFormat.bufferSize = kInputBufferSizeFor4k;
+    mInputFormat.width = DEFAULT_FRM_WIDTH;
+    mInputFormat.height = DEFAULT_FRM_HEIGHT;
+    mInputFormat.interlaced = false;
+
+    mOutputFormat.width = DEFAULT_FRM_WIDTH;
+    mOutputFormat.height = DEFAULT_FRM_HEIGHT;
+    mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_NV12_TILED;
+    //use bufferNum to check if need fetch buffer, so default is 0
+    mOutputFormat.minBufferNum = 0;
+    mOutputFormat.bufferNum = 0;
+    mOutputFormat.rect.left = 0;
+    mOutputFormat.rect.top = 0;
+    mOutputFormat.rect.right = mOutputFormat.width;
+    mOutputFormat.rect.bottom = mOutputFormat.height;
+    mOutputFormat.interlaced = false;
+
+    mVc1Format = V4L2_PIX_FMT_VC1_ANNEX_G;
+
+}
+V4l2Dec::~V4l2Dec()
+{
+}
+status_t V4l2Dec::onInit(){
+    status_t ret = UNKNOWN_ERROR;
+
+    if(pDev == NULL){
+        pDev = new V4l2Dev();
+    }
+    if(pDev == NULL)
+        return ret;
+
+    mFd = pDev->Open(V4L2_DEV_DECODER);
+    ALOGV("pV4l2Dev->Open fd=%d",mFd);
+
+    if(mFd < 0)
+        return ret;
+
+    mInMemType = V4L2_MEMORY_MMAP;
+    mOutMemType = V4L2_MEMORY_DMABUF;//V4L2_MEMORY_USERPTR
+    mState = UNINITIALIZED;
+    mInCnt = 0;
+    mOutCnt = 0;
+    return OK;
+}
+status_t V4l2Dec::onStart()
+{
+    status_t ret = UNKNOWN_ERROR;
+    ALOGV("onStart BEGIN");
+
+    ret = prepareInputParams();
+    if(ret != OK){
+        ALOGE("prepareInputParams failed");
+        return ret;
+    }
+
+    ret = SetInputFormats();
+    if(ret != OK){
+        ALOGE("SetInputFormats failed");
+        return ret;
+    }
+
+    if(mInputBufferMap.empty() || (mInputFormat.bufferSize != mInputBufferMap[0].plane.size)){
+
+        ret = prepareInputBuffers();
+        if(ret != OK)
+            return ret;
+
+        if(mInMemType == V4L2_MEMORY_MMAP)
+            ret = createInputBuffers();
+
+        if(ret != OK){
+            ALOGE("onStart createInputBuffers failed");
+            return ret;
+        }
+    }
+
+    ret = prepareOutputParams();
+    if(ret != OK){
+        ALOGD("prepareOutputParams not ok");
+        mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_NV12_TILED;
+        ret = prepareOutputParams();
+        if(ret != OK){
+            ALOGE("prepareOutputParams failed");
+            return ret;
+        }
+    }
+
+    ret = SetOutputFormats();
+    if(ret != OK){
+        ALOGE("SetOutputFormats failed");
+        return ret;
+    }
+
+    ret = createPollThread();
+    if(ret != OK)
+        return ret;
+
+    mState = RUNNING;
+
+    if(mOutputFormat.bufferNum > 0)
+        ret = createFetchThread();
+
+    mInCnt = 0;
+    mOutCnt = 0;
+    ALOGV("onStart ret=%d",ret);
+    return ret;
+}
+status_t V4l2Dec::prepareInputParams()
+{
+    status_t ret = UNKNOWN_ERROR;
+    Mutex::Autolock autoLock(mLock);
+
+    //TODO: get mime from base class
+    ret = pDev->GetStreamTypeByMime(mMime, &mInFormat);
+    if(ret != OK){
+        return ret;
+    }
+
+    // special for vc1 because vc1 has subtype
+    if (strcmp(mMime, MEDIA_MIMETYPE_VIDEO_VC1) == 0) {
+        mInFormat = mVc1Format;
+    }
+
+    if(!pDev->IsOutputFormatSupported(mInFormat)){
+        ALOGE("input format not suppoted");
+        return ret;
+    }
+
+    if(mInputFormat.bufferNum == 0){
+        mInputFormat.bufferNum = 3;
+    }
+
+    #if 0
+    struct v4l2_frmsizeenum info;
+    memset(&info, 0, sizeof(v4l2_frmsizeenum));
+    if(OK != pDev->GetFormatFrameInfo(mInFormat, &info)){
+        ALOGE("GetFormatFrameInfo failed");
+        return ret;
+    }
+
+    if(mInputFormat.width > info->max_width || mInputFormat.height > info->max_height)
+        return UNKNOWN_ERROR;
+    #endif
+    return OK;
+}
+status_t V4l2Dec::SetInputFormats()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_format format;
+    memset(&format, 0, sizeof(format));
+    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    format.fmt.pix_mp.num_planes = 1;
+    format.fmt.pix_mp.pixelformat = mInFormat;
+    format.fmt.pix_mp.plane_fmt[0].sizeimage = mInputFormat.bufferSize;
+    format.fmt.pix_mp.plane_fmt[0].bytesperline = Align(mInputFormat.width, FRAME_ALIGN);
+    format.fmt.pix_mp.width = mInputFormat.width;
+    format.fmt.pix_mp.height = mInputFormat.height;
+    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+
+    result = ioctl (mFd, VIDIOC_S_FMT, &format);
+    if(result != 0)
+        return UNKNOWN_ERROR;
+
+    memset(&format, 0, sizeof(format));
+    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+
+    result = ioctl (mFd, VIDIOC_G_FMT, &format);
+    if(result != 0)
+        return UNKNOWN_ERROR;
+
+    if(format.fmt.pix_mp.pixelformat != mInFormat){
+        ALOGE("SetInputFormats mInFormat mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if( format.fmt.pix_mp.width != mInputFormat.width ||
+        format.fmt.pix_mp.height != mInputFormat.height){
+        ALOGE("SetInputFormats resolution mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].bytesperline != Align(mInputFormat.width, FRAME_ALIGN)){
+        ALOGE("SetInputFormats stride mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].sizeimage != mInputFormat.bufferSize){
+        ALOGE("SetInputFormats bufferSize mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    return OK;
+}
+status_t V4l2Dec::prepareOutputParams()
+{
+    status_t ret = UNKNOWN_ERROR;
+    Mutex::Autolock autoLock(mLock);
+
+    ret = pDev->GetV4l2FormatByColor(mOutputFormat.pixelFormat, &mOutFormat);
+    if(ret != OK)
+        return ret;
+
+    if(!pDev->IsCaptureFormatSupported(mOutFormat)){
+        ALOGE("output format not suppoted");
+        return ret;
+    }
+
+    if(mOutFormat == V4L2_PIX_FMT_NV12 || mOutFormat == HAL_PIXEL_FORMAT_NV12_TILED){
+        //update output frame width & height
+        mOutputFormat.width = Align(mOutputFormat.rect.right, FRAME_ALIGN);
+        mOutputFormat.height = Align(mOutputFormat.rect.bottom, FRAME_ALIGN);
+        mOutputPlaneSize[0] = mOutputFormat.width * mOutputFormat.height;
+        mOutputPlaneSize[1] = mOutputPlaneSize[0]/2;
+    }else
+        return UNKNOWN_ERROR;
+
+    return OK;
+}
+status_t V4l2Dec::SetOutputFormats()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_format format;
+    memset(&format, 0, sizeof(format));
+    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    format.fmt.pix_mp.num_planes = kOutputBufferPlaneNum;
+    format.fmt.pix_mp.pixelformat = mOutFormat;
+
+    mOutputFormat.width = Align(mOutputFormat.width, FRAME_ALIGN);
+    mOutputFormat.height = Align(mOutputFormat.height, FRAME_ALIGN);
+
+    format.fmt.pix_mp.width = mOutputFormat.width;
+    format.fmt.pix_mp.height = mOutputFormat.height;
+    ALOGV("SetOutputFormats w=%d,h=%d",format.fmt.pix_mp.width,format.fmt.pix_mp.height);
+    format.fmt.pix_mp.plane_fmt[0].sizeimage = mOutputPlaneSize[0];
+    format.fmt.pix_mp.plane_fmt[0].bytesperline = Align(mOutputFormat.width, FRAME_ALIGN);
+    format.fmt.pix_mp.plane_fmt[1].sizeimage = mOutputPlaneSize[1];
+    format.fmt.pix_mp.plane_fmt[1].bytesperline = Align(mOutputFormat.width, FRAME_ALIGN);
+    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+
+    result = ioctl (mFd, VIDIOC_S_FMT, &format);
+    if(result != 0){
+        ALOGE("SetOutputFormats VIDIOC_S_FMT failed");
+        return UNKNOWN_ERROR;
+    }
+
+    memset(&format, 0, sizeof(struct v4l2_format));
+    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+
+    result = ioctl (mFd, VIDIOC_G_FMT, &format);
+    if(result < 0)
+        return UNKNOWN_ERROR;
+
+
+    if(format.fmt.pix_mp.pixelformat != mOutFormat){
+        ALOGE("SetOutputFormats mOutFormat mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if( format.fmt.pix_mp.width > mOutputFormat.width ||
+        format.fmt.pix_mp.height > mOutputFormat.height){
+        ALOGE("SetOutputFormats resolution mismatch,w=%d,h=%d,output w=%d,h=%d",
+            format.fmt.pix_mp.width,format.fmt.pix_mp.height,mOutputFormat.width, mOutputFormat.height);
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].bytesperline != Align(mOutputFormat.width, FRAME_ALIGN)){
+        ALOGE("SetOutputFormats stride mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].sizeimage !=  mOutputPlaneSize[0] ||
+        format.fmt.pix_mp.plane_fmt[1].sizeimage !=  mOutputPlaneSize[1]){
+        ALOGE("SetOutputFormats bufferSize mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    ALOGV("SetOutputFormats success");
+    return OK;
+}
+
+V4l2Dec::InputRecord::InputRecord()
+    : at_device(false), input_id(-1), ts(-1) {
+    memset(&plane, 0, sizeof(VideoFramePlane));
+}
+
+V4l2Dec::InputRecord::~InputRecord() {}
+
+V4l2Dec::OutputRecord::OutputRecord()
+    : at_device(false), picture_id(0), flag(0), mGraphicBlock(NULL) {
+    memset(&planes, 0, sizeof(VideoFramePlane)*kOutputBufferPlaneNum);
+}
+
+V4l2Dec::OutputRecord::~OutputRecord() {
+}
+
+status_t V4l2Dec::prepareInputBuffers()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = mInputFormat.bufferNum;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.memory = mInMemType;
+
+    ALOGV("prepareInputBuffers count=%d",reqbufs.count);
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0){
+        ALOGE("VIDIOC_REQBUFS failed result=%d",result);
+        return UNKNOWN_ERROR;
+    }
+
+    mInputBufferMap.resize(reqbufs.count);
+
+    for (size_t i = 0; i < mInputBufferMap.size(); i++) {
+        mInputBufferMap[i].at_device = false;
+        mInputBufferMap[i].plane.fd = -1;
+        mInputBufferMap[i].plane.vaddr = 0;
+        mInputBufferMap[i].plane.paddr = 0;
+        mInputBufferMap[i].plane.size = mInputFormat.bufferSize;
+        mInputBufferMap[i].plane.length = 0;
+        mInputBufferMap[i].plane.offset = 0;
+        mInputBufferMap[i].input_id = -1;
+    }
+
+    ALOGV("prepareInputBuffers total input=%d size=%d",mInputFormat.bufferNum, mInputBufferMap.size());
+
+    return OK;
+}
+status_t V4l2Dec::createInputBuffers()
+{
+
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes;
+    void * ptr = NULL;
+    uint64_t tmp = 0;
+
+    if(mInMemType != V4L2_MEMORY_MMAP)
+        return UNKNOWN_ERROR;
+
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(&planes, 0, sizeof(planes));
+
+    for (size_t i = 0; i < mInputBufferMap.size(); i++) {
+        stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        stV4lBuf.memory = V4L2_MEMORY_MMAP;
+        stV4lBuf.index = i;
+        stV4lBuf.length = kInputBufferPlaneNum;
+        stV4lBuf.m.planes = &planes;
+        result = ioctl(mFd, VIDIOC_QUERYBUF, &stV4lBuf);
+        if(result < 0)
+            return UNKNOWN_ERROR;
+
+        planes.length = mInputFormat.bufferSize;
+
+        ptr = mmap(NULL, planes.length,
+            PROT_READ | PROT_WRITE, /* recommended */
+            MAP_SHARED,             /* recommended */
+            mFd, planes.m.mem_offset);
+
+        if(ptr != MAP_FAILED){
+            tmp = (uint64_t)ptr;
+            mInputBufferMap[i].plane.vaddr = tmp;
+        }else
+            return NO_MEMORY;
+    }
+
+    ALOGV("createInputBuffers success");
+    return OK;
+}
+status_t V4l2Dec::destroyInputBuffers()
+{
+    Mutex::Autolock autoLock(mLock);
+    if (mInputBufferMap.empty())
+        return OK;
+
+    for (size_t i = 0; i < mInputBufferMap.size(); i++) {
+        mInputBufferMap[i].at_device = false;
+        mInputBufferMap[i].input_id = -1;
+        mInputBufferMap[i].plane.fd = -1;
+        if(mInMemType == V4L2_MEMORY_MMAP && mInputBufferMap[i].plane.vaddr != 0)
+            munmap((void*)(uintptr_t)mInputBufferMap[i].plane.vaddr, mInputBufferMap[i].plane.size);
+
+        mInputBufferMap[i].plane.vaddr = 0;
+        mInputBufferMap[i].plane.paddr = 0;
+        mInputBufferMap[i].plane.size = 0;
+        mInputBufferMap[i].plane.length = 0;
+        mInputBufferMap[i].plane.offset = 0;
+    }
+
+    int result = 0;
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = 0;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
+
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0){
+        ALOGV("ignore the result");
+    }
+        //return UNKNOWN_ERROR;
+
+    mInputBufferMap.clear();
+
+    ALOGV("destroyInputBuffers success");
+    return OK;
+}
+status_t V4l2Dec::importOutputBuffers(std::vector<GraphicBlockInfo> buffers)
+{
+#if 0
+    uint32_t out_buf_count = buffers.size();
+
+    if(out_buf_count != mOutputFormat.bufferNum){
+        ALOGE("importOutputBuffers failed");
+        return UNKNOWN_ERROR;
+    }
+
+    out_buf_count = 32; // add 4 + 3 buffers to align with CCodecBufferChannel
+    mLock.lock();
+    int result = 0;
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = out_buf_count;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.memory = mOutMemType;
+
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0){
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+
+    mOutputBufferMap.resize(out_buf_count);
+
+    for (size_t i = 0; i < mOutputBufferMap.size(); i++) {
+        OutputRecord& output_record = mOutputBufferMap[i];
+
+        if (i < buffers.size()) {
+
+        output_record.planes[0].fd = buffers[i].mDMABufFd;
+        output_record.planes[0].vaddr = buffers[i].mVirtAddr;
+        output_record.planes[0].paddr = buffers[i].mPhysAddr;
+        output_record.planes[0].size = mOutputPlaneSize[0];
+        output_record.planes[0].length = 0;
+        output_record.planes[0].offset = 0;
+        output_record.planes[1].fd = buffers[i].mDMABufFd;
+        output_record.planes[1].vaddr = buffers[i].mVirtAddr + mOutputPlaneSize[0];
+        output_record.planes[1].paddr = buffers[i].mPhysAddr + mOutputPlaneSize[0];
+        output_record.planes[1].size = mOutputPlaneSize[1];
+        output_record.planes[1].length = 0;
+        output_record.planes[1].offset = mOutputPlaneSize[0];
+
+        output_record.at_device = false;
+        output_record.picture_id = buffers[i].mBlockId;
+        } else {
+            output_record.planes[0].fd = 0;
+            output_record.planes[0].vaddr = 0;
+            output_record.planes[0].paddr = 0;
+            output_record.at_device = false;
+            output_record.picture_id = -1;
+        }
+    }
+#else
+    if(mState == STOPPING)
+        return OK;
+
+    mState = RUNNING;
+    mLock.lock();
+
+    int result = 0;
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = 32;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.memory = mOutMemType;
+
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0){
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+    if (!bNeedPostProcess)
+        mOutputBufferMap.resize(32);
+
+    mLock.unlock();
+#endif
+
+    createFetchThread();
+    return OK;
+}
+status_t V4l2Dec::destroyOutputBuffers()
+{
+    Mutex::Autolock autoLock(mLock);
+    if (mOutputBufferMap.empty())
+        return OK;
+
+    int result = 0;
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = 0;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
+
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0){
+        ALOGV("ignore VIDIOC_REQBUFS result");
+        //return UNKNOWN_ERROR;
+    }
+
+    mOutputBufferMap.clear();
+    ClearPictureBuffer();//call it here or in base class
+    ALOGV("destroyOutputBuffers success");
+    return OK;
+}
+status_t V4l2Dec::HandlePollThread()
+{
+    status_t ret = OK;
+    int32_t poll_ret = 0;
+
+    while(bPollStarted){
+        ALOGV("pollThreadHandler BEGIN");
+        poll_ret = pDev->Poll();
+        ALOGV("pollThreadHandler poll_ret=%x,mInCnt=%d,mOutCnt=%d",
+            poll_ret,mInCnt,mOutCnt);
+        if(poll_ret & V4L2_DEV_POLL_EVENT){
+            ret = onDequeueEvent();
+        }
+
+        if(poll_ret & V4L2_DEV_POLL_OUTPUT){
+            ret = dequeueInputBuffer();
+        }
+        if(poll_ret & V4L2_DEV_POLL_CAPTURE){
+            ret = dequeueOutputBuffer();
+        }
+    }
+    ALOGV("HandlePollThread stopped");
+    bPollStopped = true;
+    return OK;
+
+}
+status_t V4l2Dec::HandleFetchThread()
+{
+    while(bFetchStarted){
+        // only start fetching when vpu output buffer isn't enough
+        if (mVpuOwnedOutputBufferNum >= mOutputFormat.bufferNum || RUNNING != mState) {
+            usleep(5000);
+            continue;
+        }
+        ALOGV("getFreeGraphicBlock begin mVpuOwnedOutputBufferNum %d mOutputFormat.bufferNum %d", mVpuOwnedOutputBufferNum, mOutputFormat.bufferNum);
+
+        GraphicBlockInfo *gbInfo = getFreeGraphicBlock();
+        if (bNeedPostProcess) {
+            if(!gbInfo || gbInfo->mBlockId >= mOutputFormat.bufferNum) {
+                usleep(1000);
+                continue;
+            }
+            ALOGV("HandleFetchThread queueOutput BEGIN, blockid=%d",gbInfo->mBlockId);
+            queueOutput(gbInfo);
+        } else {
+            if(!gbInfo) {
+                status_t ret = fetchOutputBuffer();
+                if (OK == ret) {
+                    gbInfo = getFreeGraphicBlock();
+                } else if (WOULD_BLOCK == ret) {
+                    usleep(1000);
+                    continue;
+                } else {
+                    bReceiveError = true;
+                    NotifyError(BAD_VALUE);
+                    break;
+                }
+            }
+            ALOGV("HandleFetchThread queueOutput 2 BEGIN");
+            queueOutput(gbInfo);
+        }
+    }
+    ALOGV("HandleFetchThread stopped");
+    bFetchStopped = true;
+    return OK;
+}
+// static
+void *V4l2Dec::PollThreadWrapper(void *me) {
+    return (void *)(uintptr_t)static_cast<V4l2Dec *>(me)->HandlePollThread();
+}
+void *V4l2Dec::FetchThreadWrapper(void *me) {
+    return (void *)(uintptr_t)static_cast<V4l2Dec *>(me)->HandleFetchThread();
+}
+
+status_t V4l2Dec::createPollThread()
+{
+    ALOGV("%s", __FUNCTION__);
+    Mutex::Autolock autoLock(mLock);
+
+    if(!bPollStarted){
+
+        pthread_attr_t attr;
+        pthread_attr_init(&attr);
+        pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+
+        bPollStarted = true;
+        bPollStopped = false;
+        pthread_create(&mPollThread, &attr, PollThreadWrapper, this);
+        pthread_attr_destroy(&attr);
+    }
+    return OK;
+}
+status_t V4l2Dec::destroyPollThread()
+{
+    ALOGV("%s", __FUNCTION__);
+
+    if(bPollStarted){
+        int cnt = 0;
+        bPollStarted = false;
+
+        pDev->StopDecoder();
+
+        do {
+            usleep(1000);
+            cnt ++;
+        } while (!bPollStopped && cnt < 20);
+        ALOGV("%s bPollStopped bPollStopped=%d,cnt=%d", __FUNCTION__,bPollStopped,cnt);
+        Mutex::Autolock autoLock(mLock);
+        pDev->SetPollInterrupt();
+        ALOGV("%s call pthread_join", __FUNCTION__);
+        pthread_join(mPollThread, NULL);
+        pDev->ClearPollInterrupt();
+    }
+    ALOGV("%s END", __FUNCTION__);
+    return OK;
+}
+status_t V4l2Dec::createFetchThread()
+{
+    ALOGV("%s", __FUNCTION__);
+    Mutex::Autolock autoLock(mLock);
+    if(!bFetchStarted){
+        pthread_attr_t attr;
+        pthread_attr_init(&attr);
+        pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+
+        bFetchStarted = true;
+        bFetchStopped = false;
+        pthread_create(&mFetchThread, &attr, FetchThreadWrapper, this);
+        pthread_attr_destroy(&attr);
+
+    }
+    return OK;
+}
+status_t V4l2Dec::destroyFetchThread()
+{
+    ALOGV("%s", __FUNCTION__);
+
+    if(bFetchStarted){
+        int cnt = 0;
+        bFetchStarted = false;
+        do {
+            usleep(1000);
+            cnt ++;
+        } while (!bFetchStopped && cnt < 20);
+        ALOGV("%s bFetchStopped=%d,cnt=%d", __FUNCTION__,bFetchStopped,cnt);
+        Mutex::Autolock autoLock(mLock);
+        pthread_join(mFetchThread, NULL);
+    }
+    ALOGV("%s END", __FUNCTION__);
+    return OK;
+}
+status_t V4l2Dec::decodeInternal(std::unique_ptr<IMXInputBuffer> input)
+{
+    int result = 0;
+    int32_t index = -1;
+    uint32_t v4l2_flags = 0;
+
+    if(input == nullptr)
+        return BAD_VALUE;
+
+    if(STOPPED == mState || UNINITIALIZED == mState)
+        onStart();
+
+    if (!bCodecDataQueued && pCodecDataBuf && nCodecDataLen > 0) {
+        bCodecDataQueued = true;
+        status_t ret = decodeInternal(std::make_unique<IMXInputBuffer>(
+                                        pCodecDataBuf, -1, -1, nCodecDataLen, -1, false, true));
+        nCodecDataLen = 0;
+        if (ret != OK) {
+            ALOGE("queue codecdata failed with ret %d", ret);
+            return ret;
+        }
+    }
+
+    int32_t fd = input->fd;
+    uint64_t ts = input->timestamp;
+    uint32_t buf_length = 0;
+    bool eos = input->eos;
+
+    if (eos) {
+        ALOGV("get input eos, call stopDecoder");
+        Mutex::Autolock autoLock(mLock);
+        if (OK != pDev->StopDecoder())
+            ALOGW("Stop Decoder failed
");
+        return OK;
+    }
+
+    if((int64_t)ts > 0)
+        v4l2_flags |= (V4L2_BUF_FLAG_TIMESTAMP_MASK | V4L2_BUF_FLAG_TIMESTAMP_COPY);
+
+    if (input->csd)
+        v4l2_flags |= (IMX_V4L2_BUF_FLAG_CODECCONFIG | IMX_V4L2_BUF_FLAG_TIMESTAMP_INVALID);
+
+    if(input->size > mInputFormat.bufferSize){
+        ALOGE("invalid buffer size=%d,cap=%d",input->size, mInputFormat.bufferSize);
+        return UNKNOWN_ERROR;
+    }
+
+QueueOneBuffer:
+    mLock.lock();
+
+    //try to get index
+    for(int32_t i = 0; i < mInputBufferMap.size(); i++){
+        if(mInputBufferMap[i].input_id == -1 && !mInputBufferMap[i].at_device){
+            index = i;
+            break;
+        }
+    }
+
+    if (index < 0) {
+        // no available input index because input buffer queue too fast
+        mLock.unlock();
+        usleep(1000);
+        goto QueueOneBuffer;
+    }
+
+    mInputBufferMap[index].input_id = input->id;
+    ALOGV("decodeInternal input->BUF=%p, index=%d, len=%zu, ts=%lld, fd=%d",input->pInBuffer, index, input->size, ts, fd);
+
+    if(mInMemType == V4L2_MEMORY_MMAP){
+        memcpy((void*)(uintptr_t)(mInputBufferMap[index].plane.vaddr + buf_length), input->pInBuffer, input->size);
+        buf_length += input->size;
+    }
+
+    if(mInputBufferMap[index].at_device){
+        ALOGE("onQueueInputBuffer index=%d, at_device",index);
+    }
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane plane;
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(&plane, 0, sizeof(plane));
+
+    plane.bytesused = buf_length;
+    plane.length = mInputFormat.bufferSize;
+    plane.data_offset = 0;
+
+    if(mInMemType == V4L2_MEMORY_MMAP)
+        plane.m.mem_offset = 0;
+    else if(mInMemType == V4L2_MEMORY_USERPTR)
+        plane.m.userptr = (unsigned long)mInputBufferMap[index].plane.vaddr;
+    else if(mInMemType == V4L2_MEMORY_DMABUF)
+        plane.m.fd = mInputBufferMap[index].plane.fd;
+
+
+    stV4lBuf.index = index;
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    stV4lBuf.timestamp.tv_sec = ts / 1000000;
+    stV4lBuf.timestamp.tv_usec = ts % 1000000;
+    stV4lBuf.memory = mInMemType;
+    stV4lBuf.m.planes = &plane;
+    stV4lBuf.length = kInputBufferPlaneNum;
+    stV4lBuf.flags = v4l2_flags;
+
+    ALOGV("VIDIOC_QBUF OUTPUT_MPLANE BEGIN index=%d,len=%d, ts=%lld
",
+        stV4lBuf.index, plane.bytesused, (long long)ts);
+
+    result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
+    if(result < 0){
+        ALOGE("VIDIOC_QBUF OUTPUT_MPLANE failed, index=%d",index);
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+
+    mInputBufferMap[index].at_device = true;
+    ALOGV("VIDIOC_QBUF OUTPUT_MPLANE END index=%d,len=%d, ts=%lld
",
+        stV4lBuf.index, plane.bytesused, (long long)ts);
+
+    mInCnt++;
+    mLock.unlock();
+
+    if(!bInputStreamOn)
+        startInputStream();
+
+    if (input->id >= 0) {
+        ALOGV("NotifyInputBufferUsed id=%d",input->id);
+        NotifyInputBufferUsed(input->id);
+    }
+    return OK;
+}
+status_t V4l2Dec::dequeueInputBuffer()
+{
+    int result = 0;
+    int input_id = -1;
+
+    if(!bInputStreamOn || mState != RUNNING )
+        return OK;
+
+    Mutex::Autolock autoLock(mLock);
+
+    if(!bInputStreamOn || mState != RUNNING)
+        return OK;
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kInputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(planes, 0, sizeof(planes));
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    stV4lBuf.memory = mInMemType;
+    stV4lBuf.m.planes = planes;
+    stV4lBuf.length = kInputBufferPlaneNum;
+    ALOGV("VIDIOC_DQBUF OUTPUT_MPLANE BEGIN");
+    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+    if(result < 0)
+        return UNKNOWN_ERROR;
+
+    if(stV4lBuf.index >= mInputFormat.bufferNum)
+        return BAD_INDEX;
+
+    ALOGV("VIDIOC_DQBUF OUTPUT_MPLANE END index=%d",stV4lBuf.index);
+    if(!mInputBufferMap[stV4lBuf.index].at_device){
+        ALOGE("dequeueInputBuffer index=%d, not at_device",stV4lBuf.index);
+    }
+    mInputBufferMap[stV4lBuf.index].at_device = false;
+    input_id = mInputBufferMap[stV4lBuf.index].input_id;
+    mInputBufferMap[stV4lBuf.index].input_id = -1;
+
+    return OK;
+}
+status_t V4l2Dec::queueOutput(GraphicBlockInfo* pInfo)
+{
+    int result = 0;
+    int32_t fd[kOutputBufferPlaneNum];
+    uint64_t vaddr[kOutputBufferPlaneNum];
+    uint64_t paddr[kOutputBufferPlaneNum];
+    uint32_t offset[kOutputBufferPlaneNum];
+    int32_t index = -1;
+
+    if(!bFetchStarted || STOPPING == mState || FLUSHING == mState || RES_CHANGING == mState){
+        ALOGV("queueOutput return 1");
+        return OK;
+    }
+
+    ALOGV("queueOutput BEGIN id=%d",pInfo->mBlockId);
+    mLock.lock();
+
+    if(!bFetchStarted || STOPPING == mState || FLUSHING == mState || RES_CHANGING == mState){
+        mLock.unlock();
+        ALOGV("queueOutput return 2");
+        return OK;
+    }
+
+    vaddr[0] = pInfo->mVirtAddr;
+    vaddr[1] = pInfo->mVirtAddr;
+
+    paddr[0] = pInfo->mPhysAddr;
+    paddr[1] = pInfo->mPhysAddr;
+
+    offset[0] = 0;
+    offset[1] = mOutputFormat.width * mOutputFormat.height;
+
+    fd[0] = pInfo->mDMABufFd;
+    fd[1] = pInfo->mDMABufFd;
+
+    //try to get index
+    for(int32_t i = 0; i < mOutputBufferMap.size(); i++){
+        if(pInfo->mPhysAddr == mOutputBufferMap[i].planes[0].paddr){
+            index = i;
+            break;
+        }
+    }
+
+    //index not found
+    if(index < 0){
+        for(int32_t i = 0; i < mOutputBufferMap.size(); i++){
+            if(0 == mOutputBufferMap[i].planes[0].paddr){
+                mOutputBufferMap[i].planes[0].fd = fd[0];
+                mOutputBufferMap[i].planes[0].vaddr = vaddr[0];
+                mOutputBufferMap[i].planes[0].paddr = paddr[0];
+                mOutputBufferMap[i].planes[0].offset = offset[0];
+
+                mOutputBufferMap[i].planes[1].fd = fd[1];
+                mOutputBufferMap[i].planes[1].vaddr = vaddr[1];
+                mOutputBufferMap[i].planes[1].paddr = paddr[1];
+                mOutputBufferMap[i].planes[1].offset = offset[1];
+
+                mOutputBufferMap[i].picture_id = pInfo->mBlockId;
+                mOutputBufferMap[i].at_device = false;
+                index = i;
+                break;
+            }
+        }
+    }
+
+    if(index < 0){
+        ALOGE("could not create index");
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+
+    if(mOutputBufferMap[index].at_device){
+        ALOGE("queueOutput index=%d, at_device,pInfo->mBlockId=%d",index,pInfo->mBlockId);
+    }
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kOutputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(&planes, 0, sizeof(planes));
+
+
+    if(mOutMemType == V4L2_MEMORY_DMABUF){
+        planes[0].m.fd = fd[0];
+        planes[1].m.fd = fd[1];
+    }else if(mOutMemType == V4L2_MEMORY_USERPTR){
+        planes[0].m.userptr = vaddr[0];
+        planes[1].m.userptr = vaddr[1];
+    }
+
+    planes[0].length = mOutputBufferMap[index].planes[0].size;
+    planes[1].length = mOutputBufferMap[index].planes[1].size;
+
+    planes[0].data_offset = mOutputBufferMap[index].planes[0].offset;
+    planes[1].data_offset = mOutputBufferMap[index].planes[1].offset;
+
+    stV4lBuf.index = index;
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    stV4lBuf.memory = mOutMemType;
+    stV4lBuf.m.planes = &planes[0];
+    stV4lBuf.length = kOutputBufferPlaneNum;
+    stV4lBuf.flags = 0;
+
+    ALOGV("VIDIOC_QBUF CAPTURE_MPLANE BEGIN index=%d blockId=%d
",index, pInfo->mBlockId);
+
+    result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
+    if(result < 0){
+        ALOGE("VIDIOC_QBUF CAPTURE_MPLANE failed, index=%d",index);
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+
+    ALOGV("VIDIOC_QBUF CAPTURE_MPLANE END index=%d blockId=%d
",index, pInfo->mBlockId);
+    pInfo->mState = GraphicBlockInfo::State::OWNED_BY_VPU;
+
+    mVpuOwnedOutputBufferNum++;
+    mOutputBufferMap[index].at_device = true;
+    mLock.unlock();
+
+    if(!bOutputStreamOn)
+        startOutputStream();
+    return OK;
+}
+
+status_t V4l2Dec::startInputStream()
+{
+    Mutex::Autolock autoLock(mLock);
+    if(!bInputStreamOn){
+        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
+            bInputStreamOn = true;
+        }
+    }
+    return OK;
+}
+status_t V4l2Dec::stopInputStream()
+{
+    ALOGV("%s", __FUNCTION__);
+    Mutex::Autolock autoLock(mLock);
+    if(bInputStreamOn){
+        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        if(0 == ioctl(mFd, VIDIOC_STREAMOFF, &buf_type)){
+            bInputStreamOn = false;
+        }
+    }
+
+    for (size_t i = 0; i < mInputBufferMap.size(); i++) {
+        mInputBufferMap[i].at_device = false;
+        mInputBufferMap[i].input_id = -1;
+    }
+
+    bInputStreamOn = false;
+    return OK;
+}
+status_t V4l2Dec::startOutputStream()
+{
+    ALOGV("%s", __FUNCTION__);
+    Mutex::Autolock autoLock(mLock);
+    if(!bOutputStreamOn){
+        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
+            bOutputStreamOn = true;
+        }
+    }
+    return OK;
+}
+status_t V4l2Dec::stopOutputStream()
+{
+    ALOGV("%s", __FUNCTION__);
+    Mutex::Autolock autoLock(mLock);
+    //call VIDIOC_STREAMOFF and ignore the result
+    enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    ioctl(mFd, VIDIOC_STREAMOFF, &buf_type);
+    bOutputStreamOn = false;
+
+    // return capture buffer to component
+    for(int32_t i = 0; i < mOutputBufferMap.size(); i++){
+        if(mOutputBufferMap[i].planes[0].paddr > 0 && mOutputBufferMap[i].at_device) {
+            GraphicBlockInfo *gbInfo = getGraphicBlockById(mOutputBufferMap[i].picture_id);
+            gbInfo->mState = GraphicBlockInfo::State::OWNED_BY_COMPONENT;
+            mOutputBufferMap[i].at_device = false;
+            ALOGV("return capture buffer %d ", mOutputBufferMap[i].picture_id);
+        }
+    }
+
+    mVpuOwnedOutputBufferNum = 0;
+
+    return OK;
+}
+status_t V4l2Dec::dequeueOutputBuffer()
+{
+    int result = 0;
+
+    if(!bOutputStreamOn || mState != RUNNING)
+        return OK;
+
+    Mutex::Autolock autoLock(mLock);
+
+    if(!bOutputStreamOn || mState != RUNNING)
+        return OK;
+
+    int64_t ts = 0;
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kOutputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(planes, 0, sizeof(planes));
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    stV4lBuf.memory = mOutMemType;
+    stV4lBuf.m.planes = planes;
+    stV4lBuf.length = kOutputBufferPlaneNum;
+    ALOGV("VIDIOC_DQBUF CAPTURE_MPLANE BEGIN");
+    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+    if(result < 0) {
+        ALOGV("%s VIDIOC_DQBUF err=%d", __FUNCTION__, result);
+        return UNKNOWN_ERROR;
+    }
+
+    if(stV4lBuf.index >= 32/*mOutputFormat.bufferNum*/) {
+        ALOGI("dequeueOutputBuffer error");
+        return BAD_INDEX;
+    }
+
+    ts = (int64_t)stV4lBuf.timestamp.tv_sec *1000000;
+    ts += stV4lBuf.timestamp.tv_usec;
+
+    ALOGV("VIDIOC_DQBUF CAPTURE_MPLANE END index=%d ts=%lld",stV4lBuf.index, (long long)ts);
+    mVpuOwnedOutputBufferNum--;
+    mOutCnt ++;
+    mOutputBufferMap[stV4lBuf.index].at_device = false;
+    NotifyPictureReady(mOutputBufferMap[stV4lBuf.index].picture_id, ts);
+    return OK;
+}
+status_t V4l2Dec::onDequeueEvent()
+{
+    int result = 0;
+    struct v4l2_event event;
+    memset(&event, 0, sizeof(struct v4l2_event));
+    result = ioctl(mFd, VIDIOC_DQEVENT, &event);
+    if(result == 0){
+        ALOGV("onDequeueEvent type=%d",event.type);
+        switch(event.type){
+            case V4L2_EVENT_SOURCE_CHANGE:
+                if(event.u.src_change.changes & V4L2_EVENT_SRC_CH_RESOLUTION){
+                    //TODO: send event
+                    handleFormatChanged();
+                }
+                break;
+            case V4L2_EVENT_EOS:
+            {
+                Mutex::Autolock autoLock(mLock);
+                usleep(1000);
+                if(STOPPING != mState)
+                    NotifyEOS();//send eos event
+                bPollStarted = false;
+                bFetchStarted = false;
+                mState = STOPPED;
+                break;
+            }
+            case V4L2_EVENT_DECODE_ERROR:
+                ALOGE("get V4L2_EVENT_DECODE_ERROR");
+                NotifyError(UNKNOWN_ERROR);//send error event
+                break;
+            case V4L2_EVENT_SKIP:
+                NotifySkipInputBuffer(-1/*unused*/);
+                break;
+            default:
+                break;
+        }
+    }
+
+    return OK;
+}
+
+status_t V4l2Dec::DoSetConfig(DecConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    status_t ret = OK;
+
+    switch (index) {
+        case DEC_CONFIG_VC1_SUB_FORMAT: {
+            if (strcmp(mMime, MEDIA_MIMETYPE_VIDEO_VC1) != 0) {
+                ALOGE("DoSetConfig DEC_CONFIG_VC1_SUB_FORMAT only support for VC1");
+                return BAD_VALUE;
+            }
+
+            int* format = (int*)pConfig;
+            // TODO: remove this OMX_VIDEO_WMVFormat9=0x08, OMX_VIDEO_WMVFormatWVC1=0x7f000002
+            if (*format == 0x08)
+                mVc1Format = V4L2_PIX_FMT_VC1_ANNEX_G;
+            else if (*format == 0x7f000002)
+                mVc1Format = V4L2_PIX_FMT_VC1_ANNEX_L;
+
+            ALOGV("vc1 sub-format 0x%x mVc1Format %d", *format, mVc1Format);
+            break;
+        }
+        case DEC_CONFIG_HAL_PIXEL_FORMAT:{
+            uint32_t* format = (uint32_t*)pConfig;
+            if(*format == HAL_PIXEL_FORMAT_NV12_TILED)
+                bNeedPostProcess = false;
+            else
+                bNeedPostProcess = true;
+            ALOGV("set DEC_CONFIG_HAL_PIXEL_FORMAT fmt=0x%x,bNeedPostProcess=%d",*format, bNeedPostProcess);
+            break;
+        }
+        default:
+            ret = BAD_VALUE;
+            break;
+    }
+    return ret;
+}
+
+status_t V4l2Dec::DoGetConfig(DecConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    status_t ret = OK;
+
+    switch (index) {
+        case DEC_CONFIG_OUTPUT_DELAY: {
+            int *pOutputDelayValue = (int*)pConfig;
+            if(mOutputFormat.bufferNum > DEFAULT_OUTPUT_BUFFER_COUNT)
+                *pOutputDelayValue = mOutputFormat.bufferNum;
+            else
+                *pOutputDelayValue = DEFAULT_OUTPUT_BUFFER_COUNT;
+            ALOGV("DoGetConfig DEC_CONFIG_OUTPUT_DELAY =%d, mOutputFormat.bufferNum=%d",
+                *pOutputDelayValue,mOutputFormat.bufferNum);
+            break;
+        }
+        case DEC_CONFIG_COLOR_ASPECTS:
+            VideoColorAspect isocolor;
+            ret = getVideoColorAspect(&isocolor);
+            if(ret != OK)
+                break;
+            ret = convertIsoColorAspectsToCodecAspects((DecColorAspects*)&isocolor, (DecColorAspects*)pConfig);
+            break;
+        default:
+            ret = BAD_VALUE;
+            break;
+    }
+
+    return ret;
+}
+
+status_t V4l2Dec::allocateOutputBuffers() {
+    int ret;
+
+    if(mState == STOPPING)
+        return OK;
+
+    Mutex::Autolock autoLock(mLock);
+
+    if(mState == STOPPING)
+        return OK;
+
+    fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
+
+    mOutputBufferMap.resize(mOutputFormat.bufferNum);
+
+    for (int i = 0; i < mOutputFormat.bufferNum; i++) {
+        if (!bNeedPostProcess) {
+            status_t ret;
+            do {
+                ret = fetchOutputBuffer();
+            } while (WOULD_BLOCK == ret);
+
+            if (ret != OK) {
+                bReceiveError = true;
+                NotifyError(ret);
+                return ret;
+            } else
+                continue;
+        }
+
+        int fd = 0;
+        uint64_t phys_addr = 0;
+        uint64_t virt_addr = 0;
+
+        //allocate dma buffer for decoder output buffers when enable post process
+        fd = pIonAllocator->allocMemory(mOutputFormat.bufferSize, ION_MEM_ALIGN, fsl::MFLAGS_CONTIGUOUS);
+
+        if (fd <= 0) {
+            ALOGE("Ion allocate failed i=%d,size=%d", i, mOutputFormat.bufferSize);
+            return BAD_VALUE;
+        }
+
+        ret = pIonAllocator->getPhys(fd, mOutputFormat.bufferSize, phys_addr);
+        if (ret != 0) {
+            ALOGE("DmaBuffer getPhys failed");
+            return BAD_VALUE;
+        }
+
+        ret = pIonAllocator->getVaddrs(fd, mOutputFormat.bufferSize, virt_addr);
+        if (ret != 0) {
+            ALOGE("DmaBuffer getVaddrs failed");
+            return BAD_VALUE;
+        }
+
+        GraphicBlockInfo info;
+        memset(&info, 0, sizeof(GraphicBlockInfo));
+        info.mBlockId = i;
+        info.mDMABufFd = fd;
+        info.mPhysAddr = phys_addr;
+        info.mVirtAddr = virt_addr;
+        info.mCapacity = mOutputFormat.bufferSize;
+        info.mState = GraphicBlockInfo::State::OWNED_BY_COMPONENT;
+        mGraphicBlocks.push_back(std::move(info));
+        ALOGV("Ion allocate fd=%d phys_addr=%p vaddr=%p
",fd, (void*)phys_addr, (void*)virt_addr);
+        ALOGV("mOutputBufferMap[%d] phys %p, at_device %d", i,
+            (void*)mOutputBufferMap[i].planes[0].paddr, mOutputBufferMap[i].at_device);
+
+    }
+    return OK;
+}
+
+status_t V4l2Dec::freeOutputBuffers() {
+
+    ALOGV("%s", __FUNCTION__);
+    Mutex::Autolock autoLock(mLock);
+
+    if(mGraphicBlocks.empty())
+        return OK;
+
+    for (auto& info : mGraphicBlocks) {
+        ALOGV("freeOutputBuffers fd=%d,id=%d",info.mDMABufFd,info.mBlockId);
+
+        if (info.mVirtAddr > 0 && info.mCapacity > 0)
+            munmap((void*)info.mVirtAddr, info.mCapacity);
+
+        if(bNeedPostProcess && info.mDMABufFd > 0)
+            close(info.mDMABufFd);
+        if(info.mGraphicBlock != NULL){
+            ALOGV("info.mGraphicBlock reset");
+            info.mGraphicBlock.reset();
+        }
+    }
+
+    mGraphicBlocks.clear();
+    return OK;
+}
+
+status_t V4l2Dec::handleFormatChanged() {
+
+    status_t ret = OK;
+    int pre_state;
+    ALOGV("outputFormatChanged BEGIN");
+    {
+        Mutex::Autolock autoLock(mLock);
+        pre_state = mState;
+        mState = RES_CHANGING;
+        int result = 0;
+        struct v4l2_format format;
+        uint32_t pixel_format = 0;
+        memset(&format, 0, sizeof(struct v4l2_format));
+
+        format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        result = ioctl (mFd, VIDIOC_G_FMT, &format);
+
+        if(result < 0)
+            return UNKNOWN_ERROR;
+
+        ret = pDev->GetColorFormatByV4l2( format.fmt.pix_mp.pixelformat, &pixel_format);
+        if(ret != OK)
+            return ret;
+
+        mOutputFormat.pixelFormat = static_cast<int>(pixel_format);
+
+        mOutputFormat.width = Align(format.fmt.pix_mp.width, FRAME_ALIGN);
+        mOutputFormat.height = Align(format.fmt.pix_mp.height, FRAME_ALIGN);
+        mOutputFormat.interlaced = ((format.fmt.pix_mp.field == V4L2_FIELD_INTERLACED) ? true: false);
+        mOutputFormat.bufferSize = format.fmt.pix_mp.plane_fmt[0].sizeimage + format.fmt.pix_mp.plane_fmt[1].sizeimage;
+
+        mOutputPlaneSize[0] = format.fmt.pix_mp.plane_fmt[0].sizeimage;
+        mOutputPlaneSize[1] = format.fmt.pix_mp.plane_fmt[1].sizeimage;
+
+        struct v4l2_control ctl;
+        memset(&ctl, 0, sizeof(struct v4l2_control));
+
+        ctl.id = V4L2_CID_MIN_BUFFERS_FOR_CAPTURE;
+        result = ioctl(mFd, VIDIOC_G_CTRL, &ctl);
+        if(result < 0)
+            return UNKNOWN_ERROR;
+
+        if (bNeedPostProcess){
+            mOutputFormat.minBufferNum = ctl.value+3;
+        }else
+            mOutputFormat.minBufferNum = ctl.value;
+
+        if(mOutputFormat.minBufferNum > mOutputFormat.bufferNum)
+            mOutputFormat.bufferNum = mOutputFormat.minBufferNum;
+
+        if (!bNeedPostProcess) {
+            // workaround: surface setMaxDequeuedBufferCount: numOutputSlots + numInputSlots + depth + kRenderingDepth
+            // as default, kRenderingDepth = 3, depth = 0, numInputSlots = 4, numOutputSlots = outputDelayValue + 4
+            // 4 is value of kSmoothnessFactor
+            // so if we return bufferNum directly, surface will setMaxDequeuedBufferCount as bufferNum + 4 + 4 + 3,
+            // it's too much for VPU, we can cut some here to avoid it exceed the max value(32).
+            if (mOutputFormat.bufferNum >= 18)
+                mOutputFormat.bufferNum -= (4+4);
+        }
+
+        struct v4l2_crop crop;
+        crop.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+
+        result = ioctl (mFd, VIDIOC_G_CROP, &crop);
+        if(result < 0)
+            return UNKNOWN_ERROR;
+
+        mOutputFormat.rect.right = crop.c.width;
+        mOutputFormat.rect.bottom = crop.c.height;
+        mOutputFormat.rect.top = crop.c.top;
+        mOutputFormat.rect.left = crop.c.left;
+    }
+
+    if(pre_state == STOPPING || pre_state == FLUSHING){
+        ALOGI("do not handle resolution while flushing or stopping");
+        return OK;
+    }
+
+    if (bFetchStarted) {
+        destroyFetchThread();
+    }
+
+    if (bOutputStreamOn) {
+        stopOutputStream();
+        // clear capture buffer
+        mOutputBufferMap.clear();
+
+        SetOutputFormats();
+    }
+
+    outputFormatChanged();
+
+    ALOGV("outputFormatChanged w=%d,h=%d,buf cnt=%d, buffer size[0]=%d,size[1]=%d",
+        mOutputFormat.width, mOutputFormat.height, mOutputFormat.minBufferNum, mOutputPlaneSize[0], mOutputPlaneSize[1]);
+    return OK;
+}
+
+status_t V4l2Dec::getVideoColorAspect(VideoColorAspect *info)
+{
+
+    if(info == NULL)
+        return UNKNOWN_ERROR;
+
+    return pDev->GetColorDesc(info);
+}
+
+status_t V4l2Dec::stopStreaming() {
+    status_t ret = UNKNOWN_ERROR;
+
+    ret = stopInputStream();
+    if(ret != OK)
+        return ret;
+
+    ret = stopOutputStream();
+    if(ret != OK)
+        return ret;
+
+    ret = destroyPollThread();
+    if(ret != OK)
+        return ret;
+
+    ret = destroyFetchThread();
+
+    return ret;
+}
+
+status_t V4l2Dec::startStreaming() {
+    status_t ret = UNKNOWN_ERROR;
+
+    ret = startInputStream();
+    if(ret != OK)
+        return ret;
+
+    ret = startOutputStream();
+    if(ret != OK)
+        return ret;
+
+    ret = createPollThread();
+    if(ret != OK)
+        return ret;
+
+    ret = createFetchThread();
+
+    return ret;
+
+}
+
+status_t V4l2Dec::onFlush()
+{
+    ALOGV("%s", __FUNCTION__);
+    int pre_state;
+    {
+        Mutex::Autolock autoLock(mLock);
+        pre_state = mState;
+        mState = FLUSHING;
+    }
+    status_t ret = UNKNOWN_ERROR;
+
+    // let codecdata queue again after each seek
+    bCodecDataQueued = false;
+
+    ret = stopInputStream();
+    if(ret != OK)
+        return ret;
+
+    ret = stopOutputStream();
+    if(ret != OK)
+        return ret;
+
+    mState = pre_state;
+    mInCnt = 0;
+    mOutCnt = 0;
+    bReceiveError = false;
+    ALOGV("%s end", __FUNCTION__);
+    return ret;
+}
+status_t V4l2Dec::onStop()
+{
+
+    ALOGV("%s", __FUNCTION__);
+    status_t ret = UNKNOWN_ERROR;
+    {
+    Mutex::Autolock autoLock(mLock);
+    mState = STOPPING;
+    }
+    ret = onFlush();
+    if(ret != OK){
+        return ret;
+    }
+
+    ret = destroyPollThread();
+    if(ret != OK){
+        return ret;
+    }
+
+    ret = destroyFetchThread();
+    if(ret != OK){
+        return ret;
+    }
+
+    ret = destroyInputBuffers();
+    if(ret != OK){
+        return ret;
+    }
+
+    ret = destroyOutputBuffers();
+    if(ret != OK){
+        return ret;
+    }
+
+    Mutex::Autolock autoLock(mLock);
+    mState = STOPPED;
+
+    if(pDev != NULL)
+        pDev->ResetDecoder();
+    ALOGV("%s end", __FUNCTION__);
+    return OK;
+}
+status_t V4l2Dec::onDestroy()
+{
+    status_t ret = UNKNOWN_ERROR;
+    ALOGV("%s", __FUNCTION__);
+
+    if(mState != STOPPED){
+        onStop();
+        mState = STOPPED;
+    }
+
+    Mutex::Autolock autoLock(mLock);
+
+    if(mFd > 0){
+        pDev->Close();
+        ALOGV("pDev->Close %d",mFd);
+        mFd = 0;
+    }
+
+    if(pDev != NULL)
+        delete pDev;
+    pDev = NULL;
+    ALOGV("%s end", __FUNCTION__);
+    return OK;
+}
+
+bool V4l2Dec::checkIfPostProcessNeeded() {
+    return bNeedPostProcess;
+}
+
+VideoDecoderBase * CreateVideoDecoderInstance(const char* mime) {
+    return static_cast<VideoDecoderBase *>(new V4l2Dec(mime));
+}
+}
diff --git a/codec2/video_dec/v4l2_dec/V4l2Dec.h b/codec2/video_dec/v4l2_dec/V4l2Dec.h
new file mode 100755
index 0000000..eed0e37
--- /dev/null
+++ b/codec2/video_dec/v4l2_dec/V4l2Dec.h
@@ -0,0 +1,172 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+#ifndef V4L2_DECODER_H
+#define V4L2_DECODER_H
+
+#include "VideoDecoderBase.h"
+#include "V4l2Dev.h"
+
+
+namespace android {
+
+class V4l2Dec : public VideoDecoderBase{
+public:
+    V4l2Dec(const char* mime);
+    status_t onInit() override;
+    status_t onStart() override;
+    status_t onFlush() override;
+    status_t onStop() override;
+    status_t onDestroy() override;
+
+    bool checkIfPostProcessNeeded() override;
+
+    status_t prepareOutputBuffers();
+    status_t destroyOutputBuffers();
+    status_t decodeInternal(std::unique_ptr<IMXInputBuffer> input);
+    //status_t queueInput(C2FrameData * input, int32_t input_id);
+    status_t queueOutput(GraphicBlockInfo* pInfo);
+    status_t queueOutput(int index);
+    status_t dequeueInputBuffer();
+    status_t dequeueOutputBuffer();
+
+    status_t importOutputBuffers(std::vector<GraphicBlockInfo> buffers) override;
+    status_t getVideoColorAspect(VideoColorAspect *info);
+
+protected:
+    virtual ~V4l2Dec();
+    status_t DoSetConfig(DecConfig index, void* pConfig) override;
+    status_t DoGetConfig(DecConfig index, void* pConfig) override;
+
+    status_t allocateOutputBuffers() override;
+    status_t freeOutputBuffers() override;
+
+private:
+    enum {
+        kInputBufferPlaneNum = 1,
+        kOutputBufferPlaneNum = 2,
+
+    };
+
+    struct VideoFramePlane {
+        int32_t fd;
+        uint64_t vaddr;
+        uint64_t paddr;
+        uint32_t size;
+        uint32_t length;
+        uint32_t offset;
+    };
+
+    // Record for input buffers.
+    struct InputRecord {
+        InputRecord();
+        ~InputRecord();
+        bool at_device;    // held by device.
+        VideoFramePlane plane;
+        int32_t input_id;
+        int64_t ts;
+    };
+
+
+    struct OutputRecord {
+        OutputRecord();
+        OutputRecord(OutputRecord&&) = default;
+        ~OutputRecord();
+        bool at_device;
+        VideoFramePlane planes[kOutputBufferPlaneNum];
+        int32_t picture_id;     // picture buffer id as returned to PictureReady().
+        uint32_t flag;
+        std::shared_ptr<C2GraphicBlock> mGraphicBlock;
+    };
+
+    enum {
+        UNINITIALIZED,
+        STOPPED,
+        RUNNING,
+        STOPPING,
+        FLUSHING,
+        RES_CHANGING,
+    };
+
+    const char* mMime;
+    pthread_t mPollThread;
+    pthread_t mFetchThread;
+
+    V4l2Dev* pDev;
+    int32_t mFd;
+
+    enum v4l2_memory mInMemType;//support userptr and dma
+    enum v4l2_memory mOutMemType;//support userptr and dma
+
+
+    uint32_t mInFormat;//v4l2 input format
+    std::vector<InputRecord> mInputBufferMap;
+    std::vector<OutputRecord> mOutputBufferMap;
+
+    Mutex mLock;
+
+    bool bPollStarted;
+    bool bPollStopped;
+    bool bFetchStarted;
+    bool bFetchStopped;
+
+    bool bInputStreamOn;
+    bool bOutputStreamOn;
+
+    bool bCodecDataQueued;
+
+    bool bNeedPostProcess;
+
+    int mState;
+
+    uint32_t mVpuOwnedOutputBufferNum;
+
+    uint32_t mOutputPlaneSize[kOutputBufferPlaneNum];
+    uint32_t mOutFormat;//v4l2 output format
+
+    uint32_t mVc1Format;
+
+    uint32_t mInCnt;
+    uint32_t mOutCnt;
+
+
+    status_t prepareInputParams();
+    status_t SetInputFormats();
+    status_t prepareOutputParams();
+    status_t SetOutputFormats();
+
+    status_t prepareInputBuffers();
+    status_t createInputBuffers();
+    status_t destroyInputBuffers();
+
+    status_t createPollThread();
+    status_t destroyPollThread();
+    status_t createFetchThread();
+    status_t destroyFetchThread();
+
+    status_t startInputStream();
+    status_t stopInputStream();
+    status_t startOutputStream();
+    status_t stopOutputStream();
+
+    status_t stopStreaming();
+    status_t startStreaming();
+
+    status_t onDequeueEvent();
+
+    static void *PollThreadWrapper(void *);
+    status_t HandlePollThread();
+    static void *FetchThreadWrapper(void *);
+    status_t HandleFetchThread();
+
+    status_t handleFormatChanged();
+};
+
+
+
+}
+#endif
diff --git a/codec2/video_dec/v4l2_dec/v4l2_dec.go b/codec2/video_dec/v4l2_dec/v4l2_dec.go
new file mode 100644
index 0000000..7a6feb2
--- /dev/null
+++ b/codec2/video_dec/v4l2_dec/v4l2_dec.go
@@ -0,0 +1,57 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package v4l2_dec
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_v4l2_dec_defaults", v4l2DefaultsFactory)
+}
+
+
+func v4l2DefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, v4l2Defaults)
+    return module
+}
+
+func v4l2Defaults(ctx android.LoadHookContext) {
+    var Cflags []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Cflags []string
+                }
+        }
+    }
+    p := &props{}
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8Q") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else {
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
+    }
+    if ctx.Config().VendorConfig("IMXPLUGIN").String("CFG_SECURE_DATA_PATH") == "y" {
+        Cflags = append(Cflags, "-DALWAYS_ENABLE_SECURE_PLAYBACK")
+    }
+    p.Target.Android.Cflags = Cflags
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/video_dec/video_dec.go b/codec2/video_dec/video_dec.go
new file mode 100644
index 0000000..476a785
--- /dev/null
+++ b/codec2/video_dec/video_dec.go
@@ -0,0 +1,66 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package video_dec
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_video_dec_defaults", video_decDefaultsFactory)
+}
+
+func video_decDefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, video_decDefaults)
+    return module
+}
+
+func video_decDefaults(ctx android.LoadHookContext) {
+    var Shared_libs []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Shared_libs []string
+                }
+        }
+    }
+    p := &props{}
+    p.Target.Android.Enabled = proptools.BoolPtr(false)
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8MM") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_dec")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_process_dummy_post")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else if strings.Contains(board, "IMX8MQ") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_dec")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_process_dummy_post")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else if strings.Contains(board, "IMX8MP") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_dec")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_process_dummy_post")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else if strings.Contains(board, "IMX8Q") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_v4l2_dec")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_process_g2d_post")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    }
+    p.Target.Android.Shared_libs = Shared_libs
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/video_dec/vpuwrapper_dec/Android.bp b/codec2/video_dec/vpuwrapper_dec/Android.bp
new file mode 100644
index 0000000..eeb2088
--- /dev/null
+++ b/codec2/video_dec/vpuwrapper_dec/Android.bp
@@ -0,0 +1,56 @@
+imx_c2_vpuwrapper_dec_defaults {
+    name: "imx_c2_vpuwrapper_dec_default",
+}
+
+
+bootstrap_go_package {
+    name: "soong-vpuwrapper_dec",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/video_dec/vpuwrapper_dec",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "vpuwrapper_dec.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+cc_library_shared {
+    name: "lib_imx_c2_vpuwrapper_dec",
+
+    defaults: [
+        "imx_c2_vpuwrapper_dec_default",
+        "imx_defaults",
+    ],
+
+    include_dirs: [
+        "frameworks/av",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/vpu_wrapper",
+        "vendor/nxp/imx_android_mm/codec2/video_dec/common",
+        "vendor/nxp/imx_android_mm/codec2/tsm",
+        "vendor/nxp/imx_android_mm/extractor",
+    ],
+
+    shared_libs: [
+        "liblog",
+        "libutils",
+        "lib_vpu_wrapper",
+        "libcodec2",
+        "libcodec2_vndk",
+        "libstagefright_foundation", // for Mutexed
+        "lib_imx_ts_manager",
+        "lib_imx_c2_videodec_common",
+    ],
+
+    srcs: [
+        "VpuWrapperDec.cpp",
+    ],
+}
+
+
diff --git a/codec2/video_dec/vpuwrapper_dec/VpuWrapperDec.cpp b/codec2/video_dec/vpuwrapper_dec/VpuWrapperDec.cpp
new file mode 100755
index 0000000..115113b
--- /dev/null
+++ b/codec2/video_dec/vpuwrapper_dec/VpuWrapperDec.cpp
@@ -0,0 +1,1524 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "VpuWrapperDec"
+
+#include <media/stagefright/MediaDefs.h>
+#include <C2PlatformSupport.h>
+#include <sys/mman.h>
+
+#include "VpuWrapperDec.h"
+#include "graphics_ext.h"
+#include "Tsm_wrapper.h"
+#include "Imx_ext.h"
+
+namespace android {
+
+#define VPU_COMP_INFO ALOGI
+
+#define VPU_COMP_DBGLOG
+#ifdef VPU_COMP_DBGLOG
+#define VPU_COMP_LOG    ALOGV
+#else
+#define VPU_COMP_LOG(...)
+#endif
+
+#define VPU_COMP_API_DBGLOG
+#ifdef VPU_COMP_API_DBGLOG
+#define VPU_COMP_API_LOG    ALOGV
+#else
+#define VPU_COMP_API_LOG(...)
+#endif
+
+#define VPU_COMP_ERR_DBGLOG
+#ifdef VPU_COMP_ERR_DBGLOG
+#define VPU_COMP_ERR_LOG	ALOGE
+#define ASSERT(exp)	if(!(exp)) {ALOGE("%s: %d : assert condition !!!
",__FUNCTION__,__LINE__);}
+#else
+#define VPU_COMP_ERR_LOG    ALOGE
+#define ASSERT(...)
+#endif
+
+#define MAX_FRAME_NUM (30)
+// align with hantro definition
+#define MAX_VC1_FRAME_NUM 15
+#define MAX_RV_FRAME_NUM  16
+
+#define DEFAULT_OUT_BUF_CNT (5)
+#define FRAME_SURPLUS	(2)
+#define FRAME_MIN_FREE_THD (sInitInfo.nMinFrameBufferCount - 3)
+#define DEFAULT_BUF_DELAY   (0)
+
+#define INVALID_ID (-1)
+
+//stride and slice height are both 16 for g1 decoder
+//stride is 16 and slice height is 8 for g2 decoder
+#define IS_G2_DECODER   ((eCodingFormat == VPU_V_HEVC) || (eCodingFormat == VPU_V_VP9))
+#undef FRAME_ALIGN
+#define FRAME_ALIGN (8)
+#define FRAME_ALIGN_WIDTH (FRAME_ALIGN*2)
+#define FRAME_ALIGN_HEIGHT (IS_G2_DECODER ? FRAME_ALIGN : FRAME_ALIGN_WIDTH)
+
+#define Align(ptr,align)	(((unsigned long)(ptr)+(align)-1)/(align)*(align))
+
+#define VPURET2ERR(ret) ((ret != VPU_DEC_RET_SUCCESS) ? BAD_VALUE : OK)
+#define CHECK_VPU_RET(ret) if (ret != VPU_DEC_RET_SUCCESS) {ALOGE("%s line %d, ret %d
", __FUNCTION__, __LINE__, ret); return VPURET2ERR(ret);}
+#define CHECK_DEC_STATE(state) \
+    if (eVpuDecoderState != state) {\
+        VPU_COMP_ERR_LOG("%s: failure: error state transition, current state=%d
", __FUNCTION__, eVpuDecoderState);\
+        return INVALID_OPERATION;\
+    }
+
+
+
+static int pxlfmt2bpp(int pxlfmt) {
+	int bpp; // bit per pixel
+
+	switch(pxlfmt) {
+    	case HAL_PIXEL_FORMAT_YCbCr_420_P:
+    	case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+        case HAL_PIXEL_FORMAT_YCBCR_420_888:
+        case HAL_PIXEL_FORMAT_NV12_TILED:
+    	  bpp = 12;
+    	  break;
+        case HAL_PIXEL_FORMAT_P010:
+        case HAL_PIXEL_FORMAT_P010_TILED:
+        case HAL_PIXEL_FORMAT_P010_TILED_COMPRESSED:
+          bpp = 15;
+          break;
+    	case HAL_PIXEL_FORMAT_RGB_565:
+    	case HAL_PIXEL_FORMAT_YCbCr_422_P:
+    	case HAL_PIXEL_FORMAT_YCbCr_422_SP:
+        case HAL_PIXEL_FORMAT_YCBCR_422_I:
+            bpp = 16;
+            break;
+    	default:
+    	  bpp = 0;
+    	  break;
+	}
+	return bpp;
+}
+
+int ConvertMjpg2PixelFormat(int sourceFormat, int oriColorFmt) {
+	int	pixelFormat;
+	int interleave = 0;
+
+	switch (oriColorFmt) {
+		case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+		case HAL_PIXEL_FORMAT_YCbCr_422_SP:
+		//FIXME: add 4:0:0/4:4:4/...
+			interleave=1;
+			break;
+		default:
+			break;
+	}
+
+	switch (sourceFormat) {
+		case VPU_COLOR_420:
+			pixelFormat = (1 == interleave) ? HAL_PIXEL_FORMAT_YCbCr_420_SP : HAL_PIXEL_FORMAT_YCbCr_420_P;
+			break;
+		case VPU_COLOR_422H:
+			pixelFormat = (1 == interleave) ? HAL_PIXEL_FORMAT_YCbCr_422_SP : HAL_PIXEL_FORMAT_YCbCr_422_P;
+			break;
+		default:	//unknow
+			VPU_COMP_ERR_LOG("unknown mjpg color format: %d 
", sourceFormat);
+			pixelFormat = 0;
+			break;
+	}
+
+	return pixelFormat;
+}
+
+// frame pool functions
+int32_t FramePoolRegisterBuf(unsigned long pInVirtAddr, unsigned long pInPhyAddr, int32_t bufferId, VpuDecoderFrmPoolInfo * pOutFrmPool) {
+	int32_t i;
+	for (i = 0; i < VPU_DEC_MAX_NUM_MEM; i++) {
+		//insert into empty node
+		if (0 == pOutFrmPool->nFrm_phyAddr[i]) {
+			pOutFrmPool->eFrmState[i] = VPU_COM_FRM_STATE_FREE;
+			pOutFrmPool->nFrm_phyAddr[i] = pInPhyAddr;
+			pOutFrmPool->nFrm_virtAddr[i] = pInVirtAddr;
+            pOutFrmPool->nFrm_bufferId[i] = bufferId;
+			pOutFrmPool->nFrmNum++;
+			return pOutFrmPool->nFrmNum;
+		}
+	}
+	return -1;
+}
+
+int32_t FramePoolBufExist(int32_t bufferId, VpuDecoderFrmPoolInfo* pInFrmPool, int32_t* pOutIndx) {
+	int32_t i;
+
+	for(i = 0; i < VPU_DEC_MAX_NUM_MEM; i++) {
+		if (bufferId == pInFrmPool->nFrm_bufferId[i]) {
+			*pOutIndx = i;
+			return 1;
+		}
+	}
+	return 0;
+}
+
+void FramePoolGetBufProperty(VpuDecoderFrmPoolInfo* pInFrmPool, int32_t Index, VpuDecoderFrmState* pOutState, VpuDecOutFrameInfo** ppOutFrame) {
+	*pOutState = pInFrmPool->eFrmState[Index];
+	*ppOutFrame = &pInFrmPool->outFrameInfo[Index];
+}
+
+void FramePoolSetBufState(VpuDecoderFrmPoolInfo* pInFrmPool, int32_t Index,VpuDecoderFrmState eInState) {
+	pInFrmPool->eFrmState[Index] = eInState;
+}
+
+int32_t FramePoolBufNum(VpuDecoderFrmPoolInfo* pInFrmPool) {
+	return pInFrmPool->nFrmNum;
+}
+
+void FramePoolClear(VpuDecoderFrmPoolInfo* pOutFrmPool) {
+	memset(pOutFrmPool, 0, sizeof(VpuDecoderFrmPoolInfo));
+
+    int i;
+    for(i = 0; i < VPU_DEC_MAX_NUM_MEM; i++) {
+        pOutFrmPool->nFrm_bufferId[i] = -1;
+	}
+}
+
+int32_t FramePoolDecoderOutReset(VpuDecoderFrmPoolInfo* pInFrmPool, int32_t nInFrameBufNum) {
+	int32_t i;
+	int32_t nDecCnt = 0;
+	int32_t nClearedCnt = 0;
+
+	for (i = 0; i < VPU_DEC_MAX_NUM_MEM; i++) {
+    	if(pInFrmPool->nFrm_virtAddr[i]) {
+            if (pInFrmPool->eFrmState[i] != VPU_COM_FRM_STATE_OUT) {
+			    pInFrmPool->eFrmState[i] = VPU_COM_FRM_STATE_OUT;
+			    pInFrmPool->outFrameInfo[i].pDisplayFrameBuf = NULL;
+			    nClearedCnt++;
+            }
+            nDecCnt++;
+		}
+	}
+	ASSERT(nInFrameBufNum == nDecCnt);
+	return nClearedCnt;
+}
+
+int32_t FramePoolRecordOutFrame(int32_t bufferId, VpuDecoderFrmPoolInfo* pInFrmPool, VpuDecOutFrameInfo* pInFrameInfo) {
+	int32_t i;
+	//search matched node and restore output frame info
+	for(i = 0; i < VPU_DEC_MAX_NUM_MEM; i++) {
+	    if(pInFrmPool->nFrm_bufferId[i] == bufferId) {
+			pInFrmPool->outFrameInfo[i] = *pInFrameInfo;
+			return i;
+		}
+	}
+	return -1;
+}
+
+
+int32_t FramePoolFindOneDecoderUnOutputed(VpuDecoderFrmPoolInfo* pInFrmPool, VpuDecOutFrameInfo** ppOutFrame) {
+	uint32_t i;
+	//find one un-outputed frame
+	for (i = 0; i < VPU_DEC_MAX_NUM_MEM; i++) {
+			if (pInFrmPool->eFrmState[i] != VPU_COM_FRM_STATE_OUT) {
+				*ppOutFrame = &pInFrmPool->outFrameInfo[i];
+				return i;
+			}
+	}
+	*ppOutFrame = NULL;
+	return -1;
+}
+
+int32_t MemFreeBlock(VpuMemInfo* pMemBlock) {
+	int i;
+    int32_t err = 1; // ok
+
+	for (i = 0; i < pMemBlock->nSubBlockNum; i++) {
+		if (pMemBlock->MemSubBlock[i].MemType == VPU_MEM_VIRT && pMemBlock->MemSubBlock[i].pVirtAddr) {
+            free(pMemBlock->MemSubBlock[i].pVirtAddr);
+            pMemBlock->MemSubBlock[i].pVirtAddr = nullptr;
+        } else if (pMemBlock->MemSubBlock[i].MemType == VPU_MEM_PHY && pMemBlock->MemSubBlock[i].pPhyAddr) {
+			VpuMemDesc vpuMem;
+			VpuDecRetCode ret;
+			vpuMem.nSize = pMemBlock->MemSubBlock[i].nSize;
+            vpuMem.nType = VPU_MEM_DESC_NORMAL;
+            vpuMem.nVirtAddr = (unsigned long)pMemBlock->MemSubBlock[i].pVirtAddr;
+            vpuMem.nPhyAddr = (unsigned long)pMemBlock->MemSubBlock[i].pPhyAddr;
+            vpuMem.nCpuAddr = (unsigned long)pMemBlock->MemSubBlock[i].nFd;
+			ret = VPU_DecFreeMem(&vpuMem);
+			if (ret != VPU_DEC_RET_SUCCESS) {
+				VPU_COMP_LOG("%s: free vpu memory failure, ret=%d
", __FUNCTION__, ret);
+                err = 0;
+			}
+			pMemBlock->MemSubBlock[i].pVirtAddr = nullptr;
+			pMemBlock->MemSubBlock[i].pPhyAddr = nullptr;
+            pMemBlock->MemSubBlock[i].nFd = -1;
+		}
+	}
+
+	return err;
+}
+
+int32_t MemMallocBlock(VpuMemInfo* pMemBlock) {
+	int i;
+	int size;
+
+    VPU_COMP_API_LOG("%s: ", __FUNCTION__);
+
+	for (i = 0; i < pMemBlock->nSubBlockNum; i++) {
+		size = pMemBlock->MemSubBlock[i].nAlignment + pMemBlock->MemSubBlock[i].nSize;
+		if (pMemBlock->MemSubBlock[i].MemType == VPU_MEM_VIRT) {
+            unsigned char * ptr = (unsigned char *)malloc(size);
+			if (ptr == NULL) {
+				VPU_COMP_ERR_LOG("%s: get virtual memory failure, size=%d 
", __FUNCTION__, size);
+				return 0;
+			}
+			pMemBlock->MemSubBlock[i].pVirtAddr=(unsigned char *)Align(ptr, pMemBlock->MemSubBlock[i].nAlignment);
+        } else {
+			VpuMemDesc vpuMem;
+			VpuDecRetCode ret;
+			vpuMem.nSize = size;
+            vpuMem.nType = VPU_MEM_DESC_NORMAL;
+			ret = VPU_DecGetMem(&vpuMem);
+			if(ret != VPU_DEC_RET_SUCCESS) {
+				VPU_COMP_ERR_LOG("%s: get vpu memory failure, size=%d, ret=0x%X 
", __FUNCTION__, size, ret);
+				return 0;
+			}
+
+			pMemBlock->MemSubBlock[i].pVirtAddr = (unsigned char *)Align(vpuMem.nVirtAddr,pMemBlock->MemSubBlock[i].nAlignment);
+			pMemBlock->MemSubBlock[i].pPhyAddr = (unsigned char *)Align(vpuMem.nPhyAddr,pMemBlock->MemSubBlock[i].nAlignment);
+            pMemBlock->MemSubBlock[i].nFd = (int)vpuMem.nCpuAddr;
+            pMemBlock->MemSubBlock[i].nSize = vpuMem.nSize; // update size because phys size is larger due to align with pagesize
+
+            if (pMemBlock->MemSubBlock[i].pVirtAddr != (unsigned char *)vpuMem.nVirtAddr ||
+                    pMemBlock->MemSubBlock[i].pPhyAddr != (unsigned char *)vpuMem.nPhyAddr)
+                VPU_COMP_LOG("VPU_DecGetMem not aligned, nAlignment %d", pMemBlock->MemSubBlock[i].nAlignment);
+		}
+	}
+
+	return 1;
+}
+
+status_t VpuWrapperDec::createFetchThread() {
+    Mutex::Autolock autoLock(mLock);
+    if (FETCH_STATE_NONE == mFetchState) {
+        mFetchState = FETCH_STATE_START;
+
+        pthread_attr_t attr;
+        pthread_attr_init(&attr);
+        pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+
+        pthread_create(&mFetchThread, &attr, FetchThreadWrapper, this);
+        pthread_attr_destroy(&attr);
+
+        pFetchThreadMutex = malloc(sizeof(pthread_mutex_t));
+        if (!pFetchThreadMutex) {
+            ALOGE("malloc pFetchThreadMutex failed");
+            return BAD_VALUE;
+        }
+
+        pthread_mutexattr_t attr1;
+        pthread_mutexattr_init(&attr1);
+        pthread_mutexattr_settype(&attr1,PTHREAD_MUTEX_NORMAL);
+        pthread_mutex_init((pthread_mutex_t *)(pFetchThreadMutex), &attr1);
+        pthread_cond_init(&pFetchThreadCond, NULL);
+        pthread_mutexattr_destroy(&attr1);
+
+        ALOGV("createFetchThread done");
+
+    }
+    return OK;
+}
+
+status_t VpuWrapperDec::destroyFetchThread() {
+    if (FETCH_STATE_NONE != mFetchState) {
+        mFetchState = FETCH_STATE_STOPPING;
+        do {
+            usleep(10);
+        } while (FETCH_STATE_NONE != mFetchState);
+
+        Mutex::Autolock autoLock(mLock);
+
+        pthread_join(mFetchThread, NULL);
+
+        if (pFetchThreadMutex) {
+            free(pFetchThreadMutex);
+            pFetchThreadMutex = nullptr;
+        }
+
+        pthread_cond_destroy(&pFetchThreadCond);
+        ALOGV("destroyFetchThread done");
+    }
+
+    return OK;
+}
+
+void *VpuWrapperDec::FetchThreadWrapper(void *me) {
+    return (void *)(uintptr_t)static_cast<VpuWrapperDec *>(me)->HandleFetchThread();
+}
+
+status_t VpuWrapperDec::HandleFetchThread() {
+    do {
+        if (nFetchBufferNum <= 0) {
+            usleep(1000);
+            continue;
+        }
+
+        GraphicBlockInfo *gbInfo = getFreeGraphicBlock();
+        if (!gbInfo) {
+            status_t ret = fetchOutputBuffer();
+            if (WOULD_BLOCK == ret) {
+                continue;
+            } else if (OK != ret) {
+                bReceiveError = true;
+                break;
+            } else
+                gbInfo = getFreeGraphicBlock();
+        }
+        if (gbInfo) {
+            status_t ret = setOutputBuffer(gbInfo->mBlockId);
+            if (ret != OK) {
+                // because hantro vpu set the max number of registered frame buffer,
+                // if decoder fetch a new buffer but excceed the number, setOutputBuffer failed
+                // decoder need to release this buffer and fetch again until fetch a previous
+                // registered frame buffer.
+                removeGraphicBlockById(gbInfo->mBlockId);
+                usleep(5000);
+                continue;
+            } else {
+                Mutex::Autolock autoLock(mLock);
+                nFetchBufferNum--;
+                pthread_cond_signal(&pFetchThreadCond);
+            }
+        }
+    } while (mFetchState != FETCH_STATE_STOPPING);
+    ALOGV("HandleFetchThread stopped");
+    mFetchState = FETCH_STATE_NONE;
+    return OK;
+}
+
+VpuWrapperDec::VpuWrapperDec(const char* mime)
+    : mMime(mime) {
+    // init mMime2TypeMap
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_AVC, VPU_V_AVC);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_HEVC, VPU_V_HEVC);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_VP8, VPU_V_VP8);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_VP9, VPU_V_VP9);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_MPEG2, VPU_V_MPEG2);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_MPEG4, VPU_V_MPEG4);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_H263, VPU_V_H263);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_XVID, VPU_V_XVID);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_MJPEG, VPU_V_MJPG);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_VC1, VPU_V_VC1);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_REAL, VPU_V_RV);
+
+    SetDefaultSetting();
+}
+
+VpuWrapperDec::~VpuWrapperDec() {
+}
+
+void VpuWrapperDec::SetDefaultSetting() {
+ 	//clear internal variable 0
+	memset(&sMemInfo,0,sizeof(VpuMemInfo));
+	memset(&sInitInfo,0,sizeof(VpuDecInitInfo));
+	memset(&sFramePoolInfo,0,sizeof(VpuDecoderFrmPoolInfo));
+
+    int i;
+    for(i = 0; i < VPU_DEC_MAX_NUM_MEM; i++) {
+        sFramePoolInfo.nFrm_bufferId[i] = -1;
+    }
+
+    mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+    mOutputFormat.width = DEFAULT_FRM_WIDTH;
+    mOutputFormat.height = DEFAULT_FRM_HEIGHT;
+    mOutputFormat.bufferNum = DEFAULT_OUT_BUF_CNT;
+    mOutputFormat.minBufferNum = DEFAULT_OUT_BUF_CNT;
+    mOutputFormat.bufferSize = mOutputFormat.width * mOutputFormat.height * pxlfmt2bpp(mOutputFormat.pixelFormat) / 8;
+    mOutputFormat.rect.left = 0;
+    mOutputFormat.rect.top = 0;
+    mOutputFormat.rect.right = mOutputFormat.width;
+    mOutputFormat.rect.bottom = mOutputFormat.height;
+    mOutputFormat.interlaced = false;
+
+    nFreeOutBufferCnt = 0;
+    nOwnedInputCnt = 0;
+
+	nHandle = nullptr;
+    hTsHandle = nullptr;
+    bResyncTsm = true;
+
+	eCodingFormat = VPU_V_AVC;
+
+	nFrameWidthStride = -1;	//default: invalid
+	nFrameHeightStride = -1;
+	nFrameMaxCnt = -1;
+
+	bInEos = false;
+
+    nCurInputId = INVALID_ID;
+    nSkippedInputId = INVALID_ID;
+
+	eVpuDecoderState = VPU_COM_STATE_NONE;
+
+	nCapability = 0;
+
+	nMaxDurationMsThr = -1;
+	nMaxBufCntThr = -1;
+
+	bReorderDisabled = false;
+    bHasCodecColorDesc = false;
+    bHasHdr10StaticInfo = false;
+    memset(&sDecoderColorDesc,0,sizeof(DecColorAspects));
+    memset(&sParserColorDesc,0,sizeof(DecColorAspects));
+    memset(&sHdr10StaticInfo,0,sizeof(DecStaticHDRInfo));
+
+    nYOffset = 0;
+    nUVOffset = 0;
+
+    mFetchThread = 0;
+    mFetchState = FETCH_STATE_NONE;
+    pFetchThreadMutex = nullptr;
+    nFetchBufferNum = 0;
+
+	return;
+}
+
+void VpuWrapperDec::ResetDecoder() {
+    VPU_COMP_API_LOG("%s: state: %d  
", __FUNCTION__, eVpuDecoderState);
+
+    bInEos = false;
+    bReceiveError = false;
+    nCurInputId = INVALID_ID;
+    nSkippedInputId = INVALID_ID;
+    nOwnedInputCnt = 0;
+
+    tsmFlush(hTsHandle);
+    bResyncTsm = true;
+
+	//check state
+    switch (eVpuDecoderState) {
+        case VPU_COM_STATE_NONE:
+        case VPU_COM_STATE_OPENED:
+            FramePoolClear(&sFramePoolInfo);
+            break;
+        case VPU_COM_STATE_DO_DEC:
+        case VPU_COM_STATE_EOS: {
+            //flush vpu input/output
+            FlushFilter();
+            break;
+    }
+    default:
+        //forbidden !!!
+        VPU_COMP_ERR_LOG("%s: unknown state transition, current state=%d 
", __FUNCTION__, eVpuDecoderState);
+    }
+
+}
+
+status_t VpuWrapperDec::ProcessVpuInitInfo() {
+    VPU_COMP_API_LOG("%s line %d", __FUNCTION__, __LINE__);
+	VpuDecRetCode ret;
+	int nChanged=0;
+    uint32_t padWidth, padHeight;
+
+    eVpuDecoderState = VPU_COM_STATE_PROCESSING_INIT_INFO;
+
+    //process init info
+	ret = VPU_DecGetInitialInfo(nHandle, &sInitInfo);
+	if (VPU_DEC_RET_SUCCESS != ret) {
+		VPU_COMP_ERR_LOG("%s: vpu get init info failure: ret=0x%X 
", __FUNCTION__, ret);
+		return BAD_VALUE;
+	}
+
+    padWidth = Align(sInitInfo.nPicWidth, FRAME_ALIGN_WIDTH);
+    padHeight = Align(sInitInfo.nPicHeight , FRAME_ALIGN_HEIGHT);
+
+    //check change for nFrameWidth/nFrameHeight
+    if ((mOutputFormat.width != padWidth) || (mOutputFormat.height != padHeight)) {
+        mOutputFormat.width = padWidth;
+        mOutputFormat.height = padHeight;
+        nChanged = 1;
+    }
+
+    //check color format, only for mjpg : 4:2:0/4:2:2(ver/hor)/4:4:4/4:0:0
+    if (VPU_V_MJPG == eCodingFormat) {
+        int pixelFormat;
+        pixelFormat = ConvertMjpg2PixelFormat(sInitInfo.nMjpgSourceFormat, mOutputFormat.pixelFormat);
+
+        if (pixelFormat == 0) {
+            return BAD_TYPE;
+        } else if(pixelFormat != mOutputFormat.pixelFormat) {
+            mOutputFormat.pixelFormat = pixelFormat;
+            nChanged = 1;
+        }
+
+    }
+
+    if(mOutputFormat.pixelFormat != HAL_PIXEL_FORMAT_YCbCr_420_SP && mOutputFormat.pixelFormat != HAL_PIXEL_FORMAT_YCbCr_422_SP
+        && mOutputFormat.pixelFormat != 0){
+        if(IS_G2_DECODER){
+            mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_NV12_G2_TILED_COMPRESSED;
+        }else{
+            mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_NV12_G1_TILED;
+        }
+    }
+	//TODO: check change for sOutCrop ?
+	//...
+
+	//set crop info
+	VPU_COMP_LOG("%s: original init info: [top,left,bottom,right]=[%d,%d,%d,%d], 
",__FUNCTION__,
+		sInitInfo.PicCropRect.nTop, sInitInfo.PicCropRect.nLeft, sInitInfo.PicCropRect.nBottom, sInitInfo.PicCropRect.nRight);
+
+    mOutputFormat.rect.left = sInitInfo.PicCropRect.nLeft;
+    mOutputFormat.rect.top = sInitInfo.PicCropRect.nTop;
+    mOutputFormat.rect.right = sInitInfo.PicCropRect.nRight;
+    mOutputFormat.rect.bottom = sInitInfo.PicCropRect.nBottom;
+
+    //check change for mOutputFormat.bufferNumDec
+    if (sInitInfo.nMinFrameBufferCount + FRAME_SURPLUS != mOutputFormat.bufferNum) {
+        mOutputFormat.bufferNum = sInitInfo.nMinFrameBufferCount + FRAME_SURPLUS;
+    }
+
+    mOutputFormat.minBufferNum = sInitInfo.nMinFrameBufferCount;
+
+    // some SD streams need one more buffer to avoid getting a VPU_DEC_NO_ENOUGH_BUF from vpu wrapper(MA-11547, 11550, 11551)
+    if(sInitInfo.nPicWidth <= 1920 && sInitInfo.nPicHeight <= 1088)
+        mOutputFormat.bufferNum++;
+
+    nFrameMaxCnt = (nFrameMaxCnt < mOutputFormat.bufferNum + FRAME_SURPLUS ?
+                        nFrameMaxCnt : mOutputFormat.bufferNum + FRAME_SURPLUS);
+
+    nChanged = 1;
+
+    VPU_COMP_LOG("%s: Init OK, [width x height]=[%d x %d] 
", __FUNCTION__, sInitInfo.nPicWidth, sInitInfo.nPicHeight);
+    VPU_COMP_LOG("%s: rect [left, right, top, bottom]=[%d, %d, %d, %d]
", __FUNCTION__,
+        mOutputFormat.rect.left, mOutputFormat.rect.right, mOutputFormat.rect.top, mOutputFormat.rect.bottom);
+    VPU_COMP_LOG("mOutputFormat.bufferNumDec:%d ,nPadWidth: %d, nPadHeight: %d 
", mOutputFormat.bufferNum, mOutputFormat.width, mOutputFormat.height);
+
+    if(sInitInfo.hasColorDesc){
+        convertIsoColorAspectsToCodecAspects((DecColorAspects*)&sInitInfo.ColourDesc, &sDecoderColorDesc);
+        bHasCodecColorDesc = true;
+
+        VPU_COMP_INFO("hasColorDesc, colourPrimaries %d transferCharacteristics %d matrixCoeffs %d fullRange %d",
+            sDecoderColorDesc.colourPrimaries, sDecoderColorDesc.transferCharacteristics,
+            sDecoderColorDesc.matrixCoeffs, sDecoderColorDesc.fullRange);
+    }
+
+    if(sInitInfo.hasHdr10Meta) {
+        bHasHdr10StaticInfo = true;
+        sHdr10StaticInfo.mR[0] = (uint16_t)sInitInfo.Hdr10Meta.redPrimary[0];
+        sHdr10StaticInfo.mR[1] = (uint16_t)sInitInfo.Hdr10Meta.redPrimary[1];
+        sHdr10StaticInfo.mG[0] = (uint16_t)sInitInfo.Hdr10Meta.greenPrimary[0];
+        sHdr10StaticInfo.mG[1] = (uint16_t)sInitInfo.Hdr10Meta.greenPrimary[1];
+        sHdr10StaticInfo.mB[0] = (uint16_t)sInitInfo.Hdr10Meta.bluePrimary[0];
+        sHdr10StaticInfo.mB[1] = (uint16_t)sInitInfo.Hdr10Meta.bluePrimary[1];
+        sHdr10StaticInfo.mW[0] = (uint16_t)sInitInfo.Hdr10Meta.whitePoint[0];
+        sHdr10StaticInfo.mW[1] = (uint16_t)sInitInfo.Hdr10Meta.whitePoint[1];
+        sHdr10StaticInfo.mMaxDisplayLuminance = (uint16_t)(sInitInfo.Hdr10Meta.maxMasteringLuminance/10000);
+        sHdr10StaticInfo.mMinDisplayLuminance = (uint16_t)sInitInfo.Hdr10Meta.minMasteringLuminance;
+        sHdr10StaticInfo.mMaxContentLightLevel = (uint16_t)sInitInfo.Hdr10Meta.maxContentLightLevel;
+        sHdr10StaticInfo.mMaxFrameAverageLightLevel = (uint16_t)sInitInfo.Hdr10Meta.maxFrameAverageLightLevel;
+    }
+
+    if (sInitInfo.nBitDepth == 10) {
+        switch (mOutputFormat.pixelFormat) {
+            case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+                mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_P010;
+                break;
+            case HAL_PIXEL_FORMAT_NV12_G1_TILED:
+                mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_P010_TILED;
+                break;
+            case HAL_PIXEL_FORMAT_NV12_G2_TILED_COMPRESSED:
+                mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_P010_TILED_COMPRESSED;
+                break;
+            default:
+                VPU_COMP_ERR_LOG("unknown color format for HDR10: 0x%x", mOutputFormat.pixelFormat);
+        }
+    }
+
+    VPU_COMP_INFO("Vpu InitInfo hasHdr10Meta %s, hasColorDesc %s, nBitDepth %d, eColorFormat 0x%x, minBufferCnt %d, nFrameSize %d",
+        sInitInfo.hasHdr10Meta?"yes":"no", sInitInfo.hasColorDesc?"yes":"no" ,sInitInfo.nBitDepth,
+        mOutputFormat.pixelFormat, sInitInfo.nMinFrameBufferCount, sInitInfo.nFrameSize);
+
+	if (nChanged) {
+	    VPU_COMP_LOG("out format change width=%d,height=%d", mOutputFormat.width, mOutputFormat.height);
+		mOutputFormat.bufferSize = mOutputFormat.width * mOutputFormat.height * pxlfmt2bpp(mOutputFormat.pixelFormat) / 8;
+        if(mOutputFormat.bufferSize < (uint32_t)sInitInfo.nFrameSize)
+            mOutputFormat.bufferSize = sInitInfo.nFrameSize;
+        //sOutFmt.nStride = sInitInfo.nBitDepth == 10 ? mOutputFormat.width * 5 / 4 : mOutputFormat.width;
+        //sOutFmt.nSliceHeight = mOutputFormat.height;
+        if (FETCH_STATE_START == mFetchState) {
+            destroyFetchThread();
+            createFetchThread();
+
+            Mutex::Autolock autoLock(mLock);
+            nFetchBufferNum = 0;
+        }
+        FramePoolClear(&sFramePoolInfo);
+        //update state
+	    eVpuDecoderState = VPU_COM_STATE_WAIT_FRM;
+        if ( OK != outputFormatChanged())
+            return BAD_VALUE;
+    }
+
+	return OK;
+}
+
+status_t VpuWrapperDec::onInit() {
+    VPU_COMP_API_LOG("%s line %d", __FUNCTION__, __LINE__);
+    VpuDecRetCode ret;
+
+    hTsHandle = tsmCreate();
+    if (hTsHandle == NULL) {
+        VPU_COMP_ERR_LOG("Create Ts manager failed.
");
+        return BAD_VALUE;
+    }
+
+    auto node = mMime2TypeMap.find(mMime);
+    if (node == mMime2TypeMap.end()) {
+        ALOGE("%s line %d, unsupported decoder mime %s
", __FUNCTION__, __LINE__, mMime);
+        return BAD_VALUE;
+    } else
+        eCodingFormat = node->second;
+
+    if (eCodingFormat == VPU_V_VC1 || eCodingFormat == VPU_V_VC1_AP)
+        nFrameMaxCnt = MAX_VC1_FRAME_NUM;
+    else if (eCodingFormat == VPU_V_RV)
+        nFrameMaxCnt = MAX_RV_FRAME_NUM;
+    else
+        nFrameMaxCnt = MAX_FRAME_NUM;
+
+    ret = VPU_DecLoad();
+    CHECK_VPU_RET(ret);
+
+    ret = VPU_DecGetVersionInfo(&sVpuVer);
+    CHECK_VPU_RET(ret);
+
+	eVpuDecoderState = VPU_COM_STATE_LOADED;
+    return OK;
+}
+
+status_t VpuWrapperDec::onStart() {
+    VPU_COMP_API_LOG("%s line %d", __FUNCTION__, __LINE__);
+    CHECK_DEC_STATE(VPU_COM_STATE_LOADED);
+
+    VpuDecRetCode ret;
+
+    ret = VPU_DecQueryMem(&sMemInfo);
+    CHECK_VPU_RET(ret);
+
+    if (0 == MemMallocBlock(&sMemInfo)) {
+		VPU_COMP_ERR_LOG("%s line %d: malloc memory failure
",__FUNCTION__, __LINE__);
+	    return BAD_VALUE;
+    }
+
+    if (OK != OpenVpu() || nHandle == nullptr) {
+		VPU_COMP_ERR_LOG("%s: open vpu failure
",__FUNCTION__);
+		return BAD_VALUE;
+	}
+
+	//check capability
+	int capability = 0;
+	ret = VPU_DecGetCapability(nHandle, VPU_DEC_CAP_FRAMESIZE, &capability);
+	if ((ret == VPU_DEC_RET_SUCCESS) && capability) {
+		nCapability |= VPU_COM_CAPABILITY_FRMSIZE;
+	}
+
+    eVpuDecoderState = VPU_COM_STATE_OPENED;
+    return OK;
+}
+
+status_t VpuWrapperDec::onStop() {
+    VPU_COMP_API_LOG("%s: 
",__FUNCTION__);
+
+    //check state
+    switch(eVpuDecoderState) {
+        case VPU_COM_STATE_NONE:
+            // fall through
+        case VPU_COM_STATE_LOADED:
+            // decoder is already stopped
+            return OK;
+        default:
+            break;
+    }
+
+	ResetDecoder();
+    ReleaseVpuSource();
+
+    FramePoolClear(&sFramePoolInfo);
+    freeOutputBuffers();
+    nFreeOutBufferCnt = 0;
+    nFetchBufferNum = 0;
+    nOwnedInputCnt = 0;
+
+    eVpuDecoderState = VPU_COM_STATE_LOADED;
+
+    return OK;
+}
+
+status_t VpuWrapperDec::onFlush() {
+    VPU_COMP_API_LOG("%s: 
",__FUNCTION__);
+    ResetDecoder();
+    NotifyFlushDone();
+
+    return OK;
+}
+
+status_t VpuWrapperDec::onDestroy() {
+    status_t err = OK;
+	VPU_COMP_API_LOG("%s: 
",__FUNCTION__);
+
+	//check state
+    switch(eVpuDecoderState) {
+        case VPU_COM_STATE_NONE:
+            //forbidden
+            VPU_COMP_ERR_LOG("%s: failure: error state transition, current state=%d 
",__FUNCTION__,eVpuDecoderState);
+            return BAD_VALUE;
+        case VPU_COM_STATE_LOADED:
+            break;
+        default:
+            err = ReleaseVpuSource();
+        break;
+	}
+
+    if (hTsHandle)
+        tsmDestroy(hTsHandle);
+
+    //unload
+    VpuDecRetCode ret = VPU_DecUnLoad();
+    if (ret != VPU_DEC_RET_SUCCESS) {
+        VPU_COMP_ERR_LOG("%s: vpu unload failure: ret=0x%X 
",__FUNCTION__,ret);
+        err = BAD_VALUE;
+    }
+
+    eVpuDecoderState = VPU_COM_STATE_NONE;
+    return err;
+}
+
+status_t VpuWrapperDec::decodeInternal(std::unique_ptr<IMXInputBuffer> input) {
+	VpuDecRetCode ret;
+	VpuBufferNode InData;
+	int bufRetCode;
+	uint8_t* pBitstream;
+	int32_t readbytes;
+	int32_t enableFileMode=0;
+	int32_t capability=0;
+    int32_t nSecureBufferAllocSize = 0;
+    status_t err = OK;
+    uint32_t loopCnt = 0;
+
+	VPU_COMP_API_LOG("%s: state: %d, InBuf: %p, data size: %d, bInEos: %d
", \
+        __FUNCTION__, eVpuDecoderState, input->pInBuffer, input->size, bInEos);
+
+    if (nSkippedInputId != INVALID_ID) {
+        NotifySkipInputBuffer(nSkippedInputId);
+        nSkippedInputId = INVALID_ID;
+    }
+
+decode_one_frame:
+
+    if (bReceiveError) {
+        VPU_COMP_ERR_LOG("bReceiveError true, notify error and return
");
+        err = UNKNOWN_ERROR;
+        NotifyError(err);
+        return err;
+    }
+
+    bufRetCode = 0;
+
+	switch (eVpuDecoderState) {
+        case VPU_COM_STATE_LOADED:
+            if (OK != onStart())
+                return BAD_VALUE;
+            // fall through
+        case VPU_COM_STATE_OPENED:
+            // go to decode to get init info from vpu
+            break;
+		case VPU_COM_STATE_WAIT_FRM: {
+            if (OK != DecoderRegisterAllFrames()) {
+                return BAD_VALUE;
+            }
+            if (FramePoolBufNum(&sFramePoolInfo) >= sInitInfo.nMinFrameBufferCount) {
+				eVpuDecoderState = VPU_COM_STATE_DO_DEC;
+			}
+
+            if (FETCH_STATE_NONE == mFetchState) {
+                createFetchThread();
+            }
+            break;
+        }
+        case VPU_COM_STATE_RE_WAIT_FRM: {
+            // make sure free buffer cnt is enough after flush
+            if (nFreeOutBufferCnt >= sInitInfo.nMinFrameBufferCount) {
+                eVpuDecoderState = VPU_COM_STATE_DO_DEC;
+            } else {
+                // need more output buffer
+            }
+            //fall through
+        }
+		case VPU_COM_STATE_DO_DEC:
+			break;
+		//forbidden state & unknow state
+		default:
+			VPU_COMP_ERR_LOG("%s: failure state transition, current state=%d 
", __FUNCTION__, eVpuDecoderState);
+			return INVALID_OPERATION;
+	}
+
+	//for all codecs
+	pBitstream = (input->pInBuffer == nullptr) ? NULL : (uint8_t*)input->pInBuffer;
+	readbytes = input->size;
+
+    bInEos = input->eos;
+
+    if (nCurInputId == INVALID_ID && readbytes > 0) {
+        if (bResyncTsm) {
+            tsmReSync(hTsHandle, input->timestamp, MODE_AI);
+            bResyncTsm = false;
+        }
+        tsmSetBlkTs(hTsHandle, readbytes, input->timestamp);
+        nCurInputId = input->id;
+        nOwnedInputCnt++;
+    }
+
+	//check eos or null data
+	if(pBitstream == NULL && bInEos == true) {
+	    //create and send EOS data (with length=0)
+        pBitstream = (uint8_t*)0x01;
+		readbytes = 0;
+	}
+
+	//EOS: 		0==readbytesp && Bitstream!=NULL
+	//non-EOS: 	0==readbytesp && Bitstream==NULL
+
+	//seq init
+	//decode bitstream buf
+	VPU_COMP_LOG("%s: pBitstream=%p, readbytes=%d  
",__FUNCTION__, pBitstream, readbytes);
+    memset(&InData, 0, sizeof(VpuBufferNode));
+	InData.nSize = readbytes;
+	InData.pPhyAddr = NULL;
+	InData.pVirAddr = pBitstream;
+
+	InData.sCodecData.pData = pCodecDataBuf;
+	InData.sCodecData.nSize = nCodecDataLen;
+
+    if (pCodecDataBuf && nCodecDataLen > 0) {
+        int reset = 0;
+        VPU_DecConfig(nHandle, VPU_DEC_CONF_RESET_CODECDATA, &reset);
+    }
+#if 0
+    if(bEnableAndroidNativeHandleBuffer && !bInEos && readbytes > 0) {
+        int fd = (intptr_t)pBitstream;
+        GetHwBuffer((OMX_PTR)fd,(OMX_PTR *)&InData.pPhyAddr);
+        #ifdef HANTRO_VPU
+        int32_t fd2;
+        OMX_PTR dataBuf = NULL;
+        GetFdAndAddr((OMX_PTR)fd,&fd2,(OMX_PTR*)&dataBuf);
+        InData.pVirAddr = (unsigned char *)dataBuf;
+        VPU_COMP_LOG("fd=%d,phyaddr=%p,virt=%p",fd,InData.pPhyAddr,InData.pVirAddr);
+        #endif
+
+        #if 0//for debug purpose
+        int *buf = (int*)mmap(0, readbytes, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
+        InData.pVirAddr = (unsigned char *)buf;
+        #endif
+    }
+#endif
+
+	ret = VPU_DecDecodeBuf(nHandle, &InData, (int32_t*)&bufRetCode);
+	if(VPU_DEC_RET_SUCCESS != ret) {
+		VPU_COMP_ERR_LOG("%s: vpu dec buf failure: ret=0x%X 
",__FUNCTION__,ret);
+		if(VPU_DEC_RET_FAILURE_TIMEOUT == ret) {
+			VPU_DecReset(nHandle);
+			NotifyError(TIMED_OUT);
+		}
+        NotifyError(UNKNOWN_ERROR);
+		return UNKNOWN_ERROR;
+	}
+
+    VPU_COMP_LOG("%s: bufRetCode: 0x%X  
", __FUNCTION__, bufRetCode);
+
+    int decodeAgain = 0;
+    err = CheckVpuReturnCode(bufRetCode, &decodeAgain);
+
+    if (err == OK && decodeAgain) {
+        if (loopCnt++ > 50) {
+            VPU_COMP_ERR_LOG("it seems like a dead loop, quit now 
");
+            return OK;
+        }
+        goto decode_one_frame;
+    }
+
+    if (pCodecDataBuf && nCodecDataLen > 0)
+        nCodecDataLen = 0; // codecdata is handled, reset data length here.
+
+    if (err) {
+        NotifyError(err);
+    }
+
+    return err;
+}
+
+status_t VpuWrapperDec::setOutputBuffer(int32_t bufferId) {
+    VpuDecRetCode ret;
+    VpuDecOutFrameInfo * pFrameInfo;
+    int32_t exist;
+    int32_t index;
+
+    GraphicBlockInfo* info = getGraphicBlockById(bufferId);
+    if (info == nullptr) {
+        VPU_COMP_ERR_LOG("%s: failure: unvalid buffer id: %d
", __FUNCTION__, bufferId);
+	    return BAD_VALUE;
+    }
+
+    exist = FramePoolBufExist(bufferId, &sFramePoolInfo, &index);
+
+    VPU_COMP_LOG("%s, buffer id %d, exist %d, index %d", __FUNCTION__, bufferId, exist, index);
+
+    if (exist < 0) {
+		VPU_COMP_ERR_LOG("%s: failure: unvalid buffer id: %d
", __FUNCTION__, bufferId);
+		return BAD_VALUE;
+	} else if (exist == 0) {
+	    // check if current out frame number reach the max value
+	    if (FramePoolBufNum(&sFramePoolInfo) >= nFrameMaxCnt)
+            return BAD_VALUE;
+        // can't register buffer just when res changed, as vpu will memset this buffer based on framesize
+        // if framesize increased, memset crash because this buffer size is less than new framesize.
+        else if (eVpuDecoderState == VPU_COM_STATE_PROCESSING_INIT_INFO)
+            return BAD_VALUE;
+		//register frame buffer
+        if (eVpuDecoderState == VPU_COM_STATE_DO_DEC) {
+            Mutex::Autolock autoLock(mLock);
+            status_t err = DecoderRegisterOneFrame(info);
+            if (err != OK) {
+                VPU_COMP_ERR_LOG("%s: failure: can't register buffer id: %d
", __FUNCTION__, bufferId);
+                return BAD_VALUE;
+            }
+            VPU_COMP_LOG("return register frame, free buffers: %d", nFreeOutBufferCnt);
+        }
+    } else {
+		VpuDecoderFrmState eState;
+		FramePoolGetBufProperty(&sFramePoolInfo, index, &eState, &pFrameInfo);
+        VPU_COMP_LOG("set_output_buffer FramePoolGetBufProperty, state = %d
", eState);
+
+		if (eState == VPU_COM_FRM_STATE_OUT) {
+			if (NULL != pFrameInfo->pDisplayFrameBuf && eVpuDecoderState != VPU_COM_STATE_PROCESSING_INIT_INFO) {
+				//clear displayed frame
+				Mutex::Autolock autoLock(mLock);
+		        ret = VPU_DecOutFrameDisplayed(nHandle, sFramePoolInfo.outFrameInfo[index].pDisplayFrameBuf);
+				if(VPU_DEC_RET_SUCCESS != ret) {
+					VPU_COMP_ERR_LOG("%s: vpu clear frame display failure: ret=0x%X
", __FUNCTION__, ret);
+					return BAD_VALUE;
+				}
+                nFreeOutBufferCnt++;
+                VPU_COMP_LOG("return out frame, free buffers: %d", nFreeOutBufferCnt);
+			} else {
+				//this is fake output frame which is stolen at some special steps, include EOS, flush,...
+				VPU_COMP_LOG("application return one stolen buffer id: %d 
", bufferId);
+			}
+			//update buffer state
+			FramePoolSetBufState(&sFramePoolInfo, index, VPU_COM_FRM_STATE_FREE);
+            info->mState = GraphicBlockInfo::State::OWNED_BY_VPU;
+		}
+		else
+		{
+			VPU_COMP_ERR_LOG("%s: failure: repeat setting output buffer id: %d 
", __FUNCTION__, bufferId);
+			return BAD_VALUE;
+		}
+    }
+    return OK;
+}
+
+status_t VpuWrapperDec::DoSetConfig(DecConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    status_t ret = OK;
+
+    switch (index) {
+        case DEC_CONFIG_VC1_SUB_FORMAT: {
+            if (strcmp(mMime, MEDIA_MIMETYPE_VIDEO_VC1) != 0) {
+                VPU_COMP_ERR_LOG("DoSetConfig DEC_CONFIG_VC1_SUB_FORMAT only support for VC1");
+                return BAD_VALUE;
+            }
+
+            int* format = (int*)pConfig;
+            // TODO: remove this OMX_VIDEO_WMVFormat9=0x08, OMX_VIDEO_WMVFormatWVC1=0x7f000002
+            if (*format == 0x08)
+                eCodingFormat = VPU_V_VC1;
+            else if (*format == 0x7f000002)
+                eCodingFormat = VPU_V_VC1_AP;
+
+            VPU_COMP_LOG("vc1 sub-format 0x%x eCodingFormat %d", *format, eCodingFormat);
+        }
+        default:
+            ret = BAD_VALUE;
+            break;
+    }
+    return ret;
+}
+
+status_t VpuWrapperDec::DoGetConfig(DecConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    status_t ret = OK;
+
+    switch (index) {
+        case DEC_CONFIG_OUTPUT_DELAY: {
+            int *pOutputDelayValue = (int*)pConfig;
+            if (eCodingFormat == VPU_V_VC1 || eCodingFormat == VPU_V_VC1_AP)
+                *pOutputDelayValue = 8;
+            else if (eCodingFormat == VPU_V_RV)
+                *pOutputDelayValue = 8;
+            else
+                *pOutputDelayValue = 16;
+            break;
+        }
+        case DEC_CONFIG_HDR10_STATIC_INFO: {
+            if (bHasHdr10StaticInfo | bHasCodecColorDesc)
+                memcpy(pConfig, &sHdr10StaticInfo, sizeof(DecStaticHDRInfo));
+            else
+                ret = BAD_VALUE;
+            break;
+        }
+        case DEC_CONFIG_COLOR_ASPECTS: {
+            if (bHasCodecColorDesc)
+                memcpy(pConfig, &sDecoderColorDesc, sizeof(DecColorAspects));
+            else
+                ret = BAD_VALUE;
+            break;
+        }
+        default:
+            ret = BAD_VALUE;
+            break;
+    }
+
+    return ret;
+}
+
+status_t VpuWrapperDec::allocateOutputBuffers() {
+    status_t ret = OK;
+    int32_t i;
+
+    VPU_COMP_LOG("%s, line %d, try to allocate %d buffers 
", __FUNCTION__, __LINE__, mOutputFormat.bufferNum);
+
+    for (i = 0; i < mOutputFormat.bufferNum; i++) {
+        do {
+            ret = fetchOutputBuffer();
+        } while (WOULD_BLOCK == ret);
+
+        if (ret != OK)
+            break;
+    }
+
+    return ret;
+}
+
+status_t VpuWrapperDec::freeOutputBuffers() {
+    VPU_COMP_LOG("%s, line %d, mGraphicBlocks size=%d", __FUNCTION__, __LINE__, (int)mGraphicBlocks.size());
+    {
+        Mutex::Autolock autoLock(mLock);
+        nFetchBufferNum = 0;
+    }
+
+    for (auto& info : mGraphicBlocks) {
+        if (info.mVirtAddr > 0 && info.mCapacity > 0)
+            munmap((void*)info.mVirtAddr, info.mCapacity);
+
+        info.mGraphicBlock.reset();
+    }
+
+    mGraphicBlocks.clear();
+
+    return OK;
+}
+
+bool VpuWrapperDec::OutputBufferFull() {
+    return (FramePoolBufNum(&sFramePoolInfo) >= nFrameMaxCnt);
+}
+
+bool VpuWrapperDec::checkIfPostProcessNeeded() {
+    return false;
+}
+
+status_t VpuWrapperDec::FlushFilter()
+{
+	VpuDecRetCode ret;
+	VPU_COMP_LOG("%s: 
",__FUNCTION__);
+
+    Mutex::Autolock autoLock(mLock);
+
+	ret = VPU_DecFlushAll(nHandle);
+	if (VPU_DEC_RET_SUCCESS != ret) {
+		VPU_COMP_ERR_LOG("%s: vpu flush failure: ret=0x%X 
",__FUNCTION__,ret);
+		if (VPU_DEC_RET_FAILURE_TIMEOUT == ret) {
+			VPU_DecReset(nHandle);
+		}
+		return BAD_VALUE;
+	}
+
+	//since vpu will auto clear all buffers(is equal to setoutput() operation), we need to add additional protection(set VPU_COM_STATE_WAIT_FRM).
+	//otherwise, vpu may return one buffer which is still not set by user.
+	eVpuDecoderState = VPU_COM_STATE_RE_WAIT_FRM;
+
+	return OK;
+}
+
+status_t VpuWrapperDec::ReleaseVpuSource() {
+    VpuDecRetCode ret;
+    status_t err;
+
+    if (mFetchThread) {
+        destroyFetchThread();
+    }
+
+    //close vpu
+    if (nHandle) {
+        ret = VPU_DecClose(nHandle);
+        if (ret != VPU_DEC_RET_SUCCESS) {
+            VPU_COMP_ERR_LOG("%s: vpu close failure: ret=0x%X 
",__FUNCTION__,ret);
+            err = BAD_VALUE;
+        }
+    }
+
+    //release mem
+    if (0 == MemFreeBlock(&sMemInfo)) {
+        VPU_COMP_ERR_LOG("%s: free memory failure !  
",__FUNCTION__);
+        err = BAD_VALUE;
+    }
+
+    return err;
+}
+
+status_t VpuWrapperDec::CheckVpuReturnCode(int32_t bufRetCode, int* decodeAgain) {
+    status_t err = OK;
+
+    //check input buff
+	if (bufRetCode & VPU_DEC_INPUT_USED) {
+		if(nCurInputId != INVALID_ID) {
+            NotifyInputBufferUsed(nCurInputId/*input_id*/);
+            if (bufRetCode & VPU_DEC_SKIP) {
+                nSkippedInputId = nCurInputId;
+            }
+            nCurInputId = INVALID_ID;
+            if (nOwnedInputCnt > mOutputFormat.bufferNum) {
+                nOwnedInputCnt--;
+                NotifySkipInputBuffer(INVALID_ID);
+            }
+		}
+        if (bInEos && !(bufRetCode & VPU_DEC_OUTPUT_EOS)) {
+            // vpu just consumed the last input, need call VPU_DecDecodeBuf again to trigger eos.
+            *decodeAgain = 1;
+        }
+    } else {
+	    *decodeAgain = 1;
+    }
+
+	//check init info
+	if (bufRetCode & VPU_DEC_INIT_OK) {
+		err = ProcessVpuInitInfo();
+        if ((eCodingFormat == VPU_V_AVC || eCodingFormat == VPU_V_VP9 || eCodingFormat == VPU_V_HEVC) && \
+                mOutputFormat.pixelFormat != HAL_PIXEL_FORMAT_YCbCr_420_SP) {
+            VpuBufferNode input;
+            memset(&input, 0, sizeof(VpuBufferNode));
+            //do not care about the result and bufRetCode
+            (void)VPU_DecDecodeBuf(nHandle, &input, (int32_t*)&bufRetCode);
+        }
+		return err;
+	}
+
+	//check resolution change
+	if (bufRetCode & VPU_DEC_RESOLUTION_CHANGED) {
+		/*in such case:
+		   (1) the frames which haven't been output (in vpu or post-process) will be discard, So, video may be not complete continuous.
+		   (2) user need to re-allocate buffers, so buffer state will be meaningless.
+		   (3) the several frames dropped may affect timestamp if user don't use decoded handle to map frames between decoded and display ?
+		 */
+		VPU_COMP_LOG("resolution changed 
");
+
+		//get new init info to re-set some variables
+		err = ProcessVpuInitInfo();
+		return err;
+	}
+
+	//check decoded info
+	if ((nCapability & VPU_COM_CAPABILITY_FRMSIZE) && (bufRetCode & VPU_DEC_ONE_FRM_CONSUMED)) {
+		VPU_COMP_LOG("one frame is decoded 
");
+        VpuDecFrameLengthInfo sLengthInfo;
+	    VpuDecRetCode ret;
+	    ret = VPU_DecGetConsumedFrameInfo(nHandle, &sLengthInfo);
+        if (VPU_DEC_RET_SUCCESS == ret) {
+		    tsmSetFrmBoundary(hTsHandle, sLengthInfo.nStuffLength, sLengthInfo.nFrameLength, sLengthInfo.pFrame);
+	    }
+	}
+
+    //check output buff
+    if (bufRetCode & VPU_DEC_OUTPUT_DIS) {
+        eVpuDecoderState = VPU_COM_STATE_DO_OUT;
+        GetOutputBuffer();
+        {
+            Mutex::Autolock autoLock(mLock);
+            nFetchBufferNum++;
+        }
+    } else if (bufRetCode & VPU_DEC_OUTPUT_EOS) {
+        VPU_COMP_INFO("vpu return output eos
");
+        *decodeAgain = 0;
+        eVpuDecoderState = VPU_COM_STATE_EOS;
+        NotifyEOS();
+    }
+
+    //check "no enough buf"
+    if ((bufRetCode & VPU_DEC_NO_ENOUGH_BUF) && (*decodeAgain == 1)) {
+        #if 0
+        int i = 0;
+        for(i = 0; i < VPU_DEC_MAX_NUM_MEM; i++) {
+            ALOGI("nFrm[%d]: bufferId %d, phy %p, state %d",
+                i, sFramePoolInfo.nFrm_bufferId[i], (void*)sFramePoolInfo.nFrm_phyAddr[i], sFramePoolInfo.eFrmState[i]);
+        }
+        #endif
+
+        struct timeval now;
+        struct timespec outtime;
+        int wait_ret;
+
+        pthread_mutex_lock((pthread_mutex_t *)pFetchThreadMutex);
+        gettimeofday(&now, NULL);
+        outtime.tv_sec = now.tv_sec + 1;
+        outtime.tv_nsec = now.tv_usec * 1000;
+        wait_ret = pthread_cond_timedwait(&pFetchThreadCond, (pthread_mutex_t *)pFetchThreadMutex, &outtime);
+        pthread_mutex_unlock((pthread_mutex_t *)pFetchThreadMutex);
+
+        if (wait_ret) {
+            ALOGW("pthread_cond_timedwait timeout after 1s, ret=%d", wait_ret);
+        }
+        VPU_COMP_LOG("free buffers: %d, request min buffers: %d", nFreeOutBufferCnt, sInitInfo.nMinFrameBufferCount);
+    }
+
+    if ((bufRetCode & VPU_DEC_NO_ENOUGH_INBUF) && (false == bInEos)) {
+        // do nothing because input buffer will arrive to vpu in next processing.
+    }
+
+    return err;
+
+}
+
+status_t VpuWrapperDec::GetOutputBuffer() {
+    VpuDecRetCode ret;
+    bool bOutLast = false;
+	int32_t bufferId = -1;
+    int32_t index;
+    uint64_t timestamp = -1;
+
+	VPU_COMP_API_LOG("%s: state: %d 
", __FUNCTION__, eVpuDecoderState);
+
+	//check state
+	switch(eVpuDecoderState) {
+		case VPU_COM_STATE_DO_OUT:
+			//update state
+			eVpuDecoderState = VPU_COM_STATE_DO_DEC;
+			break;
+		default:
+			//forbidden
+			VPU_COMP_ERR_LOG("%s: failure state transition, current state=%d 
",__FUNCTION__,eVpuDecoderState);
+			return BAD_VALUE;
+	}
+
+	//get output frame
+
+	VpuDecOutFrameInfo sFrameInfo;
+
+	ret = VPU_DecGetOutputFrame(nHandle, &sFrameInfo);
+	if (VPU_DEC_RET_SUCCESS != ret) {
+		VPU_COMP_ERR_LOG("%s: vpu get output frame failure: ret=0x%X 
", __FUNCTION__, ret);
+		return BAD_VALUE;
+	}
+
+    bufferId = sFrameInfo.pDisplayFrameBuf->nBufferId;
+
+	//find the matched node in frame pool based on frame virtual address, and record output frame info
+	index = FramePoolRecordOutFrame(bufferId, &sFramePoolInfo, &sFrameInfo);
+	if(-1 == index) {
+		VPU_COMP_ERR_LOG("%s: can't find matched node in frame pool: buffer id = %d !!!
",__FUNCTION__, bufferId);
+		return BAD_VALUE;
+	}
+
+    timestamp = tsmGetFrmTs(hTsHandle, NULL);
+
+	//update crop info for every output frame
+    mOutputFormat.rect.left = sFrameInfo.pExtInfo->FrmCropRect.nLeft;
+    mOutputFormat.rect.right = sFrameInfo.pExtInfo->FrmCropRect.nRight;
+    mOutputFormat.rect.top = sFrameInfo.pExtInfo->FrmCropRect.nTop;
+    mOutputFormat.rect.bottom = sFrameInfo.pExtInfo->FrmCropRect.nBottom;
+
+    nYOffset = sFrameInfo.pExtInfo->rfc_luma_offset;
+    nUVOffset = sFrameInfo.pExtInfo->rfc_chroma_offset;
+
+    FramePoolSetBufState(&sFramePoolInfo, index, VPU_COM_FRM_STATE_OUT);
+
+    nFreeOutBufferCnt--;
+    nOwnedInputCnt--;
+
+    NotifyPictureReady(bufferId, timestamp);
+
+    return OK;
+}
+
+status_t VpuWrapperDec::OpenVpu() {
+	VpuDecOpenParam decOpenParam;
+	VpuDecRetCode ret;
+	int32_t para;
+
+    VPU_COMP_LOG("%s: codec format: %d, %d/%d, pixelFormat 0x%x, mime %s
",
+        __FUNCTION__, eCodingFormat, mOutputFormat.width, mOutputFormat.height, mOutputFormat.pixelFormat, mMime);
+
+	memset(&decOpenParam, 0, sizeof(VpuDecOpenParam));
+	//set open params
+	decOpenParam.CodecFormat = eCodingFormat;
+
+#ifdef SUPPORT_VIDEO_10BIT
+    decOpenParam.nEnableVideoCompressor = 1;
+#else
+    // 8mq/8mp do 10bit to 8bit convert as default
+    decOpenParam.nPixelFormat = 1;
+#endif
+
+	//FIXME: for MJPG, we need to add check for 4:4:4/4:2:2 ver/4:0:0  !!!
+	if (HAL_PIXEL_FORMAT_YCbCr_420_SP == mOutputFormat.pixelFormat ||
+            HAL_PIXEL_FORMAT_YCbCr_422_SP == mOutputFormat.pixelFormat) {
+		decOpenParam.nChromaInterleave = 1;
+	} else {
+		decOpenParam.nChromaInterleave = 0;
+	}
+
+    if(mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_NV12_G1_TILED ||
+            mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_NV12_G2_TILED ||
+            mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_NV12_G2_TILED_COMPRESSED ||
+            mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_P010_TILED ||
+            mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_P010_TILED_COMPRESSED) {
+        decOpenParam.nTiled2LinearEnable = true;
+        VPU_COMP_INFO("enable tile format");
+    }
+
+	//for special formats, such as package VC1 header,...
+	decOpenParam.nPicWidth = mOutputFormat.width;
+	decOpenParam.nPicHeight = mOutputFormat.height;
+    decOpenParam.nAdaptiveMode = (bAdaptiveMode == true) ? 1 : 0;
+    decOpenParam.nSecureMode = (bSecureMode == true) ? 1 : 0;
+    decOpenParam.nReorderEnable = 1;
+    //decOpenParam.nSecureBufferAllocSize = (bSecureMode == true) ? nSecureBufferAllocSize : 0;
+
+	//open vpu
+	ret = VPU_DecOpen(&nHandle, &decOpenParam, &sMemInfo);
+	if (ret != VPU_DEC_RET_SUCCESS) {
+		VPU_COMP_ERR_LOG("%s: vpu open failure: ret=0x%X !
",__FUNCTION__,ret);
+		return BAD_VALUE;
+	}
+
+	//set default config
+	para = VPU_DEC_SKIPNONE;
+	ret = VPU_DecConfig(nHandle, VPU_DEC_CONF_SKIPMODE, &para);
+	if (VPU_DEC_RET_SUCCESS != ret) {
+		VPU_COMP_ERR_LOG("%s: vpu config failure: config=0x%X, ret=%d 
",__FUNCTION__,(uint32_t)VPU_DEC_CONF_SKIPMODE,ret);
+		VPU_DecClose(nHandle);
+		return BAD_VALUE;
+	}
+	para = DEFAULT_BUF_DELAY;
+	ret = VPU_DecConfig(nHandle, VPU_DEC_CONF_BUFDELAY, &para);
+	if (VPU_DEC_RET_SUCCESS != ret) {
+		VPU_COMP_ERR_LOG("%s: vpu config failure: config=0x%X, ret=%d 
",__FUNCTION__,(uint32_t)VPU_DEC_CONF_SKIPMODE,ret);
+		VPU_DecClose(nHandle);
+		return BAD_VALUE;
+	}
+
+	return OK;
+}
+
+status_t VpuWrapperDec::CreateOneRegisterFrameBuffer(GraphicBlockInfo* info, VpuFrameBuffer * pFrameBuf) {
+    status_t err = OK;
+    int32_t frameNum;
+
+    memset(pFrameBuf, 0, sizeof(VpuFrameBuffer));
+
+    // register output frame buffer to frame pool/vpu
+    frameNum = FramePoolRegisterBuf(info->mVirtAddr, info->mPhysAddr, info->mBlockId, &sFramePoolInfo);
+    if (frameNum == -1) {
+        VPU_COMP_ERR_LOG("%s: register frame failure: frame pool is full ! 
", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    pFrameBuf->pbufY = (unsigned char*)info->mPhysAddr;
+	pFrameBuf->pbufVirtY = (unsigned char*)info->mVirtAddr;
+    pFrameBuf->nBufferId = info->mBlockId;
+
+    info->mState = GraphicBlockInfo::State::OWNED_BY_VPU;
+
+    return OK;
+}
+
+status_t VpuWrapperDec::DecoderRegisterOneFrame(GraphicBlockInfo* info) {
+    status_t err = OK;
+    VpuFrameBuffer frameBuf;
+    int32_t frameNum;
+
+    memset(&frameBuf, 0, sizeof(VpuFrameBuffer));
+
+    if (OK != CreateOneRegisterFrameBuffer(info, &frameBuf))
+        return BAD_VALUE;
+
+    VpuDecRetCode ret;
+	ret = VPU_DecRegisterFrameBuffer(nHandle, &frameBuf, 1);
+    if (VPU_DEC_RET_SUCCESS == ret)
+        nFreeOutBufferCnt++;
+
+    return OK;
+}
+
+status_t VpuWrapperDec::DecoderRegisterAllFrames() {
+    status_t err = OK;
+    VpuFrameBuffer frameBuf[MAX_FRAME_NUM];
+    int32_t i;
+    int32_t frameNum = 0;
+
+    CHECK_DEC_STATE(VPU_COM_STATE_WAIT_FRM);
+
+    memset(frameBuf, 0, MAX_FRAME_NUM * sizeof(VpuFrameBuffer));
+
+    // register output frame buffer to frame pool/vpu
+    for(i = 0; i < mOutputFormat.bufferNum; i++) {
+        GraphicBlockInfo* info = getFreeGraphicBlock();
+        if (info == nullptr)
+            break; // no more free block
+
+        if (OK != CreateOneRegisterFrameBuffer(info, &frameBuf[i]))
+            break;
+
+        frameNum++;
+    }
+
+    if (frameNum != mOutputFormat.bufferNum) {
+        VPU_COMP_ERR_LOG("%s: failed, not enough output buffer, request %d register %d
",
+            __FUNCTION__, mOutputFormat.bufferNum, frameNum);
+        return BAD_VALUE;
+    }
+
+    VpuDecRetCode ret;
+	ret = VPU_DecRegisterFrameBuffer(nHandle, frameBuf, frameNum);
+    if (VPU_DEC_RET_SUCCESS != ret) {
+        return BAD_VALUE;
+    }
+
+    eVpuDecoderState = VPU_COM_STATE_DO_DEC;
+    nFreeOutBufferCnt = frameNum;
+
+    return OK;
+}
+
+VideoDecoderBase * CreateVideoDecoderInstance(const char* mime) {
+    return static_cast<VideoDecoderBase *>(new VpuWrapperDec(mime));
+}
+
+}  // namespace android
+
+// end of file
diff --git a/codec2/video_dec/vpuwrapper_dec/VpuWrapperDec.h b/codec2/video_dec/vpuwrapper_dec/VpuWrapperDec.h
new file mode 100755
index 0000000..6440e42
--- /dev/null
+++ b/codec2/video_dec/vpuwrapper_dec/VpuWrapperDec.h
@@ -0,0 +1,184 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef VPU_WRAPPER_DEC_H
+#define VPU_WRAPPER_DEC_H
+
+#include<map>
+
+#include"VideoDecoderBase.h"
+#include"vpu_wrapper.h"
+
+namespace android {
+
+#define VPU_DEC_MAX_NUM_MEM	(30)
+
+typedef struct
+{
+	//virtual mem info
+	int32_t nVirtNum;
+	uint32_t virtMem[VPU_DEC_MAX_NUM_MEM];
+
+	//phy mem info
+	int32_t nPhyNum;
+	uint32_t phyMem_virtAddr[VPU_DEC_MAX_NUM_MEM];
+	uint32_t phyMem_phyAddr[VPU_DEC_MAX_NUM_MEM];
+	uint32_t phyMem_cpuAddr[VPU_DEC_MAX_NUM_MEM];
+	uint32_t phyMem_size[VPU_DEC_MAX_NUM_MEM];
+}VpuDecoderMemInfo;
+
+
+typedef enum
+{
+	VPU_COM_FRM_STATE_FREE=0,
+	VPU_COM_FRM_STATE_OUT,
+}VpuDecoderFrmState;
+
+typedef struct
+{
+	int32_t nFrmNum;
+	VpuDecoderFrmState eFrmState[VPU_DEC_MAX_NUM_MEM];
+	unsigned long nFrm_virtAddr[VPU_DEC_MAX_NUM_MEM];
+	unsigned long nFrm_phyAddr[VPU_DEC_MAX_NUM_MEM];
+    int32_t nFrm_bufferId[VPU_DEC_MAX_NUM_MEM];
+	VpuDecOutFrameInfo outFrameInfo[VPU_DEC_MAX_NUM_MEM];
+}VpuDecoderFrmPoolInfo;
+
+typedef struct
+{
+	void * pVirtAddr[VPU_DEC_MAX_NUM_MEM];
+	VpuDecOutFrameInfo outFrameInfo[VPU_DEC_MAX_NUM_MEM];
+}VpuDecoderOutMapInfo;
+
+
+typedef enum
+{
+	VPU_COM_STATE_NONE = 0,
+    VPU_COM_STATE_LOADED,
+	VPU_COM_STATE_OPENED,
+	VPU_COM_STATE_PROCESSING_INIT_INFO,
+	VPU_COM_STATE_WAIT_FRM,
+	VPU_COM_STATE_DO_DEC,
+	VPU_COM_STATE_RE_WAIT_FRM,
+	VPU_COM_STATE_DO_OUT,
+	VPU_COM_STATE_EOS,
+}VpuDecoderState;
+
+
+typedef enum
+{
+	VPU_COM_CAPABILITY_FILEMODE=0x1,
+	VPU_COM_CAPABILITY_TILE=0x2,
+	VPU_COM_CAPABILITY_FRMSIZE=0x4,
+}VpuDecoderCapability;
+
+class VpuWrapperDec : public VideoDecoderBase {
+public:
+    VpuWrapperDec(const char* mime);
+    virtual ~VpuWrapperDec();
+    bool checkIfPostProcessNeeded() override;
+    status_t setOutputBuffer(int32_t bufferId);
+
+protected:
+    status_t onInit() override;
+    status_t onStart() override;//loaded to idle
+    status_t onStop() override;//idle to loaded
+    status_t onFlush() override;//flush
+    status_t onDestroy() override;//free Buffers
+    status_t decodeInternal(std::unique_ptr<IMXInputBuffer> input) override;
+    status_t DoSetConfig(DecConfig index, void* pConfig) override;
+    status_t DoGetConfig(DecConfig index, void* pConfig) override;
+    status_t allocateOutputBuffers() override;
+    status_t freeOutputBuffers() override;
+    bool OutputBufferFull() override;
+
+private:
+    VpuMemInfo sMemInfo;				// required by vpu wrapper
+    VpuDecoderFrmPoolInfo sFramePoolInfo;// frame pool info for all output frames: decode + post-process
+    VpuDecInitInfo sInitInfo;   // seqinit info
+    VpuDecHandle nHandle;       // pointer to vpu object
+    VpuCodStd eCodingFormat;
+    VpuDecoderState eVpuDecoderState;
+    VpuVersionInfo sVpuVer;		//vpu version info
+
+    const char* mMime;
+
+    uint32_t nFreeOutBufferCnt;
+
+	bool bInEos;
+
+    int32_t nCurInputId;
+    int32_t nSkippedInputId;
+
+    void* hTsHandle;
+    bool bResyncTsm;
+
+    std::map<C2String, VpuCodStd> mMime2TypeMap;
+
+	uint32_t nCapability;			//vpu capability
+	int32_t nMaxDurationMsThr;	// control the speed of data consumed by decoder: -1 -> no threshold
+	int32_t nMaxBufCntThr;		// control the speed of data consumed by decoder: -1 -> no threshold
+	int32_t nFrameWidthStride;	//user may register frames with specified width stride
+	int32_t nFrameHeightStride;	//user may register frames with specified height stride
+	int32_t nFrameMaxCnt;		//user may register frames with specified count
+	bool bReorderDisabled;
+
+    bool bHasCodecColorDesc;
+    DecColorAspects sDecoderColorDesc;
+    DecColorAspects sParserColorDesc;
+
+    bool bHasHdr10StaticInfo;
+    DecStaticHDRInfo sHdr10StaticInfo;
+
+    uint32_t nYOffset;
+    uint32_t nUVOffset;
+
+    uint32_t nOwnedInputCnt;
+
+    // none -> start -> stopping -> none
+    enum {
+        FETCH_STATE_NONE = 0,
+        FETCH_STATE_START,
+        FETCH_STATE_STOPPING,
+    };
+
+    uint32_t mFetchState;
+
+    Mutex mLock;
+    pthread_t mFetchThread;
+    pthread_cond_t pFetchThreadCond;
+    void* pFetchThreadMutex;
+    int nFetchBufferNum;
+
+	status_t GetInputDataDepthThreshold(int32_t* pDurationThr, int32_t* pBufCntThr);
+
+	/* virtual function implementation */
+
+	status_t FlushFilter();
+
+	void SetDefaultSetting();
+    void ResetDecoder();
+	status_t ProcessVpuInitInfo();
+	status_t ReleaseVpuSource();
+    status_t PortFormatChanged(uint32_t nPortIndex);
+    bool DefaultOutputBufferNeeded();
+    status_t CheckVpuReturnCode(int32_t bufRetCode, int* decodeAgain);
+    status_t GetOutputBuffer();
+    status_t OpenVpu();
+    status_t CreateOneRegisterFrameBuffer(GraphicBlockInfo* info, VpuFrameBuffer * pFrameBuf);
+    status_t DecoderRegisterOneFrame(GraphicBlockInfo* info);
+    status_t DecoderRegisterAllFrames();
+
+    status_t createFetchThread();
+    status_t destroyFetchThread();
+    static void *FetchThreadWrapper(void *);
+    status_t HandleFetchThread();
+};
+
+}  // namespace android
+#endif // VPU_WRAPPER_DEC_H
diff --git a/codec2/video_dec/vpuwrapper_dec/vpuwrapper_dec.go b/codec2/video_dec/vpuwrapper_dec/vpuwrapper_dec.go
new file mode 100644
index 0000000..f5ee7e2
--- /dev/null
+++ b/codec2/video_dec/vpuwrapper_dec/vpuwrapper_dec.go
@@ -0,0 +1,60 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package vpuwrapper_dec
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_vpuwrapper_dec_defaults", vpuwrapperDefaultsFactory)
+}
+
+func vpuwrapperDefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, vpuwrapperDefaults)
+    return module
+}
+
+func vpuwrapperDefaults(ctx android.LoadHookContext) {
+    var Cflags []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Cflags []string
+                }
+        }
+    }
+    p := &props{}
+    var vpu_type string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_VPU_TYPE")
+    if strings.Contains(vpu_type, "hantro") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else {
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
+    }
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8MQ") {
+        Cflags = append(Cflags, "-DSUPPORT_VIDEO_10BIT")
+    }
+    if ctx.Config().VendorConfig("IMXPLUGIN").String("CFG_SECURE_DATA_PATH") == "y" {
+        Cflags = append(Cflags, "-DALWAYS_ENABLE_SECURE_PLAYBACK")
+    }
+    p.Target.Android.Cflags = Cflags
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/video_enc/Android.bp b/codec2/video_enc/Android.bp
new file mode 100644
index 0000000..ec7ed08
--- /dev/null
+++ b/codec2/video_enc/Android.bp
@@ -0,0 +1,25 @@
+imx_c2_video_enc_defaults {
+    name: "imx_c2_video_enc_default",
+}
+
+
+bootstrap_go_package {
+    name: "soong-video_enc",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/video_enc",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "video_enc.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+subdirs = [
+    "*",
+]
diff --git a/codec2/video_enc/common/Android.bp b/codec2/video_enc/common/Android.bp
new file mode 100644
index 0000000..0d65ad8
--- /dev/null
+++ b/codec2/video_enc/common/Android.bp
@@ -0,0 +1,89 @@
+cc_library_shared {
+    name: "lib_imx_c2_videoenc_common",
+
+    srcs: [
+        "VideoEncoderBase.cpp",
+    ],
+
+    include_dirs: [
+        "hardware/libhardware/include",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",    
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+    ],
+
+    header_libs: [
+        "media_plugin_headers",
+        "libcodec2_headers",
+    ],
+
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "lib_imx_c2_componentbase",
+        "libion",
+        "libcodec2_vndk",
+    ],
+
+    whole_static_libs: ["libionallocator"],
+
+    export_include_dirs: ["."],
+
+    defaults: [
+        "imx_defaults",
+    ],
+}
+
+
+cc_library_shared {
+    name: "lib_imx_c2_videoenc",
+
+    srcs: [
+        "IMXC2VideoEncoder.cpp",
+    ],
+
+    include_dirs: [
+        "frameworks/av",
+        "hardware/libhardware/include",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp-opensource/vpu_wrapper",
+        "vendor/nxp/imx_android_mm/codec2/process/common",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/imx/display/display",
+    ],
+
+    header_libs: [
+        "media_plugin_headers",
+        "libcodec2_headers",
+    ],
+
+
+    shared_libs: [
+        "libcutils", // for properties
+        "liblog",    // for ALOG
+        "libstagefright_foundation", // for Mutexed
+        "libbase", // for C2_LOG
+        "libutils",
+        "lib_imx_c2_componentbase",
+        "lib_imx_c2_videoenc_common",
+        "lib_imx_c2_process",
+        "libcodec2_vndk",
+        "lib_c2_imx_store",
+    ],
+
+
+    export_include_dirs: ["."],
+
+    defaults: [
+        "imx_defaults",
+        "imx_c2_video_enc_default",
+    ],
+}
diff --git a/codec2/video_enc/common/IMXC2VideoEncoder.cpp b/codec2/video_enc/common/IMXC2VideoEncoder.cpp
new file mode 100755
index 0000000..dc1e06d
--- /dev/null
+++ b/codec2/video_enc/common/IMXC2VideoEncoder.cpp
@@ -0,0 +1,1075 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "IMXC2VideoEncoder"
+#include <log/log.h>
+#include <utils/misc.h>
+
+#include <media/hardware/VideoAPI.h>
+#include <media/stagefright/MediaDefs.h>
+#include <media/stagefright/MediaErrors.h>
+#include <media/stagefright/MetaData.h>
+#include <media/stagefright/foundation/AUtils.h>
+
+#include <C2Debug.h>
+#include <C2PlatformSupport.h>
+#include <util/C2InterfaceHelper.h>
+
+#include "IMXC2Interface.h"
+#include "IMXC2VideoEncoder.h"
+#include "vpu_wrapper.h"
+#include "graphics_ext.h"
+#include "Memory.h"
+#include "IMXUtils.h"
+
+#include <sys/mman.h>
+
+namespace android {
+
+#define CHECK_AND_RETURN_C2_ERR(err) if((err) != OK) {ALOGE("%s, line %d", __FUNCTION__, __LINE__); return (((err) == OK) ? C2_OK : C2_CORRUPTED);}
+#define C2ERR(err) ((err) == OK ? C2_OK : C2_CORRUPTED)
+
+//#define IMX_VIDEO_ENC_TRACE
+#ifdef IMX_VIDEO_ENC_TRACE
+#define IMX_VIDEO_ENC_API_TRACE ALOGD
+#else
+#define IMX_VIDEO_ENC_API_TRACE ALOGV
+#endif
+
+class IMXC2VideoEncoder::IntfImpl : public IMXInterface<void>::BaseParams {
+public:
+    explicit IntfImpl(const std::shared_ptr<C2ReflectorHelper> &helper, C2String componentName)
+        : IMXInterface<void>::BaseParams(
+                helper,
+                componentName,
+                C2Component::KIND_ENCODER,
+                C2Component::DOMAIN_VIDEO,
+                Name2MimeType(componentName.c_str())),
+                mComponentName(componentName) {
+
+        C2String mimeType(Name2MimeType(mComponentName.c_str()));
+        char socId[20];
+        uint32_t minWidth = 64, minHeight = 64;
+        if (0 == GetSocId(socId, sizeof(socId))) {
+            if ((!strncmp(socId, "i.MX8QM", 7)) || (!strncmp(socId, "i.MX8QXP", 8))) {
+                minWidth = 128;
+                minHeight = 128;
+            } else if (!strncmp(socId, "i.MX8MM", 7)) {
+                minWidth = 132;
+                minHeight = 96;
+            }
+        }
+
+        noPrivateBuffers(); // TODO: account for our buffers here
+        noInputReferences();
+        noOutputReferences();
+        noTimeStretch();
+        setDerivedInstance(this);
+
+        addParameter(
+                DefineParam(mUsage, C2_PARAMKEY_INPUT_STREAM_USAGE)
+                .withConstValue(new C2StreamUsageTuning::input(
+                        0u, 0))
+                .build());
+
+        addParameter(
+                DefineParam(mAttrib, C2_PARAMKEY_COMPONENT_ATTRIBUTES)
+                .withConstValue(new C2ComponentAttributesSetting(
+                    C2Component::ATTRIB_IS_TEMPORAL))
+                .build());
+
+        addParameter(
+                DefineParam(mSize, C2_PARAMKEY_PICTURE_SIZE)
+                .withDefault(new C2StreamPictureSizeInfo::input(0u, 320, 240))
+                .withFields({
+                    C2F(mSize, width).inRange(minWidth, 1920, 2),
+                    C2F(mSize, height).inRange(minHeight, 1088, 2),
+                })
+                .withSetter(SizeSetter)
+                .build());
+
+        addParameter(
+                DefineParam(mPixelFormat, C2_PARAMKEY_PIXEL_FORMAT)
+                .withDefault(new C2StreamPixelFormatInfo::input(
+                                     0u, HAL_PIXEL_FORMAT_YCBCR_420_888))
+                .withFields({C2F(mPixelFormat, value).inRange(0, 0xffffffff)})
+                .withSetter(
+                    Setter<decltype(*mPixelFormat)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mGop, C2_PARAMKEY_GOP)
+                .withDefault(C2StreamGopTuning::output::AllocShared(
+                        0 /* flexCount */, 0u /* stream */))
+                .withFields({C2F(mGop, m.values[0].type_).any(),
+                             C2F(mGop, m.values[0].count).any()})
+                .withSetter(GopSetter)
+                .build());
+
+        addParameter(
+                DefineParam(mActualInputDelay, C2_PARAMKEY_INPUT_DELAY)
+                .withDefault(new C2PortActualDelayTuning::input(DEFAULT_B_FRAMES))
+                .withFields({C2F(mActualInputDelay, value).inRange(0, MAX_B_FRAMES)})
+                //.calculatedAs(InputDelaySetter, mGop)
+                .withSetter(
+                    Setter<decltype(*mActualInputDelay)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mFrameRate, C2_PARAMKEY_FRAME_RATE)
+                .withDefault(new C2StreamFrameRateInfo::output(0u, 30.))
+                // TODO: More restriction?
+                .withFields({C2F(mFrameRate, value).greaterThan(0.)})
+                .withSetter(Setter<decltype(*mFrameRate)>::StrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mBitrate, C2_PARAMKEY_BITRATE)
+                .withDefault(new C2StreamBitrateInfo::output(0u, 64000))
+                .withFields({C2F(mBitrate, value).inRange(4096, 12000000)})
+                .withSetter(BitrateSetter)
+                .build());
+
+        addParameter(
+                DefineParam(mIntraRefresh, C2_PARAMKEY_INTRA_REFRESH)
+                .withDefault(new C2StreamIntraRefreshTuning::output(
+                        0u, C2Config::INTRA_REFRESH_DISABLED, 0.))
+                .withFields({
+                    C2F(mIntraRefresh, mode).oneOf({
+                        C2Config::INTRA_REFRESH_DISABLED, C2Config::INTRA_REFRESH_ARBITRARY }),
+                    C2F(mIntraRefresh, period).any()
+                })
+                .withSetter(IntraRefreshSetter)
+                .build());
+
+        addParameter(
+            DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+            .withDefault(new C2StreamProfileLevelInfo::output(
+                    0u, PROFILE_AVC_CONSTRAINED_BASELINE, LEVEL_AVC_4_1))
+            .withFields({
+                C2F(mProfileLevel, profile).oneOf({
+                    PROFILE_AVC_BASELINE,
+                    PROFILE_AVC_CONSTRAINED_BASELINE,
+                    PROFILE_AVC_MAIN,
+                }),
+                C2F(mProfileLevel, level).oneOf({
+                    LEVEL_AVC_1,
+                    LEVEL_AVC_1B,
+                    LEVEL_AVC_1_1,
+                    LEVEL_AVC_1_2,
+                    LEVEL_AVC_1_3,
+                    LEVEL_AVC_2,
+                    LEVEL_AVC_2_1,
+                    LEVEL_AVC_2_2,
+                    LEVEL_AVC_3,
+                    LEVEL_AVC_3_1,
+                    LEVEL_AVC_3_2,
+                    LEVEL_AVC_4,
+                    LEVEL_AVC_4_1,
+                    LEVEL_AVC_4_2,
+                    LEVEL_AVC_5,
+                }),
+            })
+            .withSetter(ProfileLevelSetter, mSize, mFrameRate, mBitrate)
+            .build());
+
+        addParameter(
+                DefineParam(mRequestSync, C2_PARAMKEY_REQUEST_SYNC_FRAME)
+                .withDefault(new C2StreamRequestSyncFrameTuning::output(0u, C2_FALSE))
+                .withFields({C2F(mRequestSync, value).oneOf({ C2_FALSE, C2_TRUE }) })
+                .withSetter(Setter<decltype(*mRequestSync)>::NonStrictValueWithNoDeps)
+                .build());
+
+        addParameter(
+                DefineParam(mSyncFramePeriod, C2_PARAMKEY_SYNC_FRAME_INTERVAL)
+                .withDefault(new C2StreamSyncFrameIntervalTuning::output(0u, 1000000))
+                .withFields({C2F(mSyncFramePeriod, value).any()})
+                .withSetter(Setter<decltype(*mSyncFramePeriod)>::StrictValueWithNoDeps)
+                .build());
+    }
+
+ #if 0  // enable later if needed
+    static C2R InputDelaySetter(
+            bool mayBlock,
+            C2P<C2PortActualDelayTuning::input> &me,
+            const C2P<C2StreamGopTuning::output> &gop) {
+        (void)mayBlock;
+        uint32_t maxBframes = 0;
+        ParseGop(gop.v, nullptr, nullptr, &maxBframes);
+        me.set().value = maxBframes;
+        return C2R::Ok();
+    }
+#endif
+    static C2R BitrateSetter(bool mayBlock, C2P<C2StreamBitrateInfo::output> &me) {
+        (void)mayBlock;
+        C2R res = C2R::Ok();
+        if (me.v.value <= 4096) {
+            me.set().value = 4096;
+        }
+        return res;
+    }
+
+    static C2R SizeSetter(bool mayBlock, const C2P<C2StreamPictureSizeInfo::input> &oldMe,
+                          C2P<C2StreamPictureSizeInfo::input> &me) {
+        (void)mayBlock;
+        C2R res = C2R::Ok();
+        if (!me.F(me.v.width).supportsAtAll(me.v.width)) {
+            res = res.plus(C2SettingResultBuilder::BadValue(me.F(me.v.width)));
+            me.set().width = oldMe.v.width;
+        }
+        if (!me.F(me.v.height).supportsAtAll(me.v.height)) {
+            res = res.plus(C2SettingResultBuilder::BadValue(me.F(me.v.height)));
+            me.set().height = oldMe.v.height;
+        }
+        return res;
+    }
+
+    static C2R ProfileLevelSetter(
+            bool mayBlock,
+            C2P<C2StreamProfileLevelInfo::output> &me,
+            const C2P<C2StreamPictureSizeInfo::input> &size,
+            const C2P<C2StreamFrameRateInfo::output> &frameRate,
+            const C2P<C2StreamBitrateInfo::output> &bitrate) {
+        (void)mayBlock;
+        if (!me.F(me.v.profile).supportsAtAll(me.v.profile)) {
+            me.set().profile = PROFILE_AVC_CONSTRAINED_BASELINE;
+        }
+
+        struct LevelLimits {
+            C2Config::level_t level;
+            float mbsPerSec;
+            uint64_t mbs;
+            uint32_t bitrate;
+        };
+        constexpr LevelLimits kLimits[] = {
+            { LEVEL_AVC_1,     1485,    99,     64000 },
+            // Decoder does not properly handle level 1b.
+            // { LEVEL_AVC_1B,    1485,   99,   128000 },
+            { LEVEL_AVC_1_1,   3000,   396,    192000 },
+            { LEVEL_AVC_1_2,   6000,   396,    384000 },
+            { LEVEL_AVC_1_3,  11880,   396,    768000 },
+            { LEVEL_AVC_2,    11880,   396,   2000000 },
+            { LEVEL_AVC_2_1,  19800,   792,   4000000 },
+            { LEVEL_AVC_2_2,  20250,  1620,   4000000 },
+            { LEVEL_AVC_3,    40500,  1620,  10000000 },
+            { LEVEL_AVC_3_1, 108000,  3600,  14000000 },
+            { LEVEL_AVC_3_2, 216000,  5120,  20000000 },
+            { LEVEL_AVC_4,   245760,  8192,  20000000 },
+            { LEVEL_AVC_4_1, 245760,  8192,  50000000 },
+            { LEVEL_AVC_4_2, 522240,  8704,  50000000 },
+            { LEVEL_AVC_5,   589824, 22080, 135000000 },
+        };
+
+        uint64_t mbs = uint64_t((size.v.width + 15) / 16) * ((size.v.height + 15) / 16);
+        float mbsPerSec = float(mbs) * frameRate.v.value;
+
+        // Check if the supplied level meets the MB / bitrate requirements. If
+        // not, update the level with the lowest level meeting the requirements.
+
+        bool found = false;
+        // By default needsUpdate = false in case the supplied level does meet
+        // the requirements. For Level 1b, we want to update the level anyway,
+        // so we set it to true in that case.
+        bool needsUpdate = (me.v.level == LEVEL_AVC_1B);
+        for (const LevelLimits &limit : kLimits) {
+            if (mbs <= limit.mbs && mbsPerSec <= limit.mbsPerSec &&
+                    bitrate.v.value <= limit.bitrate) {
+                // This is the lowest level that meets the requirements, and if
+                // we haven't seen the supplied level yet, that means we don't
+                // need the update.
+                if (needsUpdate) {
+                    ALOGD("Given level %x does not cover current configuration: "
+                          "adjusting to %x", me.v.level, limit.level);
+                    me.set().level = limit.level;
+                }
+                found = true;
+                break;
+            }
+            if (me.v.level == limit.level) {
+                // We break out of the loop when the lowest feasible level is
+                // found. The fact that we're here means that our level doesn't
+                // meet the requirement and needs to be updated.
+                needsUpdate = true;
+            }
+        }
+        if (!found) {
+            // We set to the highest supported level.
+            me.set().level = LEVEL_AVC_5;
+        }
+
+        return C2R::Ok();
+    }
+
+    static C2R IntraRefreshSetter(bool mayBlock, C2P<C2StreamIntraRefreshTuning::output> &me) {
+        (void)mayBlock;
+        C2R res = C2R::Ok();
+        if (me.v.period < 1) {
+            me.set().mode = C2Config::INTRA_REFRESH_DISABLED;
+            me.set().period = 0;
+        } else {
+            // only support arbitrary mode (cyclic in our case)
+            me.set().mode = C2Config::INTRA_REFRESH_ARBITRARY;
+        }
+        return res;
+    }
+
+    static C2R GopSetter(bool mayBlock, C2P<C2StreamGopTuning::output> &me) {
+        (void)mayBlock;
+        for (size_t i = 0; i < me.v.flexCount(); ++i) {
+            const C2GopLayerStruct &layer = me.v.m.values[0];
+            if (layer.type_ == C2Config::picture_type_t(P_FRAME | B_FRAME)
+                    && layer.count > MAX_B_FRAMES) {
+                me.set().m.values[i].count = MAX_B_FRAMES;
+            }
+        }
+        return C2R::Ok();
+    }
+
+    uint32_t getProfile_l() const {
+        return mProfileLevel->profile;
+    }
+
+    uint32_t getLevel_l() const {
+        struct Level {
+            C2Config::level_t c2Level;
+            uint32_t avcLevel;
+        };
+        constexpr Level levels[] = {
+            { LEVEL_AVC_1,   10 },
+            { LEVEL_AVC_1B,   9 },
+            { LEVEL_AVC_1_1, 11 },
+            { LEVEL_AVC_1_2, 12 },
+            { LEVEL_AVC_1_3, 13 },
+            { LEVEL_AVC_2,   20 },
+            { LEVEL_AVC_2_1, 21 },
+            { LEVEL_AVC_2_2, 22 },
+            { LEVEL_AVC_3,   30 },
+            { LEVEL_AVC_3_1, 31 },
+            { LEVEL_AVC_3_2, 32 },
+            { LEVEL_AVC_4,   40 },
+            { LEVEL_AVC_4_1, 41 },
+            { LEVEL_AVC_4_2, 42 },
+            { LEVEL_AVC_5,   50 },
+        };
+        for (const Level &level : levels) {
+            if (mProfileLevel->level == level.c2Level) {
+                return level.avcLevel;
+            }
+        }
+        ALOGD("Unrecognized level: %x", mProfileLevel->level);
+        return 41;
+    }
+
+    uint32_t getSyncFramePeriod_l() const {
+        if (mSyncFramePeriod->value < 0 || mSyncFramePeriod->value == INT64_MAX) {
+            return 0;
+        }
+        double period = mSyncFramePeriod->value / 1e6 * mFrameRate->value;
+        return (uint32_t)c2_max(c2_min(period + 0.5, double(UINT32_MAX)), 1.);
+    }
+
+    // unsafe getters
+    std::shared_ptr<C2StreamPictureSizeInfo::input> getSize_l() const { return mSize; }
+    std::shared_ptr<C2StreamPixelFormatInfo::input> getPixelFormat_l() const { return mPixelFormat; }
+    std::shared_ptr<C2StreamIntraRefreshTuning::output> getIntraRefresh_l() const { return mIntraRefresh; }
+    std::shared_ptr<C2StreamFrameRateInfo::output> getFrameRate_l() const { return mFrameRate; }
+    std::shared_ptr<C2StreamBitrateInfo::output> getBitrate_l() const { return mBitrate; }
+    std::shared_ptr<C2StreamRequestSyncFrameTuning::output> getRequestSync_l() const { return mRequestSync; }
+    std::shared_ptr<C2StreamGopTuning::output> getGop_l() const { return mGop; }
+
+private:
+    C2String mComponentName;
+    std::shared_ptr<C2StreamUsageTuning::input> mUsage;
+    std::shared_ptr<C2StreamPictureSizeInfo::input> mSize;
+    std::shared_ptr<C2StreamPixelFormatInfo::input> mPixelFormat;
+    std::shared_ptr<C2StreamFrameRateInfo::output> mFrameRate;
+    std::shared_ptr<C2StreamRequestSyncFrameTuning::output> mRequestSync;
+    std::shared_ptr<C2StreamIntraRefreshTuning::output> mIntraRefresh;
+    std::shared_ptr<C2StreamBitrateInfo::output> mBitrate;
+    std::shared_ptr<C2StreamProfileLevelInfo::output> mProfileLevel;
+    std::shared_ptr<C2StreamSyncFrameIntervalTuning::output> mSyncFramePeriod;
+    std::shared_ptr<C2StreamGopTuning::output> mGop;
+};
+
+static void fillEmptyWork(const std::unique_ptr<C2Work> &work) {
+    ALOGD("fillEmptyWork");
+
+    uint32_t flags = 0;
+    if (work->input.flags & C2FrameData::FLAG_END_OF_STREAM) {
+        flags |= C2FrameData::FLAG_END_OF_STREAM;
+        ALOGV("signalling eos");
+    }
+    work->worklets.front()->output.flags = (C2FrameData::flags_t)flags;
+    work->worklets.front()->output.buffers.clear();
+    work->worklets.front()->output.ordinal = work->input.ordinal;
+    work->workletsProcessed = 1u;
+}
+
+IMXC2VideoEncoder::IMXC2VideoEncoder(
+                                    C2String name,
+                                    c2_node_id_t id,
+                                    const std::shared_ptr<IntfImpl> &intfImpl)
+    : IMXC2ComponentBase(std::make_shared<IMXInterface<IntfImpl>>(name, id, intfImpl)),
+      mIntf(intfImpl),
+      mName(name),
+      bGetBlockPool(false),
+      bStarted(false),
+      bCodecDataReceived(false),
+      bPPEnabled(false),
+      nOutBufferNum(8),
+      nCurInTimestamp(-1),
+      nCurOutTimestamp(-1),
+      nCurOutFrameIsKey(0),
+      nCurOutFrameId(-1),
+      nCurOutFrameSize(0){
+
+      mPreProcess = nullptr;
+      mEncoder = nullptr;
+}
+
+IMXC2VideoEncoder::~IMXC2VideoEncoder() {
+}
+
+c2_status_t IMXC2VideoEncoder::onInit() {
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    {
+        IntfImpl::Lock lock = mIntf->lock();
+        mSize = mIntf->getSize_l();
+        mBitrate = mIntf->getBitrate_l();
+        mFrameRate = mIntf->getFrameRate_l();
+        mIntraRefresh = mIntf->getIntraRefresh_l();
+        mPixelFormat = mIntf->getPixelFormat_l();
+    }
+
+    return C2_OK;
+}
+
+c2_status_t IMXC2VideoEncoder::onStop() {
+    status_t err = C2_OK;
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+    if (mPreProcess) {
+        err = mPreProcess->stop();
+        CHECK_AND_RETURN_C2_ERR(err);
+    }
+
+    if (mEncoder)
+        err = mEncoder->stop();
+
+    return C2ERR(err);
+}
+
+void IMXC2VideoEncoder::onReset() {
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    // release + init encoder as default
+    onRelease();
+}
+
+void IMXC2VideoEncoder::onRelease() {
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    releaseComponent();
+}
+
+c2_status_t IMXC2VideoEncoder::onFlush_sm() {
+    status_t err = OK;
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    if (mPreProcess) {
+        err = mPreProcess->flush();
+        CHECK_AND_RETURN_C2_ERR(err);
+    }
+
+    err = mEncoder->flush();
+    CHECK_AND_RETURN_C2_ERR(err);
+
+    return C2ERR(err);
+}
+
+status_t IMXC2VideoEncoder::handleDynamicConfigParam() {
+    IntfImpl::Lock lock = mIntf->lock();
+    std::shared_ptr<C2StreamIntraRefreshTuning::output> intraRefresh = mIntf->getIntraRefresh_l();
+    std::shared_ptr<C2StreamBitrateInfo::output> bitrate = mIntf->getBitrate_l();
+    std::shared_ptr<C2StreamRequestSyncFrameTuning::output> requestSync = mIntf->getRequestSync_l();
+    lock.unlock();
+
+    if (bitrate != mBitrate) {
+        ALOGI("dynamic change bitrate %d -> %d 
", mBitrate->value, bitrate->value);
+        mBitrate = bitrate;
+        mEncoder->setConfig(ENC_CONFIG_BIT_RATE, &mBitrate->value);
+    }
+
+    if (intraRefresh != mIntraRefresh) {
+        mIntraRefresh = intraRefresh;
+        mEncoder->setConfig(ENC_CONFIG_INTRA_REFRESH, &mIntraRefresh->period);
+    }
+
+    if (requestSync != mRequestSync) {
+        // we can handle IDR immediately
+        if (requestSync->value) {
+            // unset request
+            C2StreamRequestSyncFrameTuning::output clearSync(0u, C2_FALSE);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            mIntf->config({ &clearSync }, C2_MAY_BLOCK, &failures);
+            ALOGV("Got sync request");
+            int intraRefresh = 1;
+            if(mPreProcess != nullptr)
+                mPreProcess->setConfig(PROCESS_CONFIG_INTRA_REFRESH, &intraRefresh);
+            else
+                mEncoder->setConfig(ENC_CONFIG_INTRA_REFRESH, &intraRefresh);
+        }
+        mRequestSync = requestSync;
+    }
+
+    return OK;
+}
+
+void IMXC2VideoEncoder::processWork(const std::unique_ptr<C2Work> &work) {
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    work->result = C2_OK;
+    work->workletsProcessed = 0u;
+    work->worklets.front()->output.flags = work->input.flags;
+
+    std::shared_ptr<C2Buffer> inputBuffer = nullptr;
+
+    if (!work->input.buffers.empty()) {
+        std::shared_ptr<const C2GraphicView> view;
+        inputBuffer = work->input.buffers[0];
+        view = std::make_shared<const C2GraphicView>(
+            inputBuffer->data().graphicBlocks().front().map().get());
+        if (view->error() != C2_OK) {
+            ALOGE("graphic view map err = %d", view->error());
+            work->result = C2_CORRUPTED;
+            work->workletsProcessed = 1u;
+            return;
+        }
+    } else {
+        if (bStarted && (work->input.flags & C2FrameData::FLAG_END_OF_STREAM)) {
+            drainInternal(DRAIN_COMPONENT_WITH_EOS);
+            return;
+        } else {
+            // fill empty work
+            return fillEmptyWork(work);
+        }
+    }
+
+    const C2ConstGraphicBlock block = inputBuffer->data().graphicBlocks().front();
+    fsl::Memory *prvHandle = (fsl::Memory*)block.handle();
+
+    if (mPixelFormat->value == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
+        mPixelFormat->value = prvHandle->format;
+    }
+
+    uint32_t size = mSize->width * mSize->height * pxlfmt2bpp(mPixelFormat->value) / 8;
+
+    if (block.width() < mSize->width || block.height() < mSize->height) {
+        ALOGW("unexpected Capacity Aspect %d(%d) x %d(%d)", block.width(), mSize->width, block.height(), mSize->height);
+        return;
+    }
+
+    if (!bStarted) {
+        status_t err = initComponent();
+        if (err != OK)
+            return;
+
+        bStarted = true;
+    }
+
+    int fd = prvHandle->fd;
+    uint64_t pPhysAddr = prvHandle->phys;
+    uint64_t pVirtAddr = prvHandle->base;
+    uint64_t timestamp = work->input.ordinal.timestamp.peeku();
+    uint32_t flags = work->input.flags;
+    int32_t inputId = static_cast<int32_t>(work->input.ordinal.frameIndex.peeku() & 0x3FFFFFFF);
+    bool eos = ((work->input.flags & C2FrameData::FLAG_END_OF_STREAM) != 0);
+
+    ALOGV("in buffer virt addr %p phys addr %p size %d timestamp %lld frameindex %d, flags %x, pixel format 0x%x",
+          (void*)pVirtAddr, (void*)pPhysAddr, (int)size, (long long)timestamp, inputId, flags, mPixelFormat->value);
+
+    if (bPPEnabled) {
+        mPreProcess->queueInput((void*)pVirtAddr, (void*)pPhysAddr, size, timestamp, flags, fd, inputId);
+        return;
+    }
+
+    IMXInputBuffer inBuffer((void*)pVirtAddr, (void*)pPhysAddr, fd, inputId, size, timestamp, flags, eos);
+
+    status_t ret = encoderQueueBuffer(work, &inBuffer);
+    if (ret != OK)
+        ALOGW("encoderQueueBuffer failed");
+
+}
+
+c2_status_t IMXC2VideoEncoder::drainInternal(uint32_t drainMode) {
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    // trigger encoding to drain internel input buffers
+    if (drainMode == NO_DRAIN) {
+        ALOGW("drain with NO_DRAIN: no-op");
+        return C2_OK;
+    }
+    if (drainMode == DRAIN_CHAIN) {
+        ALOGW("DRAIN_CHAIN not supported");
+        return C2_OMITTED;
+    }
+
+    // DRAIN_COMPONENT_WITH_EOS
+    if (bPPEnabled) {
+        mPreProcess->queueInput(nullptr, nullptr, 0, 0, C2FrameData::FLAG_END_OF_STREAM, -1, -1);
+    } else {
+        IMXInputBuffer inBuffer(nullptr, nullptr, -1, -1, 0, 0, 0, true);
+        mEncoder->queueInput(&inBuffer);
+    }
+
+    return C2_OK;
+}
+
+status_t IMXC2VideoEncoder::initComponent() {
+    status_t err = OK;
+    int profile, level;
+    int IDRInterval;
+    int pixelFmt = mPixelFormat->value; //default value
+    std::shared_ptr<C2StreamGopTuning::output> gop;
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    const char* mime = Name2MimeType((const char*)mName.c_str());
+    if (mime == nullptr) {
+        ALOGE("Unsupported component name: %s", mName.c_str());
+        return C2_BAD_VALUE;
+    }
+
+    mEncoder = CreateVideoEncoderInstance(mime);
+    if (!mEncoder) {
+        ALOGE("CreateVideoEncoderInstance for mime(%s) failed 
", mime);
+        return C2_CORRUPTED;
+    }
+
+    if (!bGetBlockPool) {
+        if (OK != mEncoder->setLinearBlockPool(mOutputBlockPool))
+            return BAD_VALUE;
+        bGetBlockPool = true;
+    }
+
+    {
+        IntfImpl::Lock lock = mIntf->lock();
+        IDRInterval = (int)mIntf->getSyncFramePeriod_l();
+        gop = mIntf->getGop_l();
+        profile = mIntf->getProfile_l();
+        level = mIntf->getLevel_l();
+    }
+
+    bPPEnabled = mEncoder->checkIfPreProcessNeeded(pixelFmt);
+
+
+    if (bPPEnabled) {
+        // init preprocess component
+        mPreProcess = CreatePreProcessInstance();
+        if (!mPreProcess) {
+            goto RELEASE_ENCODER;
+        }
+
+        PROCESSBASE_FORMAT inFmt, outFmt;
+        inFmt.width = mSize->width;
+        inFmt.height = mSize->height;
+        inFmt.format = pixelFmt;
+        inFmt.stride = mSize->width;
+        inFmt.bufferSize = inFmt.width * inFmt.height * pxlfmt2bpp(inFmt.format) / 8;
+
+        ALOGE("PROCESS_CONFIG_INPUT_FORMAT w=%d,h=%d,pixelFmt=%x,bufferSize=%d",mSize->width,mSize->height, pixelFmt, inFmt.bufferSize);
+        err = mPreProcess->setConfig(PROCESS_CONFIG_INPUT_FORMAT, &inFmt);
+        if (err) {
+            goto RELEASE_ENCODER;
+        }
+
+        err = mPreProcess->init((ProcessBase::Client*)this, mOutputBlockPool);
+        if (err) {
+            goto RELEASE_ENCODER;
+        }
+
+        err = mPreProcess->getConfig(PROCESS_CONFIG_OUTPUT_FORMAT, &outFmt);
+        if (err) {
+            goto RELEASE_ENCODER;
+        }
+
+        pixelFmt = outFmt.format;
+    }
+
+    EncInputParam inPara;
+    memset(&inPara, 0, sizeof(EncInputParam));
+    inPara.eColorFormat = pixelFmt;
+    inPara.nPicWidth = mSize->width;
+    inPara.nPicHeight = mSize->height;
+    inPara.nWidthStride = mSize->width;
+    inPara.nHeightStride = mSize->height;
+    inPara.nRotAngle = 0;
+    inPara.nFrameRate = mFrameRate->value;
+    inPara.nBitRate = mBitrate->value;
+    inPara.nGOPSize = IDRInterval;
+    inPara.nIDRPeriod = IDRInterval;
+    inPara.nRefreshIntra = mIntraRefresh->period;
+    inPara.bEnabledSPSIDR = true;
+    inPara.nRcIntraQP = 0;
+    inPara.nProfile = profile;
+    inPara.nLevel = level;
+
+    ALOGI("initComponent: res=(%d x %d) fps=%d bitrate=%d GOP=%d pixelFormat %x",
+        inPara.nPicWidth, inPara.nPicHeight, inPara.nFrameRate, inPara.nBitRate, inPara.nGOPSize, pixelFmt);
+    ALOGI("initComponent: IDRInterval=%d RefreshIntra=%d profile=0x%x level=0x%x",
+        inPara.nIDRPeriod, inPara.nRefreshIntra, inPara.nProfile, inPara.nLevel);
+
+    mEncoder->initEncInputParamter(&inPara);
+
+    err = mEncoder->init((VideoEncoderBase::Client*)this);
+    if (err) {
+        goto RELEASE_ENCODER;
+    }
+
+    return C2_OK;
+
+RELEASE_ENCODER:
+    // release encoder if init failed, in case of upper layer don't call release
+    releaseComponent();
+    return C2_CORRUPTED;
+
+}
+
+status_t IMXC2VideoEncoder::releaseComponent() {
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    if (mPreProcess) {
+        mPreProcess->destroy();
+        mPreProcess.clear();
+    }
+
+    if (mEncoder) {
+        mEncoder->destroy();
+        mEncoder.clear();
+    }
+
+    bStarted = false;
+    return OK;
+}
+
+status_t IMXC2VideoEncoder::handleOutputFrame(int32_t outFrameId, uint32_t frameSize,
+                                                        uint64_t timestamp, int keyFrame, uint32_t offset,
+                                                        const std::unique_ptr<C2Work>& work) {
+    ALOGV("handleOutputFrame size %d ts %lld key %d work %p", frameSize, (long long)timestamp, keyFrame, work.get());
+
+    LinearBlockInfo* info = mEncoder->getLinearBlockById(outFrameId);
+    if (!info) {
+        /* notify error */
+        ALOGE("%s line %d: wrong pictureId %d", __FUNCTION__, __LINE__, outFrameId);
+        return BAD_VALUE;
+    }
+
+    if (info->mState != LinearBlockInfo::State::OWNED_BY_VPU) {
+        ALOGE("%s line %d: error linear block state, expect OWNED_BY_VPU but get %d", __FUNCTION__, __LINE__, info->mState);
+        return BAD_VALUE;
+    }
+
+    // unmap this buffer so that it can back to buffer pool
+    if (info->mVirtAddr > 0 && info->mCapacity > 0) {
+        munmap((void*)info->mVirtAddr, info->mCapacity);
+        info->mVirtAddr = 0;
+    }
+
+    // finish work
+    std::shared_ptr<C2Buffer> buffer = createLinearBuffer(std::move(info->mLinearBlock), offset, frameSize);
+
+    if (keyFrame)
+        buffer->setInfo(std::make_shared<C2StreamPictureTypeMaskInfo::output>(0u /* stream id */, C2Config::SYNC_FRAME));
+
+    uint8_t *pCsd = nullptr;
+    uint32_t nCsdSize = 0;
+
+    if (!bCodecDataReceived) {
+        status_t err = OK;
+        err = mEncoder->getCodecData(&pCsd, &nCsdSize);
+        if (OK == err && pCsd && nCsdSize > 0) {
+            bCodecDataReceived = true;
+            ALOGV("receive codecdata, size=%d", nCsdSize);
+        }
+    }
+
+    auto fillWork = [buffer, timestamp, pCsd, nCsdSize](const std::unique_ptr<C2Work> &work) {
+        uint32_t flags = 0;
+        if ((work->input.flags & C2FrameData::FLAG_END_OF_STREAM) &&
+                (c2_cntr64_t(timestamp) == work->input.ordinal.timestamp)) {
+            flags |= C2FrameData::FLAG_END_OF_STREAM;
+            ALOGV("signalling eos");
+        }
+
+        if (pCsd && nCsdSize > 0) {
+            std::unique_ptr<C2StreamInitDataInfo::output> csdInfo =
+                C2StreamInitDataInfo::output::AllocUnique(nCsdSize, 0u);
+            if (csdInfo)
+                memcpy(csdInfo->m.value, pCsd, nCsdSize);
+            work->worklets.front()->output.configUpdate.push_back(std::move(csdInfo));
+        }
+
+        work->worklets.front()->output.flags = (C2FrameData::flags_t)flags;
+        work->worklets.front()->output.buffers.clear();
+        work->worklets.front()->output.buffers.push_back(buffer);
+        work->worklets.front()->output.ordinal = work->input.ordinal;
+        work->workletsProcessed = 1u;
+    };
+
+    if (work) {
+        if (pCsd && nCsdSize > 0) {
+            std::unique_ptr<C2StreamInitDataInfo::output> csdInfo =
+                C2StreamInitDataInfo::output::AllocUnique(nCsdSize, 0u);
+            if (csdInfo)
+                memcpy(csdInfo->m.value, pCsd, nCsdSize);
+            work->worklets.front()->output.configUpdate.push_back(std::move(csdInfo));
+        }
+        work->worklets.front()->output.buffers.clear();
+        work->worklets.front()->output.buffers.push_back(buffer);
+        work->worklets.front()->output.ordinal = work->input.ordinal;
+        work->worklets.front()->output.flags = (work->input.flags & C2FrameData::FLAG_END_OF_STREAM) ?
+                                                C2FrameData::FLAG_END_OF_STREAM : (C2FrameData::flags_t)0;
+        work->workletsProcessed = 1u;
+
+    } else {
+        c2_status_t err = finish(timestamp, fillWork);
+        if (C2_NOT_FOUND == err) {
+            // need to return this output buffer to encoder because its c2work is flushed.
+            mEncoder->returnOutputBufferToEncoder(info->mBlockId);
+        }
+    }
+
+    info->mState = LinearBlockInfo::State::OWNED_BY_CLIENT;
+    info->mLinearBlock.reset();
+
+    return OK;
+}
+
+status_t IMXC2VideoEncoder::handleInputUsed(int inputId) {
+    nUsedFrameIndex = static_cast<uint64_t>(inputId);
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d, input id %d 
", __FUNCTION__, __LINE__, inputId);
+
+    if (nUsedFrameIndex == nCurFrameIndex)
+        return OK; // will handle this in processQueue later
+
+    C2Work* work = getPendingWorkByFrameIndex(nUsedFrameIndex);
+    if (!work) {
+        ALOGW("%s: can't find C2Work for id %d 
", __FUNCTION__, inputId);
+        return BAD_VALUE;
+    }
+
+    // When the work is done, the input buffer shall be reset by component.
+    work->input.buffers.front().reset();
+    ALOGV("input id %d is used 
", inputId);
+
+    return OK;
+}
+
+status_t IMXC2VideoEncoder::encoderQueueBuffer(const std::unique_ptr<C2Work> &work, IMXInputBuffer* pInBuffer) {
+    uint64_t timestamp = pInBuffer->timestamp;
+
+    if (strcmp(MEDIA_MIMETYPE_VIDEO_VP8,Name2MimeType((const char*)mName.c_str())) == 0) {
+        uint32_t frameDuration, frameRate;
+        uint32_t ticksPerSecond = 1000000;
+        if (timestamp > nCurInTimestamp) {
+            frameDuration = (uint32_t)(timestamp - nCurInTimestamp);
+        } else {
+            frameDuration = (uint32_t)ticksPerSecond/mFrameRate->value;
+        }
+
+        frameRate = (ticksPerSecond + frameDuration/2) / frameDuration;
+        if (frameRate != mFrameRate->value) {
+            mFrameRate->value = frameRate;
+            // unset request
+            C2StreamFrameRateInfo::output newFrameRate(0u, frameRate);
+            std::vector<std::unique_ptr<C2SettingResult>> failures;
+            mIntf->config({ &newFrameRate }, C2_MAY_BLOCK, &failures);
+            ALOGI("got new frame rate  %d
", frameRate);
+            mEncoder->setConfig(ENC_CONFIG_FRAME_RATE, &frameRate);
+        }
+    }
+
+    ALOGV("encoderQueueBuffer: phys %p ts %lld id %d", pInBuffer->pInputPhys, (long long)pInBuffer->timestamp, pInBuffer->id);
+
+    nCurInTimestamp = timestamp;
+    mEncoder->queueInput(pInBuffer);
+
+    ALOGV("encoderQueueBuffer done, in ts %lld, out ts %lld, work %p",
+        (long long)nCurInTimestamp, (long long)nCurOutTimestamp, work.get());
+
+#if 0
+    if (nCurInTimestamp == nCurOutTimestamp) {
+        // input data is encoded done immediately, send it out right now
+        if (OK != handleOutputFrame(nCurOutFrameId, nCurOutFrameSize, nCurOutTimestamp, nCurOutFrameIsKey, work)) {
+            ALOGW("processWork: handleOutputFrame return bad value");
+        }
+    }
+#endif
+    return OK;
+}
+
+void IMXC2VideoEncoder::clearOutputFrameBuffer() {
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+}
+
+void IMXC2VideoEncoder::notifyOutputFrameReady(int32_t outFrameId, uint32_t frameSize,
+                                                          uint64_t timestamp, int keyFrame, uint32_t offset) {
+
+    IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    ALOGV("out frame ready, out ts %lld, in ts %lld", (long long)timestamp, (long long)nCurInTimestamp);
+    nCurOutTimestamp = timestamp;
+#if 0
+    if (nCurOutTimestamp == nCurInTimestamp) {
+        // record and handle this output frame later
+        nCurOutFrameIsKey = keyFrame;
+        nCurOutFrameId = outFrameId;
+        nCurOutFrameSize = frameSize;
+        return;
+    }
+#endif
+
+    if (OK != handleOutputFrame(outFrameId, frameSize, timestamp, keyFrame, offset, nullptr)) {
+        ALOGW("handleOutputFrame return bad value");
+    }
+}
+
+void IMXC2VideoEncoder::notifyInputBufferUsed(int32_t input_id) {
+    if (bPPEnabled) {
+        // return input buffer to preprocessor
+        mPreProcess->outputBufferReturned(input_id);
+    } else {
+        handleInputUsed(input_id);
+    }
+}
+
+void IMXC2VideoEncoder::notifyFlushDone() {
+}
+
+void IMXC2VideoEncoder::notifyResetDone() {
+}
+
+void IMXC2VideoEncoder::notifyEos() {
+    finishWithException(true/*eos*/, false/*force*/);
+}
+
+void IMXC2VideoEncoder::notifyError(status_t err) {
+    (void)err;
+}
+
+status_t IMXC2VideoEncoder::fetchProcessBuffer(int *bufferId, unsigned long *phys) {
+    (void)bufferId;
+    (void)phys;
+    return OK;
+}
+
+status_t IMXC2VideoEncoder::notifyProcessInputUsed(int inputId) {
+    return handleInputUsed(inputId);
+}
+
+status_t IMXC2VideoEncoder::notifyProcessDone(int outputId, uint64_t timestamp, uint32_t flag) {
+    ProcessBlockInfo* pInfo = mPreProcess->getProcessBlockById(outputId);
+    if (!pInfo) {
+        ALOGE("notifyProcessDone get invalid outputId: %d", outputId);
+        return BAD_VALUE;
+    }
+
+    IMXInputBuffer inBuffer((void*)pInfo->mVirtAddr, (void*)pInfo->mPhysAddr, pInfo->mFd, pInfo->mBlockId,
+                            pInfo->mCapacity, timestamp, flag, false);
+
+    return encoderQueueBuffer(nullptr, &inBuffer);
+}
+
+
+status_t IMXC2VideoEncoder::notifyProcessOutputClear() {
+    return OK;
+}
+
+
+status_t IMXC2VideoEncoder::notifyProcessFlushDone() {
+    return OK;
+}
+
+
+status_t IMXC2VideoEncoder::notifyProcessResetDone() {
+    return OK;
+}
+
+
+void IMXC2VideoEncoder::notifyProcessError() {
+}
+
+void IMXC2VideoEncoder::notifyProcessEos() {
+    // queue eos to encoder
+    IMXInputBuffer inBuffer(nullptr, nullptr, -1, -1, 0, 0, 0, true);
+    mEncoder->queueInput(&inBuffer);
+}
+
+class IMXC2VideoEncoderFactory : public C2ComponentFactory {
+public:
+    IMXC2VideoEncoderFactory(C2String name)
+        : mHelper(std::static_pointer_cast<C2ReflectorHelper>(GetImxC2Store()->getParamReflector())),
+          mComponentName(name) {
+    }
+
+    virtual c2_status_t createComponent(
+            c2_node_id_t id,
+            std::shared_ptr<C2Component>* const component,
+            std::function<void(C2Component*)> deleter) override {
+        *component = std::shared_ptr<C2Component>(
+                new IMXC2VideoEncoder(mComponentName.c_str(),
+                                 id,
+                                 std::make_shared<IMXC2VideoEncoder::IntfImpl>(mHelper, mComponentName.c_str())),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual c2_status_t createInterface(
+            c2_node_id_t id,
+            std::shared_ptr<C2ComponentInterface>* const interface,
+            std::function<void(C2ComponentInterface*)> deleter) override {
+        *interface = std::shared_ptr<C2ComponentInterface>(
+                new IMXInterface<IMXC2VideoEncoder::IntfImpl>(
+                        mComponentName, id, std::make_shared<IMXC2VideoEncoder::IntfImpl>(mHelper, mComponentName)),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual ~IMXC2VideoEncoderFactory() override = default;
+
+private:
+    std::shared_ptr<C2ReflectorHelper> mHelper;
+    C2String mComponentName;
+};
+
+
+extern "C" ::C2ComponentFactory* IMXCreateCodec2Factory(C2String name) {
+    ALOGV("in %s", __func__);
+    return new ::android::IMXC2VideoEncoderFactory(name);
+}
+
+extern "C" void IMXDestroyCodec2Factory(::C2ComponentFactory* factory) {
+    ALOGV("in %s", __func__);
+    delete factory;
+}
+
+} // namespcae android
+
+/* end of file */
diff --git a/codec2/video_enc/common/IMXC2VideoEncoder.h b/codec2/video_enc/common/IMXC2VideoEncoder.h
new file mode 100644
index 0000000..346d1d7
--- /dev/null
+++ b/codec2/video_enc/common/IMXC2VideoEncoder.h
@@ -0,0 +1,107 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef IMX_C2_VIDEO_ENCODER_H_
+#define IMX_C2_VIDEO_ENCODER_H_
+
+#include <media/stagefright/foundation/MediaDefs.h>
+
+#include <C2Debug.h>
+#include <C2PlatformSupport.h>
+#include <IMXC2Interface.h>
+
+#include "IMXC2ComponentBase.h"
+#include "ProcessBase.h"
+#include "VideoEncoderBase.h"
+#include "C2_imx.h"
+
+namespace android {
+
+#define DEFAULT_B_FRAMES 0
+#define MAX_B_FRAMES     1
+
+class IMXC2VideoEncoder : public IMXC2ComponentBase,
+						           public ProcessBase::Client,
+						           public VideoEncoderBase::Client {
+public:
+	class IntfImpl;
+    IMXC2VideoEncoder(C2String name, c2_node_id_t id, const std::shared_ptr<IntfImpl> &intfImpl);
+    virtual ~IMXC2VideoEncoder();
+
+	// from VideoEncoderBase
+    void clearOutputFrameBuffer() override;
+    void notifyOutputFrameReady(int32_t outFrameId, uint32_t frameSize,
+                                           uint64_t timestamp, int keyFrame, uint32_t offset) override;
+    void notifyInputBufferUsed(int32_t input_id) override;
+    void notifyFlushDone() override;
+    void notifyResetDone() override;
+    void notifyEos() override;
+    void notifyError(status_t err) override;
+
+	// from ProcessBase
+    status_t fetchProcessBuffer(int *bufferId, unsigned long *phys) override;
+    status_t notifyProcessInputUsed(int inputId) override;
+    status_t notifyProcessDone(int outputId, uint64_t timestamp, uint32_t flag) override;
+    status_t notifyProcessOutputClear() override;
+    status_t notifyProcessFlushDone() override;
+    status_t notifyProcessResetDone() override;
+    void notifyProcessError() override;
+    void notifyProcessEos() override;
+
+protected:
+
+	// From IMXC2Component
+    c2_status_t onInit() override;
+    c2_status_t onStop() override;
+    void onReset() override;
+    void onRelease() override;
+    c2_status_t onFlush_sm() override;
+    void processWork(const std::unique_ptr<C2Work> &work) override;
+    c2_status_t drainInternal(uint32_t drainMode) override;
+
+private:
+	sp<ProcessBase> mPreProcess;
+	sp<VideoEncoderBase> mEncoder;
+	std::shared_ptr<IntfImpl> mIntf;
+
+	C2String mName; //component name or role name ?
+    bool bGetBlockPool;
+    bool bStarted;
+    bool bCodecDataReceived;
+    bool bPPEnabled;
+
+    uint32_t nOutBufferNum;
+
+    uint64_t nCurInTimestamp;
+    uint64_t nCurOutTimestamp;
+    int nCurOutFrameIsKey;
+    int32_t nCurOutFrameId;
+    uint32_t nCurOutFrameSize;
+
+    // configurations used by component in process
+    // (TODO: keep this in intf but make them internal only)
+    std::shared_ptr<C2StreamPictureSizeInfo::input> mSize;
+    std::shared_ptr<C2StreamPixelFormatInfo::input> mPixelFormat;
+    std::shared_ptr<C2StreamIntraRefreshTuning::output> mIntraRefresh;
+    std::shared_ptr<C2StreamFrameRateInfo::output> mFrameRate;
+    std::shared_ptr<C2StreamBitrateInfo::output> mBitrate;
+    std::shared_ptr<C2StreamRequestSyncFrameTuning::output> mRequestSync;
+
+    status_t initComponent();
+    status_t releaseComponent();
+    status_t handleDynamicConfigParam();
+    status_t handleOutputFrame(int32_t outFrameId, uint32_t frameSize,
+                                        uint64_t timestamp, int keyFrame, uint32_t offset,
+                                        const std::unique_ptr<C2Work>& work);
+    status_t handleInputUsed(int inputId);
+    status_t encoderQueueBuffer(const std::unique_ptr<C2Work> &work, IMXInputBuffer* pInBuffer);
+};
+
+} // namespace android
+
+#endif  // IMX_C2_VIDEO_ENCODER_H_
diff --git a/codec2/video_enc/common/VideoEncoderBase.cpp b/codec2/video_enc/common/VideoEncoderBase.cpp
new file mode 100755
index 0000000..1c81b57
--- /dev/null
+++ b/codec2/video_enc/common/VideoEncoderBase.cpp
@@ -0,0 +1,575 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "VideoEncoderBase"
+
+//#define API_TRACE
+#ifdef API_TRACE
+#define VEB_API_TRACE ALOGI
+#else
+#define VEB_API_TRACE(...)
+#endif
+
+//#define VEB_INFO_TRACE
+#ifdef VEB_INFO_TRACE
+#define VEB_INFO ALOGI
+#else
+#define VEB_INFO(...)
+#endif
+
+#include <utils/Log.h>
+//#include <cutils/properties.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <inttypes.h>
+#include <sys/mman.h>
+
+#include <C2Config.h>
+#include <C2Debug.h>
+#include <C2PlatformSupport.h>
+
+#include "graphics_ext.h"
+#include "IonAllocator.h"
+
+#include "VideoEncoderBase.h"
+
+namespace android {
+
+#define DEFAULT_ENC_BUF_OUT_CNT		0x3
+#define DEFAULT_ENC_BUF_OUT_SIZE    (2*1024*1024)	//FIXME: set one big enough value !!!
+
+static void Reply(const sp<AMessage> &msg, int32_t *err = nullptr) {
+    sp<AReplyToken> replyId;
+    CHECK(msg->senderAwaitsResponse(&replyId));
+    sp<AMessage> reply = new AMessage;
+    if (err) {
+        reply->setInt32("err", *err);
+    }
+    reply->postReply(replyId);
+}
+
+VideoFormat::VideoFormat(
+                    int format,
+                    uint32_t minNumBuffers,
+                    uint32_t width,
+                    uint32_t height,
+                    bool interlaced)
+    : pixelFormat(format),
+      minBufferNum(minNumBuffers),
+      width(width),
+      height(height),
+      interlaced(interlaced) {
+}
+
+IMXInputBuffer::IMXInputBuffer(IMXInputBuffer* pInput)
+    : pInputVirt(pInput->pInputVirt),
+      pInputPhys(pInput->pInputPhys),
+      fd(pInput->fd),
+      id(pInput->id),
+      size(pInput->size),
+      timestamp(pInput->timestamp),
+      eos(pInput->eos){
+
+}
+
+IMXInputBuffer::IMXInputBuffer(
+                    void* pVirt,
+                    void* pPhys,
+                    int fd,
+                    int id,
+                    uint32_t size,
+                    uint64_t timestamp,
+                    uint32_t flag,
+                    bool eos)
+    : pInputVirt(pVirt),
+      pInputPhys(pPhys),
+      fd(fd),
+      id(id),
+      size(size),
+      timestamp(timestamp),
+      flag(flag),
+      eos(eos){
+}
+
+VideoEncoderBase::VideoEncoderBase()
+    : bInputEos(false),
+      bOutputEos(false),
+      mLooper(new ALooper) {
+    mInputFormat.bufferNum = kInputBufferCount;
+    mInputFormat.bufferSize = kInputBufferSizeFor1080p;
+    mInputFormat.width = DEFAULT_FRM_WIDTH;
+    mInputFormat.height = DEFAULT_FRM_HEIGHT;
+
+    nOutBufferUsage = 0;//(uint64_t)(C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE);
+
+    mOutputFormat.width = DEFAULT_FRM_WIDTH;
+    mOutputFormat.height = DEFAULT_FRM_HEIGHT;
+    mOutputFormat.bufferNum = DEFAULT_ENC_BUF_OUT_CNT;
+    mOutputFormat.bufferSize = DEFAULT_ENC_BUF_OUT_SIZE;
+
+    mLooper->setName("VideoEncoderBase");
+    mLooper->start(false, false, ANDROID_PRIORITY_VIDEO);
+}
+
+VideoEncoderBase::~VideoEncoderBase() {
+}
+
+status_t VideoEncoderBase::init(Client* client/*const std::shared_ptr<C2BlockPool> &pool*/) {
+
+    VEB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    (void)mLooper->registerHandler(this);
+    mClient = client;
+    sp<AMessage> reply;
+    (new AMessage(kWhatInit, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t VideoEncoderBase::stop() {
+
+    VEB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    sp<AMessage> reply;
+    (new AMessage(kWhatStop, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t VideoEncoderBase::flush() {
+
+    VEB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    sp<AMessage> reply;
+    (new AMessage(kWhatFlush, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t VideoEncoderBase::destroy() {
+
+    VEB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    sp<AMessage> reply;
+    (new AMessage(kWhatDestroy, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+}
+
+status_t VideoEncoderBase::queueInput(IMXInputBuffer * pInBuffer) {
+
+    VEB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    bInputEos = pInBuffer->eos;
+
+    {
+        Mutexed<InputBufferQueue>::Locked queue(mInputQueue);
+        queue->push_back(std::make_unique<IMXInputBuffer>(pInBuffer));
+    }
+
+#if 0
+    sp<AMessage> reply;
+    (new AMessage(kWhatEncode, this))->postAndAwaitResponse(&reply);
+    int32_t err;
+    CHECK(reply->findInt32("err", &err));
+    return err;
+#else
+    (new AMessage(kWhatEncode, this))->post();
+    return OK;
+#endif
+}
+
+status_t VideoEncoderBase::importOutput(std::shared_ptr<C2FrameData> outputBuffer) {
+    (void)outputBuffer;
+    return OK;
+}
+
+status_t VideoEncoderBase::setConfig(EncConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    return DoSetConfig(index, pConfig);
+}
+
+status_t VideoEncoderBase::getConfig(EncConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    return DoGetConfig(index, pConfig);
+}
+
+status_t VideoEncoderBase::allocateOutputBuffers() {
+    uint32_t i;
+    C2MemoryUsage usage(nOutBufferUsage);
+
+    VEB_API_TRACE("%s, line %d, mBlockPool %p, try to allocate %d buffers 
",
+        __FUNCTION__, __LINE__, mBlockPool.get(), mOutputFormat.bufferNum);
+
+    for (i = 0; i < mOutputFormat.bufferNum; i++) {
+        std::shared_ptr<C2LinearBlock> outBlock;
+        c2_status_t err = mBlockPool->fetchLinearBlock(mOutputFormat.bufferSize, usage, &outBlock);
+        if (err != C2_OK) {
+            ALOGE("fetchLinearBlock for Output failed with status %d", err);
+            return BAD_VALUE;
+        }
+
+        if (OK != appendOutputBuffer(std::move(outBlock), &mOutputFormat.bufferSize))
+            return BAD_VALUE;
+    }
+    return OK;
+}
+
+status_t VideoEncoderBase::freeOutputBuffers() {
+    VEB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    for (auto& info : mLinearBlocks) {
+        if (info.mVirtAddr > 0 && info.mCapacity > 0)
+            munmap((void*)info.mVirtAddr, info.mCapacity);
+    }
+
+    mLinearBlocks.clear();
+
+    return OK;
+}
+
+bool VideoEncoderBase::checkIfPreProcessNeeded(int pixelFormat) {
+    return false;
+}
+
+status_t VideoEncoderBase::getCodecData(uint8_t** pCodecData, uint32_t* size) {
+    (void)pCodecData;
+    (void)size;
+    return OK;
+}
+
+status_t VideoEncoderBase::setLinearBlockPool(const std::shared_ptr<C2BlockPool>& pool) {
+
+    VEB_API_TRACE("%s, line %d, pool=%p", __FUNCTION__, __LINE__, pool.get());
+
+    if (pool.get() == nullptr) {
+        ALOGE("setLineatBlockPool get nullptr ! 
");
+        return BAD_VALUE;
+    }
+
+    mBlockPool = pool;
+    return OK;
+}
+
+status_t VideoEncoderBase::onInit() {
+    /* implement by sub class */
+    return OK;
+}
+
+status_t VideoEncoderBase::onStop() {
+    /* implement by sub class */
+    return OK;
+}
+
+status_t VideoEncoderBase::onFlush() {
+    /* implement by sub class */
+    return OK;
+}
+
+status_t VideoEncoderBase::onDestroy() {
+    /* implement by sub class */
+    return OK;
+}
+
+// input == nullptr, drain output
+status_t VideoEncoderBase::encodeInternal(std::unique_ptr<IMXInputBuffer> input) {
+    /* implement by sub class */
+    (void)input;
+    return OK;
+}
+
+status_t VideoEncoderBase::onOutputBufferReturned(int32_t bufferId) {
+    (void)bufferId;
+    return OK;
+}
+
+status_t VideoEncoderBase::getOutputVideoInfo(VideoFormat * info) {
+    (void)info;
+    return OK;
+}
+
+LinearBlockInfo* VideoEncoderBase::getLinearBlockById(int32_t blockId) {
+    if (blockId < 0 || blockId >= static_cast<int32_t>(mLinearBlocks.size())) {
+        ALOGE("getLinearBlockById failed: id=%d", blockId);
+        return nullptr;
+    }
+    return &mLinearBlocks[blockId];
+}
+
+LinearBlockInfo* VideoEncoderBase::getLinearBlockByFd(int fd) {
+    if (fd < 0) {
+        ALOGE("%s line %d: invalid fd=%d", __FUNCTION__, __LINE__, fd);
+        return nullptr;
+    }
+    auto blockIter = std::find_if(mLinearBlocks.begin(), mLinearBlocks.end(),
+                                  [fd](const LinearBlockInfo& lb) {
+                                      return lb.mDMABufFd == fd;
+                                  });
+
+    if (blockIter == mLinearBlocks.end()) {
+        ALOGE("%s line %d: failed: fd=%d", __FUNCTION__, __LINE__, fd);
+        return nullptr;
+    }
+    return &(*blockIter);
+}
+
+LinearBlockInfo* VideoEncoderBase::getLinearBlockByPhysAddr(unsigned long physAddr) {
+    if (physAddr == 0) {
+        ALOGE("%s line %d: invalid physical address=%lld", __FUNCTION__, __LINE__, (long long)physAddr);
+        return nullptr;
+    }
+    auto blockIter = std::find_if(mLinearBlocks.begin(), mLinearBlocks.end(),
+                                  [physAddr](const LinearBlockInfo& lb) {
+                                      return lb.mPhysAddr == physAddr;
+                                  });
+
+    if (blockIter == mLinearBlocks.end()) {
+        return nullptr;
+    }
+    return &(*blockIter);
+}
+
+LinearBlockInfo* VideoEncoderBase::getFreeLinearBlock() {
+    auto blockIter = std::find_if(mLinearBlocks.begin(), mLinearBlocks.end(),
+                                  [](const LinearBlockInfo& lb) {
+                                      return lb.mState == LinearBlockInfo::State::OWNED_BY_COMPONENT;;
+                                  });
+
+    if (blockIter == mLinearBlocks.end()) {
+        return nullptr;
+    }
+    return &(*blockIter);
+}
+
+void VideoEncoderBase::onOutputBufferDone() {
+#if 0
+    VEB_API_TRACE("%s, line %d", __FUNCTION__, __LINE__);
+
+    C2MemoryUsage usage(nOutBufferUsage);
+
+    std::shared_ptr<C2LinearBlock> outBlock;
+    c2_status_t c2_err = mBlockPool->fetchLinearBlock(/* size */,
+                                                    mOutputFormat.pixelFormat, usage, &outBlock);
+    if (c2_err != C2_OK) {
+        ALOGE("fetchLinearBlock for Output failed with status %d", c2_err);
+        return ;
+    }
+
+    int fd = outBlock->handle()->data[0];
+    LinearBlockInfo* info = getLinearBlockByFd(fd);
+    if (!info) {
+        // TODO: register to vpu
+        if (OK != appendOutputBuffer(outBlock))
+            return;
+        info = getLinearBlockByFd(fd);
+        if (!info) {
+            ALOGE("%s, line %d, can't handle fd=%d 
", __FUNCTION__, __LINE__, fd);
+            return;
+        }
+        VEB_INFO("%s, fetch a new buffer: fd=%d", __FUNCTION__, fd);
+    } else if (info->mState != LinearBlockInfo::State::OWNED_BY_CLIENT) {
+        ALOGE("%s, get wrong buffer state %d", __FUNCTION__, info->mState);
+        return;
+    } else {
+        ALOGV("%s, return fd %d, block id %d", __FUNCTION__, fd, (int)info->mBlockId);
+        info->mLinearBlock = std::move(outBlock);
+        info->mState = LinearBlockInfo::State::OWNED_BY_COMPONENT;
+    }
+
+    onOutputBufferReturned(info->mBlockId);
+#endif
+}
+
+void VideoEncoderBase::returnOutputBufferToEncoder(int32_t blockId) {
+    LinearBlockInfo *pInfo = getLinearBlockById(blockId);
+    if (pInfo) {
+        pInfo->mState = LinearBlockInfo::State::OWNED_BY_COMPONENT;
+    } else {
+        ALOGE("%s: invalid blockId %d", __FUNCTION__, blockId);
+    }
+}
+
+void VideoEncoderBase::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatEncode: {
+            std::unique_ptr<IMXInputBuffer> input;
+            {
+                Mutexed<InputBufferQueue>::Locked queue(mInputQueue);
+                // there is always have at least one input
+                input = std::move(queue->front());
+                queue->pop_front(); // pop in NotifyInputBufferUsed ?
+            }
+
+            status_t err = encodeInternal(std::move(input));
+            //Reply(msg, &err);
+            break;
+        }
+        case kWhatInit: {
+            int32_t err = onInit();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatStop: {
+            int32_t err = onStop();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatFlush: {
+            Mutexed<InputBufferQueue>::Locked queue(mInputQueue);
+            while (!queue->empty()) {
+                queue->pop_front();
+            }
+            int32_t err = onFlush();
+            Reply(msg, &err);
+            break;
+        }
+        case kWhatDestroy: {
+            // release resources
+            Mutexed<InputBufferQueue>::Locked queue(mInputQueue);
+            while (!queue->empty()) {
+                queue->pop_front();
+            }
+            int32_t err = onDestroy();
+            freeOutputBuffers();
+            Reply(msg, &err);
+            break;
+        }
+        default: {
+            ALOGW("Unrecognized msg: %d", msg->what());
+            break;
+        }
+    }
+}
+
+status_t VideoEncoderBase::appendOutputBuffer(std::shared_ptr<C2LinearBlock> block, uint32_t* capacity) {
+    fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
+    int ret;
+    int fd = block->handle()->data[0];
+    uint64_t pPhys = 0;
+    uint64_t pVirt = 0;
+    uint32_t size = *capacity;//mOutputFormat.bufferSize;
+
+    ret = pIonAllocator->getPhys(fd, size, (uint64_t&)pPhys);
+    if (ret != 0) {
+        ALOGE("Ion get physical address failed, fd %d", fd);
+        return BAD_VALUE;
+    }
+
+    ret = pIonAllocator->getVaddrs(fd, size, (uint64_t&)pVirt);
+    if (ret != 0) {
+        ALOGE("Ion get virtual address failed, size=%d, fd %d", size, fd);
+        return BAD_VALUE;
+    }
+
+    LinearBlockInfo* pInfo = getLinearBlockByPhysAddr(pPhys);
+    if (pInfo) {
+        // previous output buffer returned to decoder
+        pInfo->mDMABufFd = fd;
+        pInfo->mVirtAddr = pVirt;
+        pInfo->mLinearBlock = std::move(block);
+        pInfo->mCapacity = size;
+        pInfo->mState = LinearBlockInfo::State::OWNED_BY_COMPONENT;
+    } else {
+        LinearBlockInfo info;
+        memset(&info, 0, sizeof(LinearBlockInfo));
+        info.mBlockId = static_cast<int32_t>(mLinearBlocks.size());
+        info.mDMABufFd = fd;
+        info.mState = LinearBlockInfo::State::OWNED_BY_COMPONENT;
+        info.mCapacity = size;
+        info.mPhysAddr = pPhys;
+        info.mVirtAddr = pVirt;
+        info.mLinearBlock = std::move(block);
+        mLinearBlocks.push_back(std::move(info));
+
+        VEB_INFO("appendOutputBuffer id %d phys %p, virt %p 
", info.mBlockId, (void*)pPhys, (void*)pVirt);
+    }
+
+    return OK;
+}
+
+status_t VideoEncoderBase::importOutputBuffers(std::vector<LinearBlockInfo> buffers) {
+    return OK;
+}
+
+status_t VideoEncoderBase::FetchOutputBuffer(int* bufferId,
+                                                    int* fd,
+                                                    unsigned long* pPhysAddr,
+                                                    unsigned long* pVirtAddr,
+                                                    uint32_t* capacity) {
+    status_t ret = OK;
+    LinearBlockInfo* info = getFreeLinearBlock();
+
+    if (nullptr == info) {
+        std::shared_ptr<C2LinearBlock> block;
+        C2MemoryUsage usage(nOutBufferUsage);
+        c2_status_t status = mBlockPool->fetchLinearBlock(*capacity, usage, &block);
+        if (C2_OK != status) {
+            ALOGE("fetchLinearBlock for Output failed with status 0x%x", status);
+            return BAD_VALUE;
+        }
+
+        ret = appendOutputBuffer(block, capacity);
+        if (ret != OK)
+            return ret;
+
+        info = getFreeLinearBlock();
+        if (nullptr == info) {
+            // shouldn't come here because we just allocated a free block
+            ALOGE("FetchOutputBuffer: can't get a free block");
+            return BAD_VALUE;
+        }
+
+    }
+
+    *bufferId = info->mBlockId;
+    *fd = info->mDMABufFd;
+    *pPhysAddr = info->mPhysAddr;
+    *pVirtAddr = info->mVirtAddr;
+    *capacity = info->mCapacity;
+    info->mState = LinearBlockInfo::State::OWNED_BY_VPU;
+
+    return OK;
+}
+
+void VideoEncoderBase::ClearOutputFrameBuffer() {
+    mClient->clearOutputFrameBuffer();
+}
+
+void VideoEncoderBase::NotifyFlushDone () {
+    mClient->notifyFlushDone();
+}
+
+void VideoEncoderBase::NotifyInputBufferUsed(int32_t input_id) {
+    ALOGV("NotifyInputBufferUsed %d", (int)input_id);
+    mClient->notifyInputBufferUsed(input_id);
+}
+
+void VideoEncoderBase::NotifyOutputFrameReady(int32_t outFrameId, uint32_t frameSize,
+                                                         uint64_t timestamp, int keyFrame, uint32_t offset) {
+    mClient->notifyOutputFrameReady(outFrameId, frameSize, timestamp, keyFrame, offset);
+}
+
+void VideoEncoderBase::NotifyEOS() {
+    mClient->notifyEos();
+}
+
+void VideoEncoderBase::NotifyError(status_t err) {
+    mClient->notifyError(err);
+}
+
+} // namespace android
+
+/* end of file */
diff --git a/codec2/video_enc/common/VideoEncoderBase.h b/codec2/video_enc/common/VideoEncoderBase.h
new file mode 100755
index 0000000..f79d53c
--- /dev/null
+++ b/codec2/video_enc/common/VideoEncoderBase.h
@@ -0,0 +1,256 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef VIDEO_ENCODER_BASE_H
+#define VIDEO_ENCODER_BASE_H
+
+#include <C2Buffer.h>
+#include <C2Work.h>
+
+#include <media/stagefright/foundation/AHandler.h>
+#include <media/stagefright/foundation/ALooper.h>
+#include <media/stagefright/foundation/Mutexed.h>
+
+namespace android {
+
+#define DEFAULT_FRM_WIDTH   176
+#define DEFAULT_FRM_HEIGHT  144
+
+typedef enum {
+    ENC_CONFIG_BIT_RATE = 0,
+    ENC_CONFIG_FRAME_RATE,
+    ENC_CONFIG_INTRA_REFRESH,
+    ENC_CONFIG_COLOR_FORMAT,
+} EncConfig;
+
+struct LinearBlockInfo {
+    enum class State {
+        OWNED_BY_COMPONENT = 0,    // Owned by this component.
+        OWNED_BY_CLIENT,       // Owned by client.
+        OWNED_BY_VPU,          // Owned by vpu
+    };
+
+    // The ID of this block used for VPU.
+    int32_t mBlockId = -1;
+    // The ID of this block used in block pool. It indicates slot index for bufferqueue-backed
+    // block pool, and buffer ID of BufferPoolData for bufferpool block pool.
+    uint32_t mPoolId = 0;
+    State mState = State::OWNED_BY_COMPONENT;
+    // Linear block buffer allocated from allocator. The linear block should be owned until
+    // it is passed to client.
+    std::shared_ptr<C2LinearBlock> mLinearBlock;
+    // HAL pixel format used while importing to VPU.
+    int mPixelFormat; //HalPixelFormat mPixelFormat;
+    uint64_t mTimestamp;
+    int mDMABufFd;
+    unsigned long mPhysAddr;
+    unsigned long mVirtAddr;
+    uint32_t mCapacity;
+};
+
+typedef struct {
+    int eColorFormat;  // input color format
+	int nPicWidth;
+	int nPicHeight;
+	int nWidthStride;
+	int nHeightStride;
+	int nRotAngle;
+	int nFrameRate;
+	int nBitRate;			/*unit: bps*/
+	int nGOPSize;
+	//VpuEncMirrorDirection sMirror;
+	int nQuantParam;
+	int nEnableAutoSkip;
+	int nIDRPeriod;		//for H.264
+	int nRefreshIntra;	//IDR for H.264
+	bool bEnabledSPSIDR; //SPS/PPS is added for every IDR frame
+	int nRcIntraQP;		//0: auto; >0: qp value
+	int nProfile;
+    int nLevel;
+} EncInputParam;
+
+
+struct VideoFormat {
+    int pixelFormat = 0;//HalPixelFormat::UNKNOWN;
+    uint32_t minBufferNum = 0;
+    uint32_t width;
+    uint32_t height;
+    uint32_t bufferNum;
+    uint32_t bufferSize;
+    bool interlaced;
+
+    VideoFormat() {}
+    VideoFormat(int format, uint32_t minNumBuffers, uint32_t width, uint32_t height,
+                bool interlaced);
+};
+
+struct IMXInputBuffer{
+    void* pInputVirt;
+    void* pInputPhys;
+    int fd;
+    int id;
+    uint32_t size;
+    uint64_t timestamp;
+    uint32_t flag;
+    bool eos;
+
+    IMXInputBuffer() {}
+    IMXInputBuffer(IMXInputBuffer* pInput);
+    IMXInputBuffer(void* pVirt, void* pPhys, int fd, int id, uint32_t size, uint64_t timestamp, uint32_t flag, bool eos);
+};
+
+
+class VideoEncoderBase
+    : public AHandler, public std::enable_shared_from_this<VideoEncoderBase> {
+public:
+    // The adaptor client interface. This interface should be implemented in the component side.
+    class Client {
+    public:
+        // Callback to tell client how many and what size of buffers to provide.
+        virtual void notifyVideoInfo(VideoFormat *pFormat) {(void)pFormat;}
+
+        // CallBack to tell client to free picture buffers.
+        virtual void clearOutputFrameBuffer() {}
+
+        // Callback to deliver decoded pictures ready to be displayed.
+        virtual void notifyOutputFrameReady(int32_t outFrameId, uint32_t frameSize,
+                                                        uint64_t timestamp, int keyFrame, uint32_t offset) {
+            (void)outFrameId;
+            (void)frameSize;
+            (void)timestamp;
+            (void)keyFrame;
+            (void)offset;
+        }
+
+        // Callback to notify that decoder has decoded the end of the bitstream buffer with specified ID.
+        virtual void notifyInputBufferUsed(int32_t input_id) {(void)input_id;}
+
+        // Callback to tell client how many and what size of buffers to provide.
+        virtual void fetchOutputBuffer(int* bufferId,
+                                      unsigned long* pPhysAddr,
+                                      unsigned long* pVirtAddr,
+                                      uint32_t* capacity) {
+            (void)bufferId;
+            (void)pPhysAddr;
+            (void)pVirtAddr;
+            (void)capacity;
+        }
+
+        // Flush completion callback.
+        virtual void notifyFlushDone() {}
+
+        // Reset completion callback.
+        virtual void notifyResetDone() {}
+
+        // Callback to notify about errors. Note that errors in initialize() will not be reported
+        // here, instead of by its returned value.
+        virtual void notifyError(status_t err) {(void)err;}
+
+        virtual void notifyEos() {}
+    protected:
+        virtual ~Client() = default;
+    };
+
+    VideoEncoderBase();
+    virtual ~VideoEncoderBase();
+
+    status_t init(Client* client/*const std::shared_ptr<C2BlockPool> &pool*/);//load componnent and init parameters
+    status_t stop();//idle to loaded
+    status_t flush();//flush
+    status_t destroy();//free Buffers
+    status_t setConfig(EncConfig index, void* pConfig);
+    status_t getConfig(EncConfig index, void* pConfig);
+    virtual status_t DoSetConfig(EncConfig index, void* pConfig) {return OK;}
+    virtual status_t DoGetConfig(EncConfig index, void* pConfig) {return OK;}
+    virtual status_t getCodecData(uint8_t** pCodecData, uint32_t* size);
+    virtual bool checkIfPreProcessNeeded(int pixelFormat);
+
+    //status_t setClient(Client* client);
+    status_t setLinearBlockPool(const std::shared_ptr<C2BlockPool>& pool);
+    status_t queueInput(IMXInputBuffer * pInBuffer);
+    status_t importOutput(std::shared_ptr<C2FrameData> outputBuffer);
+    virtual status_t importOutputBuffers(std::vector<LinearBlockInfo> buffers);
+    LinearBlockInfo* getLinearBlockById(int32_t blockId);
+    LinearBlockInfo* getLinearBlockByFd(int fd);
+    LinearBlockInfo* getLinearBlockByPhysAddr(unsigned long physAddr);
+    LinearBlockInfo* getFreeLinearBlock();
+
+    void onOutputBufferDone();
+    void returnOutputBufferToEncoder(int32_t blockId);
+    virtual void initEncInputParamter(EncInputParam *pInPara) {(void)pInPara;}
+
+protected:
+
+    uint32_t mWidth;
+    uint32_t mHeight;
+    bool bInputEos;
+    bool bOutputEos;
+
+    VideoFormat mInputFormat;
+    VideoFormat mOutputFormat;
+
+    void onMessageReceived(const sp<AMessage> &msg) override;
+    virtual status_t onInit();
+    virtual status_t onStop();//idle to loaded
+    virtual status_t onFlush();//flush
+    virtual status_t onDestroy();//free Buffers
+    virtual status_t encodeInternal(std::unique_ptr<IMXInputBuffer> input);
+    virtual status_t onOutputBufferReturned(int32_t bufferId);
+    virtual status_t getOutputVideoInfo(VideoFormat * info);
+
+    status_t FetchOutputBuffer(int* bufferId,
+                                      int* fd,
+                                      unsigned long* pPhysAddr,
+                                      unsigned long* pVirtAddr,
+                                      uint32_t* capacity);
+
+    void ClearOutputFrameBuffer();
+    void NotifyOutputFrameReady(int32_t outFrameId, uint32_t frameSize, uint64_t timestamp, int keyFrame, uint32_t offset);
+    void NotifyInputBufferUsed(int32_t input_id);
+    void NotifyFlushDone();
+    void NotifyResetDone();
+    void NotifyEOS();
+    void NotifyError(status_t err);
+
+private:
+    enum {
+        kWhatEncode,
+        kWhatInit,
+        kWhatFlush,
+        kWhatStop,
+        kWhatReset,
+        kWhatDestroy,
+    };
+    enum {
+        kInputBufferCount = 8,
+        kInputBufferSizeFor1080p = 1024 * 1024,
+        // Input bitstream buffer size for up to 4k streams.
+        kInputBufferSizeFor4k = 4 * kInputBufferSizeFor1080p,
+        kDefaultOutputBufferCount = 8,
+    };
+
+    sp<ALooper> mLooper;
+    Client* mClient;
+
+    typedef std::list<std::unique_ptr<IMXInputBuffer>> InputBufferQueue;
+    Mutexed<InputBufferQueue> mInputQueue;
+    std::shared_ptr<C2BlockPool> mBlockPool;
+    std::vector<LinearBlockInfo> mLinearBlocks;
+    IMXInputBuffer mCurInputBuffer;
+
+    uint64_t nOutBufferUsage;
+
+    status_t allocateOutputBuffers();
+    status_t freeOutputBuffers();
+    status_t appendOutputBuffer(std::shared_ptr<C2LinearBlock> block, uint32_t* capacity);
+};
+
+VideoEncoderBase * CreateVideoEncoderInstance(const char* mime);
+
+}
+#endif // VIDEO_ENCODER_BASE_H
diff --git a/codec2/video_enc/v4l2_enc/Android.bp b/codec2/video_enc/v4l2_enc/Android.bp
new file mode 100644
index 0000000..47cd9a8
--- /dev/null
+++ b/codec2/video_enc/v4l2_enc/Android.bp
@@ -0,0 +1,72 @@
+imx_c2_v4l2_dec_defaults {
+    name: "imx_c2_v4l2_enc_default",
+}
+
+bootstrap_go_package {
+    name: "soong-v4l2_enc",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/video_enc/v4l2_enc",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "v4l2_enc.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+cc_library_shared {
+    name: "lib_imx_c2_v4l2_enc",
+
+    defaults: ["imx_c2_v4l2_enc_default"],
+
+    soc_specific: true,
+    srcs: [
+        "V4l2Enc.cpp",
+		"FrameConverter.cpp"
+    ],
+
+    header_libs: [
+        "libcodec2_headers",
+        "media_plugin_headers",
+    ],
+
+    include_dirs: [
+		"hardware/libhardware/include",
+        "frameworks/av/media/libstagefright/include",
+        "frameworks/av/media/codec2/core/include",
+        "frameworks/av/media/codec2/vndk/include",
+        "frameworks/av/media/codec2/components/base/include",    
+        "vendor/nxp/imx_android_mm/codec2/video_enc/common",
+        "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/imx_android_mm/codec2/v4l2_dev",
+        "vendor/nxp-opensource/imx/include",
+	],
+    shared_libs: [
+        "liblog",
+		"libstagefright_bufferqueue_helper",
+		"libstagefright_foundation",
+        "libcodec2_vndk",
+		"libutils",
+        "libcutils",
+        "lib_imx_c2_v4l2_dev",
+        "lib_imx_c2_videoenc_common",
+    ],
+
+    sanitize: {
+        cfi: true,
+        misc_undefined: [
+            "unsigned-integer-overflow",
+            "signed-integer-overflow",
+        ],
+        diag: {
+            cfi: true,
+        },
+    },
+
+//    compile_multilib: "32",
+}
diff --git a/codec2/video_enc/v4l2_enc/FrameConverter.cpp b/codec2/video_enc/v4l2_enc/FrameConverter.cpp
new file mode 100755
index 0000000..73a757a
--- /dev/null
+++ b/codec2/video_enc/v4l2_enc/FrameConverter.cpp
@@ -0,0 +1,293 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+#include "FrameConverter.h"
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "FrameConverter"
+#include <linux/videodev2.h>
+
+namespace android {
+status_t FrameConverter::Create(uint32_t format)
+{
+    if(format != V4L2_PIX_FMT_H264)
+        return UNKNOWN_ERROR;
+    nFormat = format;
+    pSpsPps = NULL;
+    nLen = 0;
+    return OK;
+}
+status_t FrameConverter::ConvertToCodecData(
+    uint8_t* pInData, uint32_t nSize, uint8_t* pOutData,uint32_t*nOutSize,uint32_t * nConsumeLen)
+{
+    uint8_t* pPre=pInData;
+    uint32_t spsSize=0, ppsSize=0;
+    uint8_t *sps=NULL, *pps=NULL;
+    uint8_t* pNext=NULL;
+    uint8_t naltype;
+    int32_t length=(int32_t)nSize;
+    uint8_t* pTemp=NULL,*pFilled=NULL;
+    uint32_t skipLen=0;
+
+    if(pInData == NULL || pOutData == NULL || nOutSize == NULL)
+        return UNKNOWN_ERROR;
+
+    /*search boundary of sps and pps */
+    if(false==FindStartCode(pInData,length,&pPre)){
+        goto search_finish;
+    }
+
+    pPre+=4; //skip 4 bytes of startcode
+    length-=(pPre-pInData);
+
+    if(length<=0){
+        goto search_finish;
+    }
+
+    while(1){
+        int size;
+
+        if(FindStartCode(pPre,length,&pNext)){
+            size=pNext-pPre;
+        }
+        else{
+            size=length; //last nal
+        }
+        naltype=pPre[0] & 0x1f;
+        ALOGD("find one nal, type: 0x%x, size: %d 
",naltype,size);
+        if (naltype==7) { /* SPS */
+            sps=pPre;
+            spsSize=size;
+        }
+        else if (naltype==8) { /* PPS */
+            pps= pPre;
+            ppsSize=size;
+        }else if(naltype == 0x0c){//skip coda padding bytes
+            skipLen += 4+size;
+        }
+        
+        if(pNext==NULL){
+            goto search_finish;
+        }
+        pNext+=4;
+        length-=(pNext-pPre);
+        if(length<=0){
+        	goto search_finish;
+        }
+        pPre=pNext;
+    }
+search_finish:
+    if((sps==NULL)||(pps==NULL)){
+        return UNKNOWN_ERROR;
+    }
+
+    pFilled=pOutData;
+    pFilled[0]=1;		/* version */
+    pFilled[1]=sps[1];	/* profile */
+    pFilled[2]=sps[2];	/* profile compat */
+    pFilled[3]=sps[3];	/* level */
+    pFilled[4]=0xFF;	/* 6 bits reserved (111111) + 2 bits nal size length - 1 (11) */
+    pFilled[5]=0xE1;	/* 3 bits reserved (111) + 5 bits number of sps (00001) */
+    pFilled+=6;
+
+    pFilled[0]=(spsSize>>8)&0xFF; /*sps size*/
+    pFilled[1]=spsSize&0xFF;
+    pFilled+=2;
+    memcpy(pFilled,sps,spsSize); /*sps data*/
+    pFilled+=spsSize;
+
+    pFilled[0]=1;		/* number of pps */
+    pFilled++;
+    pFilled[0]=(ppsSize>>8)&0xFF;	/*pps size*/
+    pFilled[1]=ppsSize&0xFF;
+    pFilled+=2;
+    memcpy(pFilled,pps,ppsSize); /*pps data*/
+    *nOutSize=6+2+spsSize+1+2+ppsSize;
+    *nConsumeLen = 4+4+spsSize+ppsSize+skipLen;
+
+    if(pSpsPps != NULL)
+        free(pSpsPps);
+    if(nSize > (*nConsumeLen))
+        nLen = (*nConsumeLen);
+    else
+        return UNKNOWN_ERROR;
+    pSpsPps = (uint8_t*)malloc(nLen);
+    memcpy(pSpsPps,pInData,nLen); /*sps data*/
+
+    return OK;
+}
+status_t FrameConverter::CheckSpsPps(uint8_t* pInData, uint32_t nSize, uint32_t* nConsumeLen)
+{
+    uint8_t* pPre=pInData;
+    uint32_t spsSize=0, ppsSize=0;
+    uint8_t *sps=NULL, *pps=NULL;
+    uint8_t* pNext=NULL;
+    uint8_t naltype;
+    int32_t length=(int32_t)nSize;
+    uint8_t* pTemp=NULL,*pFilled=NULL;
+    uint32_t skipLen=0;
+
+    if(pInData == NULL || nConsumeLen == NULL)
+        return UNKNOWN_ERROR;
+
+    /*search boundary of sps and pps */
+    if(false==FindStartCode(pInData,length,&pPre)){
+        goto search_finish;
+    }
+
+    pPre+=4; //skip 4 bytes of startcode
+    length-=(pPre-pInData);
+
+    if(length<=0){
+        goto search_finish;
+    }
+
+    while(1){
+        int size;
+
+        if(FindStartCode(pPre,length,&pNext)){
+            size=pNext-pPre;
+        }
+        else{
+            size=length; //last nal
+        }
+        naltype=pPre[0] & 0x1f;
+        ALOGD("find one nal, type: 0x%x, size: %d 
",naltype,size);
+        if (naltype==7) { /* SPS */
+            sps=pPre;
+            spsSize=size;
+        }
+        else if (naltype==8) { /* PPS */
+            pps= pPre;
+            ppsSize=size;
+        }else if(naltype == 0x0c){//skip coda padding bytes
+            skipLen += 4+size;
+        }
+
+        if(pNext==NULL){
+            goto search_finish;
+        }
+        pNext+=4;
+        length-=(pNext-pPre);
+        if(length<=0){
+            goto search_finish;
+        }
+        pPre=pNext;
+    }
+
+search_finish:
+    if((sps==NULL)||(pps==NULL)){
+        return UNKNOWN_ERROR;
+    }
+
+    nLen = spsSize+ppsSize+skipLen+4+4;
+
+    if(nSize < nLen)
+        return UNKNOWN_ERROR;
+
+    *nConsumeLen = nLen;
+
+    if(pSpsPps != NULL)
+        free(pSpsPps);
+
+    pSpsPps = (uint8_t*)malloc(nLen);
+    if(pSpsPps == NULL)
+        return UNKNOWN_ERROR;
+    memcpy(pSpsPps,pInData,nLen); /*sps data*/
+    ALOGD("size=%d,consume=%d,nLen=%d",nSize,*nConsumeLen,nLen);
+    return OK;
+}
+
+status_t FrameConverter::ConvertToData(uint8_t* pData, uint32_t nSize)
+{
+    /*we will replace the 'start code'(00000001) with 'nal size'(4bytes), and the buffer length no changed*/
+    uint8_t* pPre=pData;
+    int32_t length=(int32_t)nSize;
+    uint32_t nalSize=0;
+    uint32_t outSize=0;
+    uint32_t i=0;
+    uint8_t* pNext=NULL;
+    uint8_t naltype;
+
+    if(!FindStartCode(pData,length,&pPre)){
+        goto finish;
+    }
+    pPre+=4; //skip 4 bytes of startcode
+    length-=(pPre-pData);
+    while(1){
+
+        if(FindStartCode(pPre,length,&pNext)){
+            nalSize=pNext-pPre;
+        }
+        else{
+            nalSize=length; //last nal
+        }
+        naltype=pPre[0] & 0x1f;
+        ALOGD("find one nal, type: 0x%x, size: %d 
",naltype,nalSize);
+
+        pPre[-4]=(nalSize>>24)&0xFF;
+        pPre[-3]=(nalSize>>16)&0xFF;
+        pPre[-2]=(nalSize>>8)&0xFF;
+        pPre[-1]=(nalSize)&0xFF;
+
+        i++;
+        outSize+=nalSize+4;
+        ALOGD("ConvertToData find one nal, size: %d 
",nalSize);
+
+        if(pNext==NULL){
+            goto finish;
+        }
+        pNext+=4;
+        length-=(pNext-pPre);
+        pPre=pNext;
+    }
+finish:
+    return OK;
+}
+status_t FrameConverter::GetSpsPpsPtr(uint8_t** pData,uint32_t *outLen)
+{
+    if(pData == NULL || outLen == NULL)
+        return UNKNOWN_ERROR;
+
+    *pData = pSpsPps;
+    *outLen = nLen;
+    return OK;
+}
+status_t FrameConverter::Destroy()
+{
+    if(pSpsPps != NULL)
+        free(pSpsPps);
+    nLen = 0;
+    return OK;
+}
+bool FrameConverter::FindStartCode(uint8_t* pData, uint32_t nSize,uint8_t** ppStart)
+{
+    #define AVC_START_CODE 0x00000001
+    uint32_t startcode=0xFFFFFFFF;
+    uint8_t* p=pData;
+    uint8_t* pEnd=pData+nSize;
+    
+    if(nSize < 4){
+        *ppStart=NULL;
+        return false;
+    }
+    while(p<pEnd){
+        startcode=(startcode<<8)|p[0];
+        if(AVC_START_CODE==startcode){
+            break;
+        }
+        p++;
+    }
+    if(p>=pEnd){
+        *ppStart=NULL;
+        return false;
+    }
+    *ppStart=p-3;
+    return true;
+}
+}
diff --git a/codec2/video_enc/v4l2_enc/FrameConverter.h b/codec2/video_enc/v4l2_enc/FrameConverter.h
new file mode 100755
index 0000000..cf3680d
--- /dev/null
+++ b/codec2/video_enc/v4l2_enc/FrameConverter.h
@@ -0,0 +1,36 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef FRAMECONVERTER_H
+#define FRAMECONVERTER_H
+#include <media/stagefright/foundation/AHandler.h>
+#include <media/stagefright/foundation/ALooper.h>
+#include <media/stagefright/foundation/Mutexed.h>
+namespace android {
+
+class FrameConverter{
+public:
+    status_t Create(uint32_t format);
+    status_t ConvertToCodecData(uint8_t* pInData, uint32_t nSize,
+        uint8_t* pOutData,uint32_t*nOutSize,uint32_t * nConsumeLen);
+    status_t ConvertToData(uint8_t* pData, uint32_t nSize);
+    status_t GetSpsPpsPtr(uint8_t** pData,uint32_t *outLen);
+    status_t CheckSpsPps(uint8_t* pInData, uint32_t nSize, uint32_t* nConsumeLen);
+    status_t Destroy();
+
+private:
+    uint32_t nFormat;
+    uint32_t nLen;
+    uint8_t* pSpsPps;
+    
+    bool FindStartCode(uint8_t* pData, uint32_t nSize,uint8_t** ppStart);
+
+};
+}
+#endif
+
diff --git a/codec2/video_enc/v4l2_enc/V4l2Enc.cpp b/codec2/video_enc/v4l2_enc/V4l2Enc.cpp
new file mode 100644
index 0000000..0942de7
--- /dev/null
+++ b/codec2/video_enc/v4l2_enc/V4l2Enc.cpp
@@ -0,0 +1,1473 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4l2Enc"
+
+#include "V4l2Enc.h"
+#include <media/stagefright/MediaErrors.h>
+#include "graphics_ext.h"
+#include <sys/mman.h>
+#include "C2_imx.h"
+
+namespace android {
+
+#define VPU_ENCODER_LOG_LEVELFILE "/data/vpu_enc_level"
+#define DUMP_ENC_INPUT_FILE "/data/temp_enc_in.yuv"
+#define DUMP_ENC_OUTPUT_FILE "/data/temp_enc_out.bit"
+
+#define DUMP_ENC_FLAG_INPUT     0x1
+#define DUMP_ENC_FLAG_OUTPUT    0x2
+
+#define Align(ptr,align)    (((uint32_t)(ptr)+(align)-1)/(align)*(align))
+#define FRAME_ALIGN     (2)
+
+V4l2Enc::V4l2Enc(const char* mime):
+    mMime(mime),
+    mPollThread(0),
+    mFetchThread(0),
+    pDev(NULL),
+    mFd(-1){
+
+    mInputFormat.bufferNum = 8;
+    mInputFormat.bufferSize = DEFAULT_FRM_WIDTH * DEFAULT_FRM_HEIGHT * 3/2;
+    mInputFormat.width = DEFAULT_FRM_WIDTH;
+    mInputFormat.height = DEFAULT_FRM_HEIGHT;
+    mInputFormat.interlaced = false;
+    mInputFormat.pixelFormat = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+
+    mOutputFormat.width = DEFAULT_FRM_WIDTH;
+    mOutputFormat.height = DEFAULT_FRM_HEIGHT;
+    mOutputFormat.minBufferNum = 2;
+    mOutputFormat.bufferNum = 4;
+    mOutputFormat.interlaced = false;
+
+    mConverter = NULL;
+
+    bPreProcess = false;
+    ALOGV("mMime=%s",mMime);
+    mState = UNINITIALIZED;
+
+}
+V4l2Enc::~V4l2Enc()
+{
+    if(bFetchStarted || bPollStarted)
+        onStop();
+
+    onDestroy();
+}
+status_t V4l2Enc::onInit(){
+    status_t ret = UNKNOWN_ERROR;
+
+    if(pDev == NULL){
+        pDev = new V4l2Dev();
+    }
+    if(pDev == NULL)
+        return ret;
+
+    mFd = pDev->Open(V4L2_DEV_ENCODER);
+    ALOGV("onInit pV4l2Dev->Open fd=%d",mFd);
+
+    if(mFd < 0)
+        return ret;
+
+    //V4L2_MEMORY_USERPTR; V4L2_MEMORY_DMABUF; V4L2_MEMORY_MMAP
+    mInMemType = V4L2_MEMORY_DMABUF;
+    mOutMemType = V4L2_MEMORY_MMAP;
+    mFrameOutNum = 0;
+
+    ret = prepareOutputParams();
+
+    ParseVpuLogLevel();
+    mState = UNINITIALIZED;
+
+    return ret;
+}
+status_t V4l2Enc::onStart()
+{
+
+    status_t ret = UNKNOWN_ERROR;
+
+    bPollStarted = false;
+    bFetchStarted = false;
+    bInputStreamOn = false;
+    bOutputStreamOn = false;
+    bSyncFrame = false;
+    bHasCodecData = false;
+
+    mFrameOutNum = 0;
+
+    if(!strcmp(mMime, "video/avc")){
+        mConverter = new FrameConverter();
+        if(mConverter == NULL){
+            ret = UNKNOWN_ERROR;
+            return ret;
+        }
+        ALOGV("NEW FrameConverter");
+        ret = mConverter->Create(V4L2_PIX_FMT_H264);
+    }
+
+    ret = SetOutputFormats();
+    if(ret != OK)
+        return ret;
+
+    ret = prepareOutputBuffers();
+    ALOGV("onStart prepareInputBuffers ret=%d",ret);
+    if(ret != OK)
+        return ret;
+
+    ret = prepareInputParams();
+    if(ret != OK){
+        ALOGE("prepareInputParams failed");
+        return ret;
+    }
+
+    ret = SetInputFormats();
+    if(ret != OK){
+        ALOGE("SetInputFormats failed");
+        return ret;
+    }
+
+    if(mInputBufferMap.empty() || (mInputFormat.bufferSize != mInputPlaneSize[0] + mInputPlaneSize[1])){
+
+        ret = prepareInputBuffers();
+        ALOGV("onStart prepareInputBuffers ret=%d",ret);
+        if(ret != OK)
+            return ret;
+    }
+
+    ret = pDev->SetEncoderParam(&mEncParam);
+    if(ret != OK){
+        ALOGE("SetEncoderParam failed");
+        return ret;
+    }
+
+    ret = pDev->SetFrameRate(mTargetFps);
+    if(ret != OK){
+        ALOGE("SetFrameRate failed");
+        return ret;
+    }
+
+
+    //allocate output buffers
+    for(int32_t i = 0; i < mOutputFormat.bufferNum; i++){
+        ret = allocateOutputBuffer(i);
+        if(ret != OK){
+            ALOGE("allocateOutputBuffer failed");
+            return ret;
+        }
+    }
+
+    ret = createPollThread();
+    if(ret != OK){
+        ALOGE("createPollThread failed");
+        return ret;
+    }
+    mState = RUNNING;
+
+    ret = createFetchThread();
+
+    ALOGV("onStart ret=%d",ret);
+
+    return ret;
+}
+status_t V4l2Enc::prepareOutputParams()
+{
+    status_t ret = UNKNOWN_ERROR;
+    Mutex::Autolock autoLock(mLock);
+
+    ret = pDev->GetStreamTypeByMime(mMime, &mOutFormat);
+    if(ret != OK)
+        return ret;
+
+    ALOGV("mOutFormat=%x",mOutFormat);
+    if(!pDev->IsCaptureFormatSupported(mOutFormat)){
+        ALOGE("encoder format not suppoted");
+        return ret;
+    }
+
+    if(mOutputFormat.bufferNum == 0){
+        mOutputFormat.bufferNum = 2;
+    }
+    ALOGV("bufferNum=%d,bufferSize=%d",mOutputFormat.bufferNum, mOutputFormat.bufferSize);
+    mWidthAlign = 1;
+    mHeightAlign = 1;
+
+    struct v4l2_frmsizeenum info;
+    memset(&info, 0, sizeof(v4l2_frmsizeenum));
+    if(OK != pDev->GetFormatFrameInfo(mOutFormat, &info)){
+        ALOGE("GetFormatFrameInfo failed");
+        return ret;
+    }
+
+    mWidthAlign = info.stepwise.step_width;
+    mHeightAlign = info.stepwise.step_height;
+
+    return OK;
+}
+status_t V4l2Enc::SetOutputFormats()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    mOutputFormat.width = Align(mOutputFormat.width, mWidthAlign);
+    mOutputFormat.height = Align(mOutputFormat.height, mHeightAlign);
+
+    struct v4l2_format format;
+    memset(&format, 0, sizeof(format));
+    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    format.fmt.pix_mp.num_planes = kOutputBufferPlaneNum;
+    format.fmt.pix_mp.pixelformat = mOutFormat;
+    format.fmt.pix_mp.plane_fmt[0].sizeimage = mOutputFormat.bufferSize;
+    format.fmt.pix_mp.plane_fmt[0].bytesperline = Align(mOutputFormat.width, mWidthAlign);
+    format.fmt.pix_mp.width = mOutputFormat.width;
+    format.fmt.pix_mp.height = mOutputFormat.height;
+    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+
+    result = ioctl (mFd, VIDIOC_S_FMT, &format);
+    if(result != 0)
+        return UNKNOWN_ERROR;
+
+    memset(&format, 0, sizeof(format));
+    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+
+    result = ioctl (mFd, VIDIOC_G_FMT, &format);
+    if(result != 0)
+        return UNKNOWN_ERROR;
+
+    if(format.fmt.pix_mp.pixelformat != mOutFormat){
+        ALOGE("SetOutputFormats mInFormat mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if( format.fmt.pix_mp.width != mOutputFormat.width ||
+        format.fmt.pix_mp.height != mOutputFormat.height){
+        ALOGE("SetOutputFormats resolution mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].bytesperline != Align(mOutputFormat.width, mWidthAlign)){
+        ALOGE("SetOutputFormats stride mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].sizeimage != mOutputFormat.bufferSize){
+        ALOGE("SetOutputFormats bufferSize mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    return OK;
+}
+status_t V4l2Enc::prepareInputParams()
+{
+    status_t ret = UNKNOWN_ERROR;
+    Mutex::Autolock autoLock(mLock);
+
+    ret = pDev->GetV4l2FormatByColor(mInputFormat.pixelFormat, &mInFormat);
+    if(ret != OK){
+        ALOGE("prepareInputParams failed, pixelFormat=%x,mInFormat=%x",mInputFormat.pixelFormat,mInFormat);
+        return ret;
+    }
+
+    if(!pDev->IsOutputFormatSupported(mInFormat)){
+        ALOGE("encoder input format not suppoted");
+        return ret;
+    }
+
+    if(mInFormat == V4L2_PIX_FMT_NV12){
+        //update output frame width & height
+        mInputFormat.width = Align(mInputFormat.width, mWidthAlign);
+        mInputFormat.height = Align(mInputFormat.height, mHeightAlign);
+
+        mInputPlaneSize[0] = mInputFormat.width * mInputFormat.height;
+        mInputPlaneSize[1] = mInputPlaneSize[0]/2;
+        mInputFormat.bufferSize = mInputPlaneSize[0] + mInputPlaneSize[1];
+        ALOGV("prepareInputParams w=%d,h=%d,input buffer size=%d",mInputFormat.width, mInputFormat.height, mInputFormat.bufferSize);
+
+    }else{
+        ALOGE("encoder input format not NV12");
+        return UNKNOWN_ERROR;
+    }
+
+    return OK;
+}
+status_t V4l2Enc::SetInputFormats()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_format format;
+    memset(&format, 0, sizeof(format));
+    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    format.fmt.pix_mp.num_planes = kInputBufferPlaneNum;
+    format.fmt.pix_mp.pixelformat = mInFormat;
+    format.fmt.pix_mp.width = mInputFormat.width;
+    format.fmt.pix_mp.height = mInputFormat.height;
+    format.fmt.pix_mp.plane_fmt[0].sizeimage = mInputPlaneSize[0];
+    format.fmt.pix_mp.plane_fmt[0].bytesperline = Align(mInputFormat.width, mWidthAlign);
+    format.fmt.pix_mp.plane_fmt[1].sizeimage = mInputPlaneSize[1];
+    format.fmt.pix_mp.plane_fmt[1].bytesperline = Align(mInputFormat.width, mWidthAlign);
+    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+
+    result = ioctl (mFd, VIDIOC_S_FMT, &format);
+    if(result != 0){
+        ALOGE("SetInputFormats VIDIOC_S_FMT failed");
+        return UNKNOWN_ERROR;
+    }
+
+    memset(&format, 0, sizeof(struct v4l2_format));
+    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+
+    result = ioctl (mFd, VIDIOC_G_FMT, &format);
+    if(result < 0)
+        return UNKNOWN_ERROR;
+
+
+    if(format.fmt.pix_mp.pixelformat != mInFormat){
+        ALOGE("SetInputFormats mOutFormat mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.width != mInputFormat.width ||
+        format.fmt.pix_mp.height != mInputFormat.height){
+        ALOGE("SetInputFormats resolution mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    if(format.fmt.pix_mp.plane_fmt[0].sizeimage != mInputPlaneSize[0] ||
+        format.fmt.pix_mp.plane_fmt[1].sizeimage != mInputPlaneSize[1]){
+        ALOGE("SetInputFormats bufferSize mismatch");
+        return UNKNOWN_ERROR;
+    }
+
+    ALOGV("SetInputFormats success");
+    return OK;
+}
+
+V4l2Enc::InputRecord::InputRecord()
+    : at_device(false), input_id(-1), ts(-1) {
+    memset(&planes, 0, kInputBufferPlaneNum * sizeof(VideoFramePlane));
+}
+
+V4l2Enc::InputRecord::~InputRecord() {}
+
+V4l2Enc::OutputRecord::OutputRecord()
+    : at_device(false), picture_id(0), flag(0) {
+}
+
+V4l2Enc::OutputRecord::~OutputRecord() {
+}
+status_t V4l2Enc::prepareInputBuffers()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = mInputFormat.bufferNum;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.memory = mInMemType;
+    ALOGV("prepareInputBuffers VIDIOC_REQBUFS bufferNum=%d",reqbufs.count);
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0){
+        ALOGE("VIDIOC_REQBUFS failed result=%d",result);
+        return UNKNOWN_ERROR;
+    }
+    ALOGV("prepareInputBuffers mInputBufferMap resize=%d",reqbufs.count);
+    mInputBufferMap.resize(reqbufs.count);
+
+    ALOGV("prepareInputBuffers total input=%d size=%d",mOutputFormat.bufferNum, mOutputBufferMap.size());
+
+    for (size_t i = 0; i < mInputBufferMap.size(); i++) {
+        mInputBufferMap[i].at_device = false;
+        mInputBufferMap[i].input_id = -1;
+        mInputBufferMap[i].planes[0].fd = -1;
+    }
+    return OK;
+}
+status_t V4l2Enc::prepareOutputBuffers()
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = mOutputFormat.bufferNum;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.memory = mOutMemType;
+
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0){
+        ALOGE("VIDIOC_REQBUFS failed result=%d",result);
+        return UNKNOWN_ERROR;
+    }
+
+    mOutputBufferMap.resize(reqbufs.count);
+
+    for (size_t i = 0; i < mOutputBufferMap.size(); i++) {
+        mOutputBufferMap[i].at_device = false;
+        mOutputBufferMap[i].plane.fd = -1;
+        mOutputBufferMap[i].plane.addr = 0;
+        mOutputBufferMap[i].plane.size = mOutputFormat.bufferSize;
+        mOutputBufferMap[i].plane.length = 0;
+        mOutputBufferMap[i].plane.offset = 0;
+        mOutputBufferMap[i].flag = 0;
+    }
+
+    ALOGV("VIDIOC_REQBUFS CAPTURE_MPLANE success input=%d size=%d",mOutputFormat.bufferNum, mOutputBufferMap.size());
+
+    return OK;
+}
+status_t V4l2Enc::destroyInputBuffers()
+{
+    Mutex::Autolock autoLock(mLock);
+    if (mInputBufferMap.empty())
+        return OK;
+
+    int result = 0;
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = 0;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
+
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0)
+        return UNKNOWN_ERROR;
+
+    mInputBufferMap.clear();
+    ALOGV("destroyInputBuffers success");
+    return OK;
+}
+status_t V4l2Enc::destroyOutputBuffers()
+{
+    Mutex::Autolock autoLock(mLock);
+    if (mOutputBufferMap.empty())
+        return OK;
+
+    int result = 0;
+    struct v4l2_requestbuffers reqbufs;
+    memset(&reqbufs, 0, sizeof(reqbufs));
+    reqbufs.count = 0;
+    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
+
+    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
+
+    if(result != 0)
+        return UNKNOWN_ERROR;
+
+    mOutputBufferMap.clear();
+    //clearOutputFrameBuffer();//call it here or in base class
+    ALOGV("destroyOutputBuffers success");
+    return OK;
+}
+status_t V4l2Enc::HandlePollThread()
+{
+    status_t ret = OK;
+    int32_t poll_ret = 0;
+
+    while(bPollStarted){
+        ALOGV("pollThreadHandler BEGIN");
+        poll_ret = pDev->Poll();
+        ALOGV("pollThreadHandler poll_ret=%x",poll_ret);
+
+        if(!bPollStarted)
+            break;
+
+        if(poll_ret & V4L2_DEV_POLL_EVENT){
+            ret = onDequeueEvent();
+        }
+        if(poll_ret & V4L2_DEV_POLL_OUTPUT){
+            ret = dequeueInputBuffer();
+        }
+        if(poll_ret & V4L2_DEV_POLL_CAPTURE){
+            ret = dequeueOutputBuffer();
+        }
+        ALOGV("pollThreadHandler END ret=%x",ret);
+    }
+    ALOGV("HandlePollThread return");
+    return OK;
+
+}
+status_t V4l2Enc::HandleFetchThread()
+{
+    int blockId;
+    int fd;
+    unsigned long nOutPhy;
+    unsigned long nOutVirt;
+    uint32_t nOutLength = mOutputFormat.bufferSize;
+
+    while(bFetchStarted){
+        int32_t i = 0;
+        int32_t j = 0;
+        if(mOutputBufferMap.empty() || RUNNING != mState){
+            usleep(1000);
+            continue;
+        }
+        
+        bool fetch = false;
+        int32_t currNum = (mFrameOutNum % mOutputFormat.bufferNum);
+
+        for (i = currNum; i < currNum + mOutputFormat.bufferNum; i++) {
+            j = i;
+            if(i < mOutputFormat.bufferNum)
+                j = i;
+            else
+                j = i - mOutputFormat.bufferNum;
+
+            if(mOutputBufferMap[j].at_device == false){
+                fetch = true;
+                break;
+            }
+        }
+
+        if(!fetch){
+            usleep(1000);
+            continue;
+        }
+
+         if(!bFetchStarted)
+            break;
+
+        ALOGV("call FetchOutputBuffer BEGIN");
+        queueOutput(j, -1, 0);
+        //if(OK == FetchOutputBuffer(&blockId, &fd, &nOutPhy, &nOutVirt, &nOutLength)){
+        //queueOutput(blockId, fd, nOutVirt);
+        //}
+
+    }
+    return OK;
+}
+// static
+void *V4l2Enc::PollThreadWrapper(void *me) {
+    return (void *)(uintptr_t)static_cast<V4l2Enc *>(me)->HandlePollThread();
+}
+void *V4l2Enc::FetchThreadWrapper(void *me) {
+    return (void *)(uintptr_t)static_cast<V4l2Enc *>(me)->HandleFetchThread();
+}
+
+status_t V4l2Enc::createPollThread()
+{
+    Mutex::Autolock autoLock(mLock);
+
+    if(!bPollStarted){
+        pthread_attr_t attr;
+        pthread_attr_init(&attr);
+        pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+
+        bPollStarted = true;
+        pthread_create(&mPollThread, &attr, PollThreadWrapper, this);
+        pthread_attr_destroy(&attr);
+    }
+    return OK;
+}
+status_t V4l2Enc::destroyPollThread()
+{
+    ALOGV("destroyPollThread BEGIN");
+
+    if(bPollStarted){
+        bPollStarted = false;
+        ALOGV("destroyPollThread bPollStarted FALSE");
+        usleep(1000);
+        pDev->SetPollInterrupt();
+        mLock.lock();
+        pthread_join(mPollThread, NULL);
+        mLock.unlock();
+        pDev->ClearPollInterrupt();
+    }
+    return OK;
+}
+status_t V4l2Enc::createFetchThread()
+{
+    Mutex::Autolock autoLock(mLock);
+
+    if(!bFetchStarted){
+        pthread_attr_t attr;
+        pthread_attr_init(&attr);
+        pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+        
+        bFetchStarted = true;
+        pthread_create(&mFetchThread, &attr, FetchThreadWrapper, this);
+        pthread_attr_destroy(&attr);
+    }
+    return OK;
+}
+status_t V4l2Enc::destroyFetchThread()
+{
+    ALOGV("destroyFetchThread BEGIN");
+
+    if(bFetchStarted){
+        bFetchStarted = false;
+        ALOGV("destroyFetchThread bFetchStarted FALSE");
+        usleep(1000);
+        mLock.lock();
+        pthread_join(mFetchThread, NULL);
+        mLock.unlock();
+    }
+
+    return OK;
+}
+status_t V4l2Enc::encodeInternal(std::unique_ptr<IMXInputBuffer> input)
+{
+    int result = 0;
+
+    int32_t index = -1;
+    uint32_t v4l2_flags = 0;
+
+    if(input == nullptr)
+        return BAD_VALUE;
+
+    if(STOPPED == mState || UNINITIALIZED == mState)
+        onStart();
+
+    mLock.lock();
+
+    bool eos = input->eos;
+
+    if(eos)
+        v4l2_flags |= V4L2_BUF_FLAG_LAST;
+
+    //handle eos
+    if(eos && -1 == input->id && 0 == input->size){
+        ALOGV("encodeInternal StopEncoder");
+        pDev->StopEncoder();
+        mLock.unlock();
+        return OK;
+    }
+
+    if((int64_t)input->timestamp >= 0)
+        v4l2_flags |= (V4L2_BUF_FLAG_TIMESTAMP_MASK | V4L2_BUF_FLAG_TIMESTAMP_COPY);
+
+    if(bSyncFrame || (input->flag & FLAG_SYNC_FRAME)){
+        v4l2_flags |= V4L2_BUF_FLAG_KEYFRAME;
+        bSyncFrame = false;
+    }
+
+    if(input->size > mInputFormat.bufferSize){
+        ALOGE("invalid buffer size=%d,cap=%d",input->size, mInputFormat.bufferSize);
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+
+    //try to get index
+    for(int32_t i = 0; i < mInputBufferMap.size(); i++){
+        if((mInputBufferMap[i].planes[0].fd == input->fd 
+            || mInputBufferMap[i].planes[0].addr == (uint64_t)input->pInputVirt) 
+            && !mInputBufferMap[i].at_device){
+            index = i;
+            break;
+        }
+    }
+
+    //index not found
+    if(index < 0){
+        for(int32_t i = 0; i < mInputBufferMap.size(); i++){
+            if(-1 == mInputBufferMap[i].planes[0].fd){
+                mInputBufferMap[i].planes[0].fd = input->fd;
+                mInputBufferMap[i].planes[0].addr = (uint64_t)input->pInputVirt;
+                mInputBufferMap[i].planes[0].offset = 0;
+                index = i;
+                break;
+            }
+        }
+    }
+
+    if(index < 0){
+        mLock.unlock();
+        ALOGE("encodeInternal invalid index");
+        return UNKNOWN_ERROR;
+    }
+
+    mInputBufferMap[index].input_id = input->id;
+    ALOGV("encodeInternal input_id=%d,input->BUF=%p,phys=%x, index=%d, len=%zu, ts=%lld, fd=%d",
+        input->id, input->pInputVirt,input->pInputPhys, index, input->size, input->timestamp, input->fd);
+
+    if(mInputBufferMap[index].at_device){
+        ALOGE("onQueueInputBuffer index=%d, at_device",index);
+    }
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kInputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(&planes[0], 0, kInputBufferPlaneNum * sizeof(struct v4l2_plane));
+
+    planes[0].bytesused = mInputPlaneSize[0];
+    planes[0].length = mInputPlaneSize[0];
+    planes[0].data_offset = 0;
+
+    if(bPreProcess){
+        planes[1].bytesused = mInputPlaneSize[1];
+        planes[1].length = mInputPlaneSize[1];
+        planes[1].data_offset = 0;
+    }else{
+        planes[1].bytesused = mInputPlaneSize[0]+ mInputPlaneSize[1];
+        planes[1].length = mInputPlaneSize[0] + mInputPlaneSize[1];
+        planes[1].data_offset = mInputPlaneSize[0];
+    }
+
+    if(mInMemType == V4L2_MEMORY_USERPTR){
+        planes[0].m.userptr = mInputBufferMap[index].planes[0].addr = (uint64_t)input->pInputVirt;
+        planes[1].m.userptr = mInputBufferMap[index].planes[1].addr = (uint64_t)input->pInputVirt;
+    }else if(mInMemType == V4L2_MEMORY_DMABUF){
+        if(bPreProcess)
+            planes[0].m.fd = mInputBufferMap[index].planes[0].fd = (int)(uint64_t)input->pInputPhys;
+        else
+            planes[0].m.fd = mInputBufferMap[index].planes[0].fd = input->fd;
+
+        planes[1].m.fd = mInputBufferMap[index].planes[1].fd = input->fd;
+
+    }
+
+    stV4lBuf.index = index;
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    if((int64_t)input->timestamp > 0){
+        stV4lBuf.timestamp.tv_sec = (int64_t)input->timestamp/1000000;
+        stV4lBuf.timestamp.tv_usec = (int64_t)input->timestamp - stV4lBuf.timestamp.tv_sec * 1000000;
+    }
+    stV4lBuf.memory = mInMemType;
+    stV4lBuf.m.planes = &planes[0];
+    stV4lBuf.length = kInputBufferPlaneNum;
+    stV4lBuf.flags = v4l2_flags;
+
+    ALOGV("V4l2Enc OUTPUT_MPLANE VIDIOC_QBUF index=%d,len=%d, ts=%lld,fd0=%d,fd1=%d
",
+        stV4lBuf.index, planes[0].bytesused, (long long)input->timestamp,planes[0].m.fd, planes[1].m.fd);
+
+    result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
+    if(result < 0){
+        ALOGE("VIDIOC_QBUF failed, index=%d, result=%x",index,result);
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+
+    mInputBufferMap[index].at_device = true;
+
+    dumpInputBuffer(input->fd, mInputPlaneSize[0]+ mInputPlaneSize[1]);
+    mLock.unlock();
+
+    if(!bInputStreamOn)
+        startInputStream();
+
+    if(eos)
+        pDev->StopEncoder();
+
+    return OK;
+}
+status_t V4l2Enc::dequeueInputBuffer()
+{
+    int result = 0;
+    int input_id = -1;
+
+    if(!bInputStreamOn || mState != RUNNING )
+        return OK;
+
+    Mutex::Autolock autoLock(mLock);
+    if(!bInputStreamOn  || mState != RUNNING )
+        return OK;
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kInputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(planes, 0, sizeof(planes));
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    stV4lBuf.memory = mInMemType;
+    stV4lBuf.m.planes = planes;
+    stV4lBuf.length = kInputBufferPlaneNum;
+    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+    if(result < 0)
+        return UNKNOWN_ERROR;
+
+    ALOGV("V4l2Enc OUTPUT_MPLANE VIDIOC_DQBUF index=%d
", stV4lBuf.index);
+
+    if(stV4lBuf.index >= mInputFormat.bufferNum)
+        return BAD_INDEX;
+
+    if(!mInputBufferMap[stV4lBuf.index].at_device){
+        ALOGE("dequeueInputBuffer index=%d, not at_device",stV4lBuf.index);
+    }
+    mInputBufferMap[stV4lBuf.index].at_device = false;
+    input_id = mInputBufferMap[stV4lBuf.index].input_id;
+    mInputBufferMap[stV4lBuf.index].input_id = -1;
+
+    ALOGV("dequeueInputBuffer NotifyInputBufferUsed id=%d",input_id);
+    NotifyInputBufferUsed(input_id);
+
+    return OK;
+}
+status_t V4l2Enc::queueOutput(int buffer_id, int fd, unsigned long nVaddr)
+{
+    int result = 0;
+    int32_t index = -1;
+    
+    if(!bFetchStarted || STOPPING == mState || FLUSHING == mState){
+        ALOGV("queueOutput return 1");
+        return OK;
+    }
+
+    mLock.lock();
+
+    if(!bFetchStarted || STOPPING == mState || FLUSHING == mState){
+        ALOGV("queueOutput return 2");
+        mLock.unlock();
+        return OK;
+    }
+
+    if(V4L2_MEMORY_MMAP == mOutMemType){
+        //pass index from buffer_id
+        index = buffer_id;
+    }else{
+
+        //try to get index
+        for(int32_t i = 0; i < mOutputBufferMap.size(); i++){
+            if((fd == mOutputBufferMap[i].plane.fd || nVaddr == mOutputBufferMap[i].plane.addr) 
+                && !mInputBufferMap[i].at_device){
+                index = i;
+                break;
+            }
+        }
+
+        //index not found
+        if(index < 0){
+            for(int32_t i = 0; i < mOutputBufferMap.size(); i++){
+                if(-1 == mOutputBufferMap[i].plane.fd && !mOutputBufferMap[index].at_device){
+                    mOutputBufferMap[i].plane.fd = fd;
+                    mOutputBufferMap[i].plane.addr = nVaddr;
+                    mOutputBufferMap[i].plane.offset = 0;
+                    index = i;
+                    break;
+                }
+            }
+        }
+    }
+
+    if(index < 0){
+        ALOGE("could not create mOutputBufferMap index, fd=%d,vaddr=%x, buffer_id=%d", fd, nVaddr, buffer_id);
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+
+    ALOGV("queueOutput index=%d, nVaddr=%x, fd=%d, buffer_id=%d", index, nVaddr, fd, buffer_id);
+
+    mOutputBufferMap[index].picture_id = buffer_id;
+
+    if(mOutputBufferMap[index].at_device){
+        ALOGE("onQueueInputBuffer index=%d, at_device",index);
+    }
+
+    if(mOutputBufferMap[index].plane.fd != fd){
+        ALOGE("mOutputBufferMap addr mismatch index=%d,%d,%d",
+            index,mOutputBufferMap[index].plane.fd, fd);
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kOutputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(&planes[0], 0, sizeof(struct v4l2_plane));
+
+    planes[0].length = mOutputBufferMap[index].plane.size;
+    planes[0].data_offset = mOutputBufferMap[index].plane.offset;
+
+    if(mOutMemType == V4L2_MEMORY_DMABUF){
+        planes[0].m.fd = fd;
+    }else if(mOutMemType == V4L2_MEMORY_USERPTR){
+        planes[0].m.userptr = nVaddr;
+    }else if(mOutMemType == V4L2_MEMORY_MMAP){
+        planes[0].m.mem_offset = mOutputBufferMap[index].plane.offset;
+        planes[0].data_offset = 0;
+    }
+
+    stV4lBuf.index = index;
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    stV4lBuf.memory = mOutMemType;
+    stV4lBuf.m.planes = &planes[0];
+    stV4lBuf.length = kOutputBufferPlaneNum;
+    stV4lBuf.flags = 0;
+
+    ALOGV("CAPTURE_MPLANE VIDIOC_QBUF index=%d
",index);
+
+    result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
+    if(result < 0){
+        ALOGE("VIDIOC_QBUF failed, index=%d",index);
+        mLock.unlock();
+        return UNKNOWN_ERROR;
+    }
+
+    mOutputBufferMap[index].at_device = true;
+
+    mLock.unlock();
+
+    if(!bOutputStreamOn)
+        startOutputStream();
+    return OK;
+}
+
+status_t V4l2Enc::startInputStream()
+{
+    Mutex::Autolock autoLock(mLock);
+    if(!bInputStreamOn){
+        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
+            bInputStreamOn = true;
+            ALOGV("VIDIOC_STREAMON OUTPUT_MPLANE success");
+        }
+    }
+    return OK;
+}
+status_t V4l2Enc::stopInputStream()
+{
+    Mutex::Autolock autoLock(mLock);
+    if(bInputStreamOn){
+        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        if(0 == ioctl(mFd, VIDIOC_STREAMOFF, &buf_type)){
+            bInputStreamOn = false;
+            ALOGV("VIDIOC_STREAMOFF OUTPUT_MPLANE success");
+        }
+    }
+
+
+    for (size_t i = 0; i < mInputBufferMap.size(); i++) {
+        mInputBufferMap[i].at_device = false;
+        mInputBufferMap[i].input_id = -1;
+    }
+
+    return OK;
+}
+status_t V4l2Enc::startOutputStream()
+{
+    Mutex::Autolock autoLock(mLock);
+    if(!bOutputStreamOn){
+        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
+            bOutputStreamOn = true;
+            ALOGV("VIDIOC_STREAMON CAPTURE_MPLANE success");
+        }
+    }
+    return OK;
+}
+status_t V4l2Enc::stopOutputStream()
+{
+    Mutex::Autolock autoLock(mLock);
+
+    //call VIDIOC_STREAMOFF and ignore the result
+    enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    ioctl(mFd, VIDIOC_STREAMOFF, &buf_type);
+    bOutputStreamOn = false;
+    ALOGV("VIDIOC_STREAMOFF CAPTURE_MPLANE success");
+
+    for (size_t i = 0; i < mOutputBufferMap.size(); i++) {
+        mOutputBufferMap[i].at_device = false;
+    }
+    return OK;
+}
+status_t V4l2Enc::dequeueOutputBuffer()
+{
+    int result = 0;
+    if(!bOutputStreamOn  || mState != RUNNING)
+        return OK;
+
+    Mutex::Autolock autoLock(mLock);
+    if(!bOutputStreamOn  || mState != RUNNING)
+        return OK;
+
+    uint64_t ts = 0;
+    uint32_t out_len = 0;
+    int keyFrame = 0;
+    uint32_t out_offset = 0;
+
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kOutputBufferPlaneNum];
+    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    memset(planes, 0, sizeof(planes));
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    stV4lBuf.memory = mOutMemType;
+    stV4lBuf.m.planes = planes;
+    stV4lBuf.length = kOutputBufferPlaneNum;
+    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+    if(result < 0)
+        return UNKNOWN_ERROR;
+
+    if(stV4lBuf.index >= mOutputFormat.bufferNum)
+        return BAD_INDEX;
+
+    out_len = stV4lBuf.m.planes[0].bytesused;
+    ts = (uint64_t)stV4lBuf.timestamp.tv_sec *1000000;
+    ts += stV4lBuf.timestamp.tv_usec;
+    keyFrame = (stV4lBuf.flags & V4L2_BUF_FLAG_KEYFRAME)?1:0;
+
+    ALOGV("V4l2Enc CAPTURE_MPLANE VIDIOC_DQBUF index=%d, len=%d,ts=%lld,flag=%x",stV4lBuf.index, out_len, ts, stV4lBuf.flags);
+
+    if(!bHasCodecData && mConverter != NULL){
+        uint8_t* vAddr = (uint8_t*)mOutputBufferMap[stV4lBuf.index].plane.addr;
+        if(OK ==  mConverter->CheckSpsPps(vAddr, out_len, &out_offset))
+            bHasCodecData = true;
+    }
+
+    int blockId = 0;
+    int fd;
+    unsigned long nOutPhy;
+    unsigned long nOutVirt;
+
+    if(mOutMemType == V4L2_MEMORY_MMAP){
+        if (OK == FetchOutputBuffer(&blockId, &fd, &nOutPhy, &nOutVirt, &out_len))
+            memcpy((void*)nOutVirt, (void*)mOutputBufferMap[stV4lBuf.index].plane.addr, out_len);
+        else
+            return UNKNOWN_ERROR;
+        dumpOutputBuffer((void*)nOutVirt, out_len);
+    }
+
+    if(stV4lBuf.flags & V4L2_BUF_FLAG_LAST){
+        ALOGV("get last frame");
+        NotifyEOS();
+        bPollStarted = false;
+        bFetchStarted = false;
+        mState = STOPPED;
+        mOutputBufferMap[stV4lBuf.index].at_device = false;
+        return OK;
+    }
+
+    ALOGV("dequeueOutputBuffer NotifyOutputFrameReady blockId=%d,len=%d,ts=%lld,keyFrame=%x,out_offset=%d",blockId, out_len, ts, keyFrame,out_offset);
+    NotifyOutputFrameReady(blockId, out_len, ts, keyFrame, out_offset);
+
+    mFrameOutNum ++;
+    mOutputBufferMap[stV4lBuf.index].at_device = false;
+    return OK;
+}
+status_t V4l2Enc::onDequeueEvent()
+{
+    int result = 0;
+    struct v4l2_event event;
+    memset(&event, 0, sizeof(struct v4l2_event));
+    result = ioctl(mFd, VIDIOC_DQEVENT, &event);
+    if(result == 0){
+        ALOGV("onDequeueEvent type=%d",event.type);
+        switch(event.type){
+            case V4L2_EVENT_SOURCE_CHANGE:
+                if(event.u.src_change.changes & V4L2_EVENT_SRC_CH_RESOLUTION){
+                    //TODO: send event
+                    //handleFormatChanged();
+                }
+                break;
+            case V4L2_EVENT_EOS:
+                ALOGV("get V4L2_EVENT_EOS event, wait for last frame");
+                break;
+            case V4L2_EVENT_DECODE_ERROR:
+                NotifyError(UNKNOWN_ERROR);//send error event
+                break;
+            default:
+                break;
+        }
+    }
+
+    return OK;
+}
+
+status_t V4l2Enc::DoSetConfig(EncConfig index, void* pConfig) {
+
+    status_t ret = OK;
+
+    if (!pConfig)
+        return BAD_VALUE;
+
+    switch (index) {
+        case ENC_CONFIG_BIT_RATE:
+        {
+            mEncParam.nBitRate = (*(int*)pConfig);
+            break;
+        }
+        case ENC_CONFIG_INTRA_REFRESH:
+        {
+            if(0 == (*(int*)pConfig))
+                bSyncFrame = false;
+            else
+                bSyncFrame = true;
+            break;
+        }
+        case ENC_CONFIG_COLOR_FORMAT:
+        {
+            mInputFormat.pixelFormat = (*(int*)pConfig);
+            break;
+        }
+        default:
+            ret = BAD_VALUE;
+            break;
+    }
+    return ret;
+}
+
+status_t V4l2Enc::DoGetConfig(EncConfig index, void* pConfig) {
+    if (!pConfig)
+        return BAD_VALUE;
+
+    status_t ret = OK;
+
+    return ret;
+}
+#if 0
+status_t V4l2Enc::handleFormatChanged() {
+
+    status_t ret = OK;
+
+    {
+        Mutex::Autolock autoLock(mLock);
+
+        int result = 0;
+        struct v4l2_format format;
+        uint32_t pixel_format = 0;
+        memset(&format, 0, sizeof(struct v4l2_format));
+
+        format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        result = ioctl (mFd, VIDIOC_G_FMT, &format);
+
+        if(result < 0)
+            return UNKNOWN_ERROR;
+
+        ret = pDev->GetColorFormatByV4l2( format.fmt.pix_mp.pixelformat, &pixel_format);
+        if(ret != OK)
+            return ret;
+
+        mOutputFormat.pixelFormat = static_cast<int>(pixel_format);
+
+        mOutputFormat.width = Align(format.fmt.pix_mp.width, FRAME_ALIGN);
+        mOutputFormat.height = Align(format.fmt.pix_mp.height, FRAME_ALIGN);
+        mOutputFormat.interlaced = ((format.fmt.pix_mp.field == V4L2_FIELD_INTERLACED) ? true: false);
+
+        mOutputPlaneSize[0] = format.fmt.pix_mp.plane_fmt[0].sizeimage;
+        mOutputPlaneSize[1] = format.fmt.pix_mp.plane_fmt[1].sizeimage;
+
+        struct v4l2_control ctl;
+        memset(&ctl, 0, sizeof(struct v4l2_control));
+
+        ctl.id = V4L2_CID_MIN_BUFFERS_FOR_CAPTURE;
+        result = ioctl(mFd, VIDIOC_G_CTRL, &ctl);
+        if(result < 0)
+            return UNKNOWN_ERROR;
+
+        mOutputFormat.minBufferNum = ctl.value;
+        if(mOutputFormat.minBufferNum > mOutputFormat.bufferNum)
+            mOutputFormat.bufferNum = mOutputFormat.minBufferNum;
+
+        struct v4l2_crop crop;
+        crop.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+
+        result = ioctl (mFd, VIDIOC_G_CROP, &crop);
+        if(result < 0)
+            return UNKNOWN_ERROR;
+
+        mOutputFormat.rect.right = crop.c.width;
+        mOutputFormat.rect.bottom = crop.c.height;
+        mOutputFormat.rect.top = crop.c.top;
+        mOutputFormat.rect.left = crop.c.left;
+    }
+
+    outputFormatChanged();
+
+    ALOGV("getOutputVideoInfo w=%d,h=%d,buf cnt=%d, buffer size[0]=%d,size[1]=%d",
+        mOutputFormat.width, mOutputFormat.height, mOutputFormat.minBufferNum, mOutputPlaneSize[0], mOutputPlaneSize[1]);
+    return OK;
+}
+#endif
+
+status_t V4l2Enc::onFlush()
+{
+    status_t ret = UNKNOWN_ERROR;
+    ALOGV("onFlush BEGIN");
+    int pre_state;
+    {
+    Mutex::Autolock autoLock(mLock);
+    pre_state = mState;
+    mState = FLUSHING;
+    }
+
+    ret = stopInputStream();
+    if(ret != OK)
+        return ret;
+
+    ret = stopOutputStream();
+    if(ret != OK)
+        return ret;
+
+    mState = pre_state;
+    ALOGV("onFlush END ret=%d",ret);
+
+    return ret;
+}
+status_t V4l2Enc::onStop()
+{
+    status_t ret = UNKNOWN_ERROR;
+  
+    ALOGV("onStop BEGIN");
+    {
+    Mutex::Autolock autoLock(mLock);
+    mState = STOPPING;
+    }
+    ret = onFlush();
+    if(ret != OK)
+        return ret;
+
+    ret = destroyFetchThread();
+    if(ret != OK)
+        return ret;
+
+    ALOGV("onStop destroyFetchThread success");
+    ret = destroyPollThread();
+    if(ret != OK)
+        return ret;
+
+    ALOGV("onStop destroyPollThread success");
+
+    ret = destroyInputBuffers();
+    if(ret != OK)
+        return ret;
+
+    ret = freeOutputBuffers();
+    if(ret != OK)
+        return ret;
+
+    ret = destroyOutputBuffers();
+    if(ret != OK)
+        return ret;
+
+    if(mConverter != NULL){
+        mConverter->Destroy();
+        delete mConverter;
+    }
+    ALOGV("onStop END ret=%d",ret);
+
+    mState = STOPPED;
+    return ret;
+}
+status_t V4l2Enc::onDestroy()
+{
+    status_t ret = UNKNOWN_ERROR;
+
+    ALOGV("onDestroy");
+    Mutex::Autolock autoLock(mLock);
+
+    if(pDev == NULL)
+        return UNKNOWN_ERROR;
+
+    if(mFd > 0){
+        pDev->Close();
+        mFd = 0;
+    }
+
+    if(pDev != NULL)
+        delete pDev;
+    pDev = NULL;
+
+    ALOGV("onDestroy END");
+    return OK;
+}
+void V4l2Enc::initEncInputParamter(EncInputParam *pInPara) {
+    if(pInPara == NULL)
+        return;
+
+    memset(&mEncParam, 0, sizeof(V4l2EncInputParam));
+
+    mTargetFps = pInPara->nFrameRate;
+    mEncParam.nRotAngle = pInPara->nRotAngle;
+    mEncParam.nBitRate = pInPara->nBitRate;
+    //TODO: set bitrate mode
+    mEncParam.nBitRateMode = V4L2_MPEG_VIDEO_BITRATE_MODE_VBR;
+    mEncParam.nGOPSize = pInPara->nGOPSize;
+    mEncParam.nIntraFreshNum = pInPara->nRefreshIntra;
+
+    mInputFormat.pixelFormat = pInPara->eColorFormat;
+    mWidth = pInPara->nPicWidth;
+    mHeight = pInPara->nPicHeight;
+
+    mInputFormat.bufferNum = 8;
+    mInputFormat.bufferSize = mWidth * mHeight * 3/2;
+    mInputFormat.width = mWidth;
+    mInputFormat.height = mHeight;
+    mInputFormat.interlaced = false;
+    mInputFormat.pixelFormat = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+
+    mOutputFormat.width = mWidth;
+    mOutputFormat.height = mHeight;
+    mOutputFormat.minBufferNum = 2;
+    mOutputFormat.bufferNum = 8;
+    mOutputFormat.interlaced = false;
+    
+    ALOGD("initEncInputParamter nRotAngle=%d,nBitRate=%d,nGOPSize=%d,nRefreshIntra=%d,mTargetFps=%d",
+        pInPara->nRotAngle, pInPara->nBitRate, pInPara->nGOPSize, pInPara->nRefreshIntra,mTargetFps);
+    
+    return;
+}
+status_t V4l2Enc::getCodecData(uint8_t** pCodecData, uint32_t* size) {
+    ALOGV("getCodecData");
+    if(bHasCodecData && mConverter != NULL)
+        return mConverter->GetSpsPpsPtr(pCodecData, size);
+    else
+        return UNKNOWN_ERROR;
+}
+bool V4l2Enc::checkIfPreProcessNeeded(int pixelFormat) 
+{
+    switch (pixelFormat) {
+    case HAL_PIXEL_FORMAT_RGB_565:
+    case HAL_PIXEL_FORMAT_RGB_888:
+    case HAL_PIXEL_FORMAT_RGBA_8888:
+    case HAL_PIXEL_FORMAT_RGBX_8888:
+    case HAL_PIXEL_FORMAT_BGRA_8888:
+        ALOGV("bPreProcess TRUE");
+        bPreProcess = true;
+        return true;
+    default:
+        bPreProcess = false;
+        return false;
+    }
+}
+
+status_t V4l2Enc::allocateOutputBuffer(int32_t index)
+{
+    int result = 0;
+    Mutex::Autolock autoLock(mLock);
+
+    uint8_t * ptr = NULL;
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kOutputBufferPlaneNum];
+
+    if(index > mOutputFormat.bufferNum)
+        return UNKNOWN_ERROR;
+
+    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    stV4lBuf.memory = V4L2_MEMORY_MMAP;
+    stV4lBuf.index = index;
+    stV4lBuf.length = kOutputBufferPlaneNum;
+    stV4lBuf.m.planes = planes;
+
+    result = ioctl(mFd, VIDIOC_QUERYBUF, &stV4lBuf);
+    if(result < 0)
+        return UNKNOWN_ERROR;
+        
+    planes[0].length = mOutputFormat.bufferSize;
+
+    ptr = (uint8_t *)mmap(NULL, planes[0].length,
+        PROT_READ | PROT_WRITE, /* recommended */
+        MAP_SHARED,             /* recommended */
+        mFd, planes[0].m.mem_offset);
+    if(ptr != MAP_FAILED){
+       mOutputBufferMap[index].plane.addr = (uint64_t)ptr;
+    }else
+        return UNKNOWN_ERROR;
+
+    mOutputBufferMap[index].plane.fd = -1;
+    mOutputBufferMap[index].plane.size = planes[0].length;
+    mOutputBufferMap[index].plane.offset = planes[0].m.mem_offset;
+    mOutputBufferMap[index].at_device = false;
+    ALOGV("allocateOutputBuffer index=%d,size=%d,offset=%x,addr=%x",
+        index,planes[0].length, planes[0].m.mem_offset, ptr);
+    return OK;
+}
+status_t V4l2Enc::freeOutputBuffers()
+{
+    Mutex::Autolock autoLock(mLock);
+
+    if(mOutputBufferMap.empty())
+        return OK;
+
+    for(int32_t i = 0; i < mOutputFormat.bufferNum; i++){
+        if(0 != mOutputBufferMap[i].plane.addr){
+            ALOGV("munmap %p",mOutputBufferMap[i].plane.addr);
+            munmap((void*)mOutputBufferMap[i].plane.addr,mOutputBufferMap[i].plane.size);
+        }
+
+        if(mOutputBufferMap[i].plane.fd > 0)
+            close(mOutputBufferMap[i].plane.fd);
+
+        mOutputBufferMap[i].plane.offset = 0;
+        mOutputBufferMap[i].at_device = false;
+    }
+    mOutputBufferMap.clear();
+    return OK;
+}
+void V4l2Enc::ParseVpuLogLevel()
+{
+    int level=0;
+    FILE* fpVpuLog;
+    nDebugFlag = 0;
+    
+    fpVpuLog=fopen(VPU_ENCODER_LOG_LEVELFILE, "r");
+    if (NULL==fpVpuLog){
+        return;
+    }
+
+    char symbol;
+    int readLen = 0;
+
+    readLen = fread(&symbol,1,1,fpVpuLog);
+    if(feof(fpVpuLog) != 0){
+        ;
+    }
+    else{
+        level=atoi(&symbol);
+        if((level<0) || (level>255)){
+            level=0;
+        }
+    }
+    fclose(fpVpuLog);
+
+    nDebugFlag=level;
+
+    if(nDebugFlag != 0)
+        ALOGV("ParseVpuLogLevel nDebugFlag=%x",nDebugFlag);
+    return;
+}
+void V4l2Enc::dumpInputBuffer(int fd, uint32_t size)
+{
+    FILE * pfile = NULL;
+    void* buf = NULL;
+
+    if(fd <= 0){
+        ALOGV("dumpInputBuffer invalid fd");
+        return;
+    }
+
+    if(!(nDebugFlag & DUMP_ENC_FLAG_INPUT))
+        return;
+
+    if(mFrameOutNum < 200)
+        pfile = fopen(DUMP_ENC_INPUT_FILE,"ab");
+
+    if(pfile){
+        buf = mmap(0, size, PROT_READ, MAP_SHARED, fd, 0);
+        fwrite(buf,1,size,pfile);
+        ALOGV("dumpInputBuffer write %d",size);
+        munmap(buf, size);
+        fclose(pfile);
+    }else
+        ALOGE("dumpInputBuffer failed to open %s",DUMP_ENC_INPUT_FILE);
+    return;
+}
+void V4l2Enc::dumpOutputBuffer(void* buf, uint32_t size)
+{
+    FILE * pfile = NULL;
+    if(buf == NULL)
+        return;
+
+    if(!(nDebugFlag & DUMP_ENC_FLAG_OUTPUT))
+        return;
+
+    if(mFrameOutNum < 200)
+        pfile = fopen(DUMP_ENC_OUTPUT_FILE,"ab");
+
+    if(pfile){
+        fwrite(buf,1,size,pfile);
+        fclose(pfile);
+    }
+    return;
+}
+
+VideoEncoderBase * CreateVideoEncoderInstance(const char* mime) {
+    return static_cast<VideoEncoderBase *>(new V4l2Enc(mime));
+}
+}
diff --git a/codec2/video_enc/v4l2_enc/V4l2Enc.h b/codec2/video_enc/v4l2_enc/V4l2Enc.h
new file mode 100755
index 0000000..d92e275
--- /dev/null
+++ b/codec2/video_enc/v4l2_enc/V4l2Enc.h
@@ -0,0 +1,170 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ */
+#ifndef V4L2_ENCODER_H
+#define V4L2_ENCODER_H
+
+#include "VideoEncoderBase.h"
+#include "V4l2Dev.h"
+#include "FrameConverter.h"
+
+namespace android {
+
+class V4l2Enc : public VideoEncoderBase{
+public:
+    V4l2Enc(const char* mime);
+
+    status_t prepareOutputBuffers();
+    status_t destroyOutputBuffers();
+    //status_t queueInput(C2FrameData * input, int32_t input_id);
+    status_t queueOutput(int buffer_id, int fd, unsigned long nVaddr);
+    //status_t setOutputBuffer(int bufferId, unsigned long pPhyAddr, unsigned long pVirtAddr, uint32_t capacity)
+    status_t dequeueInputBuffer();
+    status_t dequeueOutputBuffer();
+
+
+protected:
+    virtual ~V4l2Enc();
+    status_t DoSetConfig(EncConfig index, void* pConfig) override;
+    status_t DoGetConfig(EncConfig index, void* pConfig) override;
+    void initEncInputParamter(EncInputParam *pInPara) override;
+    status_t getCodecData(uint8_t** pCodecData, uint32_t* size) override;
+    bool checkIfPreProcessNeeded(int pixelFormat) override;
+
+    status_t onInit() override;
+    status_t onStart();
+    status_t onStop() override;//idle to loaded
+    status_t onFlush() override;//flush
+    status_t onDestroy() override;//free Buffers
+
+    status_t encodeInternal(std::unique_ptr<IMXInputBuffer> input) override;
+
+private:
+    enum {
+        kInputBufferPlaneNum = 2,
+        kOutputBufferPlaneNum = 1,
+
+    };
+
+    struct VideoFramePlane {
+        int32_t fd;
+        uint64_t addr;
+        uint32_t size;
+        uint32_t length;
+        uint32_t offset;
+    };
+
+    // Record for input buffers.
+    struct InputRecord {
+        InputRecord();
+        ~InputRecord();
+        bool at_device;    // held by device.
+        VideoFramePlane planes[kInputBufferPlaneNum];
+        int32_t input_id;
+        int64_t ts;
+    };
+
+
+    struct OutputRecord {
+        OutputRecord();
+        OutputRecord(OutputRecord&&) = default;
+        ~OutputRecord();
+        bool at_device;
+        VideoFramePlane plane;
+        int32_t picture_id;     // picture buffer id as returned to PictureReady().
+        uint32_t flag;
+        //std::shared_ptr<C2GraphicBlock> mGraphicBlock;
+    };
+
+    enum {
+        UNINITIALIZED,
+        STOPPED,
+        RUNNING,
+        STOPPING,
+        FLUSHING,
+    };
+
+    const char* mMime;
+    pthread_t mPollThread;
+    pthread_t mFetchThread;
+
+    V4l2Dev* pDev;
+    int32_t mFd;
+
+    enum v4l2_memory mInMemType;//support userptr and dma
+    enum v4l2_memory mOutMemType;//support userptr and dma
+
+    V4l2EncInputParam mEncParam;
+    uint32_t mTargetFps;
+    
+    
+    uint32_t mInFormat;//v4l2 output format
+    uint32_t mOutFormat;//v4l2 capture format
+    uint32_t mInputPlaneSize[kInputBufferPlaneNum];
+    uint32_t mWidthAlign;
+    uint32_t mHeightAlign;
+
+    std::vector<InputRecord> mInputBufferMap;
+    std::vector<OutputRecord> mOutputBufferMap;
+
+    Mutex mLock;
+
+    bool bPollStarted;
+    bool bFetchStarted;
+
+    bool bInputStreamOn;
+    bool bOutputStreamOn;
+
+    bool bSyncFrame;
+    bool bHasCodecData;
+    bool bStarted;
+    bool bPreProcess;
+    FrameConverter * mConverter;
+
+    uint64_t mFrameOutNum;
+    uint32_t nDebugFlag;
+    int mState;
+
+    status_t prepareInputParams();
+    status_t SetInputFormats();
+    status_t prepareOutputParams();
+    status_t SetOutputFormats();
+
+    status_t prepareInputBuffers();
+    status_t createInputBuffers();
+    status_t destroyInputBuffers();
+
+    status_t createPollThread();
+    status_t destroyPollThread();
+    status_t createFetchThread();
+    status_t destroyFetchThread();
+
+    status_t startInputStream();
+    status_t stopInputStream();
+    status_t startOutputStream();
+    status_t stopOutputStream();
+
+    status_t onDequeueEvent();
+
+    static void *PollThreadWrapper(void *);
+    status_t HandlePollThread();
+    static void *FetchThreadWrapper(void *);
+    status_t HandleFetchThread();
+
+    status_t handleFormatChanged();
+    status_t allocateOutputBuffer(int32_t index);
+    status_t freeOutputBuffers();
+
+    void ParseVpuLogLevel();
+    void dumpInputBuffer(int fd, uint32_t size);
+    void dumpOutputBuffer(void* buf, uint32_t size);
+};
+
+
+
+}
+#endif
diff --git a/codec2/video_enc/v4l2_enc/v4l2_enc.go b/codec2/video_enc/v4l2_enc/v4l2_enc.go
new file mode 100755
index 0000000..34b4636
--- /dev/null
+++ b/codec2/video_enc/v4l2_enc/v4l2_enc.go
@@ -0,0 +1,55 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package v4l2_enc
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_v4l2_enc_defaults", v4l2DefaultsFactory)
+}
+
+
+func v4l2DefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, v4l2Defaults)
+    return module
+}
+
+func v4l2Defaults(ctx android.LoadHookContext) {
+    var Cflags []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Cflags []string
+                }
+        }
+    }
+    p := &props{}
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8Q") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    } else {
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
+    }
+
+    p.Target.Android.Cflags = Cflags
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/video_enc/video_enc.go b/codec2/video_enc/video_enc.go
new file mode 100644
index 0000000..d4016be
--- /dev/null
+++ b/codec2/video_enc/video_enc.go
@@ -0,0 +1,63 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package video_enc
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_video_enc_defaults", video_encDefaultsFactory)
+}
+
+func video_encDefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, video_encDefaults)
+    return module
+}
+
+func video_encDefaults(ctx android.LoadHookContext) {
+    var Shared_libs []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Shared_libs []string
+                }
+        }
+    }
+    p := &props{}
+    p.Target.Android.Enabled = proptools.BoolPtr(false)
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8MM") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_enc")
+		Shared_libs = append(Shared_libs, "lib_imx_c2_process_g2d_pre")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    }else if strings.Contains(board, "IMX8MP") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_enc")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_process_g2d_pre")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    }else if strings.Contains(board, "IMX8Q") {
+        Shared_libs = append(Shared_libs, "lib_imx_c2_v4l2_enc")
+		Shared_libs = append(Shared_libs, "lib_imx_c2_process_isi_pre")
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+    }
+    p.Target.Android.Shared_libs = Shared_libs
+    // TODO: enable it when imx8q v4l2enc is enabled.
+    ctx.AppendProperties(p)
+}
diff --git a/codec2/video_enc/vpuwrapper_enc/Android.bp b/codec2/video_enc/vpuwrapper_enc/Android.bp
new file mode 100644
index 0000000..0836482
--- /dev/null
+++ b/codec2/video_enc/vpuwrapper_enc/Android.bp
@@ -0,0 +1,56 @@
+imx_c2_vpuwrapper_enc_defaults {
+    name: "imx_c2_vpuwrapper_enc_default",
+}
+
+
+bootstrap_go_package {
+    name: "soong-vpuwrapper_enc",
+    pkgPath: "android/soong/vendor/nxp/imx_android_mm/codec2/video_enc/vpuwrapper_enc",
+    deps: [
+        "blueprint",
+        "blueprint-pathtools",
+        "soong",
+        "soong-android",
+        "soong-cc",
+        "soong-genrule",
+    ],
+    srcs: [
+        "vpuwrapper_enc.go",
+    ],
+    pluginFor: ["soong_build"],
+}
+
+cc_library_shared {
+    name: "lib_imx_c2_vpuwrapper_enc",
+
+    defaults: [
+        "imx_c2_vpuwrapper_enc_default",
+        "imx_defaults",
+    ],
+
+    include_dirs: [
+        "frameworks/av",
+        "vendor/nxp-opensource/imx/include",
+        "vendor/nxp-opensource/vpu_wrapper",
+        "vendor/nxp/imx_android_mm/codec2/video_enc/common",
+        "vendor/nxp/imx_android_mm/codec2/tsm",
+        "vendor/nxp-opensource/imx/display/display",
+    ],
+
+    shared_libs: [
+        "liblog",
+        "libutils",
+        "lib_vpu_wrapper",
+        "libcodec2",
+        "libcodec2_vndk",
+        "libstagefright_foundation", // for Mutexed
+        "lib_imx_ts_manager",
+        "lib_imx_c2_videoenc_common",
+    ],
+
+    srcs: [
+        "VpuWrapperEnc.cpp",
+    ],
+}
+
+
diff --git a/codec2/video_enc/vpuwrapper_enc/VpuWrapperEnc.cpp b/codec2/video_enc/vpuwrapper_enc/VpuWrapperEnc.cpp
new file mode 100755
index 0000000..811de24
--- /dev/null
+++ b/codec2/video_enc/vpuwrapper_enc/VpuWrapperEnc.cpp
@@ -0,0 +1,1045 @@
+/**
+ *  Copyright 2019-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "VpuWrapperEnc"
+
+#include <media/stagefright/MediaDefs.h>
+
+#include "VpuWrapperEnc.h"
+#include "graphics_ext.h"
+#include "Tsm_wrapper.h"
+
+//#define DUMP_YUV
+#ifdef  DUMP_YUV
+#include "IonAllocator.h"
+#include <sys/mman.h>
+#endif
+
+namespace android {
+
+#define VPU_ENC_COMP_INFO ALOGI
+
+//#define VPU_ENC_COMP_DBGLOG
+#ifdef VPU_ENC_COMP_DBGLOG
+#define VPU_ENC_COMP_LOG    ALOGD
+#else
+#define VPU_ENC_COMP_LOG(...)
+#endif
+
+//#define VPU_ENC_COMP_API_DBGLOG
+#ifdef VPU_ENC_COMP_API_DBGLOG
+#define VPU_ENC_COMP_API_LOG    ALOGI
+#else
+#define VPU_ENC_COMP_API_LOG(...)
+#endif
+
+#define VPU_ENC_COMP_ERR_DBGLOG
+#ifdef VPU_ENC_COMP_ERR_DBGLOG
+#define VPU_ENC_COMP_ERR_LOG	ALOGE
+#define ASSERT(exp)	if(!(exp)) {ALOGE("%s: %d : assert condition !!!
",__FUNCTION__,__LINE__);}
+#else
+#define VPU_ENC_COMP_ERR_LOG    ALOGE
+#define ASSERT(...)
+#endif
+
+#ifdef NULL
+#undef NULL
+#define NULL 0
+#endif
+
+#define Align(ptr,align)    (((unsigned long)ptr+(align)-1)/(align)*(align))
+
+#define ENC_MAX_FRAME_NUM       (VPU_ENC_MAX_NUM_MEM)
+
+#define DEFAULT_ENC_FRM_WIDTH       (320)
+#define DEFAULT_ENC_FRM_HEIGHT      (240)
+#define DEFAULT_ENC_FRM_RATE        (30)
+#define DEFAULT_ENC_FRM_BITRATE     (256 * 1024)
+
+#define DEFAULT_ENC_BUF_IN_CNT      0x2
+#define DEFAULT_ENC_BUF_IN_SIZE     (DEFAULT_ENC_FRM_WIDTH*DEFAULT_ENC_FRM_HEIGHT*3/2)
+#define DEFAULT_ENC_BUF_OUT_CNT     0x3
+#define DEFAULT_ENC_BUF_OUT_SIZE    (1024*1024) //FIXME: set one big enough value !!!
+
+#define VPU_ENC_VP8_BITRATE_THRESHOLD   (20000000) // 20Mbps
+
+#define VPURET2ERR(ret) ((ret != VPU_ENC_RET_SUCCESS) ? BAD_VALUE : OK)
+#define CHECK_VPU_RET(ret) if (ret != VPU_ENC_RET_SUCCESS) {ALOGE("%s line %d, ret %d
", __FUNCTION__, __LINE__, ret); return VPURET2ERR(ret);}
+#define CHECK_DEC_STATE(state) \
+    if (eVpuEncoderState != state) {\
+        VPU_ENC_COMP_ERR_LOG("%s: failure: error state transition, current state=%d
", __FUNCTION__, eVpuEncoderState);\
+        return INVALID_OPERATION;\
+    }
+
+
+int32_t MemFreeBlock(VpuMemInfo* pMemBlock) {
+	int i;
+    int32_t err = 1; // ok
+
+	for (i = 0; i < pMemBlock->nSubBlockNum; i++) {
+
+        if (pMemBlock->MemSubBlock[i].MemType == VPU_MEM_VIRT && pMemBlock->MemSubBlock[i].pVirtAddr) {
+            free(pMemBlock->MemSubBlock[i].pVirtAddr);
+            pMemBlock->MemSubBlock[i].pVirtAddr = nullptr;
+        } else if (pMemBlock->MemSubBlock[i].MemType == VPU_MEM_PHY && pMemBlock->MemSubBlock[i].pPhyAddr) {
+			VpuMemDesc vpuMem;
+			VpuEncRetCode ret;
+			vpuMem.nSize = pMemBlock->MemSubBlock[i].nSize;
+            vpuMem.nVirtAddr = (unsigned long)pMemBlock->MemSubBlock[i].pVirtAddr;
+            vpuMem.nPhyAddr = (unsigned long)pMemBlock->MemSubBlock[i].pPhyAddr;
+            vpuMem.nCpuAddr = (unsigned long)pMemBlock->MemSubBlock[i].nFd;
+
+            ret = VPU_EncFreeMem(&vpuMem);
+
+            if (ret != VPU_ENC_RET_SUCCESS) {
+				VPU_ENC_COMP_LOG("%s: free vpu memory failure, ret=%d
", __FUNCTION__, ret);
+                err = 0;
+			}
+
+            pMemBlock->MemSubBlock[i].pVirtAddr = nullptr;
+			pMemBlock->MemSubBlock[i].pPhyAddr = nullptr;
+            pMemBlock->MemSubBlock[i].nFd = -1;
+		}
+	}
+
+	return err;
+}
+
+int32_t MemMallocBlock(VpuMemInfo* pMemBlock) {
+	int i;
+	int size;
+
+    VPU_ENC_COMP_API_LOG("%s: ", __FUNCTION__);
+
+	for (i = 0; i < pMemBlock->nSubBlockNum; i++) {
+		size = pMemBlock->MemSubBlock[i].nAlignment + pMemBlock->MemSubBlock[i].nSize;
+		if (pMemBlock->MemSubBlock[i].MemType == VPU_MEM_VIRT) {
+            unsigned char * ptr = (unsigned char *)malloc(size);
+			if (ptr == NULL) {
+				VPU_ENC_COMP_LOG("%s: get virtual memory failure, size=%d 
", __FUNCTION__, size);
+				return 0;
+			}
+			pMemBlock->MemSubBlock[i].pVirtAddr=(unsigned char *)Align(ptr, pMemBlock->MemSubBlock[i].nAlignment);
+        } else {
+			VpuMemDesc vpuMem;
+			VpuEncRetCode ret;
+			vpuMem.nSize = size;
+            vpuMem.nType = VPU_MEM_DESC_NORMAL;
+			ret = VPU_EncGetMem(&vpuMem);
+			if(ret != VPU_ENC_RET_SUCCESS) {
+				VPU_ENC_COMP_LOG("%s: get vpu memory failure, size=%d, ret=0x%X 
", __FUNCTION__, size, ret);
+				return 0;
+			}
+
+			pMemBlock->MemSubBlock[i].pVirtAddr = (unsigned char *)Align(vpuMem.nVirtAddr,pMemBlock->MemSubBlock[i].nAlignment);
+			pMemBlock->MemSubBlock[i].pPhyAddr = (unsigned char *)Align(vpuMem.nPhyAddr,pMemBlock->MemSubBlock[i].nAlignment);
+            pMemBlock->MemSubBlock[i].nFd = (int)vpuMem.nCpuAddr;
+            pMemBlock->MemSubBlock[i].nSize = vpuMem.nSize; // update size because phys size is larger due to align with pagesize
+
+            if (pMemBlock->MemSubBlock[i].pVirtAddr != (unsigned char *)vpuMem.nVirtAddr ||
+                    pMemBlock->MemSubBlock[i].pPhyAddr != (unsigned char *)vpuMem.nPhyAddr)
+                VPU_ENC_COMP_LOG("VPU_DecGetMem not aligned, nAlignment %d", pMemBlock->MemSubBlock[i].nAlignment);
+		}
+	}
+
+	return 1;
+}
+
+int OutFrameBufRegister(int bufferId,
+                                  unsigned long pInPhyAddr,
+                                  unsigned long pInVirtAddr,
+                                  uint32_t capacity,
+                                  VpuEncoderMemInfo* pOutEncMem) {
+
+	if (!pInPhyAddr || !pInVirtAddr || !pOutEncMem) {
+        return -1;
+	}
+
+    int i;
+	for (i = 0; i < VPU_ENC_MAX_NUM_MEM; i++) {
+		//insert into empty node
+		if (NULL == pOutEncMem->phyMem_phyAddr[i]) {
+			pOutEncMem->phyMem_phyAddr[i] = pInPhyAddr;
+			pOutEncMem->phyMem_virtAddr[i] = pInVirtAddr;
+            pOutEncMem->phyMem_size[i] = capacity;
+            pOutEncMem->phyMem_bufferId[i] = bufferId;
+			pOutEncMem->nPhyNum++;
+			return pOutEncMem->nPhyNum;
+		}
+	}
+
+	return -1;
+}
+
+int OutFrameBufNum(VpuEncoderMemInfo* pOutEncMem) {
+    return pOutEncMem->nPhyNum;
+}
+
+int OutFrameBufExist(unsigned long physAddr, VpuEncoderMemInfo* pInEncMem) {
+	int i;
+
+	//physical space
+	for (i = 0; i < VPU_ENC_MAX_NUM_MEM; i++) {
+		//search matched node
+		if(physAddr == pInEncMem->phyMem_phyAddr[i]) {
+			return 1;
+		}
+	}
+
+    return 0;
+}
+
+int OutFrameBufClear(VpuEncoderMemInfo* pOutEncMem)
+{
+	int i;
+	//clear all node
+	for(i=0;i<VPU_ENC_MAX_NUM_MEM;i++)
+	{
+		pOutEncMem->phyMem_virtAddr[i]=NULL;
+		pOutEncMem->phyMem_phyAddr[i]=NULL;
+		pOutEncMem->phyMem_virtAddr[i]=NULL;
+		pOutEncMem->phyMem_cpuAddr[i]=NULL;
+		pOutEncMem->phyMem_size[i]=0;
+	}
+	pOutEncMem->nVirtNum=0;
+	pOutEncMem->nPhyNum=0;
+	return 1;
+}
+
+int OutFrameBufPhyFindValid(VpuEncoderMemInfo* pInMem,
+                                        unsigned long* pOutPhy,
+                                        unsigned long* pOutVirt,
+                                        uint32_t* pOutLen) {
+	int i;
+
+	for (i = 0; i < VPU_ENC_MAX_NUM_MEM; i++) {
+		//find one non-empty physical node
+		if (NULL != pInMem->phyMem_phyAddr[i]) {
+			*pOutPhy = pInMem->phyMem_phyAddr[i];
+			*pOutVirt = pInMem->phyMem_virtAddr[i];
+		    *pOutLen = pInMem->phyMem_size[i];
+			return i;
+		}
+	}
+	return -1;
+}
+
+int OutFrameBufVirtFindValidAndClear(VpuEncoderMemInfo* pInMem, int* bufferId) {
+	uint32_t i;
+
+	for (i = 0; i < VPU_ENC_MAX_NUM_MEM; i++) {
+		//find one non-empty physical node and return its buffer id
+		if (NULL != pInMem->phyMem_phyAddr[i]) {
+			*bufferId = pInMem->phyMem_bufferId[i];
+			//clear the node
+			pInMem->phyMem_virtAddr[i] = 0;
+			pInMem->phyMem_phyAddr[i] = 0;
+			pInMem->phyMem_virtAddr[i] = 0;
+			pInMem->phyMem_cpuAddr[i] = 0;
+            pInMem->phyMem_bufferId[i] = -1;
+			pInMem->phyMem_size[i] = 0;
+			pInMem->nPhyNum--;
+			return i;
+		}
+	}
+	return -1;
+}
+
+int OutFrameBufPhyClear(VpuEncoderMemInfo* pOutDecMem, unsigned long pInPhyAddr, int* bufferId) {
+	//find node according physical address and (1) return virtual address (2) clear node
+	uint32_t i;
+
+	for (i = 0; i < VPU_ENC_MAX_NUM_MEM; i++) {
+		if (pInPhyAddr == pOutDecMem->phyMem_phyAddr[i]) {
+			//return buffer id
+			*bufferId = pOutDecMem->phyMem_bufferId[i];
+			//clear specified physical node
+			pOutDecMem->phyMem_virtAddr[i] = 0;
+			pOutDecMem->phyMem_phyAddr[i] = 0;
+			pOutDecMem->phyMem_virtAddr[i]= 0;
+			pOutDecMem->phyMem_cpuAddr[i] = 0;
+            pOutDecMem->phyMem_bufferId[i] = -1;
+			pOutDecMem->phyMem_size[i] =0;
+
+			pOutDecMem->nPhyNum--;
+			return 1;
+		}
+	}
+
+	return -1;
+}
+
+
+
+int SetDefaultEncParam(VpuEncInputParam* pEncParam) {
+	pEncParam->eFormat = VPU_V_AVC;
+	pEncParam->nPicWidth = DEFAULT_ENC_FRM_WIDTH;
+	pEncParam->nPicHeight = DEFAULT_ENC_FRM_HEIGHT;
+	pEncParam->nWidthStride = pEncParam->nPicWidth;
+	pEncParam->nHeightStride = pEncParam->nPicHeight;
+	pEncParam->nRotAngle = 0;
+	pEncParam->nFrameRate = 30;
+	ASSERT(0 != pEncParam->nFrameRate);
+	pEncParam->nBitRate = 0;
+	pEncParam->nGOPSize = 15;
+	pEncParam->nChromaInterleave = 0;
+	pEncParam->sMirror = VPU_ENC_MIRDIR_NONE;
+
+	/* "nQuantParam" is used for all quantization parameters in case of VBR (no rate control).
+	The range of value is 1-31 for MPEG-4 and 0-51 for H.264. When rate control is
+	enabled, this field is ignored*/
+	pEncParam->nQuantParam = 10;
+
+	pEncParam->nEnableAutoSkip = 1;
+
+	pEncParam->nIDRPeriod=pEncParam->nGOPSize;
+	pEncParam->nRefreshIntra = 0;
+	pEncParam->nIntraFreshNum = 0;
+	pEncParam->bEnabledSPSIDR = false;
+	pEncParam->nRcIntraQP = 0;
+	return 1;
+}
+
+VpuWrapperEnc::VpuWrapperEnc(const char* mime)
+    : mMime(mime) {
+
+    // init mMime2TypeMap
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_AVC, VPU_V_AVC);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_VP8, VPU_V_VP8);
+    mMime2TypeMap.emplace(MEDIA_MIMETYPE_VIDEO_HEVC, VPU_V_HEVC);
+
+    pCodecdataBuf = nullptr;
+    nCodecDataLen = 0;
+
+    SetDefaultSetting();
+}
+
+VpuWrapperEnc::~VpuWrapperEnc() {
+}
+
+void VpuWrapperEnc::SetDefaultSetting() {
+ 	//set default
+
+	//clear internal variable 0
+	memset(&sEncInitInfo, 0, sizeof(VpuEncInitInfo));
+	memset(&sMemInfo, 0, sizeof(VpuMemInfo));
+	memset(&sEncOutFrameInfo, 0, sizeof(VpuEncoderMemInfo));
+	memset(&sVpuEncInputPara, 0, sizeof(VpuEncInputParam));
+    memset(&sColorDesc, 0, sizeof(VpuColourDesc));
+
+	nHandle = nullptr;
+	pInBufferPhys = nullptr;
+	pInBufferVirt = nullptr;
+	nInSize = 0;
+	bInEos = false;
+	pOutBufferPhys = nullptr;
+    poutBufferVirt = nullptr;
+	nOutSize = 0;
+	nOutGOPFrameCnt = 1;
+	eVpuEncoderState = VPU_ENC_COM_STATE_NONE;
+
+	SetDefaultEncParam(&sVpuEncInputPara);
+
+	return;
+}
+
+status_t VpuWrapperEnc::onInit() {
+    VpuEncRetCode ret;
+    VpuVersionInfo ver;
+
+    VPU_ENC_COMP_API_LOG("%s line %d", __FUNCTION__, __LINE__);
+
+    hTsHandle = tsmCreate();
+    if (hTsHandle == nullptr) {
+        ALOGE("Create Ts manager failed.
");
+        return BAD_VALUE;
+    }
+
+    ret = VPU_EncLoad();
+    CHECK_VPU_RET(ret);
+
+    ret = VPU_EncGetVersionInfo(&ver);
+    CHECK_VPU_RET(ret);
+
+    VPU_ENC_COMP_LOG("vpu lib version : rel.major.minor=%d.%d.%d 
",
+        ver.nLibRelease, ver.nLibMajor, ver.nLibMinor);
+	VPU_ENC_COMP_LOG("vpu fw version : rel.major.minor=%d.%d.%d 
",
+        ver.nFwRelease, ver.nFwMajor, ver.nFwMinor);
+
+    auto node = mMime2TypeMap.find(mMime);
+    if (node == mMime2TypeMap.end()) {
+        VPU_ENC_COMP_ERR_LOG("%s line %d, unsupported decoder mime %s
", __FUNCTION__, __LINE__, mMime);
+        return BAD_VALUE;
+    } else
+        sVpuEncInputPara.eFormat = node->second;
+
+	if (OK != OpenVpu()) {
+		VPU_ENC_COMP_ERR_LOG("%s: vpu init failure 
",__FUNCTION__);
+		return BAD_VALUE;
+	}
+
+    //eVpuEncoderState = VPU_ENC_COM_STATE_WAIT_FRM;
+    eVpuEncoderState= VPU_ENC_COM_STATE_DO_DEC;
+    return OK;
+}
+
+status_t VpuWrapperEnc::onStop() {
+    status_t err = OK;
+	VPU_ENC_COMP_API_LOG("%s: 
",__FUNCTION__);
+
+	//check state
+	switch(eVpuEncoderState)
+	{
+		case VPU_ENC_COM_STATE_NONE:
+			//forbidden
+			VPU_ENC_COMP_ERR_LOG("%s: failure: error state transition, current state=%d 
",__FUNCTION__,eVpuEncoderState);
+			return BAD_VALUE;
+		default:
+			break;
+	}
+
+	err = ReleaseVpuSource();
+
+    if (hTsHandle) {
+        tsmDestroy(hTsHandle);
+        hTsHandle = nullptr;
+    }
+
+	//clear handle
+	nHandle = nullptr;
+
+	//restore default to support following switch from loaded to idle later.
+	SetDefaultSetting();
+
+	//update state
+	eVpuEncoderState = VPU_ENC_COM_STATE_LOADED;
+    return OK;
+}
+
+status_t VpuWrapperEnc::onFlush() {
+    status_t err = OK;
+
+    VPU_ENC_COMP_API_LOG("%s: state: %d  
", __FUNCTION__, eVpuEncoderState);
+
+    //check state
+    switch (eVpuEncoderState) {
+        case VPU_ENC_COM_STATE_DO_DEC:
+            break;
+        default:
+            //forbidden !!!
+            VPU_ENC_COMP_ERR_LOG("%s: unknown state transition, current state=%d 
", __FUNCTION__, eVpuEncoderState);
+    }
+
+    //clear input buffer
+    pInBufferPhys = nullptr;
+    pInBufferVirt = nullptr;
+    nInSize = 0;
+    bInEos = false;
+    nCurInputId = -1;
+
+    tsmFlush(hTsHandle);
+
+    NotifyFlushDone();
+
+    return err;
+}
+
+status_t VpuWrapperEnc::onDestroy() {
+    status_t err = OK;
+	VPU_ENC_COMP_API_LOG("%s: 
",__FUNCTION__);
+
+	//check state
+	switch(eVpuEncoderState)
+	{
+		case VPU_ENC_COM_STATE_NONE:
+			//forbidden
+			VPU_ENC_COMP_ERR_LOG("%s: failure: error state transition, current state=%d 
",__FUNCTION__,eVpuEncoderState);
+			return BAD_VALUE;
+		default:
+			//invalid state, we need to close/unload vpu
+			VPU_ENC_COMP_ERR_LOG("invalid state: %d, close vpu manually 
",eVpuEncoderState);
+			err = ReleaseVpuSource();
+			break;
+	}
+
+    if (hTsHandle) {
+        tsmDestroy(hTsHandle);
+        hTsHandle = nullptr;
+    }
+
+	eVpuEncoderState = VPU_ENC_COM_STATE_LOADED;
+    return err;
+}
+
+status_t VpuWrapperEnc::encodeInternal(std::unique_ptr<IMXInputBuffer> input) {
+	VpuEncRetCode ret;
+	int index;
+	unsigned long nOutPhy;
+	unsigned long nOutVirt;
+	uint32_t nOutLength;
+	VpuEncEncParam sEncEncParam;
+	int nValidInput = 1;
+	unsigned long nInputPhy, nInputVirt;
+	int nInputSize;
+    status_t err = OK;
+    int encodeCnt = 0;
+
+	switch (eVpuEncoderState) {
+		//forbidden state
+		case VPU_ENC_COM_STATE_NONE:
+		case VPU_ENC_COM_STATE_DO_OUT:
+			VPU_ENC_COMP_ERR_LOG("%s: failure: error state transition, current state=%d 
", __FUNCTION__, eVpuEncoderState);
+			return INVALID_OPERATION;
+        case VPU_ENC_COM_STATE_WAIT_FRM: {
+            if (OutFrameBufNum(&sEncOutFrameInfo) < sEncInitInfo.nMinFrameBufferCount) {
+                VPU_ENC_COMP_LOG("OutFrameBufNum is not enough, request %d 
", sEncInitInfo.nMinFrameBufferCount);
+                return OK;
+            }
+
+            eVpuEncoderState = VPU_ENC_COM_STATE_LOADED;
+            // fallthrough
+        }
+        case VPU_ENC_COM_STATE_LOADED: {
+            if ((nullptr == pInBufferPhys || nInSize <= 0) && (false == bInEos)) {
+			    return BAD_VALUE;
+			}
+
+			eVpuEncoderState = VPU_ENC_COM_STATE_DO_DEC;
+            break;
+        }
+		case VPU_ENC_COM_STATE_DO_DEC:
+			break;
+		default:
+			VPU_ENC_COMP_ERR_LOG("%s: failure state transition, current state=%d 
", __FUNCTION__, eVpuEncoderState);
+			return INVALID_OPERATION;
+	}
+
+    if (input && input->eos) {
+        bInEos = true;
+        pInBufferPhys = nullptr;
+        pInBufferVirt = nullptr;
+        nInSize = 0;
+    } else if (input) {
+        pInBufferPhys = input->pInputPhys;
+        pInBufferVirt = input->pInputVirt;
+        nInSize = input->size;
+        nCurInputId = input->id;
+        tsmSetBlkTs(hTsHandle, nInSize, input->timestamp);
+
+        #ifdef DUMP_YUV
+        if (nInSize > 0) {
+            unsigned long virtAddr = (unsigned long)pInBufferVirt;
+            bool needUnmap = false;
+            if (virtAddr == 0) {
+                int fd = input->fd;
+                fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
+                int ret = pIonAllocator->getVaddrs(fd, nInSize, (uint64_t&)virtAddr);
+                if (ret != 0) {
+                    VPU_ENC_COMP_ERR_LOG("Ion get physical address failed, fd %d", fd);
+                } else
+                    needUnmap = true;
+            }
+
+            if (virtAddr > 0) {
+                FILE * pfile;
+                pfile = fopen("/data/dumpYUV","ab");
+                if(pfile) {
+                    ALOGI("dump size %d", nInSize);
+                    fwrite((void*)virtAddr,1,nInSize,pfile);
+                    fclose(pfile);
+                } else {
+                    VPU_ENC_COMP_ERR_LOG("open dumpfile failed
");
+                }
+            }
+            if (needUnmap && virtAddr > 0)
+                munmap((void*)virtAddr, nInSize);
+        }
+        #endif
+    }
+
+	if ((nullptr == pInBufferPhys) || (nInSize <= 0)) {
+		nValidInput = 0;
+		nInputPhy = 0;
+		nInputVirt = 0;
+		nInputSize = 0;
+	} else {
+		nInputPhy = (unsigned long)pInBufferPhys;
+		nInputVirt = (unsigned long)pInBufferVirt;
+		nInputSize = nInSize;
+	}
+
+    if (0 == nValidInput) {
+		if (bInEos)	{
+			//eos: and no output frame
+			pOutBufferPhys = nullptr;//no real output frame
+			poutBufferVirt = nullptr;
+            nInSize = 0;
+			NotifyEOS();
+            return OK;
+		} else {
+			//no input buffer
+			ALOGE("!!!! nValidInput is true");
+            return OK;
+		}
+    }
+
+    int blockId;
+    int fd;
+    nOutLength = mOutputFormat.bufferSize;
+    if (FetchOutputBuffer(&blockId, &fd, &nOutPhy, &nOutVirt, &nOutLength) != OK)
+        return BAD_VALUE;
+    if (setOutputBuffer(blockId, nOutPhy, nOutVirt, nOutLength) != OK)
+        return BAD_VALUE;
+    if (-1 == OutFrameBufPhyFindValid(&sEncOutFrameInfo, &nOutPhy, &nOutVirt, &nOutLength))
+		return BAD_VALUE;
+
+	VPU_ENC_COMP_LOG("%s: state: %d, InBuf: virt(%p), phys(%p), inSize(%d), bInEos: %d, OutBuf: virt(%p), phys(%p)
", \
+            __FUNCTION__, eVpuEncoderState, (void*)nInputVirt, (void*)nInputPhy, nInputSize, bInEos,
+            (void*)nOutVirt, (void*)nOutPhy);
+
+    memset(&sEncEncParam, 0, sizeof(VpuEncEncParam));
+	sEncEncParam.eFormat = sVpuEncInputPara.eFormat;
+	sEncEncParam.nPicWidth = sVpuEncInputPara.nWidthStride;//sVpuEncInputPara.nPicWidth;
+	sEncEncParam.nPicHeight = sVpuEncInputPara.nHeightStride;//sVpuEncInputPara.nPicHeight;
+	sEncEncParam.nFrameRate = sVpuEncInputPara.nFrameRate;
+	sEncEncParam.nQuantParam = sVpuEncInputPara.nQuantParam;
+	sEncEncParam.nInPhyInput = nInputPhy;
+	sEncEncParam.nInVirtInput = nInputVirt;
+	sEncEncParam.nInInputSize = nInputSize;
+	sEncEncParam.nInPhyOutput = nOutPhy;
+	sEncEncParam.nInVirtOutput = nOutVirt;
+	sEncEncParam.nInOutputBufLen = nOutLength;
+
+	//(1)check the frame count, for H.264
+	//In current design, we will set IDR frame for every I frame
+	//(2)check I refresh command by user
+	if ((1 == sVpuEncInputPara.nRefreshIntra) ||
+        ((VPU_V_AVC == sEncEncParam.eFormat || VPU_V_VP8 == sEncEncParam.eFormat) && (1 == nOutGOPFrameCnt))) {
+		sEncEncParam.nForceIPicture = 1;
+		sVpuEncInputPara.nRefreshIntra = 0; 	//clear it every time
+		nOutGOPFrameCnt = 1;
+	} else {
+		sEncEncParam.nForceIPicture=0;
+	}
+
+	sEncEncParam.nSkipPicture = 0;
+	sEncEncParam.nEnableAutoSkip = sVpuEncInputPara.nEnableAutoSkip;
+
+encode_one_frame:
+	ret = VPU_EncEncodeFrame(nHandle, &sEncEncParam);
+
+    encodeCnt++;
+
+	if (VPU_ENC_RET_SUCCESS != ret) {
+		if (VPU_ENC_RET_FAILURE_TIMEOUT == ret) {
+			VPU_ENC_COMP_ERR_LOG("%s: encode frame timeout 
",__FUNCTION__);
+			VPU_EncReset(nHandle);
+		}
+		return BAD_VALUE;
+	}
+
+	//check input
+	if (sEncEncParam.eOutRetCode & VPU_ENC_INPUT_USED) {
+        tsmSetFrmBoundary(hTsHandle, 0, nInSize, nullptr);
+        pInBufferPhys = nullptr;  //clear input
+		pInBufferVirt = nullptr;
+		nInSize = 0;
+
+        if(nCurInputId != (-1)) {
+            NotifyInputBufferUsed(nCurInputId/*input_id*/);
+            nCurInputId = -1;
+		}
+	} else {
+		//not used
+	}
+
+	//check output
+	if (sEncEncParam.eOutRetCode & VPU_ENC_OUTPUT_DIS) {
+
+		eVpuEncoderState = VPU_ENC_COM_STATE_DO_OUT;
+
+        //record output info
+		pOutBufferPhys = (void*)nOutPhy;
+        poutBufferVirt = (void*)nOutVirt;
+		nOutSize = sEncEncParam.nOutOutputSize;
+        GetOutputBuffer();
+		VPU_ENC_COMP_LOG("[%d]frame data: %d 
", nOutGOPFrameCnt, nOutSize);
+
+        //update count
+		nOutGOPFrameCnt++;
+		if (nOutGOPFrameCnt > sVpuEncInputPara.nGOPSize) {
+			nOutGOPFrameCnt = 1;
+		}
+	} else if(sEncEncParam.eOutRetCode & VPU_ENC_OUTPUT_SEQHEADER) {
+	    // save codec data
+	    if (!pCodecdataBuf) {
+            pCodecdataBuf = (uint8_t*)malloc(sEncEncParam.nOutOutputSize);
+            if (!pCodecdataBuf) {
+                VPU_ENC_COMP_ERR_LOG("%s line %d, malloc %d failed", __FUNCTION__, __LINE__, sEncEncParam.nOutOutputSize);
+            }
+        }
+        memcpy(pCodecdataBuf, (void*)nOutVirt, sEncEncParam.nOutOutputSize);
+        nCodecDataLen += sEncEncParam.nOutOutputSize;
+		VPU_ENC_COMP_LOG("sequence header: %d 
",sEncEncParam.nOutOutputSize);
+
+	}
+
+    if (!(sEncEncParam.eOutRetCode & VPU_ENC_INPUT_USED)) {
+	    if (encodeCnt > 100)
+            NotifyError(BAD_VALUE);
+        else
+            goto encode_one_frame; // input buffer is not consumed, call encode again.
+    }
+
+    return err;
+}
+
+status_t VpuWrapperEnc::setOutputBuffer(int bufferId, unsigned long pPhyAddr, unsigned long pVirtAddr, uint32_t capacity) {
+    VpuDecRetCode ret;
+    VpuDecOutFrameInfo * pFrameInfo;
+    int32_t exist;
+
+    exist = OutFrameBufExist(pPhyAddr, &sEncOutFrameInfo);
+
+    VPU_ENC_COMP_LOG("%s, buffer id %d, exist %d", __FUNCTION__, bufferId, exist);
+
+    if (exist == 0) {
+		//register output frame buffer
+		if (-1 == OutFrameBufRegister(bufferId, pPhyAddr, pVirtAddr, capacity, &sEncOutFrameInfo)) {
+			VPU_ENC_COMP_ERR_LOG("%s: failure: unvalid buffer ! 
",__FUNCTION__);
+			return BAD_VALUE;
+		}
+    } else {
+        VPU_ENC_COMP_LOG("%s line %d, enter error state", __FUNCTION__, __LINE__);
+        return BAD_VALUE;
+    }
+    return OK;
+}
+
+status_t VpuWrapperEnc::getOutputVideoInfo(VideoFormat * info) {
+    return OK;
+}
+
+status_t VpuWrapperEnc::DoSetConfig(EncConfig index, void* pConfig) {
+    switch (index) {
+        case ENC_CONFIG_BIT_RATE: {
+            int kbps;
+            sVpuEncInputPara.nBitRate = (*(int*)pConfig);
+            kbps = sVpuEncInputPara.nBitRate/1000;
+            if (VPU_ENC_RET_SUCCESS != VPU_EncConfig(nHandle, VPU_ENC_CONF_BIT_RATE, &kbps)) {
+                VPU_ENC_COMP_ERR_LOG("%s line %d: failure
", __FUNCTION__, __LINE__);
+                return BAD_VALUE;
+            }
+            VPU_ENC_COMP_LOG("config bit rate %d", sVpuEncInputPara.nBitRate);
+            break;
+        }
+        case ENC_CONFIG_FRAME_RATE: {
+            int frameRate = (*(int*)pConfig);
+            if (sVpuEncInputPara.nFrameRate != frameRate) {
+                int bps, kbps;
+                bps = sVpuEncInputPara.nBitRate * sVpuEncInputPara.nFrameRate / frameRate;
+                kbps = bps/1000;
+                if (VPU_ENC_RET_SUCCESS == VPU_EncConfig(nHandle, VPU_ENC_CONF_BIT_RATE, &kbps)) {
+                    sVpuEncInputPara.nFrameRate = frameRate;
+                    sVpuEncInputPara.nBitRate = bps;
+                } else {
+                    VPU_ENC_COMP_ERR_LOG("%s line %d: failure
", __FUNCTION__, __LINE__);
+                    return BAD_VALUE;
+                }
+                VPU_ENC_COMP_LOG("config frame rate %d, bit rate %d", frameRate, bps);
+            }
+            break;
+        }
+        case ENC_CONFIG_INTRA_REFRESH: {
+            sVpuEncInputPara.nRefreshIntra = (*(int*)pConfig);
+            VPU_ENC_COMP_LOG("config RefreshIntra %d", sVpuEncInputPara.nRefreshIntra);
+            break;
+        }
+        case ENC_CONFIG_COLOR_FORMAT: {
+            sVpuEncInputPara.ePixelFormat = (*(int*)pConfig);
+            break;
+        }
+        default:
+            return BAD_VALUE;
+    }
+
+    return OK;
+}
+
+status_t VpuWrapperEnc::DoGetConfig(EncConfig index, void* pConfig) {
+    return OK;
+}
+
+bool VpuWrapperEnc::checkIfPreProcessNeeded(int pixelFormat) {
+    switch (pixelFormat) {
+#ifndef HANTRO_VC8000E
+        // vc8000e don't need pre process because it emplement full video range;
+        // h1 need pre process to handle RGB
+        case HAL_PIXEL_FORMAT_RGB_565:
+        case HAL_PIXEL_FORMAT_RGB_888:
+		case HAL_PIXEL_FORMAT_RGBA_8888:
+        case HAL_PIXEL_FORMAT_RGBX_8888:
+		case HAL_PIXEL_FORMAT_BGRA_8888:
+#endif
+        case HAL_PIXEL_FORMAT_YV12:
+            VPU_ENC_COMP_LOG("need pre-process, pixel format %x", pixelFormat);
+            return true;
+        default:
+            VPU_ENC_COMP_LOG("no need pre-process, pixel format %x", pixelFormat);
+            return false;
+    }
+}
+
+void VpuWrapperEnc::initEncInputParamter(EncInputParam *pInPara) {
+    if (!pInPara) {
+        VPU_ENC_COMP_ERR_LOG("invalid encoder input parameter !");
+        return;
+    }
+
+    sVpuEncInputPara.nPicWidth = pInPara->nPicWidth;
+    sVpuEncInputPara.nPicHeight = pInPara->nPicHeight;
+    sVpuEncInputPara.nWidthStride = pInPara->nWidthStride;
+    sVpuEncInputPara.nHeightStride = pInPara->nHeightStride;
+    sVpuEncInputPara.nFrameRate = pInPara->nFrameRate;
+    sVpuEncInputPara.nRotAngle = pInPara->nRotAngle;
+    sVpuEncInputPara.nBitRate = pInPara->nBitRate;
+    sVpuEncInputPara.nGOPSize = pInPara->nGOPSize;
+    sVpuEncInputPara.nIDRPeriod = pInPara->nIDRPeriod;
+    sVpuEncInputPara.nRefreshIntra = pInPara->nRefreshIntra;
+    sVpuEncInputPara.bEnabledSPSIDR = pInPara->bEnabledSPSIDR;
+    sVpuEncInputPara.nRcIntraQP = pInPara->nRcIntraQP;
+    sVpuEncInputPara.nEnableAutoSkip = pInPara->nEnableAutoSkip;
+    sVpuEncInputPara.nQuantParam = pInPara->nQuantParam;
+    sVpuEncInputPara.ePixelFormat = pInPara->eColorFormat;
+
+    if (pInPara->eColorFormat == HAL_PIXEL_FORMAT_YCbCr_420_SP ||
+            pInPara->eColorFormat == HAL_PIXEL_FORMAT_YCBCR_420_888) {
+        sVpuEncInputPara.nChromaInterleave = 1;
+    }
+}
+
+status_t VpuWrapperEnc::getCodecData(uint8_t** pCodecData, uint32_t* size) {
+    status_t ret = OK;
+
+    if (!pCodecData || !size)
+        return BAD_VALUE;
+
+    if (pCodecdataBuf && nCodecDataLen > 0) {
+        *pCodecData = pCodecdataBuf;
+        *size = nCodecDataLen;
+    }
+
+    return ret;
+}
+
+status_t VpuWrapperEnc::FlushFilter()
+{
+	VpuEncRetCode ret;
+	VPU_ENC_COMP_LOG("%s: 
",__FUNCTION__);
+
+    //clear input buffer
+	pInBufferPhys = NULL;
+	pInBufferVirt = NULL;
+	nInSize = 0;
+	bInEos = false;
+
+	//clear out frame info
+	OutFrameBufClear(&sEncOutFrameInfo);
+
+	return OK;
+}
+
+status_t VpuWrapperEnc::ReleaseVpuSource()
+{
+	VpuEncRetCode ret;
+    status_t err;
+
+	//close vpu
+	if (nHandle) {
+		ret = VPU_EncClose(nHandle);
+		if (ret != VPU_ENC_RET_SUCCESS)
+		{
+			VPU_ENC_COMP_ERR_LOG("%s: vpu close failure: ret=0x%X 
",__FUNCTION__,ret);
+			err = BAD_VALUE;
+		}
+	}
+
+	//release mem
+	if (0 == MemFreeBlock(&sMemInfo)) {
+		VPU_ENC_COMP_ERR_LOG("%s: free memory failure !  
",__FUNCTION__);
+		err = BAD_VALUE;
+	}
+
+	//unload
+	ret = VPU_EncUnLoad();
+	if (ret != VPU_ENC_RET_SUCCESS) {
+		VPU_ENC_COMP_ERR_LOG("%s: vpu unload failure: ret=0x%X 
",__FUNCTION__,ret);
+		err = BAD_VALUE;
+	}
+
+    if (pCodecdataBuf) {
+        free(pCodecdataBuf);
+        pCodecdataBuf = nullptr;
+        nCodecDataLen = 0;
+    }
+
+	return err;
+}
+
+
+status_t VpuWrapperEnc::GetOutputBuffer() {
+	int bufferId = -1;
+    int isKeyFrame = 0;
+    uint64_t timestamp = -1;
+
+	VPU_ENC_COMP_API_LOG("%s: state: %d 
", __FUNCTION__, eVpuEncoderState);
+
+	//check state
+	switch(eVpuEncoderState) {
+		case VPU_ENC_COM_STATE_DO_OUT:
+			//update state
+			eVpuEncoderState = VPU_ENC_COM_STATE_DO_DEC;
+			break;
+		default:
+			//forbidden
+			VPU_ENC_COMP_ERR_LOG("%s: failure state transition, current state=%d 
",__FUNCTION__,eVpuEncoderState);
+			return BAD_VALUE;
+	}
+
+	if (NULL == pOutBufferPhys) {
+		//no real output frame: for eos case
+		if (-1 == OutFrameBufVirtFindValidAndClear(&sEncOutFrameInfo, &bufferId)) {
+			VPU_ENC_COMP_ERR_LOG("%s: failure: can not find one valid virtual address !!! 
",__FUNCTION__);
+			return BAD_VALUE;
+		}
+
+	} else {
+		if (-1 == OutFrameBufPhyClear(&sEncOutFrameInfo, (unsigned long)pOutBufferPhys, &bufferId)) {
+			VPU_ENC_COMP_ERR_LOG("%s: failure: unvalid output physical address !!! 
",__FUNCTION__);
+			return BAD_VALUE;
+		}
+	}
+
+    timestamp = tsmGetFrmTs(hTsHandle, nullptr);
+    isKeyFrame = (1 == nOutGOPFrameCnt);
+    NotifyOutputFrameReady(bufferId, nOutSize, timestamp, isKeyFrame, 0);
+    return OK;
+}
+
+VpuColorFormat VPUCom_ConvertPixelFmt2Vpu(int pixelFormat) {
+  VpuColorFormat vpuColorFmt = VPU_COLOR_420;
+
+  switch((int)pixelFormat) {
+    case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+    case HAL_PIXEL_FORMAT_YCbCr_420_P:
+    case HAL_PIXEL_FORMAT_YCBCR_420_888:
+        vpuColorFmt = VPU_COLOR_420;
+        break;
+    case HAL_PIXEL_FORMAT_YCBCR_422_I:
+        vpuColorFmt = VPU_COLOR_422YUYV;
+        break;
+#ifdef HANTRO_VC8000E
+    case HAL_PIXEL_FORMAT_RGBA_8888: // fall through
+    case HAL_PIXEL_FORMAT_RGBX_8888:
+        vpuColorFmt = VPU_COLOR_ARGB8888;
+        break;
+    case HAL_PIXEL_FORMAT_BGRA_8888:
+        vpuColorFmt = VPU_COLOR_BGRA8888;
+        break;
+#else
+    case HAL_PIXEL_FORMAT_RGBA_8888: // fall through
+    case HAL_PIXEL_FORMAT_RGBX_8888:
+        vpuColorFmt = VPU_COLOR_BGRA8888;
+        break;
+    case HAL_PIXEL_FORMAT_BGRA_8888:
+        vpuColorFmt = VPU_COLOR_ARGB8888;
+        break;
+#endif
+    default:
+      VPU_ENC_COMP_LOG("unknown pixel format %d
", pixelFormat);
+      break;
+  }
+
+  return vpuColorFmt;
+}
+
+status_t VpuWrapperEnc::OpenVpu() {
+	VpuEncRetCode ret;
+	VpuEncOpenParamSimp sEncOpenParam;
+
+	ret = VPU_EncQueryMem(&sMemInfo);
+	if (ret != VPU_ENC_RET_SUCCESS) {
+		VPU_ENC_COMP_ERR_LOG("%s: vpu query memory failure: ret=0x%X 
",__FUNCTION__,ret);
+		return BAD_VALUE;
+	}
+
+	if (0 == MemMallocBlock(&sMemInfo)) {
+		VPU_ENC_COMP_ERR_LOG("%s: malloc memory failure: 
",__FUNCTION__);
+		return BAD_VALUE;
+	}
+
+	memset(&sEncOpenParam, 0, sizeof(VpuEncOpenParamSimp));
+
+	sEncOpenParam.eFormat = sVpuEncInputPara.eFormat;
+	sEncOpenParam.nPicWidth = sVpuEncInputPara.nPicWidth;
+	sEncOpenParam.nPicHeight = sVpuEncInputPara.nPicHeight;
+	sEncOpenParam.nRotAngle = sVpuEncInputPara.nRotAngle;
+	sEncOpenParam.nFrameRate = sVpuEncInputPara.nFrameRate;
+	sEncOpenParam.nBitRate = sVpuEncInputPara.nBitRate / 1000; // convert bps -> kbps
+	sEncOpenParam.nGOPSize = sVpuEncInputPara.nGOPSize;
+	sEncOpenParam.nIntraQP = sVpuEncInputPara.nRcIntraQP;
+	sEncOpenParam.nChromaInterleave = sVpuEncInputPara.nChromaInterleave;
+	sEncOpenParam.sMirror = sVpuEncInputPara.sMirror;
+    sEncOpenParam.eColorFormat = VPUCom_ConvertPixelFmt2Vpu(sVpuEncInputPara.ePixelFormat);
+
+	if (1 == sEncOpenParam.nChromaInterleave) {
+		//for reduce the bus loading, we set tile format for vpu internal frame buffers.
+		sEncOpenParam.nMapType = 1;
+		sEncOpenParam.nLinear2TiledEnable = 1;
+	}
+
+	//open vpu
+	ret = VPU_EncOpenSimp(&nHandle, &sMemInfo, &sEncOpenParam);
+	if (ret != VPU_ENC_RET_SUCCESS) {
+		VPU_ENC_COMP_ERR_LOG("%s: vpu open failure: ret=0x%X 
",__FUNCTION__,ret);
+		return BAD_VALUE;
+	}
+
+	//set default config
+	ret = VPU_EncConfig(nHandle, VPU_ENC_CONF_NONE, NULL);
+	if (VPU_ENC_RET_SUCCESS != ret) {
+		VPU_ENC_COMP_ERR_LOG("%s: vpu config failure: config=0x%X, ret=%d 
",__FUNCTION__,(int)VPU_ENC_CONF_NONE,ret);
+		return BAD_VALUE;
+	}
+
+	if (true == sVpuEncInputPara.bEnabledSPSIDR) {
+		ret = VPU_EncConfig(nHandle, VPU_ENC_CONF_ENA_SPSPPS_IDR, NULL);
+		if(VPU_ENC_RET_SUCCESS!=ret){
+			VPU_ENC_COMP_ERR_LOG("%s: vpu config failure: config=0x%X, ret=%d 
",__FUNCTION__,(int)VPU_ENC_CONF_ENA_SPSPPS_IDR,ret);
+			return BAD_VALUE;
+		}
+	}
+
+	//get initinfo
+	ret = VPU_EncGetInitialInfo(nHandle, &sEncInitInfo);
+	if (VPU_ENC_RET_SUCCESS != ret) {
+		VPU_ENC_COMP_ERR_LOG("%s: init vpu failure 
",__FUNCTION__);
+		return BAD_VALUE;
+	}
+
+	return OK;
+}
+
+VideoEncoderBase * CreateVideoEncoderInstance(const char* mime) {
+    return static_cast<VideoEncoderBase *>(new VpuWrapperEnc(mime));
+}
+
+}  // namespace android
+
+// end of file
diff --git a/codec2/video_enc/vpuwrapper_enc/VpuWrapperEnc.h b/codec2/video_enc/vpuwrapper_enc/VpuWrapperEnc.h
new file mode 100755
index 0000000..d4566c3
--- /dev/null
+++ b/codec2/video_enc/vpuwrapper_enc/VpuWrapperEnc.h
@@ -0,0 +1,132 @@
+/**
+ *  Copyright 2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of NXP,
+ *  and contain its proprietary and confidential information.
+ */
+
+#ifndef VPU_WRAPPER_ENC_H
+#define VPU_WRAPPER_ENC_H
+
+#include <map>
+
+#include"VideoEncoderBase.h"
+#include"vpu_wrapper.h"
+
+namespace android {
+#define VPU_ENC_MAX_NUM_MEM (36)
+typedef struct
+{
+	//virtual mem info
+	int nVirtNum;
+	unsigned long virtMem[VPU_ENC_MAX_NUM_MEM];
+
+	//phy mem info
+	int nPhyNum;
+	unsigned long phyMem_virtAddr[VPU_ENC_MAX_NUM_MEM];
+	unsigned long phyMem_phyAddr[VPU_ENC_MAX_NUM_MEM];
+	int phyMem_cpuAddr[VPU_ENC_MAX_NUM_MEM];
+    int phyMem_bufferId[VPU_ENC_MAX_NUM_MEM];
+	uint32_t phyMem_size[VPU_ENC_MAX_NUM_MEM];
+}VpuEncoderMemInfo;
+
+typedef enum {
+    VPU_ENC_COM_STATE_NONE = 0,
+    VPU_ENC_COM_STATE_WAIT_FRM,
+    VPU_ENC_COM_STATE_LOADED,
+    VPU_ENC_COM_STATE_DO_DEC,
+    VPU_ENC_COM_STATE_DO_OUT,
+} VpuEncoderState;
+
+typedef struct {
+    VpuCodStd eFormat;
+    int ePixelFormat;
+    int nPicWidth;
+    int nPicHeight;
+    int nWidthStride;
+    int nHeightStride;
+    int nRotAngle;
+    int nFrameRate;
+    int nBitRate;           /*unit: bps*/
+    int nGOPSize;
+    int nChromaInterleave;
+    VpuEncMirrorDirection sMirror;
+    int nQuantParam;
+
+    int nEnableAutoSkip;
+    int nIDRPeriod;     //for H.264
+    int nRefreshIntra;  //IDR for H.264
+    int nIntraFreshNum;
+    bool bEnabledSPSIDR; //SPS/PPS is added for every IDR frame
+    int nRcIntraQP;     //0: auto; >0: qp value
+} VpuEncInputParam;
+
+
+class VpuWrapperEnc : public VideoEncoderBase {
+public:
+    VpuWrapperEnc(const char* mime);
+    virtual ~VpuWrapperEnc();
+
+    status_t DoSetConfig(EncConfig index, void* pConfig) override;
+    status_t DoGetConfig(EncConfig index, void* pConfig) override;
+    status_t getCodecData(uint8_t** pCodecData, uint32_t* size) override;
+    bool checkIfPreProcessNeeded(int pixelFormat) override;
+    void initEncInputParamter(EncInputParam *pInPara) override;
+
+protected:
+    status_t onInit() override;
+    status_t onStop() override;//idle to loaded
+    status_t onFlush() override;//flush
+    status_t onDestroy() override;//free Buffers
+    status_t encodeInternal(std::unique_ptr<IMXInputBuffer> input) override;
+    status_t getOutputVideoInfo(VideoFormat * info) override;
+    status_t setOutputBuffer(int bufferId, unsigned long pPhyAddr, unsigned long pVirtAddr, uint32_t capacity);
+
+private:
+    VpuMemInfo sMemInfo;
+    VpuEncoderMemInfo sEncOutFrameInfo;
+    VpuEncInitInfo sEncInitInfo;    // seqinit info
+    VpuEncHandle nHandle;       // pointer to vpu object
+
+    const char* mMime;
+
+    void* pInBufferPhys;
+    void* pInBufferVirt;
+    int32_t nInSize;
+    void* pOutBufferPhys;
+    void* poutBufferVirt;
+    int32_t nOutSize;
+    int32_t nOutGOPFrameCnt;    // used for H.264: [1,2,...,GOPSize]
+
+    VpuColourDesc sColorDesc;
+    VpuEncoderState eVpuEncoderState;
+    VpuEncInputParam sVpuEncInputPara;
+
+	bool bInEos;
+    bool bStarted;
+
+    std::unique_ptr<IMXInputBuffer> mCurInputBuffer;
+    int32_t nCurInputId;
+
+    void* hTsHandle;
+
+    std::map<const char*, VpuCodStd> mMime2TypeMap;
+
+    uint8_t* pCodecdataBuf;
+    uint32_t nCodecDataLen;
+
+
+	/* virtual function implementation */
+
+	status_t FlushFilter();
+
+	void SetDefaultSetting();
+	status_t ReleaseVpuSource();
+    bool DefaultOutputBufferNeeded();
+    status_t GetOutputBuffer();
+    status_t OpenVpu();
+};
+
+}  // namespace android
+#endif // VPU_WRAPPER_ENC_H
diff --git a/codec2/video_enc/vpuwrapper_enc/vpuwrapper_enc.go b/codec2/video_enc/vpuwrapper_enc/vpuwrapper_enc.go
new file mode 100644
index 0000000..219428c
--- /dev/null
+++ b/codec2/video_enc/vpuwrapper_enc/vpuwrapper_enc.go
@@ -0,0 +1,59 @@
+// Copyright 2019 NXP
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package vpuwrapper_enc
+
+import (
+        "android/soong/android"
+        "android/soong/cc"
+        "strings"
+        "github.com/google/blueprint/proptools"
+)
+
+func init() {
+    android.RegisterModuleType("imx_c2_vpuwrapper_enc_defaults", vpuwrapper_encDefaultsFactory)
+}
+
+func vpuwrapper_encDefaultsFactory() (android.Module) {
+    module := cc.DefaultsFactory()
+    android.AddLoadHook(module, vpuwrapper_encDefaults)
+    return module
+}
+
+func vpuwrapper_encDefaults(ctx android.LoadHookContext) {
+    var Cflags []string
+    type props struct {
+        Target struct {
+                Android struct {
+                        Enabled *bool
+                        Cflags []string
+                }
+        }
+    }
+    p := &props{}
+    p.Target.Android.Enabled = proptools.BoolPtr(false)
+    var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
+    if strings.Contains(board, "IMX8MM") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+        Cflags = append(Cflags, "-DHANTRO_H1")
+    } else if strings.Contains(board, "IMX8MP") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+        Cflags = append(Cflags, "-DHANTRO_VC8000E")
+    }
+    if ctx.Config().VendorConfig("IMXPLUGIN").String("CFG_SECURE_DATA_PATH") == "y" {
+        Cflags = append(Cflags, "-DALWAYS_ENABLE_SECURE_PLAYBACK")
+    }
+    p.Target.Android.Cflags = Cflags
+    ctx.AppendProperties(p)
+}
diff --git a/extractor/Android.bp b/extractor/Android.bp
new file mode 100755
index 0000000..5436261
--- /dev/null
+++ b/extractor/Android.bp
@@ -0,0 +1,50 @@
+cc_library_shared {
+
+    name: "libimxextractor",
+
+    srcs: [
+        "ImxExtractor.cpp",
+        "ImxInspector.cpp",
+    ],
+
+    header_libs: [
+        "libmedia_headers",
+        "libstagefright_headers",
+        "libstagefright_foundation_headers",
+    ],
+	
+    include_dirs: [
+        "frameworks/av/include/media/stagefright",
+        "frameworks/av/include/media",
+		"frameworks/av/include",
+		"frameworks/av/media/libstagefright/include",
+	    "vendor/nxp/fsl-codec/ghdr/common",
+    ],
+
+    shared_libs: [
+        "liblog",
+		"libutils",
+		"libcutils",
+        "libmediandk",
+		"libstagefright_foundation",
+    ],
+
+    cflags: [
+        "-Werror",
+        "-Wall",
+        "-fvisibility=hidden",
+    ],
+    version_script: "exports.lds",
+    relative_install_path: "extractors",
+    compile_multilib: "first",
+	
+    sanitize: {
+        cfi: true,
+        misc_undefined: [
+            "unsigned-integer-overflow",
+            "signed-integer-overflow",
+        ],
+    },
+//    vendor: true
+}
+
diff --git a/extractor/ImxExtractor.cpp b/extractor/ImxExtractor.cpp
new file mode 100755
index 0000000..09ff6fd
--- /dev/null
+++ b/extractor/ImxExtractor.cpp
@@ -0,0 +1,3363 @@
+/**
+ *  Copyright 2016 Freescale Semiconductor, Inc.
+ *  Copyright 2017-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "ImxExtractor"
+#include <utils/Log.h>
+
+#include "ImxExtractor.h"
+#include "Imx_ext.h"
+
+#include <media/DataSourceBase.h>
+#include <media/MediaTrack.h>
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/AUtils.h>
+#include <media/stagefright/foundation/ABuffer.h>
+#include <media/stagefright/foundation/ByteUtils.h>
+#include <media/stagefright/foundation/ColorUtils.h>
+#include <media/stagefright/foundation/hexdump.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <media/stagefright/foundation/avc_utils.h>
+#include <media/stagefright/MediaErrors.h>
+#include <media/stagefright/MetaDataUtils.h>
+#include <media/stagefright/MediaBufferGroup.h>
+#include <media/stagefright/MediaDefs.h>
+#include <media/stagefright/MetaDataBase.h>
+
+
+#include <utils/String8.h>
+#include <utils/RefBase.h>
+#include <dlfcn.h>
+#include <OMX_Video.h>
+#include <OMX_Audio.h>
+#include <OMX_Implement.h>
+#include <cutils/properties.h>
+#include <inttypes.h>
+#include <ImxInspector.h>
+
+namespace android {
+#define MAX_USER_DATA_STRING_LENGTH 1024
+#define MAX_FRAME_BUFFER_LENGTH 10000000
+#define MAX_FRAME_BUFFER_LENGTH_4K 50000000
+#define MAX_VIDEO_BUFFER_SIZE (512*1024)
+#define MAX_AUDIO_BUFFER_SIZE (16*1024)
+#define MAX_TEXT_BUFFER_SIZE (1024)
+#define MAX_TRACK_COUNT 32
+#define SEEK_CHECK_TOLERANCE (2*1000000)// 2 seconds
+
+struct ImxMediaSource : public MediaTrackHelper {
+    explicit ImxMediaSource(
+            ImxExtractor *extractor, size_t index, AMediaFormat * metadata);
+
+    virtual media_status_t start();
+    virtual media_status_t stop();
+
+    virtual media_status_t getFormat(AMediaFormat *format);
+
+    virtual media_status_t read(
+            MediaBufferHelper **buffer, const ReadOptions *options);
+
+    bool started();
+    void addMediaBuffer(MediaBufferHelper *buffer);
+    bool full();
+protected:
+    virtual ~ImxMediaSource();
+private:
+    ImxExtractor *mExtractor;
+    size_t mSourceIndex;
+    Mutex mLock;
+
+    AMediaFormat *mFormat;
+    List<MediaBufferHelper *> mPendingFrames;
+
+    bool mStarted;
+    bool mIsAVC;
+    bool mIsHEVC;
+    bool mIsVorbis;
+    size_t mNALLengthSize;
+    size_t mBufferSize;
+    uint32 mFrameSent;
+
+    void clearPendingFrames();
+    ImxMediaSource(const ImxMediaSource &);
+    ImxMediaSource &operator=(const ImxMediaSource &);
+};
+
+ImxMediaSource::ImxMediaSource(ImxExtractor *extractor, size_t index, AMediaFormat * metadata)
+    : mExtractor(extractor),
+      mSourceIndex(index),
+      mFormat(metadata)
+{
+    mStarted = false;
+    const char *mime;
+    const char *containerMime = NULL;
+    CHECK(AMediaFormat_getString(mFormat, AMEDIAFORMAT_KEY_MIME, &mime));
+
+    mIsAVC = !strcasecmp(mime, MEDIA_MIMETYPE_VIDEO_AVC);
+    mIsHEVC = !strcasecmp(mime, MEDIA_MIMETYPE_VIDEO_HEVC);
+
+    AMediaFormat *extractor_meta = AMediaFormat_new();
+    if(AMEDIA_OK == mExtractor->getMetaData(extractor_meta)){
+        AMediaFormat_getString(extractor_meta, AMEDIAFORMAT_KEY_MIME, &containerMime);
+    }
+    AMediaFormat_delete(extractor_meta);
+
+    mIsVorbis = containerMime != NULL && !strcasecmp(containerMime, MEDIA_MIMETYPE_CONTAINER_MATROSKA) && !strcasecmp(mime, MEDIA_MIMETYPE_AUDIO_VORBIS);
+
+    mNALLengthSize = 0;
+    mBufferSize = 0;
+    mFrameSent = 0;
+
+    if (mIsAVC) {
+
+        void *data;
+        size_t size;
+        if(!AMediaFormat_getBuffer(mFormat, AMEDIAFORMAT_KEY_CSD_AVC, &data, &size))
+            return;
+
+        const uint8_t *ptr = (const uint8_t *)data;
+
+        CHECK(size >= 7);
+         CHECK_EQ((unsigned)ptr[0], 1u);  // configurationVersion == 1
+
+        // The number of bytes used to encode the length of a NAL unit.
+        mNALLengthSize = 1 + (ptr[4] & 3);
+        ALOGD("ImxMediaSource::ImxMediaSource avc mNALLengthSize=%zu",mNALLengthSize);
+    } else if (mIsHEVC) {
+
+        void *data;
+        size_t size;
+        if(!AMediaFormat_getBuffer(mFormat, AMEDIAFORMAT_KEY_CSD_HEVC, &data,&size))
+            return;
+
+        const uint8_t *ptr = (const uint8_t *)data;
+
+        CHECK(size >= 7);
+        CHECK_EQ((unsigned)ptr[0], 1u);  // configurationVersion == 1
+
+        mNALLengthSize = 1 + (ptr[21] & 3);
+        ALOGD("ImxMediaSource::ImxMediaSource hevc mNALLengthSize=%zu",mNALLengthSize);
+    }
+}
+ImxMediaSource::~ImxMediaSource()
+{
+    ALOGV("ImxMediaSource::~ImxMediaSource BEGIN mSourceIndex=%zu",mSourceIndex);
+    clearPendingFrames();
+    mExtractor->DisableTrack(mSourceIndex);
+    mExtractor->DetachMediaBufferGroupHelper(mSourceIndex);
+    mExtractor->ClearTrackSource(mSourceIndex);
+    ALOGV("ImxMediaSource::~ImxMediaSource END mSourceIndex=%zu",mSourceIndex);
+
+}
+media_status_t ImxMediaSource::start()
+{
+    media_status_t ret = AMEDIA_OK;
+    size_t max_buf_size = 0;
+    mStarted = true;
+    ret = mExtractor->GetTrackMaxBufferSize(mSourceIndex, &max_buf_size);
+    if(ret != AMEDIA_OK)
+        return ret;
+
+    mBufferGroup->init(1 /* number of buffers */, max_buf_size /* buffer size */, 65536/* growth limit */);
+    mExtractor->AttachMediaBufferGroupHelper(mSourceIndex, mBufferGroup);
+    mExtractor->ActiveTrack(mSourceIndex);
+
+    ALOGD("source start track %zu",mSourceIndex);
+
+    return AMEDIA_OK;
+}
+void ImxMediaSource::clearPendingFrames() {
+    ALOGV("clearPendingFrames mBufferSize=%zu.mPendingFrames=%zu",mBufferSize,mPendingFrames.size());
+    while (!mPendingFrames.empty()) {
+        MediaBufferHelper *frame = *mPendingFrames.begin();
+        mPendingFrames.erase(mPendingFrames.begin());
+
+        frame->release();
+        frame = NULL;
+    }
+    mBufferSize = 0;
+
+}
+
+media_status_t ImxMediaSource::stop()
+{
+    clearPendingFrames();
+    mStarted = false;
+    mExtractor->DisableTrack(mSourceIndex);
+    mExtractor->DetachMediaBufferGroupHelper(mSourceIndex);
+    ALOGD("source stop track %zu",mSourceIndex);
+    return AMEDIA_OK;
+}
+media_status_t ImxMediaSource::getFormat(AMediaFormat *format)
+{
+    ALOGV("ImxMediaSource::getFormat");
+    return AMediaFormat_copy(format, mFormat);
+}
+static unsigned U24_AT(const uint8_t *ptr) {
+    return ptr[0] << 16 | ptr[1] << 8 | ptr[2];
+}
+media_status_t ImxMediaSource::read(
+        MediaBufferHelper **out, const ReadOptions *options)
+{
+    status_t ret = OK;
+    *out = NULL;
+    uint32_t seekFlag = 0;
+    //int64_t targetSampleTimeUs = -1ll;
+    size_t srcSize = 0;
+    size_t srcOffset = 0;
+    int32_t i = 0;
+    int64_t seekTimeUs;
+    ReadOptions::SeekMode mode;
+
+    int64_t targetSampleTimeUs = -1;
+    const char *containerMime = NULL;
+    const char *mime = NULL;
+
+    if (options && options->getSeekTo(&seekTimeUs, &mode)) {
+        switch (mode) {
+            case ReadOptions::SEEK_PREVIOUS_SYNC:
+                seekFlag = SEEK_FLAG_NO_LATER;
+                break;
+            case ReadOptions::SEEK_NEXT_SYNC:
+                seekFlag = SEEK_FLAG_NO_EARLIER;
+                break;
+            case ReadOptions::SEEK_CLOSEST_SYNC:
+            case ReadOptions::SEEK_CLOSEST:
+                seekFlag = SEEK_FLAG_NEAREST;
+                break;
+            case ReadOptions::SEEK_FRAME_INDEX:
+                seekFlag = SEEK_FLAG_FRAME_INDEX;
+                break;
+            default:
+                seekFlag = SEEK_FLAG_NEAREST;
+                break;
+        }
+
+        if (mode == ReadOptions::SEEK_CLOSEST) {
+            targetSampleTimeUs = seekTimeUs;
+        }
+
+        ALOGV("ImxMediaSource::read seekTimeUs %" PRId64 ", mode %d, seekFlag %d", seekTimeUs, mode, seekFlag);
+
+        clearPendingFrames();
+
+        AMediaFormat* meta = AMediaFormat_new();
+        status_t result = mExtractor->getMetaData(meta);
+        if(result == OK){
+
+            AMediaFormat_getString(meta, AMEDIAFORMAT_KEY_MIME, &containerMime);
+            AMediaFormat_getString(mFormat, AMEDIAFORMAT_KEY_MIME, &mime);
+
+            if((mode == ReadOptions::SEEK_CLOSEST) && containerMime && !strcasecmp(containerMime,MEDIA_MIMETYPE_CONTAINER_MPEG4)){
+                seekFlag = SEEK_FLAG_CLOSEST;
+            }
+
+            if(mFrameSent < 10 && containerMime && !strcasecmp(containerMime, MEDIA_MIMETYPE_CONTAINER_FLV)
+                        && mime && !strcasecmp(mime,MEDIA_MIMETYPE_VIDEO_SORENSON))
+            {
+                ALOGV("read first frame before seeking track, mFrameSent %d", mFrameSent);
+                int64_t time = 0;
+                int32_t j=0;
+                ret = mExtractor->HandleSeekOperation(mSourceIndex,&time,seekFlag);
+                while (mPendingFrames.empty()) {
+                    media_status_t err = mExtractor->GetNextSample(mSourceIndex,false);
+                    if (err != AMEDIA_OK) {
+                        clearPendingFrames();
+                        return err;
+                    }
+                    j++;
+                    if(j > 1 && OK != mExtractor->CheckInterleaveEos(mSourceIndex)){
+                        ALOGE("get interleave eos");
+                        return AMEDIA_ERROR_MALFORMED;
+                    }
+                }
+                MediaBufferHelper *frame = *mPendingFrames.begin();
+                AMediaFormat *bufMeta = frame->meta_data();
+                AMediaFormat_setInt64(bufMeta, AMEDIAFORMAT_KEY_TIME_US, seekTimeUs);
+            }
+
+        }
+        AMediaFormat_delete(meta);
+        ret = mExtractor->HandleSeekOperation(mSourceIndex,&seekTimeUs,seekFlag);
+        if(seekFlag == SEEK_FLAG_CLOSEST || seekFlag == SEEK_FLAG_FRAME_INDEX)
+            targetSampleTimeUs = seekTimeUs;
+    }
+
+    while (mPendingFrames.empty()) {
+        media_status_t err = mExtractor->GetNextSample(mSourceIndex,false);
+
+        if (err != AMEDIA_OK) {
+            clearPendingFrames();
+
+            return err;
+        }
+        i++;
+        if(i > 1 && OK != mExtractor->CheckInterleaveEos(mSourceIndex)){
+            ALOGE("get interleave eos");
+            return AMEDIA_ERROR_END_OF_STREAM;
+        }
+    }
+
+    MediaBufferHelper *frame = *mPendingFrames.begin();
+    mPendingFrames.erase(mPendingFrames.begin());
+
+    *out = frame;
+    mBufferSize -= frame->range_length();
+
+    mFrameSent++;
+
+    if (mIsVorbis) {
+        int64_t timeUs;
+        CHECK(AMediaFormat_getInt64(frame->meta_data(), AMEDIAFORMAT_KEY_TIME_US, &timeUs));
+        ALOGV("ImxMediaSource::read mSourceIndex=%zu size=%zu,time %" PRId64 "",mSourceIndex,frame->range_length(),timeUs);
+
+        int32_t sampleRate;
+        if (!AMediaFormat_getInt32(mFormat, AMEDIAFORMAT_KEY_SAMPLE_RATE,
+                                   &sampleRate)) {
+            return AMEDIA_ERROR_MALFORMED;
+        }
+        int64_t durationUs;
+        if (!AMediaFormat_getInt64(mFormat, AMEDIAFORMAT_KEY_DURATION,
+                                   &durationUs)) {
+            return AMEDIA_ERROR_MALFORMED;
+        }
+        //same logic with MatroskaSource::readBlock()
+        if (timeUs < durationUs) {
+            int32_t validSamples = ((durationUs - timeUs) * sampleRate) / 1000000ll;
+            AMediaFormat_setInt32(frame->meta_data(), AMEDIAFORMAT_KEY_VALID_SAMPLES, validSamples);
+        }
+    }
+
+    if(!mIsAVC && !mIsHEVC){
+        return AMEDIA_OK;
+    }
+
+    if (targetSampleTimeUs >= 0) {
+        AMediaFormat_setInt64(frame->meta_data(),
+                AMEDIAFORMAT_KEY_TARGET_TIME, targetSampleTimeUs);
+    }
+
+    //convert to nal frame
+    uint8_t *srcPtr =
+        (uint8_t *)frame->data() + frame->range_offset();
+    srcSize = frame->range_length();
+
+    if(srcPtr[0] == 0x0 && srcPtr[1] == 0x0 && srcPtr[2] == 0x0 && srcPtr[3] == 0x1){
+        return AMEDIA_OK;
+    }
+
+    if(0 == mNALLengthSize)
+        return AMEDIA_OK;
+
+    //replace the 4 bytes when nal length size is 4
+    if(4 == mNALLengthSize){
+
+        while(srcOffset + mNALLengthSize <= srcSize){
+            size_t NALsize = U32_AT(srcPtr + srcOffset);
+            if((uint64_t)NALsize + (uint64_t) srcOffset >= 0xffffffff){
+                ALOGE("invalid NALsize 0x%zu", NALsize);
+                break;
+            }
+
+            srcPtr[srcOffset++] = 0;
+            srcPtr[srcOffset++] = 0;
+            srcPtr[srcOffset++] = 0;
+            srcPtr[srcOffset++] = 1;
+
+            //memcpy(&srcPtr[srcOffset], "\x00\x00\x00\x01", 4);
+            srcOffset += NALsize;
+        }
+        if(srcOffset < srcSize){
+            frame->release();
+            frame = NULL;
+
+            return AMEDIA_ERROR_MALFORMED;
+        }
+        ALOGV("ImxMediaSource::read 2 size=%zu",srcSize);
+
+        return AMEDIA_OK;
+    }
+
+    //create a new MediaBuffer and copy all data from old buffer to new buffer.
+    size_t dstSize = 0;
+    MediaBufferHelper *buffer = NULL;
+    uint8_t *dstPtr = NULL;
+    //got the buffer size when pass is 0, then copy buffer when pass is 1
+    for (int32_t pass = 0; pass < 2; pass++) {
+        ALOGV("ImxMediaSource::read pass=%d,begin",pass);
+        size_t srcOffset = 0;
+        size_t dstOffset = 0;
+        while (srcOffset + mNALLengthSize <= srcSize) {
+            size_t NALsize;
+            switch (mNALLengthSize) {
+                case 1: NALsize = srcPtr[srcOffset]; break;
+                case 2: NALsize = U16_AT(srcPtr + srcOffset); break;
+                case 3: NALsize = U24_AT(srcPtr + srcOffset); break;
+                case 4: NALsize = U32_AT(srcPtr + srcOffset); break;
+                default:
+                    TRESPASS();
+            }
+
+            if (NALsize == 0) {
+                frame->release();
+                frame = NULL;
+
+                return AMEDIA_ERROR_MALFORMED;
+            } else if (srcOffset + mNALLengthSize + NALsize > srcSize) {
+                break;
+            }
+
+            if (pass == 1) {
+                memcpy(&dstPtr[dstOffset], "\x00\x00\x00\x01", 4);
+
+                memcpy(&dstPtr[dstOffset + 4],
+                       &srcPtr[srcOffset + mNALLengthSize],
+                       NALsize);
+                ALOGV("ImxMediaSource::read 3 copy %zu",4+NALsize);
+            }
+
+            dstOffset += 4;  // 0x00 00 00 01
+            dstOffset += NALsize;
+
+            srcOffset += mNALLengthSize + NALsize;
+        }
+
+        if (srcOffset < srcSize) {
+            // There were trailing bytes or not enough data to complete
+            // a fragment.
+
+            frame->release();
+            frame = NULL;
+
+            return AMEDIA_ERROR_MALFORMED;
+        }
+
+        if (pass == 0) {
+            dstSize = dstOffset;
+
+            mBufferGroup->acquire_buffer(&buffer, false, dstSize);
+            buffer->set_range(0, dstSize);
+
+            AMediaFormat *frameMeta = frame->meta_data();
+
+            int64_t timeUs;
+            CHECK(AMediaFormat_getInt64(frameMeta, AMEDIAFORMAT_KEY_TIME_US, &timeUs));
+
+            int32_t isSync;
+            CHECK(AMediaFormat_getInt32(frameMeta, AMEDIAFORMAT_KEY_IS_SYNC_FRAME, &isSync));
+
+            AMediaFormat *bufMeta = buffer->meta_data();
+            AMediaFormat_setInt64(bufMeta, AMEDIAFORMAT_KEY_TIME_US, timeUs);
+            AMediaFormat_setInt32(bufMeta, AMEDIAFORMAT_KEY_IS_SYNC_FRAME, isSync);
+
+            dstPtr = (uint8_t *)buffer->data();
+            ALOGV("ImxMediaSource::read 3 size=%zu,ts=%" PRId64 "",dstSize,timeUs);
+        }
+    }
+
+    frame->release();
+    frame = NULL;
+    *out = buffer;
+
+    return AMEDIA_OK;
+}
+
+void ImxMediaSource::addMediaBuffer(MediaBufferHelper *buffer)
+{
+    if(buffer == NULL)
+        return;
+
+    mBufferSize += buffer->range_length();
+    mPendingFrames.push_back(buffer);
+
+    return;
+}
+bool ImxMediaSource::started()
+{
+    return mStarted;
+}
+bool ImxMediaSource::full()
+{
+    size_t maxBufferSize;
+    int width = 0;
+    int height = 0;
+
+    if(AMediaFormat_getInt32(mFormat, AMEDIAFORMAT_KEY_WIDTH, &width)
+        && AMediaFormat_getInt32(mFormat, AMEDIAFORMAT_KEY_HEIGHT, &height)
+        && width >= 3840 && height >= 2160){
+        maxBufferSize = MAX_FRAME_BUFFER_LENGTH_4K;
+    }
+    else
+        maxBufferSize = MAX_FRAME_BUFFER_LENGTH;
+
+    if(mBufferSize > maxBufferSize)
+        return true;
+    else
+        return false;
+}
+
+struct ImxDataSourceReader{
+public:
+    ImxDataSourceReader(DataSourceHelper *source);
+
+    bool isStreaming() const;
+    bool isLiveStreaming() const;
+    bool AddBufferReadLimitation(uint32_t index,uint32_t size);
+    bool AttachMediaBufferGroupHelper(uint32_t track_num, MediaBufferGroupHelper * buf_group);
+    bool DetachMediaBufferGroupHelper(uint32_t track_num);
+    bool AcquireBuffer(uint32_t track_num, size_t size, MediaBufferHelper **out_buf);
+    uint32_t GetBufferReadLimitation(uint32_t index);
+    DataSourceHelper *mDataSource;
+    Mutex mLock;
+    int64_t mOffset;
+    bool bStopReading;
+    int64_t mLength;
+private:
+
+    bool mIsLiveStreaming;
+    bool mIsStreaming;
+    uint32_t mMaxBufferSize[MAX_TRACK_COUNT];
+    MediaBufferGroupHelper *mBufferGroup[MAX_TRACK_COUNT];
+
+    ImxDataSourceReader(const ImxDataSourceReader &);
+    ImxDataSourceReader &operator=(const ImxDataSourceReader &);
+};
+static FslFileHandle appFileOpen ( const uint8 * file_path, const uint8 * mode, void * context)
+{
+    if(NULL == mode || !context)
+    {
+        ALOGE("appLocalFileOpen: Invalid parameter
");
+        return NULL;
+    }
+    if(file_path)
+        ALOGV("file_path=%s",file_path);
+
+    ImxDataSourceReader *h = (ImxDataSourceReader *)context;
+    FslFileHandle sourceFileHandle =(FslFileHandle)&h->mDataSource;
+
+    Mutex::Autolock autoLock(h->mLock);
+
+    if(sourceFileHandle != NULL){
+        ALOGV("appFileOpen success,sourceFileHandle=%p",sourceFileHandle);
+        return sourceFileHandle;
+    }else
+        return NULL;
+}
+static uint32  appReadFile( FslFileHandle file_handle, void * buffer, uint32 nb, void * context)
+{
+    ImxDataSourceReader *h = (ImxDataSourceReader *)context;
+    int ret = 0;
+
+    if (!file_handle || !context || !buffer)
+        return 0;
+
+    Mutex::Autolock autoLock(h->mLock);
+    if(h->bStopReading){
+        return 0;
+    }
+
+    //ALOGV("appLocalReadFile nb %u",(unsigned int)nb);
+
+    ret = h->mDataSource->readAt(h->mOffset, buffer, nb);
+
+    //ALOGV("appReadFile at %lld nb %u, result %d", h->mOffset, (unsigned int)nb, ret);
+
+    if(ret > 0)
+    {
+        h->mOffset += ret;
+        return ret;
+    }
+    else
+    {
+        //ALOGV("appLocalReadFile 0");
+        return 0xffffffff;
+    }
+}
+
+
+static int32   appSeekFile( FslFileHandle file_handle, int64 offset, int32 whence, void * context)
+{
+
+    ImxDataSourceReader *h = (ImxDataSourceReader *)context;
+    int nContentPipeResult = 0;
+    if (!file_handle || !context)
+        return -1;
+
+    Mutex::Autolock autoLock(h->mLock);
+    //ALOGV("appSeekFile current location=%lld,offset %lld, whence %d",h->mOffset, offset, whence);
+
+    switch(whence) {
+        case SEEK_CUR:
+        {
+            if(h->mLength > 0 && (h->mOffset + offset > h->mLength || h->mOffset + offset < 0)){
+                nContentPipeResult = -1;
+            }else
+                h->mOffset += offset;
+        }
+        break;
+        case SEEK_SET:
+        {
+            if(h->mLength > 0 && offset > h->mLength)
+                nContentPipeResult = -1;
+            else
+                h->mOffset = offset;
+        }
+        break;
+        case SEEK_END:
+        {
+            if(offset > 0 ||  h->mLength + offset < 0 || h->isLiveStreaming())
+                nContentPipeResult = -1;
+            else
+                h->mOffset = h->mLength + offset;
+        }
+        break;
+        default:
+            nContentPipeResult = -1;
+            break;
+    }
+
+    if( 0 == nContentPipeResult) /* success */
+        return 0;
+
+    ALOGV("appSeekFile fail %d", nContentPipeResult);
+    return -1;
+}
+static int64  appGetCurrentFilePos( FslFileHandle file_handle, void * context)
+{
+    ImxDataSourceReader *h = (ImxDataSourceReader *)context;
+
+    if (!file_handle || !context)
+        return -1;
+
+    return h->mOffset;
+}
+
+static int64   appFileSize( FslFileHandle file_handle, void * context)
+{
+    if (!file_handle || !context)
+        return -1;
+
+    ImxDataSourceReader *h = (ImxDataSourceReader *)context;
+
+    ALOGV("appFileSize %" PRId64 "", h->mLength);
+
+    return h->mLength;
+}
+
+static int32 appFileClose( FslFileHandle file_handle, void * context)
+{
+    if (!file_handle || !context)
+        return -1;
+    ImxDataSourceReader *h = (ImxDataSourceReader *)context;
+
+    Mutex::Autolock autoLock(h->mLock);
+    file_handle = NULL;
+    h->mOffset = 0;
+    ALOGV("appFileClose");
+    return 0;
+}
+
+static int64   appCheckAvailableBytes(FslFileHandle file_handle, int64 bytesRequested, void * context)
+{
+    if (!file_handle || !context)
+        return 0;
+
+    return bytesRequested;
+}
+
+static uint32  appGetFlag( FslFileHandle file_handle, void * context)
+{
+    uint32 flag = 0;
+
+    if (!file_handle || !context)
+        return 0;
+
+    ImxDataSourceReader *h = (ImxDataSourceReader *)context;
+    if(h->isLiveStreaming()){
+        flag |= FILE_FLAG_NON_SEEKABLE;
+        flag |= FILE_FLAG_READ_IN_SEQUENCE;
+    }
+    if(h->isStreaming())
+        flag |= FILE_FLAG_READ_IN_SEQUENCE;
+
+    ALOGV("appLocalGetFlag %x", flag);
+
+    return flag;
+}
+
+static void *appCalloc(uint32 TotalNumber, uint32 TotalSize)
+{
+    void *PtrCalloc = NULL;
+
+    if((0 == TotalSize)||(0==TotalNumber))
+        ALOGW("
Warning: ZERO size IN LOCAL CALLOC");
+
+    PtrCalloc = malloc(TotalNumber*TotalSize);
+
+    if (PtrCalloc == NULL) {
+
+        ALOGE("
Error: MEMORY FAILURE IN LOCAL CALLOC");
+        return NULL;
+    }
+    memset(PtrCalloc, 0, TotalSize*TotalNumber);
+    return (PtrCalloc);
+}
+
+static void* appMalloc (uint32 TotalSize)
+{
+
+    void *PtrMalloc = NULL;
+
+    if(0 == TotalSize)
+        ALOGW("
Warning: ZERO size IN LOCAL MALLOC");
+
+    PtrMalloc = malloc(TotalSize);
+
+    if (PtrMalloc == NULL) {
+
+        ALOGE("
Error: MEMORY FAILURE IN LOCAL MALLOC");
+    }
+    return (PtrMalloc);
+}
+static void appFree (void *MemoryBlock)
+{
+    if(MemoryBlock)
+        free(MemoryBlock);
+}
+
+static void * appReAlloc (void *MemoryBlock, uint32 TotalSize)
+{
+    void *PtrMalloc = NULL;
+
+    if(0 == TotalSize)
+        ALOGW("
Warning: ZERO size IN LOCAL REALLOC");
+
+    PtrMalloc = (void *)realloc(MemoryBlock, TotalSize);
+    if (PtrMalloc == NULL) {
+        ALOGE("
Error: MEMORY FAILURE IN LOCAL REALLOC");
+    }
+
+    return PtrMalloc;
+}
+static uint8* appRequestBuffer(   uint32 streamNum,
+                                uint32 *size,
+                                void ** bufContext,
+                                void * parserContext)
+{
+    ImxDataSourceReader *h;
+    uint8 * dataBuf = NULL;
+    MediaBufferHelper * buffer = NULL;
+    uint32_t limitSize = 0;
+
+    if (!size || !bufContext || !parserContext)
+        return NULL;
+
+    //ALOGV("appRequestBuffer streamNum=%u",streamNum);
+
+    h = (ImxDataSourceReader *)parserContext;
+
+    if((*size) >= 100000000){
+        return NULL;
+    }
+
+    limitSize = h->GetBufferReadLimitation(streamNum);
+    if((*size) > limitSize && limitSize > 0)
+        *size = limitSize;
+
+
+    if(false == h->AcquireBuffer(streamNum, (size_t)(*size), &buffer)){
+        ALOGE("appRequestBuffer streamNum=%u failed",streamNum);
+        return NULL;
+    }
+
+    buffer->set_range(0, (*size));
+    //ALOGV("appRequestBuffer streamNum=%u,len=%d,size=%zu",streamNum,(*size),buffer->size());
+    *bufContext = (void*)buffer;
+    dataBuf = (uint8*)buffer->data();
+
+    return dataBuf;
+}
+
+
+static void appReleaseBuffer(uint32 streamNum, uint8 * pBuffer, void * bufContext, void * parserContext)
+{
+    ImxDataSourceReader *h;
+    MediaBufferHelper * buffer = NULL;
+
+    ALOGV("appReleaseBuffer streamNum=%u",streamNum);
+
+    if (!pBuffer || !bufContext || !parserContext)
+        return;
+    h = (ImxDataSourceReader *)parserContext;
+    buffer = (MediaBufferHelper *)(bufContext);
+    buffer->release();
+    buffer = NULL;
+
+    return;
+}
+
+ImxDataSourceReader::ImxDataSourceReader(DataSourceHelper *source)
+    :mDataSource(source),
+    mOffset(0),
+    mLength(0)
+{
+    off64_t size = 0;
+
+    mIsLiveStreaming = (mDataSource->flags() & 32);
+    mIsStreaming = (mDataSource->flags() & DataSourceBase::kIsCachingDataSource);
+
+    if(!mIsLiveStreaming){
+        status_t ret = mDataSource->getSize(&size);
+        if(ret == OK)
+            mLength = size;
+        else if(ret > 0)
+            mLength = ret;
+    }else{
+        mLength = 0;
+    }
+
+    ALOGV("ImxDataSourceReader: mLength is  %" PRId64 "", mLength);
+
+    bStopReading = false;
+    memset(&mMaxBufferSize[0], 0, MAX_TRACK_COUNT*sizeof(uint32_t));
+    memset(&mBufferGroup[0], 0, MAX_TRACK_COUNT*sizeof(MediaBufferGroupHelper*));
+}
+bool ImxDataSourceReader::isStreaming() const
+{
+    return mIsStreaming;
+}
+bool ImxDataSourceReader::isLiveStreaming() const
+{
+    return mIsLiveStreaming;
+}
+bool ImxDataSourceReader::AddBufferReadLimitation(uint32_t track_num,uint32_t size)
+{
+    if(track_num < MAX_TRACK_COUNT){
+        mMaxBufferSize[track_num] = size;
+        return true;
+    }else
+        return false;
+}
+uint32_t ImxDataSourceReader::GetBufferReadLimitation(uint32_t track_num)
+{
+    if(track_num < MAX_TRACK_COUNT){
+        return mMaxBufferSize[track_num];
+    }else
+        return 0;
+}
+bool ImxDataSourceReader::AttachMediaBufferGroupHelper(uint32_t track_num, MediaBufferGroupHelper * buf_group)
+{
+    if(track_num < MAX_TRACK_COUNT){
+        mBufferGroup[track_num] = buf_group;
+        return true;
+    }else
+        return false;
+}
+bool ImxDataSourceReader::DetachMediaBufferGroupHelper(uint32_t track_num)
+{
+    if(track_num < MAX_TRACK_COUNT && mBufferGroup[track_num] != NULL){
+        mBufferGroup[track_num] = NULL;
+        return true;
+    }else
+        return false;
+}
+bool ImxDataSourceReader::AcquireBuffer(uint32_t track_num, size_t size, MediaBufferHelper **out_buf)
+{
+    MediaBufferHelper * buffer = NULL;
+
+    if(track_num >= MAX_TRACK_COUNT || mBufferGroup[track_num] == NULL){
+        ALOGE("AcquireBuffer failed due to no mBufferGroup[%d],size=%zu",track_num, size);
+        return false;
+    }
+
+    if(OK == mBufferGroup[track_num]->acquire_buffer(&buffer, false, size)){
+        buffer->set_range(0, size);
+        *out_buf = buffer;
+        ALOGV("AcquireBuffer track_num=%d,size=%zu",track_num,size);
+        return true;
+    }
+    ALOGE("AcquireBuffer failed mBufferGroup[%d],size=%zu",track_num, size);
+
+    return false;
+}
+typedef struct{
+    const char* name;
+    const char* mime;
+}fsl_mime_struct;
+
+fsl_mime_struct mime_table[]={
+    {"mp4",MEDIA_MIMETYPE_CONTAINER_MPEG4},
+    {"mkv",MEDIA_MIMETYPE_CONTAINER_MATROSKA},
+    {"avi",MEDIA_MIMETYPE_CONTAINER_AVI},
+    {"asf",MEDIA_MIMETYPE_CONTAINER_ASF},
+    {"flv",MEDIA_MIMETYPE_CONTAINER_FLV},
+    {"mpg2",MEDIA_MIMETYPE_CONTAINER_MPEG2TS},
+    {"mpg2",MEDIA_MIMETYPE_CONTAINER_MPEG2PS},
+    {"rm",MEDIA_MIMETYPE_CONTAINER_RMVB},
+    {"mp3",MEDIA_MIMETYPE_AUDIO_MPEG},
+    {"aac",MEDIA_MIMETYPE_AUDIO_AAC_ADTS},
+    {"ape",MEDIA_MIMETYPE_AUDIO_APE},
+    {"flac",MEDIA_MIMETYPE_AUDIO_FLAC},
+    {"dsf",MEDIA_MIMETYPE_CONTAINER_DSF},
+};
+typedef struct{
+    uint32_t type;
+    uint32_t subtype;
+    const char* mime;
+}codec_mime_struct;
+codec_mime_struct video_mime_table[]={
+    {VIDEO_H263,0,MEDIA_MIMETYPE_VIDEO_H263},
+    {VIDEO_H264,0,MEDIA_MIMETYPE_VIDEO_AVC},
+    {VIDEO_HEVC,0,MEDIA_MIMETYPE_VIDEO_HEVC},
+    {VIDEO_MPEG2,0,MEDIA_MIMETYPE_VIDEO_MPEG2},
+    {VIDEO_MPEG4,0,MEDIA_MIMETYPE_VIDEO_MPEG4},
+    {VIDEO_JPEG,0,MEDIA_MIMETYPE_VIDEO_MJPEG},
+    {VIDEO_MJPG,VIDEO_MJPEG_2000,NULL},
+    {VIDEO_MJPG,VIDEO_MJPEG_FORMAT_B,NULL},
+    {VIDEO_MJPG,0,MEDIA_MIMETYPE_VIDEO_MJPEG},
+    {VIDEO_DIVX,VIDEO_DIVX3,MEDIA_MIMETYPE_VIDEO_DIVX3},
+    {VIDEO_DIVX,VIDEO_DIVX4,MEDIA_MIMETYPE_VIDEO_DIVX4},
+    {VIDEO_DIVX,VIDEO_DIVX5_6,MEDIA_MIMETYPE_VIDEO_DIVX},
+    {VIDEO_DIVX,0,MEDIA_MIMETYPE_VIDEO_DIVX},
+    {VIDEO_XVID,0,MEDIA_MIMETYPE_VIDEO_XVID},
+    {VIDEO_WMV,VIDEO_WMV7,MEDIA_MIMETYPE_VIDEO_WMV},
+    {VIDEO_WMV,VIDEO_WMV8,MEDIA_MIMETYPE_VIDEO_WMV},
+    {VIDEO_WMV,VIDEO_WMV9,MEDIA_MIMETYPE_VIDEO_VC1},
+    {VIDEO_WMV,VIDEO_WMV9A,MEDIA_MIMETYPE_VIDEO_VC1},
+    {VIDEO_WMV,VIDEO_WVC1,MEDIA_MIMETYPE_VIDEO_VC1},
+    {VIDEO_REAL,0,MEDIA_MIMETYPE_VIDEO_REAL},
+    {VIDEO_SORENSON_H263,0,MEDIA_MIMETYPE_VIDEO_SORENSON},
+    {VIDEO_ON2_VP,VIDEO_VP8,MEDIA_MIMETYPE_VIDEO_VP8},
+    {VIDEO_ON2_VP,VIDEO_VP9,MEDIA_MIMETYPE_VIDEO_VP9},
+    {VIDEO_AV1,0,MEDIA_MIMETYPE_VIDEO_AV1},
+};
+codec_mime_struct audio_mime_table[]={
+    {AUDIO_MP3,0,MEDIA_MIMETYPE_AUDIO_MPEG},
+    {AUDIO_VORBIS,0,MEDIA_MIMETYPE_AUDIO_VORBIS},
+    {AUDIO_AAC,AUDIO_ER_BSAC,MEDIA_MIMETYPE_AUDIO_BSAC},
+    {AUDIO_AAC,0,MEDIA_MIMETYPE_AUDIO_AAC_FSL},
+    {AUDIO_MPEG2_AAC,0,MEDIA_MIMETYPE_AUDIO_AAC_FSL},
+    {AUDIO_AC3,0,MEDIA_MIMETYPE_AUDIO_AC3},
+    {AUDIO_EC3,0,MEDIA_MIMETYPE_AUDIO_EAC3},
+    {AUDIO_WMA,0,MEDIA_MIMETYPE_AUDIO_WMA},
+    {AUDIO_AMR,AUDIO_AMR_NB,MEDIA_MIMETYPE_AUDIO_AMR_NB},
+    {AUDIO_AMR,AUDIO_AMR_WB,MEDIA_MIMETYPE_AUDIO_AMR_WB},
+    {AUDIO_PCM,0,MEDIA_MIMETYPE_AUDIO_RAW},
+    {AUDIO_REAL,REAL_AUDIO_RAAC,MEDIA_MIMETYPE_AUDIO_AAC_FSL},
+    {AUDIO_REAL,REAL_AUDIO_SIPR,MEDIA_MIMETYPE_AUDIO_REAL},
+    {AUDIO_REAL,REAL_AUDIO_COOK,MEDIA_MIMETYPE_AUDIO_REAL},
+    {AUDIO_REAL,REAL_AUDIO_ATRC,MEDIA_MIMETYPE_AUDIO_REAL},
+    {AUDIO_PCM_ALAW,0,MEDIA_MIMETYPE_AUDIO_G711_ALAW},
+    {AUDIO_PCM_MULAW,0,MEDIA_MIMETYPE_AUDIO_G711_MLAW},
+    {AUDIO_FLAC,0,MEDIA_MIMETYPE_AUDIO_FLAC},
+    {AUDIO_OPUS,0,MEDIA_MIMETYPE_AUDIO_OPUS},
+    {AUDIO_APE,0,MEDIA_MIMETYPE_AUDIO_APE},
+    {AUDIO_DSD,0,MEDIA_MIMETYPE_AUDIO_DSD},
+    {AUDIO_AC4,0,MEDIA_MIMETYPE_AUDIO_AC4},
+    {AUDIO_ADPCM,AUDIO_IMA_ADPCM,MEDIA_MIMETYPE_AUDIO_DVI_IMA_ADPCM},
+    {AUDIO_ADPCM,AUDIO_ADPCM_MS,MEDIA_MIMETYPE_AUDIO_MS_ADPCM},
+};
+ImxExtractor::ImxExtractor(DataSourceHelper *source,const char *mime)
+    : mDataSource(source),
+    mReader(new ImxDataSourceReader(mDataSource)),
+    mMime(strdup(mime)),
+    bInit(false)
+{
+    memset(&mLibName,0,255);
+    mLibHandle = NULL;
+    IParser = NULL;
+    parserHandle = NULL;
+    mFileMetaData = AMediaFormat_new();
+    AMediaFormat_setString(mFileMetaData, AMEDIAFORMAT_KEY_MIME, mMime);
+
+    currentVideoTs = 0;
+    currentAudioTs = 0;
+    mVideoActived = false;
+    mAudioActived = false;
+    bWaitForAudioStartTime = false;
+    mVideoIndex = 0;
+    mAudioIndex = 0;
+    mReadMode = PARSER_READ_MODE_TRACK_BASED;
+    mNumTracks = 0;
+    bSeekable = false;
+    mMovieDuration = 0;
+
+    memset(&fileOps, 0, sizeof(FslFileStream));
+    memset(&memOps, 0, sizeof(ParserMemoryOps));
+    memset(&outputBufferOps, 0, sizeof(ParserOutputBufferOps));
+
+    ALOGD("ImxExtractor::ImxExtractor mime=%s",mMime);
+}
+ImxExtractor::~ImxExtractor()
+{
+    if(parserHandle)
+    {
+        IParser->deleteParser(parserHandle);
+        parserHandle = NULL;
+    }
+
+    if(IParser){
+        delete IParser;
+        IParser = NULL;
+    }
+
+    if(mReader != NULL){
+        delete mReader;
+        mReader = NULL;
+    }
+
+    if (mLibHandle != NULL) {
+        dlclose(mLibHandle);
+        mLibHandle = NULL;
+    }
+    AMediaFormat_clear(mFileMetaData);
+    AMediaFormat_delete(mFileMetaData);
+    free(mMime);
+
+    ALOGD("ImxExtractor::~ImxExtractor");
+}
+status_t ImxExtractor::Init()
+{
+    status_t ret = OK;
+
+    if(mReader == NULL)
+        return UNKNOWN_ERROR;
+
+    ALOGD("ImxExtractor::Init BEGIN");
+    memset (&fileOps, 0, sizeof(FslFileStream));
+    fileOps.Open = appFileOpen;
+    fileOps.Read= appReadFile;
+    fileOps.Seek = appSeekFile;
+    fileOps.Tell = appGetCurrentFilePos;
+    fileOps.Size= appFileSize;
+    fileOps.Close = appFileClose;
+    fileOps.CheckAvailableBytes = appCheckAvailableBytes;
+    fileOps.GetFlag = appGetFlag;
+
+    memset (&memOps, 0, sizeof(ParserMemoryOps));
+    memOps.Calloc = appCalloc;
+    memOps.Malloc = appMalloc;
+    memOps.Free= appFree;
+    memOps.ReAlloc= appReAlloc;
+
+    outputBufferOps.RequestBuffer = appRequestBuffer;
+    outputBufferOps.ReleaseBuffer = appReleaseBuffer;
+    ret = CreateParserInterface();
+    if(ret != OK){
+        ALOGE("ImxExtractor create parser failed");
+        return ret;
+    }
+
+    ret = ParseFromParser();
+
+    ALOGD("ImxExtractor::Init ret=%d",ret);
+
+    if(ret == OK)
+        bInit = true;
+    return ret;
+}
+size_t ImxExtractor::countTracks()
+{
+    status_t ret = OK;
+    if(!bInit){
+        ret = Init();
+
+        if(ret != OK)
+            return 0;
+    }
+
+    return mTracks.size();
+}
+MediaTrackHelper * ImxExtractor::getTrack(size_t index)
+{
+    ImxMediaSource* source;
+    ALOGD("ImxExtractor::getTrack index=%zu",index);
+
+    if (index >= mTracks.size()) {
+        return NULL;
+    }
+    TrackInfo *trackInfo = &mTracks.editItemAt(index);
+
+    AMediaFormat * meta = trackInfo->mMeta;
+    source = new ImxMediaSource(this,index,meta);
+
+    trackInfo->mSource = source;
+    //ALOGE("getTrack source string cnt=%d",source->getStrongCount());
+
+    return source;
+}
+
+media_status_t ImxExtractor::getTrackMetaData(AMediaFormat *meta,size_t index, uint32_t flags)
+{
+    if(!bInit){
+        status_t ret = OK;
+        ret = Init();
+
+        if(ret != OK)
+            return AMEDIA_ERROR_UNKNOWN;
+    }
+    if(flags){
+        ;//
+    }
+
+    ALOGV("getTrackMetaData index=%zu",index);
+    return AMediaFormat_copy(meta, mTracks.itemAt(index).mMeta);
+    //return OK;
+}
+
+media_status_t ImxExtractor::getMetaData(AMediaFormat *meta)
+{
+    if(!bInit){
+        status_t ret = OK;
+        ret = Init();
+
+        if(ret != OK)
+            return AMEDIA_ERROR_UNKNOWN;
+    }
+
+    if(meta == nullptr){
+        ALOGE("meta == NULL");
+        return AMEDIA_ERROR_UNKNOWN;
+    }
+    AMediaFormat_clear(meta);
+    return AMediaFormat_copy(meta, mFileMetaData);
+
+    //return AMEDIA_OK;
+}
+uint32_t ImxExtractor::flags() const
+{
+    uint32_t x = CAN_PAUSE;
+    if (!mReader->isLiveStreaming() && bSeekable) {
+        x |= CAN_SEEK_BACKWARD | CAN_SEEK_FORWARD | CAN_SEEK;
+    }
+
+    return x;
+}
+status_t ImxExtractor::GetLibraryName()
+{
+    const char * name = NULL;
+    for (size_t i = 0; i < sizeof(mime_table) / sizeof(mime_table[0]); i++) {
+        if (!strcmp((const char *)mMime, mime_table[i].mime)) {
+            name = mime_table[i].name;
+            break;
+        }
+    }
+    if(name == NULL || strlen(name) > 128)
+        return NAME_NOT_FOUND;
+
+
+    strcpy(mLibName, "/system/lib64/extractors/lib_");
+    strcat(mLibName,name);
+    strcat(mLibName,"_parser_arm11_elinux.3.0.so");
+
+    ALOGD("GetLibraryName %s",mLibName);
+    return OK;
+}
+status_t ImxExtractor::CreateParserInterface()
+{
+    status_t ret = OK;
+    int32 err = PARSER_SUCCESS;
+    tFslParserQueryInterface  myQueryInterface;
+
+    ret = GetLibraryName();
+    if(ret != OK)
+        return ret;
+
+    do{
+        mLibHandle = dlopen(mLibName, RTLD_NOW);
+        if (mLibHandle == NULL){
+            ALOGD("dlopen fail");
+            ret = UNKNOWN_ERROR;
+            break;
+        }
+        ALOGD("load parser name %s",mLibName);
+        myQueryInterface = (tFslParserQueryInterface)dlsym(mLibHandle, "FslParserQueryInterface");
+        if(myQueryInterface == NULL){
+            ret = UNKNOWN_ERROR;
+            break;
+        }
+
+        IParser = new FslParserInterface;
+        if(IParser == NULL){
+            ret = UNKNOWN_ERROR;
+            break;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_VERSION_INFO, (void **)&IParser->getVersionInfo);
+        if(err)
+            break;
+
+        if(!IParser->getVersionInfo){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        // create & delete
+        err = myQueryInterface(PARSER_API_CREATE_PARSER, (void **)&IParser->createParser);
+        if(err)
+            break;
+
+        if(!IParser->createParser){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        err = myQueryInterface(PARSER_API_CREATE_PARSER2, (void **)&IParser->createParser2);
+        if(err)
+            ALOGW("IParser->createParser2 not found");
+
+        err = myQueryInterface(PARSER_API_DELETE_PARSER, (void **)&IParser->deleteParser);
+        if(err)
+            break;
+
+        if(!IParser->deleteParser){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+        //index init
+        err = myQueryInterface(PARSER_API_INITIALIZE_INDEX, (void **)&IParser->initializeIndex);
+        if(err)
+            break;
+
+        //movie properties
+        err = myQueryInterface(PARSER_API_IS_MOVIE_SEEKABLE, (void **)&IParser->isSeekable);
+        if(err)
+            break;
+
+        if(!IParser->isSeekable){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_MOVIE_DURATION, (void **)&IParser->getMovieDuration);
+        if(err)
+            break;
+
+        if(!IParser->getMovieDuration){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+        err = myQueryInterface(PARSER_API_GET_USER_DATA, (void **)&IParser->getUserData);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_META_DATA, (void **)&IParser->getMetaData);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_NUM_TRACKS, (void **)&IParser->getNumTracks);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_NUM_PROGRAMS, (void **)&IParser->getNumPrograms);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_PROGRAM_TRACKS, (void **)&IParser->getProgramTracks);
+        if(err)
+            break;
+
+        if((!IParser->getNumTracks && !IParser->getNumPrograms)
+            ||(IParser->getNumPrograms && !IParser->getProgramTracks))
+        {
+            ALOGE("Invalid API to get tracks or programs.");
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        //track properties
+        err = myQueryInterface(PARSER_API_GET_TRACK_TYPE, (void **)&IParser->getTrackType);
+        if(err)
+            break;
+
+        if(!IParser->getTrackType){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_TRACK_DURATION, (void **)&IParser->getTrackDuration);
+        if(err)
+            break;
+        if(!IParser->getTrackDuration){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_LANGUAGE, (void **)&IParser->getLanguage);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_BITRATE, (void **)&IParser->getBitRate);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_DECODER_SPECIFIC_INFO, (void **)&IParser->getDecoderSpecificInfo);
+        if(err)
+            break;
+
+        //ignore the result because it is new api and some parser did implement it.
+        err = myQueryInterface(PARSER_API_GET_TRACK_EXT_TAG, (void **)&IParser->getTrackExtTag);
+        if(err)
+            err = PARSER_SUCCESS;
+
+        //video properties
+        err = myQueryInterface(PARSER_API_GET_VIDEO_FRAME_WIDTH, (void **)&IParser->getVideoFrameWidth);
+        if(err)
+            break;
+        err = myQueryInterface(PARSER_API_GET_VIDEO_FRAME_HEIGHT, (void **)&IParser->getVideoFrameHeight);
+        if(err)
+            break;
+        err = myQueryInterface(PARSER_API_GET_VIDEO_FRAME_RATE, (void **)&IParser->getVideoFrameRate);
+        if(err)
+            break;
+        err = myQueryInterface(PARSER_API_GET_VIDEO_FRAME_ROTATION, (void **)&IParser->getVideoFrameRotation);
+        if(err){
+            IParser->getVideoFrameRotation = NULL;
+            err = PARSER_SUCCESS;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_VIDEO_COLOR_INFO, (void **)&IParser->getVideoColorInfo);
+        if(err){
+            IParser->getVideoColorInfo = NULL;
+            err = PARSER_SUCCESS;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_VIDEO_HDR_COLOR_INFO, (void **)&IParser->getVideoHDRColorInfo);
+        if(err){
+            IParser->getVideoHDRColorInfo = NULL;
+            err = PARSER_SUCCESS;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_VIDEO_DISPLAY_WIDTH, (void **)&IParser->getVideoDisplayWidth);
+        if(err){
+            IParser->getVideoDisplayWidth = NULL;
+            err = PARSER_SUCCESS;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_VIDEO_DISPLAY_HEIGHT, (void **)&IParser->getVideoDisplayHeight);
+        if(err){
+            IParser->getVideoDisplayHeight = NULL;
+            err = PARSER_SUCCESS;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_VIDEO_FRAME_COUNT, (void **)&IParser->getVideoFrameCount);
+        if(err){
+            IParser->getVideoFrameCount = NULL;
+            err = PARSER_SUCCESS;
+        }
+
+        //audio properties
+        err = myQueryInterface(PARSER_API_GET_AUDIO_NUM_CHANNELS, (void **)&IParser->getAudioNumChannels);
+        if(err)
+            break;
+        if(!IParser->getAudioNumChannels){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+        err = myQueryInterface(PARSER_API_GET_AUDIO_SAMPLE_RATE, (void **)&IParser->getAudioSampleRate);
+        if(err)
+            break;
+        if(!IParser->getAudioSampleRate){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_AUDIO_BITS_PER_SAMPLE, (void **)&IParser->getAudioBitsPerSample);
+        if(err)
+            break;
+        err = myQueryInterface(PARSER_API_GET_AUDIO_BLOCK_ALIGN, (void **)&IParser->getAudioBlockAlign);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_AUDIO_CHANNEL_MASK, (void **)&IParser->getAudioChannelMask);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_AUDIO_BITS_PER_FRAME, (void **)&IParser->getAudioBitsPerFrame);
+        if(err)
+            break;
+
+        //subtitle properties
+        err = myQueryInterface(PARSER_API_GET_TEXT_TRACK_WIDTH, (void **)&IParser->getTextTrackWidth);
+        if(err)
+            break;
+        err = myQueryInterface(PARSER_API_GET_TEXT_TRACK_HEIGHT, (void **)&IParser->getTextTrackHeight);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_TEXT_TRACK_MIME, (void **)&IParser->getTextTrackMime);
+        if(err)
+            break;
+
+        //track reading function
+        err = myQueryInterface(PARSER_API_GET_READ_MODE, (void **)&IParser->getReadMode);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_SET_READ_MODE, (void **)&IParser->setReadMode);
+        if(err)
+            break;
+
+        if(!IParser->getReadMode || !IParser->setReadMode){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        err = myQueryInterface(PARSER_API_ENABLE_TRACK, (void **)&IParser->enableTrack);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_NEXT_SAMPLE, (void **)&IParser->getNextSample);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_NEXT_SYNC_SAMPLE, (void **)&IParser->getNextSyncSample);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_FILE_NEXT_SAMPLE, (void **)&IParser->getFileNextSample);
+        if(err)
+            break;
+
+        err = myQueryInterface(PARSER_API_GET_FILE_NEXT_SYNC_SAMPLE, (void **)&IParser->getFileNextSyncSample);
+        if(err)
+            break;
+
+        if(!IParser->getNextSample && !IParser->getFileNextSample){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        if(IParser->getFileNextSample && !IParser->enableTrack){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        err = myQueryInterface(PARSER_API_SEEK, (void **)&IParser->seek);
+        if(err)
+            break;
+        if(!IParser->seek){
+            err = PARSER_ERR_INVALID_API;
+            break;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_SAMPLE_CRYPTO_INFO, (void **)&IParser->getSampleCryptoInfo);
+
+        if(!IParser->getSampleCryptoInfo){
+            err = PARSER_SUCCESS;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_AUDIO_PRESENTATION_NUM, (void **)&IParser->getAudioPresentationNum);
+        if(!IParser->getAudioPresentationNum) {
+            err = PARSER_SUCCESS;
+        }
+
+        err = myQueryInterface(PARSER_API_GET_AUDIO_PRESENTATION_INFO, (void **)&IParser->getAudioPresentationInfo);
+        if(!IParser->getAudioPresentationInfo) {
+            err = PARSER_SUCCESS;
+        }
+
+    }while(0);
+
+
+    if(err){
+        ALOGW("ImxExtractor::CreateParserInterface parser err=%d",err);
+        ret = UNKNOWN_ERROR;
+    }
+
+    if(ret == OK){
+        ALOGD("ImxExtractor::CreateParserInterface success");
+    }else{
+        if(mLibHandle)
+            dlclose(mLibHandle);
+        mLibHandle = NULL;
+
+        if(IParser != NULL)
+            delete IParser;
+        IParser = NULL;
+        ALOGW("ImxExtractor::CreateParserInterface failed,ret=%d",ret);
+    }
+
+    return ret;
+}
+status_t ImxExtractor::ParseFromParser()
+{
+    int32 err = (int32)PARSER_SUCCESS;
+    uint32 flag = FLAG_H264_NO_CONVERT | FLAG_OUTPUT_PTS | FLAG_ID3_FORMAT_NON_UTF8 | FLAG_OUTPUT_H264_SEI_POS_DATA;
+
+    uint32 trackCnt = 0;
+    bool bLive = mReader->isLiveStreaming();
+    ALOGI("Core parser %s 
", IParser->getVersionInfo());
+
+    if(IParser->createParser2){
+        if(mReader->isStreaming())
+            flag |= FILE_FLAG_READ_IN_SEQUENCE;
+
+        if(bLive){
+            flag |= FILE_FLAG_NON_SEEKABLE;
+            flag |= FILE_FLAG_READ_IN_SEQUENCE;
+        }
+
+        err = IParser->createParser2(flag,
+                &fileOps,
+                &memOps,
+                &outputBufferOps,
+                (void *)mReader,
+                &parserHandle);
+        ALOGD("createParser2 flag=%x,err=%d
",flag,err);
+    }else{
+        err = IParser->createParser(bLive,
+                &fileOps,
+                &memOps,
+                &outputBufferOps,
+                (void *)mReader,
+                &parserHandle);
+        ALOGD("createParser flag=%x,err=%d
",flag,err);
+    }
+
+    if(PARSER_SUCCESS !=  err)
+    {
+        ALOGE("fail to create the parser: %d
", err);
+        return UNKNOWN_ERROR;
+    }
+    if(mReader->isStreaming() || !strcasecmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG2TS)
+        || !strcasecmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG2PS))
+        mReadMode = PARSER_READ_MODE_FILE_BASED;
+    else
+        mReadMode = PARSER_READ_MODE_TRACK_BASED;
+
+    err = IParser->setReadMode(parserHandle, mReadMode);
+    if(PARSER_SUCCESS != err)
+    {
+        ALOGW("fail to set read mode to %d
", mReadMode);
+        if(mReadMode == PARSER_READ_MODE_TRACK_BASED)
+            mReadMode = PARSER_READ_MODE_FILE_BASED;
+        else
+            mReadMode = PARSER_READ_MODE_TRACK_BASED;
+        err = IParser->setReadMode(parserHandle, mReadMode);
+        if(PARSER_SUCCESS != err)
+        {
+            ALOGE("fail to set read mode to %d
", mReadMode);
+            return UNKNOWN_ERROR;
+        }
+    }
+
+    if ((NULL == IParser->getNextSample && PARSER_READ_MODE_TRACK_BASED == mReadMode)
+            || (NULL == IParser->getFileNextSample && PARSER_READ_MODE_FILE_BASED == mReadMode)){
+        ALOGE("get next sample did not exist");
+        return UNKNOWN_ERROR;
+    }
+
+    err = IParser->getNumTracks(parserHandle, &trackCnt);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    mNumTracks = trackCnt;
+    if(IParser->initializeIndex){
+        err = IParser->initializeIndex(parserHandle);
+        ALOGV("initializeIndex err=%d
",err);
+    }
+
+    ALOGI("mReadMode=%d,mNumTracks=%u",mReadMode,mNumTracks);
+    err = IParser->isSeekable(parserHandle,&bSeekable);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    ALOGI("bSeekable %d", bSeekable);
+
+    err = IParser->getMovieDuration(parserHandle, (uint64 *)&mMovieDuration);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    err = ParseMetaData();
+    if(err)
+        return UNKNOWN_ERROR;
+
+    err = ParseMediaFormat();
+    if(err)
+        return UNKNOWN_ERROR;
+    return OK;
+}
+status_t ImxExtractor::ParseMetaData()
+{
+    struct KeyMap {
+        const char* tag;
+        UserDataID key;
+    };
+    const KeyMap kKeyMap[] = {
+        { AMEDIAFORMAT_KEY_TITLE, USER_DATA_TITLE },
+        { AMEDIAFORMAT_KEY_GENRE, USER_DATA_GENRE },
+        { AMEDIAFORMAT_KEY_ARTIST, USER_DATA_ARTIST },
+        { AMEDIAFORMAT_KEY_YEAR, USER_DATA_YEAR },
+        { AMEDIAFORMAT_KEY_ALBUM, USER_DATA_ALBUM },
+        { AMEDIAFORMAT_KEY_COMPOSER, USER_DATA_COMPOSER },
+        { AMEDIAFORMAT_KEY_LYRICIST, USER_DATA_MOVIEWRITER },
+        { AMEDIAFORMAT_KEY_CDTRACKNUMBER, USER_DATA_TRACKNUMBER },
+        { AMEDIAFORMAT_KEY_LOCATION, USER_DATA_LOCATION},
+        //{ (char *)"totaltracknumber", USER_DATA_TOTALTRACKNUMBER},
+        { AMEDIAFORMAT_KEY_DISCNUMBER, USER_DATA_DISCNUMBER},
+        { AMEDIAFORMAT_KEY_YEAR, USER_DATA_CREATION_DATE},//map data to year for id3 parser & mp4 parser.
+        { AMEDIAFORMAT_KEY_COMPILATION, USER_DATA_COMPILATION},
+        { AMEDIAFORMAT_KEY_ALBUMARTIST, USER_DATA_ALBUMARTIST},
+        { AMEDIAFORMAT_KEY_AUTHOR, USER_DATA_AUTHOR},
+        { AMEDIAFORMAT_KEY_ENCODER_DELAY,USER_DATA_AUD_ENC_DELAY},
+        { AMEDIAFORMAT_KEY_ENCODER_PADDING,USER_DATA_AUD_ENC_PADDING},
+        { AMEDIAFORMAT_KEY_DATE, USER_DATA_MP4_CREATION_TIME},//only get from mp4 parser.
+    };
+    uint32_t kNumMapEntries = sizeof(kKeyMap) / sizeof(kKeyMap[0]);
+
+    if (IParser->getMetaData){
+
+        uint8 *metaData = NULL;
+        uint32 metaDataSize = 0;
+        UserDataFormat userDataFormat;
+
+        for (uint32_t i = 0; i < kNumMapEntries; ++i) {
+            userDataFormat = USER_DATA_FORMAT_UTF8;
+            IParser->getMetaData(parserHandle, kKeyMap[i].key, &userDataFormat, &metaData, \
+                &metaDataSize);
+
+            if((metaData != NULL) && ((int32_t)metaDataSize > 0) && USER_DATA_FORMAT_UTF8 == userDataFormat)
+            {
+                if(metaDataSize > MAX_USER_DATA_STRING_LENGTH)
+                    metaDataSize = MAX_USER_DATA_STRING_LENGTH;
+
+                AMediaFormat_setString(mFileMetaData, kKeyMap[i].tag, (const char*)metaData);
+
+                ALOGI("FslParser Key: %d	 format=%d,size=%d,Value: %s
",
+                    kKeyMap[i].key,userDataFormat,(int)metaDataSize,metaData);
+            }else if((metaData != NULL) && ((int32)metaDataSize > 0) && USER_DATA_FORMAT_INT_LE == userDataFormat){
+                if(metaDataSize == 4)
+                    AMediaFormat_setInt32(mFileMetaData, kKeyMap[i].tag, *(int32*)metaData);
+                ALOGI("FslParser Key2: %d	 format=%d,size=%d,Value: %d
",
+                    kKeyMap[i].key,userDataFormat,(int)metaDataSize,*(int32*)metaData);
+            }else if((metaData != NULL) && ((int32)metaDataSize > 0) && USER_DATA_FORMAT_UINT_LE == userDataFormat){
+                if(USER_DATA_MP4_CREATION_TIME == kKeyMap[i].key && metaDataSize == 8){
+                    uint64 data = *(uint64*)metaData;
+                    String8 str;
+                    if(ConvertMp4TimeToString(data,&str)){
+                        AMediaFormat_setString(mFileMetaData, kKeyMap[i].tag, (const char*)str.string());
+                        ALOGI("FslParser kKeyDate=%s",str.string());
+                    }
+
+                }
+            }
+        }
+
+        //capture fps
+        userDataFormat = USER_DATA_FORMAT_FLOAT32_BE;
+        IParser->getMetaData(parserHandle, USER_DATA_CAPTURE_FPS, &userDataFormat, &metaData, \
+        &metaDataSize);
+        if(4 == metaDataSize && metaData){
+            char tmp[20] = {0};
+            uint32 len = 0;
+            uint32 value= 0;
+            float data = 0.0;
+            value += *metaData << 24;
+            value += *(metaData+1) << 16;
+            value += *(metaData+2) << 8;
+            value += *(metaData+3);
+            data = *(float *)&value;
+            len = sprintf((char*)&tmp, "%f", data);
+            ALOGI("get fps=%s,len=%u",tmp,len);
+            AMediaFormat_setFloat(mFileMetaData, AMEDIAFORMAT_KEY_CAPTURE_RATE, data);
+        }
+
+        userDataFormat = USER_DATA_FORMAT_JPEG;
+        IParser->getMetaData(parserHandle, USER_DATA_ARTWORK, &userDataFormat, &metaData, \
+            &metaDataSize);
+        if(metaData && metaDataSize)
+        {
+            AMediaFormat_setBuffer(mFileMetaData, AMEDIAFORMAT_KEY_ALBUMART, metaData, metaDataSize);
+        }
+
+        metaData = NULL;
+        metaDataSize = 0;
+        //pssh
+        userDataFormat = USER_DATA_FORMAT_UTF8;
+        IParser->getMetaData(parserHandle, USER_DATA_PSSH, &userDataFormat, &metaData, \
+            &metaDataSize);
+        if(metaData && metaDataSize)
+        {
+            AMediaFormat_setBuffer(mFileMetaData, AMEDIAFORMAT_KEY_PSSH, metaData, metaDataSize);
+        }
+    }
+    return OK;
+}
+status_t ImxExtractor::ParseMediaFormat()
+{
+    uint32 trackCountToCheck = mNumTracks;
+    uint32 programCount = 0;
+    uint32 trackCountInOneProgram = 0;
+    uint32_t index=0;
+    uint32_t i = 0;
+    uint32_t defaultProgram = 0;
+    uint32 * pProgramTrackTable = NULL;
+    int32 err = (int32)PARSER_SUCCESS;
+    status_t ret = OK;
+    MediaType trackType;
+    uint32 decoderType;
+    uint32 decoderSubtype;
+    uint64 sSeekPosTmp = 0;
+    ALOGD("ImxExtractor::ParseMediaFormat BEGIN");
+    if(IParser->getNumPrograms && IParser->getProgramTracks){
+        err = IParser->getNumPrograms(parserHandle, &programCount);
+        if(PARSER_SUCCESS !=  err || programCount == 0)
+            return UNKNOWN_ERROR;
+
+        err = IParser->getProgramTracks(parserHandle, defaultProgram, &trackCountInOneProgram, &pProgramTrackTable);
+        if(PARSER_SUCCESS !=  err || trackCountInOneProgram == 0 || pProgramTrackTable == 0)
+            return UNKNOWN_ERROR;
+
+        trackCountToCheck = trackCountInOneProgram;
+    }
+
+    for(index = 0; index < trackCountToCheck; index ++){
+        if(pProgramTrackTable)
+            i = pProgramTrackTable[index];
+        else
+            i = index;
+
+        err = IParser->getTrackType( parserHandle,i,(uint32 *)&trackType,&decoderType,&decoderSubtype);
+        if(err)
+            continue;
+
+        if(trackType == MEDIA_VIDEO)
+            ret = ParseVideo(i,decoderType,decoderSubtype);
+        else if(trackType == MEDIA_AUDIO)
+            ret = ParseAudio(i,decoderType,decoderSubtype);
+        else if(trackType == MEDIA_TEXT)
+            ret = ParseText(i,decoderType,decoderSubtype);
+        else
+            ret = UNKNOWN_ERROR;
+
+        if(ret)
+            continue;
+
+        err = IParser->seek(parserHandle, i, &sSeekPosTmp, SEEK_FLAG_NO_LATER);
+        if(err)
+            return UNKNOWN_ERROR;
+    }
+
+    return OK;
+}
+
+status_t ImxExtractor::ParseVideo(uint32 index, uint32 type,uint32 subtype)
+{
+    int32 err = (int32)PARSER_SUCCESS;
+    uint32_t i = 0;
+    const char* mime = NULL;
+    uint64_t duration = 0;
+    uint8 * decoderSpecificInfo = NULL;
+    uint32 decoderSpecificInfoSize = 0;
+    uint32 width = 0;
+    uint32 height = 0;
+    uint32 display_width = 0;
+    uint32 display_height = 0;
+    uint32 frame_count = 0;
+
+    uint32 rotation = 0;
+    uint32 rate = 0;
+    uint32 scale = 0;
+    uint32 fps = 0;
+    uint32 bitrate = 0;
+    size_t sourceIndex = 0;
+    size_t max_size = 0;
+    int64_t thumbnail_ts = -1;
+
+    ALOGD("ParseVideo index=%u,type=%u,subtype=%u",index,type,subtype);
+    for(i = 0; i < sizeof(video_mime_table)/sizeof(codec_mime_struct); i++){
+        if (type == video_mime_table[i].type){
+            if((video_mime_table[i].subtype > 0) && (subtype == (video_mime_table[i].subtype))){
+                mime = video_mime_table[i].mime;
+                break;
+            }else if(video_mime_table[i].subtype == 0){
+                mime = video_mime_table[i].mime;
+                break;
+            }
+        }
+    }
+
+    if(mime == NULL)
+        return UNKNOWN_ERROR;
+
+    err = IParser->getTrackDuration(parserHandle, index,(uint64 *)&duration);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    if(IParser->getDecoderSpecificInfo){
+        err = IParser->getDecoderSpecificInfo(parserHandle, index, &decoderSpecificInfo, &decoderSpecificInfoSize);
+        if(err)
+            return UNKNOWN_ERROR;
+    }
+    err = IParser->getBitRate(parserHandle, index, &bitrate);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    err = IParser->getVideoFrameWidth(parserHandle, index, &width);
+    if(err){
+        return UNKNOWN_ERROR;
+    }
+
+    err = IParser->getVideoFrameHeight(parserHandle, index, &height);
+    if(err){
+        return UNKNOWN_ERROR;
+    }
+
+    err = IParser->getVideoFrameRate(parserHandle, index, &rate, &scale);
+    if(err){
+        return UNKNOWN_ERROR;
+    }
+
+    if(rate > 0 && scale > 0)
+        fps = rate/scale;
+
+    if(fps > 250)
+        fps = 0;
+
+    if(IParser->getVideoFrameRotation){
+        err = IParser->getVideoFrameRotation(parserHandle,index,&rotation);
+        if(err){
+            return UNKNOWN_ERROR;
+        }
+    }
+
+    if(IParser->getVideoDisplayWidth){
+        err = IParser->getVideoDisplayWidth(parserHandle, index, &display_width);
+        if(err){
+            return UNKNOWN_ERROR;
+        }
+    }
+
+    if(IParser->getVideoDisplayHeight){
+        err = IParser->getVideoDisplayHeight(parserHandle, index, &display_height);
+        if(err){
+            return UNKNOWN_ERROR;
+        }
+    }
+
+    if(IParser->getVideoFrameCount){
+        err = IParser->getVideoFrameCount(parserHandle, index, &frame_count);
+        if(err){
+            return UNKNOWN_ERROR;
+        }
+    }
+
+    ALOGI("ParseVideo width=%u,height=%u,fps=%u,rotate=%u",width,height,fps,rotation);
+
+    AMediaFormat *meta = AMediaFormat_new();
+
+    AMediaFormat_setString(meta, AMEDIAFORMAT_KEY_MIME, mime);
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_TRACK_ID, index);
+
+    if(decoderSpecificInfoSize > 0 && decoderSpecificInfo != NULL){
+        ALOGI("video codec data size=%u",decoderSpecificInfoSize);
+        if(type == VIDEO_H264){
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD_AVC, decoderSpecificInfo, decoderSpecificInfoSize);
+            ALOGI("add avcc metadata for h264 video size=%u",decoderSpecificInfoSize);
+        }else if(type == VIDEO_HEVC){
+            //stagefright will check the first bytes, so modify to pass it.
+            if(decoderSpecificInfo[0] != 1)
+                decoderSpecificInfo[0] = 1;
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD_HEVC, decoderSpecificInfo, decoderSpecificInfoSize);
+            ALOGI("add hvcc metadata for hevc video size=%u",decoderSpecificInfoSize);
+        }else if(type == VIDEO_MPEG4){
+            addESDSFromCodecPrivate(meta,false,decoderSpecificInfo,decoderSpecificInfoSize);
+            ALOGI("add esds metadata for mpeg4 video size=%u",decoderSpecificInfoSize);
+        }else{
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD_0, decoderSpecificInfo, decoderSpecificInfoSize);
+        }
+    }else if(type == VIDEO_H264 || type == VIDEO_HEVC || type == VIDEO_MPEG4){
+        thumbnail_ts = 0;
+    }
+
+    if(!strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG2TS) || !strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG2PS))
+        thumbnail_ts = -1;
+
+    if(0 == thumbnail_ts){
+        thumbnail_ts = -1;
+        AMediaFormat_setInt32(meta, "special_thumbnail", 1);
+    }
+
+    if(!strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_FLV))
+        thumbnail_ts = 0;
+
+    if (type == VIDEO_H264 || type == VIDEO_HEVC) {
+        // AVC requires compression ratio of at least 2, and uses
+        // macroblocks
+        max_size = ((width + 15) / 16) * ((height + 15) / 16) * 192;
+    } else if (type == VIDEO_ON2_VP) {
+        // MA-13518: android.media.cts.DecoderConformanceTest#testVP9Other
+        // vp90_2_09_subpixel_00.vp9 frame size exceeds w * h * 3 / 2, increase to w * h * 2
+        max_size = width * height * 2;
+    } else {
+        // For all other formats there is no minimum compression
+        // ratio. Use compression ratio of 1.
+        max_size = width * height * 3 / 2;
+    }
+    if(0 == max_size)
+        max_size = MAX_VIDEO_BUFFER_SIZE;
+    //max_size += 20;
+    max_size += max_size / 10;
+
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_MAX_INPUT_SIZE, max_size);
+
+    if(type == VIDEO_WMV){
+        int32_t wmvType = 0;
+        switch(subtype){
+            case VIDEO_WMV7:
+                wmvType = OMX_VIDEO_WMVFormat7;
+                break;
+            case VIDEO_WMV8:
+                wmvType = OMX_VIDEO_WMVFormat8;
+                break;
+            case VIDEO_WMV9:
+                wmvType = OMX_VIDEO_WMVFormat9;
+                break;
+            case VIDEO_WMV9A:
+                wmvType = OMX_VIDEO_WMVFormat9a;
+                break;
+            case VIDEO_WVC1:
+                wmvType = OMX_VIDEO_WMVFormatWVC1;
+                break;
+            default:
+                break;
+        }
+        //TODO: remove openmax index
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_SUB_FORMAT, wmvType);
+    }
+
+    if (bitrate > 0){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_BIT_RATE, bitrate);
+    }
+
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_WIDTH, width);
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_HEIGHT, height);
+    AMediaFormat_setInt64(meta, AMEDIAFORMAT_KEY_DURATION, duration);
+
+    if(display_width > 0){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_DISPLAY_WIDTH, display_width);
+    }
+    if(display_height > 0){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_DISPLAY_HEIGHT, display_height);
+    }
+    if(frame_count > 0){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_FRAME_COUNT, frame_count);
+    }
+
+    // stagefright uses framerate only in MPEG4 extractor, let fslextrator be same with it
+    if(fps > 0 && !strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG4)){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_FRAME_RATE, fps);
+    }
+
+    if(rotation > 0){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_ROTATION, rotation);
+    }
+
+    if(thumbnail_ts < 0)
+        thumbnail_ts = duration > 5000000 ? 5000000:duration;
+
+    AMediaFormat_setInt64(meta, AMEDIAFORMAT_KEY_THUMBNAIL_TIME, thumbnail_ts);
+
+
+    if(IParser->getVideoColorInfo){
+        int32_t primaries = 0;
+        int32_t iso_transfer = 0;
+        int32_t matrix = 0;
+        int32_t full_range = 0;
+        err = IParser->getVideoColorInfo(parserHandle, index, &primaries,&iso_transfer,&matrix,&full_range);
+
+        if(err == PARSER_SUCCESS){
+            //ColorAspects aspects;
+            bool fullRange = (full_range == 1);
+            int32_t existingColor;
+
+            // only store the first color specification
+            if (!AMediaFormat_getInt32(meta, AMEDIAFORMAT_KEY_COLOR_RANGE, &existingColor)) {
+
+                int32_t range = 0;
+                int32_t standard = 0;
+                int32_t transfer = 0;
+                ColorUtils::convertIsoColorAspectsToPlatformAspects(
+                        primaries, iso_transfer, matrix, fullRange,
+                        &range, &standard, &transfer);
+
+                if (range != 0) {
+                    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_COLOR_RANGE, range);
+                }
+                if (standard != 0) {
+                    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_COLOR_STANDARD, standard);
+                }
+                if (transfer != 0) {
+                    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_COLOR_TRANSFER, transfer);
+                }
+                ALOGI("get color info, %d,%d,%d,%d
", primaries, range, standard, transfer);
+            }
+
+        }else //failed if no color info provided
+            err = PARSER_SUCCESS;
+
+    }
+
+    if(IParser->getVideoHDRColorInfo){
+        VideoHDRColorInfo info;
+        memset(&info,0,sizeof(VideoHDRColorInfo));
+
+        err = IParser->getVideoHDRColorInfo(parserHandle, index, &info);
+        if(err == PARSER_SUCCESS){
+            err = SetMkvHDRColorInfoMetadata(&info,meta);
+        }else //failed if no hdr color info provided
+            err = PARSER_SUCCESS;
+    }
+
+
+    ParseTrackExtMetadata(index,meta);
+
+    mTracks.push();
+    sourceIndex = mTracks.size() - 1;
+    TrackInfo *trackInfo = &mTracks.editItemAt(sourceIndex);
+    trackInfo->mTrackNum = index;
+    trackInfo->mExtractor = this;
+    trackInfo->bCodecInfoSent = false;
+    trackInfo->bPartial = false;
+    trackInfo->buffer = NULL;
+    trackInfo->outTs = 0;
+    trackInfo->syncFrame = 0;
+    trackInfo->mMeta = meta;
+    trackInfo->mSource = NULL;
+    trackInfo->max_input_size = max_size;
+    trackInfo->type = MEDIA_VIDEO;
+    trackInfo->bIsNeedConvert = false;
+    trackInfo->bitPerSample = 0;
+    trackInfo->bMp4Encrypted = false;
+    trackInfo->bMkvEncrypted = false;
+    void * cryptoKeyData = 0;
+    size_t cryptoKeySize = 0;
+
+    if(!AMediaFormat_getBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, &cryptoKeyData, &cryptoKeySize) && cryptoKeySize > 0){
+        if(!strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG4)){
+            void *data;
+            size_t size;
+
+            if(AMediaFormat_getBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, &data, &size) && data && size <=16)
+                memcpy(trackInfo->default_kid,data,size);
+
+            AMediaFormat_getInt32(meta,AMEDIAFORMAT_KEY_CRYPTO_MODE, &trackInfo->default_isEncrypted);
+            AMediaFormat_getInt32(meta,AMEDIAFORMAT_KEY_CRYPTO_MODE, &trackInfo->default_iv_size);
+
+            trackInfo->bMp4Encrypted = true;
+        }else if(!strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_MATROSKA))
+            trackInfo->bMkvEncrypted = true;
+    }
+
+    mReader->AddBufferReadLimitation(index,max_size);
+
+    ALOGI("add video track index=%u,source index=%zu,mime=%s",index,sourceIndex,mime);
+    return OK;
+}
+
+status_t ImxExtractor::ParseAudio(uint32 index, uint32 type,uint32 subtype)
+{
+    int32 err = (int32)PARSER_SUCCESS;
+    uint32_t i = 0;
+    uint32 bitrate = 0;
+    uint32 channel = 0;
+    uint32 samplerate = 0;
+    uint32 bitPerSample = 0;
+    uint32 bitsPerFrame = 0;
+    uint32 audioBlockAlign = 0;
+    uint32 audioChannelMask = 0;
+    const char* mime = NULL;
+    uint64_t duration = 0;
+    uint8 * decoderSpecificInfo = NULL;
+    uint32 decoderSpecificInfoSize = 0;
+    uint8 language[8];
+    size_t sourceIndex = 0;
+    int32_t encoderDelay = 0;
+    int32_t encoderPadding = 0;
+
+    ALOGD("ParseAudio index=%u,type=%u,subtype=%u",index,type,subtype);
+    for(i = 0; i < sizeof(audio_mime_table)/sizeof(codec_mime_struct); i++){
+        if (type == audio_mime_table[i].type){
+            if((audio_mime_table[i].subtype > 0) && (subtype == (audio_mime_table[i].subtype))){
+                mime = audio_mime_table[i].mime;
+                break;
+            }else if(audio_mime_table[i].subtype == 0){
+                mime = audio_mime_table[i].mime;
+                break;
+            }
+        }
+    }
+
+    if(mime == NULL)
+        return UNKNOWN_ERROR;
+
+    err = IParser->getTrackDuration(parserHandle, index,(uint64 *)&duration);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    if(IParser->getDecoderSpecificInfo){
+        err = IParser->getDecoderSpecificInfo(parserHandle, index, &decoderSpecificInfo, &decoderSpecificInfoSize);
+        if(err)
+            return UNKNOWN_ERROR;
+    }
+
+    err = IParser->getBitRate(parserHandle, index, &bitrate);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    err = IParser->getAudioNumChannels(parserHandle, index, &channel);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    err = IParser->getAudioSampleRate(parserHandle, index, &samplerate);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    if(IParser->getAudioBitsPerSample){
+        err = IParser->getAudioBitsPerSample(parserHandle, index, &bitPerSample);
+        if(err)
+            return UNKNOWN_ERROR;
+    }
+    if(IParser->getAudioBitsPerFrame){
+        err = IParser->getAudioBitsPerFrame(parserHandle, index, &bitsPerFrame);
+        if(err)
+            return UNKNOWN_ERROR;
+    }
+
+    if(IParser->getAudioBlockAlign){
+        err = IParser->getAudioBlockAlign(parserHandle, index, &audioBlockAlign);//wma & adpcm
+        if(err)
+            return UNKNOWN_ERROR;
+    }
+
+    if(IParser->getAudioChannelMask){
+        err = IParser->getAudioChannelMask(parserHandle, index, &audioChannelMask);//not use
+        if(err)
+            return UNKNOWN_ERROR;
+    }
+    if(IParser->getLanguage) {
+        memset(language, 0, sizeof(language)/sizeof(language[0]));
+        err = IParser->getLanguage(parserHandle, index, &language[0]);
+        ALOGI("audio track %u, lanuage: %s
", index, language);
+    }
+    else
+        strcpy((char*)&language, "unknown");
+
+    if (type == AUDIO_AC4 ) {
+        GetAudioPresentationInfo(index);
+    }
+
+    AMediaFormat *meta = AMediaFormat_new();
+    // switch to google.aac.decoder for m4a clips to pass testDecodeM4a, MA-8801
+    if(type == AUDIO_AAC && subtype != AUDIO_ER_BSAC && !strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG4) && mNumTracks == 1){
+        mime = MEDIA_MIMETYPE_AUDIO_AAC;
+    }
+
+    AMediaFormat_setString(meta, AMEDIAFORMAT_KEY_MIME, mime);
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_TRACK_ID, index);
+
+    if(decoderSpecificInfoSize > 0 && decoderSpecificInfo != NULL){
+        ALOGI("audio codec data size=%u",decoderSpecificInfoSize);
+        if(type == AUDIO_AAC){
+            addESDSFromCodecPrivate(meta,true,decoderSpecificInfo,decoderSpecificInfoSize);
+            ALOGI("add esds metadata for aac audio size=%u",decoderSpecificInfoSize);
+        }else if(type == AUDIO_VORBIS){
+            if(OK != addVorbisCodecInfo(meta,decoderSpecificInfo,decoderSpecificInfoSize))
+                ALOGE("add vorbis codec info error");
+        }else if(type == AUDIO_OPUS){
+            int64_t defaultValue = 0;
+
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD_0, decoderSpecificInfo, decoderSpecificInfoSize);
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD_1, &defaultValue, sizeof(defaultValue));
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD_2, &defaultValue, sizeof(defaultValue));
+
+        }else{
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD_0, decoderSpecificInfo, decoderSpecificInfoSize);
+        }
+    }
+
+    if(type == AUDIO_PCM && (subtype == AUDIO_PCM_S16BE || subtype == AUDIO_PCM_S24BE || subtype == AUDIO_PCM_S32BE )){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_PCM_BIG_ENDIAN, 1);
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD, decoderSpecificInfo, decoderSpecificInfoSize);
+    }
+
+    size_t max_size = MAX_AUDIO_BUFFER_SIZE;//16*1024
+    if(type == AUDIO_APE) {
+        max_size = 262144; //enlarge buffer size to 256*1024 for ape audio
+    }
+    else if(type == AUDIO_MP3){
+        max_size = 8192;
+    }
+    else if (type == AUDIO_PCM && bitPerSample == 24) {
+        // workaround for MA-12617, audio sample size exceed 16*1024, add to 32*1024
+        max_size = 32786;
+    }
+    else if(type == AUDIO_DSD){
+        const int DSD_BLOCK_SIZE = 4096;
+        const int DSD_CHANNEL_NUM_MAX = 6;
+        max_size = DSD_BLOCK_SIZE * DSD_CHANNEL_NUM_MAX;
+    }
+
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_MAX_INPUT_SIZE, max_size);
+
+    if(type == AUDIO_WMA){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_SUB_FORMAT, subtype);
+        ALOGI("WMA subtype=%u",subtype);
+    }
+
+    /*
+      stagefright's mediaextractor doesn't read meta data bitPerSample from
+      file, fslExtractor shall be same with it, otherwise cts NativeDecoderTest will fail.
+      This cts uses aac&vorbis tracks, acodec needs bitPerSample for wma&ape tracks,
+      so just block aac&vorbis from passing bitPerSample.
+      */
+    if(bitPerSample > 0 && type != AUDIO_AAC && type != AUDIO_VORBIS){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_BITS_PER_SAMPLE, bitPerSample);
+    }
+
+    if(audioBlockAlign > 0){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_AUDIO_BLOCK_ALIGN, audioBlockAlign);
+    }
+
+    if(bitsPerFrame > 0){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_BITS_PER_FRAME, bitsPerFrame);
+    }
+
+    if(type == AUDIO_AAC) {
+        if(subtype == AUDIO_AAC_ADTS){
+            AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_IS_ADTS, 1);
+        }else if (subtype == AUDIO_AAC_ADIF){
+            AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_IS_ADIF, 1);
+        }
+    }else if(bitrate > 0){
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_BIT_RATE, bitrate);
+    }
+
+    if(type == AUDIO_AMR){
+        if(subtype == AUDIO_AMR_NB){
+            channel = 1;
+            samplerate = 8000;
+        }else if(subtype == AUDIO_AMR_WB){
+            channel = 1;
+            samplerate = 16000;
+        }
+    }
+
+    if(type == AUDIO_AC3 && samplerate == 0)
+        samplerate = 44100; // invalid samplerate will lead to findMatchingCodecs fail
+
+    AMediaFormat_setInt64(meta, AMEDIAFORMAT_KEY_DURATION, duration);
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_CHANNEL_COUNT, channel);
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_SAMPLE_RATE, samplerate);
+    AMediaFormat_setString(meta, AMEDIAFORMAT_KEY_LANGUAGE, (const char*)&language);
+
+    if(AMediaFormat_getInt32(mFileMetaData, AMEDIAFORMAT_KEY_ENCODER_DELAY, &encoderDelay))
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_ENCODER_DELAY, encoderDelay);
+
+    if(AMediaFormat_getInt32(mFileMetaData, AMEDIAFORMAT_KEY_ENCODER_PADDING, &encoderPadding))
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_ENCODER_PADDING, encoderPadding);
+
+    ParseTrackExtMetadata(index,meta);
+
+#if 0//test
+    if(type == AUDIO_MP3) {
+        meta->setInt32(kKeyEncoderDelay, 576);
+        meta->setInt32(kKeyEncoderPadding, 1908);
+
+    }
+#endif
+    ALOGI("ParseAudio channel=%d,sampleRate=%d,bitRate=%d,bitPerSample=%d,audioBlockAlign=%d",
+        (int)channel,(int)samplerate,(int)bitrate,(int)bitPerSample,(int)audioBlockAlign);
+    mTracks.push();
+    sourceIndex = mTracks.size() - 1;
+    TrackInfo *trackInfo = &mTracks.editItemAt(sourceIndex);
+    trackInfo->mTrackNum = index;
+    trackInfo->mExtractor = this;
+    trackInfo->bCodecInfoSent = false;
+    trackInfo->mMeta = meta;
+    trackInfo->bPartial = false;
+    trackInfo->buffer = NULL;
+    trackInfo->outTs = 0;
+    trackInfo->syncFrame = 0;
+    trackInfo->mSource = NULL;
+    trackInfo->max_input_size = max_size;
+    trackInfo->type = MEDIA_AUDIO;
+    trackInfo->bIsNeedConvert = (type == AUDIO_PCM && bitPerSample!= 16);
+    trackInfo->bitPerSample = bitPerSample;
+    trackInfo->bMp4Encrypted = false;
+    trackInfo->bMkvEncrypted = false;
+
+    void * cryptoKeyData = 0;
+    size_t cryptoKeySize = 0;
+
+    if(!AMediaFormat_getBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, &cryptoKeyData, &cryptoKeySize)){
+        if(!strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG4)){
+
+            void *data;
+            size_t size;
+
+            if(AMediaFormat_getBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, &data, &size) && data && size <=16)
+                memcpy(trackInfo->default_kid,data,size);
+
+            AMediaFormat_getInt32(meta,AMEDIAFORMAT_KEY_CRYPTO_MODE, &trackInfo->default_isEncrypted);
+            AMediaFormat_getInt32(meta,AMEDIAFORMAT_KEY_CRYPTO_MODE, &trackInfo->default_iv_size);
+
+            trackInfo->bMp4Encrypted = true;
+        }
+    }
+
+
+    mReader->AddBufferReadLimitation(index,max_size);
+    ALOGI("add audio track index=%u,sourceIndex=%zu,mime=%s",index,sourceIndex,mime);
+    return OK;
+}
+status_t ImxExtractor::ParseText(uint32 index, uint32 type,uint32 subtype)
+{
+
+    int32 err = (int32)PARSER_SUCCESS;
+    uint8 language[8];
+    uint32 width = 0;
+    uint32 height = 0;
+    const char* mime = NULL;
+    uint32 mime_len = 0;
+    ALOGD("ParseText index=%u,type=%u,subtype=%u",index,type,subtype);
+    switch(type){
+        case TXT_3GP_STREAMING_TEXT:
+        case TXT_QT_TEXT:
+            mime = MEDIA_MIMETYPE_TEXT_3GPP;
+            break;
+        case TXT_SUBTITLE_TEXT:
+            mime = MEDIA_MIMETYPE_TEXT_SRT;
+            break;
+        case TXT_SUBTITLE_SSA:
+            mime = MEDIA_MIMETYPE_TEXT_SSA;
+            break;
+        case TXT_SUBTITLE_ASS:
+            mime = MEDIA_MIMETYPE_TEXT_ASS;
+            break;
+        default:
+            break;
+    }
+
+    err = IParser->getTextTrackWidth(parserHandle,index,&width);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    err = IParser->getTextTrackHeight(parserHandle,index,&height);
+    if(err)
+        return UNKNOWN_ERROR;
+
+    if(IParser->getTextTrackMime && NULL == mime){
+        err = IParser->getTextTrackMime(parserHandle,index,(uint8**)&mime,&mime_len);
+        if(err)
+             return UNKNOWN_ERROR;
+    }
+
+    if(mime == NULL)
+        return UNKNOWN_ERROR;
+
+    if(IParser->getLanguage) {
+        memset(language, 0, sizeof(language)/sizeof(language[0]));
+        err = IParser->getLanguage(parserHandle, index, &language[0]);
+        ALOGI("text track %u, lanuage: %s
", index, language);
+    }
+    else
+        strcpy((char*)&language, "unknown");
+
+    AMediaFormat *meta = AMediaFormat_new();
+    AMediaFormat_setString(meta, AMEDIAFORMAT_KEY_MIME, mime);
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_TRACK_ID, index);
+
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_WIDTH, width);
+    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_HEIGHT, height);
+    AMediaFormat_setString(meta, AMEDIAFORMAT_KEY_LANGUAGE, (const char*)&language);
+
+    ParseTrackExtMetadata(index,meta);
+
+    mTracks.push();
+    TrackInfo *trackInfo = &mTracks.editItemAt(mTracks.size() - 1);
+    trackInfo->mTrackNum = index;
+    trackInfo->mExtractor = this;
+    trackInfo->bCodecInfoSent = false;
+    trackInfo->mMeta = meta;
+    trackInfo->bPartial = false;
+    trackInfo->buffer = NULL;
+    trackInfo->outTs = 0;
+    trackInfo->syncFrame = 0;
+    trackInfo->mSource = NULL;
+    trackInfo->max_input_size = MAX_TEXT_BUFFER_SIZE;
+    trackInfo->type = MEDIA_TEXT;
+    trackInfo->bIsNeedConvert = false;
+    trackInfo->bitPerSample = 0;
+    trackInfo->bMkvEncrypted = false;
+    trackInfo->bMp4Encrypted = false;
+    mReader->AddBufferReadLimitation(index,MAX_TEXT_BUFFER_SIZE);
+    ALOGD("add text track");
+    return OK;
+}
+status_t ImxExtractor::ParseTrackExtMetadata(uint32 index, AMediaFormat *meta)
+{
+    int32 err = (int32)PARSER_SUCCESS;
+    if(meta == NULL)
+        return UNKNOWN_ERROR;
+
+    if(IParser->getTrackExtTag){
+        TrackExtTagList *pList = NULL;
+        TrackExtTagItem *pItem = NULL;
+        err = IParser->getTrackExtTag(parserHandle, index, &pList);
+        if(err)
+            return UNKNOWN_ERROR;
+
+        if(pList && pList->num > 0){
+            pItem = pList->m_ptr;
+            while(pItem != NULL){
+                if(pItem->index == FSL_PARSER_TRACKEXTTAG_TX3G){
+                    AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_TEXT_FORMAT_DATA, pItem->data, pItem->size);
+                    ALOGI("kKeyTextFormatData %d",pItem->size);
+                }else if(pItem->index == FSL_PARSER_TRACKEXTTAG_CRPYTOKEY){
+                    uint32 type = 0;
+                    if(!strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG4)){
+                        type = 'tenc';
+                    }
+                    ALOGI("has AMEDIAFORMAT_KEY_CRYPTO_KEY");
+                    AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, pItem->data, pItem->size);
+                }else if(pItem->index == FSL_PARSER_TRACKEXTTAG_CRPYTOMODE ){
+                    int32 cryptoMode = *(int32*)pItem->data;
+                    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_CRYPTO_MODE, cryptoMode);
+                }else if(pItem->index == FSL_PARSER_TRACKEXTTAG_CRPYTODEFAULTIVSIZE ){
+                    int32 defaultIVSize = *(int32*)pItem->data;
+                    AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_CRYPTO_DEFAULT_IV_SIZE, defaultIVSize);
+                }
+                pItem = pItem->nextItemPtr;
+            }
+        }
+    }
+
+    return OK;
+}
+int ImxExtractor::bytesForSize(size_t size) {
+    // use at most 28 bits (4 times 7)
+    CHECK(size <= 0xfffffff);
+
+    if (size > 0x1fffff) {
+        return 4;
+    } else if (size > 0x3fff) {
+        return 3;
+    } else if (size > 0x7f) {
+        return 2;
+    }
+    return 1;
+}
+void ImxExtractor::storeSize(uint8_t *data, size_t &idx, size_t size) {
+    int numBytes = bytesForSize(size);
+    idx += numBytes;
+
+    data += idx;
+    size_t next = 0;
+    while (numBytes--) {
+        *--data = (size & 0x7f) | next;
+        size >>= 7;
+        next = 0x80;
+    }
+}
+void ImxExtractor::addESDSFromCodecPrivate(AMediaFormat *meta, bool isAudio, void *priv, size_t privSize)
+{
+
+    int privSizeBytesRequired = bytesForSize(privSize);
+    int esdsSize2 = 14 + privSizeBytesRequired + privSize;
+    int esdsSize2BytesRequired = bytesForSize(esdsSize2);
+    int esdsSize1 = 4 + esdsSize2BytesRequired + esdsSize2;
+    int esdsSize1BytesRequired = bytesForSize(esdsSize1);
+    size_t esdsSize = 1 + esdsSize1BytesRequired + esdsSize1;
+    uint8_t *esds = new uint8_t[esdsSize];
+
+    size_t idx = 0;
+    esds[idx++] = 0x03;
+    storeSize(esds, idx, esdsSize1);
+    esds[idx++] = 0x00; // ES_ID
+    esds[idx++] = 0x00; // ES_ID
+    esds[idx++] = 0x00; // streamDependenceFlag, URL_Flag, OCRstreamFlag
+    esds[idx++] = 0x04;
+    storeSize(esds, idx, esdsSize2);
+    esds[idx++] = isAudio ? 0x40   // Audio ISO/IEC 14496-3
+                          : 0x20;  // Visual ISO/IEC 14496-2
+    for (int i = 0; i < 12; i++) {
+        esds[idx++] = 0x00;
+    }
+    esds[idx++] = 0x05;
+    storeSize(esds, idx, privSize);
+    memcpy(esds + idx, priv, privSize);
+
+    AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_ESDS, esds, esdsSize);
+
+    delete[] esds;
+    esds = NULL;
+
+}
+status_t ImxExtractor::addVorbisCodecInfo(AMediaFormat *meta, void *_codecPrivate, size_t codecPrivateSize) {
+
+    size_t offset = 0;
+    int32_t start1 = 0;
+    int32_t start2 = 0;
+    int32_t start3 = 0;
+
+    if(_codecPrivate == NULL || codecPrivateSize < 6)
+        return ERROR_MALFORMED;
+
+    const uint8_t *ptr = (const uint8_t *)_codecPrivate;
+
+    while(offset < codecPrivateSize-6){
+        if((ptr[offset] == 0x01) && (memcmp(&ptr[offset+1],"vorbis",6)==0)){
+            start1 = offset;
+        }else if((ptr[offset] == 0x03) && (memcmp(&ptr[offset+1],"vorbis",6)==0)){
+            start2 = offset;
+        }else if((ptr[offset] == 0x05) && (memcmp(&ptr[offset+1],"vorbis",6)==0)){
+            start3 = offset;
+        }
+        offset ++;
+    }
+
+    if(!(start2 > start1 && start3 > start2))
+        return ERROR_MALFORMED;
+
+    //formerly kKeyVorbisInfo
+    AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD_0, &ptr[start1], start2 - start1);
+    // formerly kKeyVorbisBooks
+    AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CSD_1, &ptr[start3], codecPrivateSize - start3);
+    ALOGV("addVorbisCodecInfo SUCCESS csd0_len=%d,csd1_len=%d",start2 - start1,(int)codecPrivateSize - start3);
+
+    return OK;
+}
+status_t ImxExtractor::ActiveTrack(uint32 index)
+{
+    uint64 seekPos = 0;
+    Mutex::Autolock autoLock(mLock);
+    bool seek = true;
+
+    TrackInfo *trackInfo = &mTracks.editItemAt(index);
+    if(trackInfo == NULL)
+        return UNKNOWN_ERROR;
+    trackInfo->bCodecInfoSent = false;
+    if(trackInfo->type == MEDIA_VIDEO){
+        seekPos = currentVideoTs;
+        mVideoActived = true;
+        mVideoIndex = index;
+    }else if(trackInfo->type == MEDIA_AUDIO){
+        seekPos = currentAudioTs;
+        mAudioActived = true;
+        mAudioIndex = index;
+    }else if(currentVideoTs > 0)
+        seekPos = currentVideoTs;
+    else
+        seekPos = currentAudioTs;
+
+    IParser->enableTrack(parserHandle,trackInfo->mTrackNum, TRUE);
+
+    if(trackInfo->type == MEDIA_TEXT || trackInfo->type == MEDIA_AUDIO){
+        if(isTrackModeParser())
+            seek = true;
+        else
+            seek = false;
+    }
+
+    if(seek)
+        IParser->seek(parserHandle, trackInfo->mTrackNum, &seekPos, SEEK_FLAG_NO_LATER);
+
+    ALOGD("start track %d",trackInfo->mTrackNum);
+    return OK;
+}
+status_t ImxExtractor::DisableTrack(uint32 index)
+{
+    Mutex::Autolock autoLock(mLock);
+    TrackInfo *trackInfo = &mTracks.editItemAt(index);
+    if(trackInfo == NULL)
+        return UNKNOWN_ERROR;
+
+    if(trackInfo->type == MEDIA_VIDEO){
+        mVideoActived = false;
+    }else if(trackInfo->type == MEDIA_AUDIO){
+        mAudioActived = false;
+    }
+
+    IParser->enableTrack(parserHandle,trackInfo->mTrackNum, FALSE);
+    ALOGD("close track %d",trackInfo->mTrackNum);
+    return OK;
+}
+media_status_t ImxExtractor::HandleSeekOperation(uint32_t index,int64_t * ts,uint32_t flag)
+{
+    TrackInfo *pInfo = NULL;
+    int64_t target;
+    bool seek = true;
+    bool seek2 = false;
+    int64_t ts2;
+    TrackInfo *pInfo2 = NULL;
+    if(ts == NULL)
+        return AMEDIA_ERROR_UNKNOWN;
+
+    target = *ts;
+    ts2 = *ts;
+    pInfo = &mTracks.editItemAt(index);
+
+    if(pInfo == NULL)
+        return AMEDIA_ERROR_UNKNOWN;
+
+    ALOGD("HandleSeekOperation BEGIN index=%d,target=%" PRId64 ",flag=%x",index,target,flag);
+
+    if(mReadMode == PARSER_READ_MODE_FILE_BASED){
+        if(pInfo->type == MEDIA_AUDIO && mVideoActived){
+            seek = false;
+            //for track mode parser, it must seek audio track.
+            if(isTrackModeParser())
+                seek = true;
+        }else if(pInfo->type == MEDIA_TEXT && mVideoActived){
+            seek = false;
+        }
+
+        if(pInfo->type == MEDIA_VIDEO && mAudioActived && isTrackModeParser()){
+            pInfo2 = &mTracks.editItemAt(mAudioIndex);
+            seek2 = true;
+            if(pInfo2->type != MEDIA_AUDIO)
+                seek2 = false;
+
+            //check distance between target video position and current audio
+            //do not trig the seconds seek when distance is close.
+            if((target + SEEK_CHECK_TOLERANCE > currentAudioTs) &&
+                (target < currentAudioTs + SEEK_CHECK_TOLERANCE)){
+                seek2 = false;
+                ALOGV("skip audio seek");
+            }
+        }
+
+
+        if(pInfo->type == MEDIA_AUDIO && mVideoActived && isTrackModeParser()){
+            pInfo2 = &mTracks.editItemAt(mVideoIndex);
+            seek2 = true;
+            if(pInfo2->type != MEDIA_VIDEO)
+                seek2 = false;
+
+            //check distance between target audio postion and current video
+            //do not trig the seconds seek when distance is close.
+            if((target + SEEK_CHECK_TOLERANCE > currentVideoTs) &&
+                (target < currentVideoTs + SEEK_CHECK_TOLERANCE)){
+                seek2 = false;
+                ALOGV("skip video seek");
+            }
+        }
+    }
+
+    if(seek){
+        IParser->seek(parserHandle, pInfo->mTrackNum, (uint64*)ts, flag);
+        //clear temp buffer
+
+        if(pInfo->buffer != NULL){
+            pInfo->buffer->release();
+            pInfo->buffer = NULL;
+        }
+        ALOGD("HandleSeekOperation do seek index=%d",index);
+    }
+
+
+    if(seek2 && pInfo2 != NULL){
+        IParser->seek(parserHandle, pInfo2->mTrackNum, (uint64*)&ts2, flag);
+        //clear temp buffer
+        if(pInfo2->buffer != NULL){
+            pInfo2->buffer->release();
+            pInfo2->buffer = NULL;
+        }
+        ALOGD("HandleSeekOperation do seek 2 index=%d",index);
+        pInfo2->bPartial = false;
+    }
+
+    pInfo->bPartial = false;
+
+    if(pInfo->type == MEDIA_VIDEO)
+        currentVideoTs = target;
+    else if(pInfo->type == MEDIA_AUDIO) {
+        currentAudioTs = target;
+        bWaitForAudioStartTime = true;
+    }
+
+    ALOGD("HandleSeekOperation result index=%d,ts=%" PRId64 ",flag=%x",index,*ts,flag);
+    return AMEDIA_OK;
+}
+media_status_t ImxExtractor::GetNextSample(uint32_t index,bool is_sync)
+{
+    int32 err = (int32)PARSER_SUCCESS;
+    void * buffer_context = NULL;
+    uint64 ts = 0;
+    uint64 duration = 0;
+    uint8 *tmp = NULL;
+    uint32 datasize = 0;
+    uint32 sampleFlag = 0;
+    uint32 track_num_got = 0;
+    uint32 direction = 0;
+    bool bufferIsValid = false;
+
+    TrackInfo *pInfo = NULL;
+    Mutex::Autolock autoLock(mLock);
+
+    pInfo = &mTracks.editItemAt(index);
+    track_num_got = pInfo->mTrackNum;
+    pInfo = NULL;
+
+    ALOGV("GetNextSample readmode=%u index=%u BEGIN",mReadMode,track_num_got);
+    do{
+
+        if(mReadMode == PARSER_READ_MODE_TRACK_BASED){
+            if (is_sync)
+            {
+                err = IParser->getNextSyncSample(parserHandle,
+                        direction,
+                        track_num_got,
+                        &tmp,
+                        &buffer_context,
+                        &datasize,
+                        (uint64 *)&ts,
+                        &duration,
+                        (uint32 *)&sampleFlag);
+            }
+            else
+            {
+                err = IParser->getNextSample(parserHandle,
+                        track_num_got,
+                        &tmp,
+                        &buffer_context,
+                        &datasize,
+                        (uint64 *)&ts,
+                        &duration,
+                        (uint32 *)&sampleFlag);
+            }
+        }else{
+            if (is_sync)
+            {
+                err = IParser->getFileNextSyncSample(parserHandle,
+                        direction,
+                        &track_num_got,
+                        &tmp,
+                        &buffer_context,
+                        &datasize,
+                        (uint64 *)&ts,
+                        &duration,
+                        (uint32 *)&sampleFlag);
+            }
+            else
+            {
+                err = IParser->getFileNextSample(parserHandle,
+                        &track_num_got,
+                        &tmp,
+                        &buffer_context,
+                        &datasize,
+                        (uint64 *)&ts,
+                        &duration,
+                        (uint32 *)&sampleFlag);
+            }
+        }
+
+        if(PARSER_NOT_READY == err){
+            return AMEDIA_ERROR_WOULD_BLOCK;
+        }
+
+        ALOGV("GetNextSample err %d get track num=%u ts=%lld,size=%u,flag=%x",err, track_num_got,ts,datasize,sampleFlag);
+
+        if(PARSER_SUCCESS != err){
+            if(err == PARSER_READ_ERROR)
+                return AMEDIA_ERROR_IO;
+            else if(err == PARSER_ERR_INVALID_PARAMETER)
+                return AMEDIA_ERROR_MALFORMED;
+            else
+                return AMEDIA_ERROR_END_OF_STREAM;
+        }
+
+        pInfo = &mTracks.editItemAt(index);
+        if(pInfo && pInfo->mTrackNum != track_num_got){
+
+            size_t trackCount = mTracks.size();
+            for (size_t index = 0; index < trackCount; index++) {
+                pInfo = &mTracks.editItemAt(index);
+                if(pInfo->mTrackNum == track_num_got)
+                    break;
+                pInfo = NULL;
+            }
+            if(pInfo == NULL)
+                continue;
+        }
+
+        if(tmp && buffer_context && pInfo) {
+            MediaBufferHelper * buffer = pInfo->buffer;
+
+            if(sampleFlag & FLAG_SAMPLE_NOT_FINISHED)
+                pInfo->bPartial = true;
+
+            if(pInfo->bPartial){
+
+                if(buffer == NULL){
+                    buffer = (MediaBufferHelper *)buffer_context;
+                    pInfo->outTs = ts;
+                    pInfo->outDuration = duration;
+                    pInfo->syncFrame = (sampleFlag & FLAG_SYNC_SAMPLE);
+                    buffer->set_range(0,datasize);
+                    pInfo->buffer = buffer;
+                    ALOGV("bPartial first buffer");
+                }else {
+                    MediaBufferHelper * lastBuf = buffer;
+                    MediaBufferHelper * currBuf = (MediaBufferHelper *)buffer_context;
+                    if (pInfo->type == MEDIA_VIDEO && (sampleFlag & FLAG_SAMPLE_H264_SEI_POS_DATA)) {
+                        // add sei position data to last video frame buffer as the meta data
+                        sp<ABuffer> sei = new ABuffer(sizeof(NALPosition));
+                        NALPosition *nalPos = (NALPosition *)sei->data();
+                        SeiPosition *seiPos = (SeiPosition *)currBuf->data();
+                        nalPos->nalOffset = seiPos->offset;
+                        nalPos->nalSize = seiPos->size;
+
+                        AMediaFormat_setBuffer(buffer->meta_data(), AMEDIAFORMAT_KEY_SEI, sei->data(), sei->size());
+                        currBuf->release();
+                    } else {
+                        void* meta_value;
+                        size_t meta_size = 0;
+                        size_t lastLen = lastBuf->range_length();
+
+                        if(0/*lastBuf->range_length() + currBuf->range_length() < lastBuf->size()*/){
+                            buffer = lastBuf;
+                            buffer->set_range(0,lastLen + (size_t)datasize);
+                            memcpy((uint8*)buffer->data()+lastLen,currBuf->data(),currBuf->range_length());
+                            currBuf->release();
+                            pInfo->buffer = buffer;
+                        } else if(true == mReader->AcquireBuffer(track_num_got, lastLen + (size_t)datasize , &buffer)){
+                            buffer->set_range(0,lastLen + (size_t)datasize);
+
+                            memcpy(buffer->data(),lastBuf->data(),lastLen);
+                            memcpy((uint8*)buffer->data()+lastLen,currBuf->data(),currBuf->range_length());
+
+                            if(AMediaFormat_getBuffer(lastBuf->meta_data(), AMEDIAFORMAT_KEY_SEI, &meta_value, &meta_size)){
+                                AMediaFormat_setBuffer(buffer->meta_data(), AMEDIAFORMAT_KEY_SEI, meta_value, meta_size);
+                            }
+                            lastBuf->release();
+                            currBuf->release();
+                            pInfo->buffer = buffer;
+                        }else{
+                            ALOGE("could not AcquireBuffer");
+                            break;
+                        }
+                    }
+                    ALOGV("bPartial second buffer");
+                }
+
+                if(!(sampleFlag & FLAG_SAMPLE_NOT_FINISHED))
+                    pInfo->bPartial = false;
+            }
+            else{
+                buffer = (MediaBufferHelper *)buffer_context;
+                pInfo->outTs = ts;
+                pInfo->outDuration = duration;
+                pInfo->syncFrame = (sampleFlag & FLAG_SYNC_SAMPLE);
+                pInfo->buffer = buffer;
+                buffer->set_range(0,datasize);
+            }
+
+        }else {
+            // mpg2 parser often send an empty buffer as the last partial frame.
+            if(pInfo && pInfo->bPartial && !(sampleFlag & FLAG_SAMPLE_NOT_FINISHED))
+                pInfo->bPartial = false;
+        }
+
+        if (pInfo && pInfo->buffer != NULL && (pInfo->buffer->range_length() < pInfo->max_input_size))
+            bufferIsValid = true;
+        else
+            bufferIsValid = false;
+
+    }while((sampleFlag & FLAG_SAMPLE_NOT_FINISHED) && bufferIsValid);
+
+    if(pInfo && pInfo->buffer != NULL ){
+        ImxMediaSource *source = pInfo->mSource;
+        bool add = false;
+        if(source != NULL  && source->started()){
+            add = true;
+            if(pInfo->type == MEDIA_AUDIO && bWaitForAudioStartTime == true) {
+                if(pInfo->outTs >= 0 && pInfo->outTs < currentAudioTs && mVideoActived == true) {
+                    ALOGV("drop audio after seek ts= %" PRId64 ",audio_ts= %" PRId64 "",pInfo->outTs,currentAudioTs);
+                    add = false;
+                } else if(pInfo->outTs == -1) {
+                    // drop audio as invalid start time after seek
+                    add = false;
+                } else {
+                    // get audio start time
+                    bWaitForAudioStartTime = false;
+                }
+            }
+        }
+        if(add){
+            bool readDrmInfo = false;
+            //check the last complete sample we read
+            if((sampleFlag & FLAG_SAMPLE_COMPRESSED_SAMPLE) && !(sampleFlag & FLAG_SAMPLE_NOT_FINISHED)){
+                readDrmInfo = true;
+            }
+
+            if(pInfo->type == MEDIA_AUDIO && mAudioPresentations.size() > 0) {
+                if (sampleFlag & FLAG_SAMPLE_AUDIO_PRESENTATION_CHANGED)
+                    GetAudioPresentationInfo(index);
+
+                std::ostringstream outStream(std::ios::out);
+                serializeAudioPresentations(mAudioPresentations, &outStream);
+                AMediaFormat_setBuffer(pInfo->buffer->meta_data(), AMEDIAFORMAT_KEY_AUDIO_PRESENTATION_INFO,
+                                            outStream.str().data(), outStream.str().size());
+            }
+
+            if(pInfo->bIsNeedConvert) {
+                MediaBufferHelper * buffer = pInfo->buffer;
+                MediaBufferHelper * tmp = NULL;
+                if(mReader->AcquireBuffer(pInfo->mTrackNum, 2 * buffer->range_length() , &tmp)){
+                    convertPCMData(buffer, tmp, pInfo->bitPerSample);
+                    pInfo->buffer = tmp;
+                    buffer->release();
+                }
+            }
+
+            MediaBufferHelper *mbuf = pInfo->buffer;
+            AMediaFormat * meta = mbuf->meta_data();
+            AMediaFormat_setInt64(meta, AMEDIAFORMAT_KEY_TIME_US, pInfo->outTs);
+            AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_IS_SYNC_FRAME, pInfo->syncFrame);
+            AMediaFormat_setInt64(meta, AMEDIAFORMAT_KEY_DURATION,  pInfo->outDuration);
+
+            ALOGV("addMediaBuffer ts=%" PRId64 ",size=%zu",pInfo->outTs,pInfo->buffer->size());
+            if(pInfo->bMkvEncrypted){
+                SetMkvCrpytBufferInfo(pInfo,mbuf);
+            }else if(pInfo->bMp4Encrypted && readDrmInfo){
+                SetMp4CrpytBufferInfo(pInfo,mbuf);
+            }
+            source->addMediaBuffer(mbuf);
+            if(pInfo->type == MEDIA_VIDEO)
+                currentVideoTs = pInfo->outTs;
+            else if(pInfo->type == MEDIA_AUDIO)
+                currentAudioTs = pInfo->outTs;
+
+            //do not release the buffer, pass it to ImxMediaSource
+            pInfo->buffer = NULL;
+        }else{
+            pInfo->buffer->release();
+            pInfo->buffer = NULL;
+        }
+    }
+
+    //check for get subtitle track in file mode, avoid interleave
+    pInfo = &mTracks.editItemAt(index);
+    if(pInfo->type == MEDIA_TEXT && pInfo->mTrackNum != track_num_got)
+        return AMEDIA_ERROR_WOULD_BLOCK;
+
+    //the return value WOULD_BLOCK can only be used when playing rtp streaming.
+    //for other case, we must read and give a frame buffer when calling ImxMediaSource::read()
+    if(mReader->isLiveStreaming() && mReadMode == PARSER_READ_MODE_FILE_BASED
+        && (pInfo->mTrackNum != track_num_got))
+        return AMEDIA_ERROR_WOULD_BLOCK;
+
+    return AMEDIA_OK;
+}
+status_t ImxExtractor::CheckInterleaveEos(__unused uint32_t index)
+{
+    bool bTrackFull = false;
+
+    if(mReadMode == PARSER_READ_MODE_TRACK_BASED)
+        return OK;
+
+    if(mTracks.size() < 2)
+        return OK;
+
+    for(size_t i = 0; i < mTracks.size(); i++){
+        TrackInfo *pInfo = &mTracks.editItemAt(i);
+        ImxMediaSource *source = pInfo->mSource;
+        if(source != NULL && source->started() && source->full()){
+            bTrackFull = true;
+            ALOGE("get a full track mTrackNum=%d",pInfo->mTrackNum);
+            break;
+        }
+    }
+    if(bTrackFull)
+        return ERROR_END_OF_STREAM;
+    else
+        return OK;
+}
+status_t ImxExtractor::ClearTrackSource(uint32_t index)
+{
+    if (index >= mTracks.size()) {
+        return UNKNOWN_ERROR;
+    }
+    TrackInfo *trackInfo = &mTracks.editItemAt(index);
+    if(trackInfo){
+        if(trackInfo->buffer != NULL)
+            trackInfo->buffer->release();
+
+        trackInfo->mSource = NULL;
+    }
+    return OK;
+}
+
+bool ImxExtractor::isTrackModeParser()
+{
+    if(!strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_MPEG4) || !strcmp(mMime, MEDIA_MIMETYPE_CONTAINER_AVI))
+        return true;
+    else
+        return false;
+}
+status_t ImxExtractor::convertPCMData(MediaBufferHelper * inBuffer, MediaBufferHelper* outBuffer, int32_t bitPerSample)
+{
+    if(bitPerSample == 8) {
+        // Convert 8-bit unsigned samples to 16-bit signed.
+        ssize_t numBytes = inBuffer->range_length();
+
+        int16_t *dst = (int16_t *)outBuffer->data();
+        const uint8_t *src = (const uint8_t *)inBuffer->data()+inBuffer->range_offset();
+
+        while (numBytes-- > 0) {
+            *dst++ = ((int16_t)(*src) - 128) * 256;
+            ++src;
+        }
+        outBuffer->set_range(0, 2 * inBuffer->range_length());
+
+    }else if (bitPerSample == 24) {
+        // Convert 24-bit signed samples to 16-bit signed.
+        const uint8_t *src = (const uint8_t *)inBuffer->data()+inBuffer->range_offset();
+        int16_t *dst = (int16_t *)outBuffer->data();
+        size_t numSamples = inBuffer->range_length() / 3;
+        for (size_t i = 0; i < numSamples; i++) {
+            int32_t x = (int32_t)(src[0] | src[1] << 8 | src[2] << 16);
+            x = (x << 8) >> 8;  // sign extension
+            x = x >> 8;
+            *dst++ = (int16_t)x;
+            src += 3;
+        }
+        outBuffer->set_range(0, 2 * numSamples);
+    }
+
+    return OK;
+}
+status_t ImxExtractor::SetMkvCrpytBufferInfo(TrackInfo *pInfo, MediaBufferHelper *buf)
+{
+
+    uint8 *buffer_ptr = (uint8 *)buf->data();
+    int32_t buffer_len = buf->size();
+    AMediaFormat * meta = buf->meta_data();
+
+    //parse the struct from http://www.webmproject.org/docs/webm-encryption/
+    if (buffer_ptr[0] & 0x1) {
+        if(buffer_len < 9)
+            return ERROR_MALFORMED;
+
+        buffer_len -= 9;
+
+        //full-sample encrypted block format
+        int32 plainSizes[] = { 0 };
+        int32 encryptedSizes[] = { buffer_len };
+        uint8 ctrCounter[16] = { 0 };
+
+        uint8 *keyId = NULL;
+        size_t keySize = 0;
+
+        memcpy(ctrCounter, buffer_ptr + 1, 8);
+
+        AMediaFormat *trackMeta = pInfo->mMeta;
+
+        CHECK(AMediaFormat_getBuffer(trackMeta, AMEDIAFORMAT_KEY_CRYPTO_KEY, (void**)&keyId, &keySize));
+
+
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, (void*)keyId, keySize);
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_IV, (void*)ctrCounter, 16);
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_PLAIN_SIZES, (void*)plainSizes, sizeof(plainSizes));
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_ENCRYPTED_SIZES, (void*)encryptedSizes, sizeof(encryptedSizes));
+
+        buf->set_range(9, buffer_len);
+
+    } else {
+        //unencrypted block format
+        buffer_len -= 1;
+        int32 plainSizes[] = { buffer_len };
+        int32 encryptedSizes[] = { 0 };
+
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_PLAIN_SIZES, (void*)plainSizes, sizeof(plainSizes));
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_ENCRYPTED_SIZES, (void*)encryptedSizes, sizeof(encryptedSizes));
+
+        buf->set_range(1, buffer_len);
+    }
+
+    return OK;
+}
+status_t ImxExtractor::SetMp4CrpytBufferInfo(TrackInfo *pInfo, MediaBufferHelper *buf)
+{
+    int32 err = (int32)PARSER_SUCCESS;
+
+    if(pInfo == NULL || buf == NULL)
+        return ERROR_MALFORMED;
+
+    AMediaFormat* meta = buf->meta_data();
+    uint8 *iv;
+    uint32 ivSize = 0;
+    uint8 *clear;
+    uint32 clearSize = 0;
+    uint8 * encrypted;
+    uint32 encryptedSize = 0;
+    err = IParser->getSampleCryptoInfo(parserHandle,pInfo->mTrackNum,&iv,&ivSize,
+            &clear, &clearSize, &encrypted, &encryptedSize);
+    if(err == PARSER_SUCCESS){
+
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_IV, (void*)iv, 16);
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_CRYPTO_MODE, pInfo->default_isEncrypted);
+        AMediaFormat_setInt32(meta, AMEDIAFORMAT_KEY_CRYPTO_DEFAULT_IV_SIZE, pInfo->default_iv_size);
+
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, (void*)pInfo->default_kid, 16);
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_PLAIN_SIZES, (void*)clear, clearSize);
+        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_ENCRYPTED_SIZES, (void*)encrypted, encryptedSize);
+
+        ALOGV("SetMp4CrpytBufferInfo clear size=%d,encryptedSize=%d,ivsize=%d",
+            clearSize,encryptedSize,pInfo->default_iv_size);
+    }else{
+        ALOGV("getNextDrmInfoSample of track %d, failed!",pInfo->mTrackNum);
+    }
+
+    return OK;
+}
+#define DELTA_TIME (24 * 3600 * (66*365 + 17))//seconds passed from Jan,1,1904 to Jan,1,1970
+bool ImxExtractor::ConvertMp4TimeToString(uint64 inTime, String8 *s) {
+
+    time_t time2 = 0;
+    struct tm * tms = NULL;
+    char str[32];
+    size_t strLen = 0;
+
+    //according to spec, creation time is an unsinged int64 value.
+    if((int64_t)inTime < DELTA_TIME + INT64_MIN)
+        return false;
+
+    // google's cts test want to return 1904 year and 1970 year, so time2 may be negative
+    time2 = (int64_t)inTime - DELTA_TIME;
+
+    tms = gmtime(&time2);
+    if(tms != NULL){
+        strLen = strftime(str, sizeof(str), "%Y%m%dT%H%M%S.000Z", tms);
+    }
+
+    if(strLen > 0){
+        s->setTo(str);
+        return true;
+    }
+
+    return false;
+}
+status_t ImxExtractor::SetMkvHDRColorInfoMetadata(VideoHDRColorInfo *pInfo, AMediaFormat *meta)
+{
+    HDRStaticInfo targetInfo;
+    bool update = false;
+
+    if(pInfo == NULL || meta == NULL)
+        return UNKNOWN_ERROR;
+
+    memset(&targetInfo,0,sizeof(HDRStaticInfo));
+    if(pInfo->maxCLL > 0 || pInfo->maxFALL > 0){
+        targetInfo.sType1.mMaxContentLightLevel = pInfo->maxCLL;
+        targetInfo.sType1.mMaxFrameAverageLightLevel = pInfo->maxFALL;
+        update = true;
+    }
+
+    if(pInfo->hasMasteringMetadata){
+        //use timescale 50000
+        #define HDR_TIMESCALE 50000
+        if((pInfo->PrimaryRChromaticityX >= 0 && pInfo->PrimaryRChromaticityX <=1)
+            && (pInfo->PrimaryRChromaticityY >= 0 && pInfo->PrimaryRChromaticityY <=1)
+            && (pInfo->PrimaryGChromaticityX >= 0 && pInfo->PrimaryGChromaticityX <=1)
+            && (pInfo->PrimaryGChromaticityY >= 0 && pInfo->PrimaryGChromaticityY <=1)
+            && (pInfo->PrimaryBChromaticityX >= 0 && pInfo->PrimaryBChromaticityX <=1)
+            && (pInfo->PrimaryBChromaticityY >= 0 && pInfo->PrimaryBChromaticityY <=1)){
+
+            targetInfo.sType1.mR.x = (uint16_t)(pInfo->PrimaryRChromaticityX * HDR_TIMESCALE + 0.5);
+            targetInfo.sType1.mR.y = (uint16_t)(pInfo->PrimaryRChromaticityY * HDR_TIMESCALE + 0.5);
+            targetInfo.sType1.mG.x = (uint16_t)(pInfo->PrimaryGChromaticityX * HDR_TIMESCALE + 0.5);
+            targetInfo.sType1.mG.y = (uint16_t)(pInfo->PrimaryGChromaticityY * HDR_TIMESCALE + 0.5);
+            targetInfo.sType1.mB.x = (uint16_t)(pInfo->PrimaryBChromaticityX * HDR_TIMESCALE + 0.5);
+            targetInfo.sType1.mB.y = (uint16_t)(pInfo->PrimaryBChromaticityY * HDR_TIMESCALE + 0.5);
+            update = true;
+            ALOGI("get HDR RGB=(%d,%d),(%d,%d),(%d,%d)",targetInfo.sType1.mR.x,targetInfo.sType1.mR.y,
+                targetInfo.sType1.mG.x,targetInfo.sType1.mG.y,
+                targetInfo.sType1.mB.x,targetInfo.sType1.mB.y);
+        }
+
+        if((pInfo->WhitePointChromaticityX >= 0 && pInfo->WhitePointChromaticityX <=1) &&
+            (pInfo->WhitePointChromaticityY >= 0 && pInfo->WhitePointChromaticityY <=1)){
+            targetInfo.sType1.mW.x = (uint16_t)(pInfo->WhitePointChromaticityX *HDR_TIMESCALE + 0.5);
+            targetInfo.sType1.mW.y = (uint16_t)(pInfo->WhitePointChromaticityY *HDR_TIMESCALE + 0.5);
+            update = true;
+            ALOGI("WhitePoint=(%d,%d)",targetInfo.sType1.mW.x,targetInfo.sType1.mW.y);
+        }
+
+        if(pInfo->LuminanceMax < 65535.5){
+            targetInfo.sType1.mMaxDisplayLuminance = (uint16_t)(pInfo->LuminanceMax + 0.5);
+            if(targetInfo.sType1.mMaxDisplayLuminance < 1)
+                targetInfo.sType1.mMaxDisplayLuminance = 1;
+            update = true;
+            ALOGI("mMaxDisplayLuminance=%d",targetInfo.sType1.mMaxDisplayLuminance);
+        }
+        if(pInfo->LuminanceMin < 6.5535){
+            targetInfo.sType1.mMinDisplayLuminance = (uint16_t)(pInfo->LuminanceMin * 10000 + 0.5);
+            if(targetInfo.sType1.mMinDisplayLuminance < 1)
+                targetInfo.sType1.mMinDisplayLuminance = 1;
+            update = true;
+            ALOGI("mMinDisplayLuminance=%d",targetInfo.sType1.mMinDisplayLuminance);
+        }
+    }
+
+    if(update){
+        targetInfo.mID = HDRStaticInfo::kType1;
+        ColorUtils::setHDRStaticInfoIntoAMediaFormat(targetInfo, meta);
+    }
+    return OK;
+}
+
+status_t ImxExtractor::GetAudioPresentationInfo(uint32_t index) {
+    if (!IParser->getAudioPresentationNum || !IParser->getAudioPresentationInfo)
+        return BAD_VALUE;
+
+    int32 err = (int32)PARSER_SUCCESS;
+    int32 presentationNum = 0;
+
+    err = IParser->getAudioPresentationNum(parserHandle, index, &presentationNum);
+    if (err || presentationNum <= 0)
+        return BAD_VALUE;
+
+    mAudioPresentations.clear();
+
+    for (int idx = 0; idx < presentationNum; idx++) {
+        int32 presentationId = -1;
+        char *language;
+        uint32 masteringIndication;
+        uint32 audioDescriptionAvailable;
+        uint32 spokenSubtitlesAvailable;
+        uint32 dialogueEnhancementAvailable;
+        err = IParser->getAudioPresentationInfo(parserHandle, index, idx, &presentationId, \
+                                    &language, &masteringIndication,&audioDescriptionAvailable, \
+                                    &spokenSubtitlesAvailable,&dialogueEnhancementAvailable);
+        if (err) {
+            mAudioPresentations.clear();
+            return BAD_VALUE;
+        }
+
+        AudioPresentationV1 ap;
+        ap.mPresentationId = presentationId;
+        ap.mMasteringIndication = static_cast<MasteringIndication>(masteringIndication);
+        ap.mAudioDescriptionAvailable = (audioDescriptionAvailable == 1);
+        ap.mSpokenSubtitlesAvailable = (spokenSubtitlesAvailable == 1);
+        ap.mDialogueEnhancementAvailable = (dialogueEnhancementAvailable == 1);
+        ap.mLanguage = String8(language);
+        ALOGI("language %s mPresentationId %d, mMasteringIndication %d, Available(%d %d %d)",\
+        ap.mLanguage.c_str(), ap.mPresentationId, ap.mAudioDescriptionAvailable,\
+        ap.mAudioDescriptionAvailable, ap.mSpokenSubtitlesAvailable, ap.mDialogueEnhancementAvailable);
+        mAudioPresentations.push_back(std::move(ap));
+    }
+
+    return OK;
+}
+
+bool ImxExtractor::AttachMediaBufferGroupHelper(uint32_t index, MediaBufferGroupHelper * buf_group)
+{
+    Mutex::Autolock autoLock(mLock);
+    TrackInfo *trackInfo = &mTracks.editItemAt(index);
+    if(trackInfo == NULL)
+        return false;
+
+    return mReader->AttachMediaBufferGroupHelper(trackInfo->mTrackNum, buf_group);
+}
+bool ImxExtractor::DetachMediaBufferGroupHelper(uint32_t index)
+{
+    Mutex::Autolock autoLock(mLock);
+    TrackInfo *trackInfo = &mTracks.editItemAt(index);
+    if(trackInfo == NULL)
+        return false;
+
+    return mReader->DetachMediaBufferGroupHelper(trackInfo->mTrackNum);
+}
+media_status_t ImxExtractor::GetTrackMaxBufferSize(uint32_t index, size_t * max_buffer)
+{
+    Mutex::Autolock autoLock(mLock);
+    TrackInfo *trackInfo = &mTracks.editItemAt(index);
+    if(trackInfo == NULL)
+        return AMEDIA_ERROR_INVALID_PARAMETER;
+
+    *max_buffer = mReader->GetBufferReadLimitation(trackInfo->mTrackNum);
+    return AMEDIA_OK;
+}
+static CMediaExtractor* CreateExtractor(CDataSource *source, void *meta) {
+    return wrap(new ImxExtractor(new DataSourceHelper(source), (const char *)meta));
+}
+
+static CreatorFunc Sniff(
+        CDataSource *source, float *confidence, void **meta,
+        FreeMetaFunc *) {
+    DataSourceHelper helper(source);
+    if (SniffIMX(&helper, confidence, meta)) {
+        return CreateExtractor;
+    }
+
+    return NULL;
+}
+
+static const char *extensions[] = {
+    //mp4
+    "3g2",
+    "3ga",
+    "3gp",
+    "3gpp",
+    "3gpp2",
+    "m4a",
+    "m4r",
+    "m4v",
+    "mov",
+    "mp4",
+    "qt",
+    //mkv
+    "mka",
+    "mkv",
+    "webm",
+    //aac
+    "aac",
+    //amr
+    "amr",
+    "awb",
+    //flac
+    "flac",
+    "fl",
+    //mp3
+    "mp2",
+    "mp3",
+    "mpeg",
+    "mpg",
+    "mpga",
+    //mpeg2
+    "m2p",
+    "m2ts",
+    "mts",
+    "ts",
+    //others
+    "divx", "adts", "asf", "wmv", "vob",
+    "f4v", "flv", "rmvb", "rm", "ra", "rv", "ape", "dsf",
+    NULL
+};
+
+extern "C" {
+// This is the only symbol that needs to be exported
+__attribute__ ((visibility ("default")))
+ExtractorDef GETEXTRACTORDEF() {
+    return {
+        EXTRACTORDEF_VERSION,
+        UUID("30228ab1-2652-43ec-aac6-9055e6b8b39d"),
+        10000, // version
+        "IMX Extractor",
+        { .v3 = {Sniff, extensions} },
+    };
+}
+
+} // extern "C"
+
+
+}// namespace android
diff --git a/extractor/ImxExtractor.h b/extractor/ImxExtractor.h
new file mode 100755
index 0000000..df4511d
--- /dev/null
+++ b/extractor/ImxExtractor.h
@@ -0,0 +1,226 @@
+/**
+ *  Copyright 2016 Freescale Semiconductor, Inc.
+ *  Copyright 2017-2020 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+#ifndef IMX_EXTRACTOR_H_
+
+#define IMX_EXTRACTOR_H_
+
+#include <media/stagefright/foundation/AudioPresentationInfo.h>
+#include <media/MediaExtractorPluginApi.h>
+#include <media/MediaExtractorPluginHelper.h>
+#include <media/NdkMediaFormat.h>
+#include <utils/KeyedVector.h>
+#include <utils/List.h>
+#include <utils/String8.h>
+#include <utils/Vector.h>
+#include <utils/Mutex.h>
+
+#undef bool
+#define bool bool
+
+#include "fsl_media_types.h"
+#include "fsl_parser.h"
+
+namespace android {
+
+struct AMessage;
+struct ABuffer;
+
+class DataSource;
+class String8;
+struct ImxMediaSource;
+struct ImxDataSourceReader;
+class MediaBuffer;
+
+
+typedef struct
+{
+    /* creation & deletion */
+    FslParserVersionInfo                getVersionInfo;
+    FslCreateParser                     createParser;
+    FslDeleteParser                     deleteParser;
+    FslCreateParser2                    createParser2;
+
+    /* index export/import */
+    FslParserInitializeIndex            initializeIndex;
+    FslParserImportIndex                importIndex;
+    FslParserExportIndex                exportIndex;
+
+    /* movie properties */
+    FslParserIsSeekable                 isSeekable;
+    FslParserGetMovieDuration           getMovieDuration;
+    FslParserGetUserData                getUserData;
+    FslParserGetMetaData                getMetaData;
+
+    FslParserGetNumTracks               getNumTracks;
+
+    FslParserGetNumPrograms             getNumPrograms;
+    FslParserGetProgramTracks           getProgramTracks;
+
+    /* generic track properties */
+    FslParserGetTrackType               getTrackType;
+    FslParserGetTrackDuration           getTrackDuration;
+    FslParserGetLanguage                getLanguage;
+    FslParserGetBitRate                 getBitRate;
+    FslParserGetDecSpecificInfo         getDecoderSpecificInfo;
+    FslParserGetTrackExtTag             getTrackExtTag;
+
+    /* video properties */
+    FslParserGetVideoFrameWidth         getVideoFrameWidth;
+    FslParserGetVideoFrameHeight        getVideoFrameHeight;
+    FslParserGetVideoFrameRate          getVideoFrameRate;
+    FslParserGetVideoFrameRotation      getVideoFrameRotation;
+    FslParserGetVideoColorInfo          getVideoColorInfo;
+    FslParserGetVideoHDRColorInfo       getVideoHDRColorInfo;
+    FslParserGetVideoDisplayWidth       getVideoDisplayWidth;
+    FslParserGetVideoDisplayHeight      getVideoDisplayHeight;
+    FslParserGetVideoFrameCount         getVideoFrameCount;
+
+    /* audio properties */
+    FslParserGetAudioNumChannels        getAudioNumChannels;
+    FslParserGetAudioSampleRate         getAudioSampleRate;
+    FslParserGetAudioBitsPerSample      getAudioBitsPerSample;
+    FslParserGetAudioBlockAlign         getAudioBlockAlign;
+    FslParserGetAudioChannelMask        getAudioChannelMask;
+    FslParserGetAudioBitsPerFrame       getAudioBitsPerFrame;
+
+    /* text/subtitle properties */
+    FslParserGetTextTrackWidth          getTextTrackWidth;
+    FslParserGetTextTrackHeight         getTextTrackHeight;
+    FslParserGetTextTrackMime           getTextTrackMime;
+
+    /* sample reading, seek & trick mode */
+    FslParserGetReadMode                getReadMode;
+    FslParserSetReadMode                setReadMode;
+
+    FslParserEnableTrack                enableTrack;
+
+    FslParserGetNextSample              getNextSample;
+    FslParserGetNextSyncSample          getNextSyncSample;
+
+    FslParserGetFileNextSample              getFileNextSample;
+    FslParserGetFileNextSyncSample          getFileNextSyncSample;
+    FslParserGetSampleCryptoInfo       getSampleCryptoInfo;
+    FslParserSeek                       seek;
+    FslParserGetAudioPresentationNum    getAudioPresentationNum;
+    FslParserGetAudioPresentationInfo   getAudioPresentationInfo;
+
+}FslParserInterface;
+
+class ImxExtractor : public MediaExtractorPluginHelper {
+public:
+    explicit ImxExtractor(DataSourceHelper *source, const char *mime = NULL);
+
+    virtual size_t countTracks();
+    virtual MediaTrackHelper *getTrack(size_t index);
+    virtual media_status_t getTrackMetaData(AMediaFormat *meta,size_t index, uint32_t flags);
+
+    virtual media_status_t getMetaData(AMediaFormat *meta);
+
+    virtual uint32_t flags() const;
+    virtual const char * name() { return "ImxExtractor"; }
+    status_t Init();
+    status_t ActiveTrack(uint32 index);
+    status_t DisableTrack(uint32 index);
+    media_status_t HandleSeekOperation(uint32_t index,int64_t * ts, uint32_t flag);
+    media_status_t GetNextSample(uint32_t index,bool is_sync);
+    status_t CheckInterleaveEos(uint32_t index);
+    status_t ClearTrackSource(uint32_t index);
+    bool AttachMediaBufferGroupHelper(uint32_t index, MediaBufferGroupHelper * buf_group);
+    bool DetachMediaBufferGroupHelper(uint32_t index);
+    media_status_t GetTrackMaxBufferSize(uint32_t index, size_t * max_buffer);
+
+protected:
+    virtual ~ImxExtractor();
+
+private:
+    DataSourceHelper *mDataSource;
+    ImxDataSourceReader *mReader;
+    char *mMime;
+    bool bInit;
+    char mLibName[255];
+    void *mLibHandle;
+    FslParserInterface * IParser;
+    FslFileStream fileOps;
+    ParserMemoryOps memOps;
+    ParserOutputBufferOps outputBufferOps;
+
+    uint32_t mReadMode;
+    uint32_t mNumTracks;
+    bool bSeekable;
+    uint64_t mMovieDuration;
+    struct TrackInfo {
+        uint32_t mTrackNum;
+        ImxMediaSource *mSource;
+        AMediaFormat *mMeta;
+        const ImxExtractor *mExtractor;
+        bool bCodecInfoSent;
+
+        bool bPartial;
+        MediaBufferHelper * buffer;
+
+        int64_t outTs = 0;
+        int64_t outDuration = 0;
+        int32_t syncFrame = 0;
+        uint32_t max_input_size;
+        uint32_t type;
+        bool bIsNeedConvert;
+        int32_t bitPerSample;
+        bool bMkvEncrypted;
+        bool bMp4Encrypted;
+        //mp4 track crypto info
+        int32_t default_isEncrypted;
+        int32_t default_iv_size;
+        uint8_t default_kid[16];
+    };
+    Vector<TrackInfo> mTracks;
+
+    AMediaFormat *mFileMetaData;
+
+    FslParserHandle  parserHandle;
+
+    Mutex mLock;
+    int64_t currentVideoTs;
+    int64_t currentAudioTs;
+    uint32_t mVideoIndex;
+    uint32_t mAudioIndex;
+    bool mVideoActived;
+    bool mAudioActived;
+    bool bWaitForAudioStartTime;
+
+    AudioPresentationCollection mAudioPresentations;
+
+    bool isLiveStreaming() const;
+    status_t GetLibraryName();
+    status_t CreateParserInterface();
+    status_t ParseFromParser();
+    status_t ParseMetaData();
+    status_t ParseMediaFormat();
+    status_t ParseVideo(uint32 index, uint32 type,uint32 subtype);
+    status_t ParseAudio(uint32 index, uint32 type,uint32 subtype);
+    status_t ParseText(uint32 index, uint32 type,uint32 subtype);
+    status_t ParseTrackExtMetadata(uint32 index, AMediaFormat *meta);
+    int bytesForSize(size_t size);
+    void storeSize(uint8_t *data, size_t &idx, size_t size);
+    void addESDSFromCodecPrivate(AMediaFormat *meta, bool isAudio, void *priv, size_t privSize);
+    status_t addVorbisCodecInfo(AMediaFormat *meta, void *_codecPrivate, size_t codecPrivateSize);
+
+    bool isTrackModeParser();
+    status_t convertPCMData(MediaBufferHelper* inBuffer, MediaBufferHelper* outBuffer, int32_t bitPerSample);
+    status_t SetMkvCrpytBufferInfo(TrackInfo *pInfo, MediaBufferHelper *mbuf);
+    status_t SetMp4CrpytBufferInfo(TrackInfo *pInfo, MediaBufferHelper *mbuf);
+    bool ConvertMp4TimeToString(uint64 inTime, String8 *s);
+    status_t SetMkvHDRColorInfoMetadata(VideoHDRColorInfo *pInfo, AMediaFormat *meta);
+    status_t GetAudioPresentationInfo(uint32_t index);
+
+    ImxExtractor(const ImxExtractor &);
+    ImxExtractor &operator=(const ImxExtractor &);
+};
+}
+#endif
diff --git a/extractor/ImxInspector.cpp b/extractor/ImxInspector.cpp
new file mode 100755
index 0000000..bcbed5e
--- /dev/null
+++ b/extractor/ImxInspector.cpp
@@ -0,0 +1,848 @@
+/**
+ *  Copyright (C) 2016 Freescale Semiconductor, Inc.
+ *  Copyright 2018-2019 NXP
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+//#define LOG_NDEBUG 0
+#define LOG_TAG "FslInspector"
+#include <utils/Log.h>
+
+#include "ImxInspector.h"
+#include "Imx_ext.h"
+
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/ABuffer.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <media/stagefright/foundation/AUtils.h>
+#include <media/stagefright/MediaDefs.h>
+#include <utils/String8.h>
+#include <utils/RefBase.h>
+#include <media/stagefright/foundation/avc_utils.h>
+#include <media/stagefright/foundation/ByteUtils.h>
+
+#define FSL_EBML_ID_HEADER             0x1A45DFA3
+#define EBML_BYTE0 0x1A
+
+namespace android {
+
+static bool TryAACADIFType(char* buffer,size_t len, const char**mime,float *confidence)
+{
+    if(len < 4)
+        return false;
+
+    if (buffer[0] == 'A' && buffer[1] == 'D' && buffer[2] == 'I' && buffer[3] == 'F') {
+        *mime = MEDIA_MIMETYPE_AUDIO_AAC_ADTS;
+        *confidence = 0.25f;
+        return true;
+    }
+
+    return false;
+}
+
+static bool TryApeType(char* buffer,size_t len, const char** mime,float *confidence)
+{
+    if(len < 4)
+        return false;
+    if (buffer[0] == 'M' && buffer[1] == 'A' && buffer[2] == 'C' && buffer[3] == ' ') {
+        *mime = MEDIA_MIMETYPE_AUDIO_APE;
+        *confidence = 0.25f;
+        return true;
+    }
+
+    return false;
+}
+static bool TryAviType(char* buffer,size_t len, const char** mime,float *confidence)
+{
+    if(len < 12)
+        return false;
+
+    if (buffer[0] == 'R' && buffer[1] == 'I' && buffer[2] == 'F' && buffer[3] == 'F' &&
+            buffer[8] == 'A' && buffer[9] == 'V' && buffer[10] == 'I' && buffer[11] == ' ' ) {
+        *mime = MEDIA_MIMETYPE_CONTAINER_AVI;
+        *confidence = 0.25f;
+        ALOGI("TryAviType SUCCESS");
+        return true;
+    }
+
+    return false;
+}
+static bool TryMp4Type(char* buffer, size_t len, const char**mime, float *confidence)
+{
+    if(len < 12)
+        return false;
+
+    // ignore HEIF format, let google's mp4 parser to handle it
+    if (buffer[4] == 'f' && buffer[5] == 't' && buffer[6] == 'y' && buffer[7] == 'p'){
+        if((buffer[8] == 'm' && buffer[9] == 'i' && buffer[10] == 'f' && buffer[11] == '1')
+            || (buffer[8] == 'h' && buffer[9] == 'e' && buffer[10] == 'i' && buffer[11] == 'c')
+            || (buffer[8] == 'm' && buffer[9] == 's' && buffer[10] == 'f' && buffer[11] == '1')
+            || (buffer[8] == 'h' && buffer[9] == 'e' && buffer[10] == 'v' && buffer[11] == 'c')
+            )
+        {
+            return false;
+        }
+    }
+
+    if ((buffer[4] == 'f' && buffer[5] == 't' && buffer[6] == 'y' && buffer[7] == 'p')
+            || (buffer[4] == 'm' && buffer[5] == 'o' && buffer[6] == 'o' && buffer[7] == 'v')
+            || (buffer[4] == 's' && buffer[5] == 'k' && buffer[6] == 'i' && buffer[7] == 'p')
+            || (buffer[4] == 'm' && buffer[5] == 'd' && buffer[6] == 'a' && buffer[7] == 't')
+            || (buffer[4] == 'w' && buffer[5] == 'i' && buffer[6] == 'd' && buffer[7] == 'e')) {
+        *mime = MEDIA_MIMETYPE_CONTAINER_MPEG4;
+        *confidence = 0.45f; // shall be larger than google's confidence 0.4
+        ALOGI("TryMp4Type SUCCESS");
+        return true;
+    }
+
+    return false;
+}
+
+static bool TryFlvType(char* buffer,size_t len,const char**mime,float *confidence)
+{
+    if(len < 8)
+        return false;
+
+    if (buffer[0] == 'F' && buffer[1] == 'L' && buffer[2] == 'V'){
+        *mime = MEDIA_MIMETYPE_CONTAINER_FLV;
+        *confidence = 0.25f; // shall larger than SniffMP3's confidence
+        ALOGI("TryFlvType SUCCESS");
+        return true;
+    }
+
+    return false;
+}
+static bool TryAsfType(char* buffer,size_t len,const char**mime,float *confidence)
+{
+    if(len < 16)
+        return false;
+    static const char ASF_GUID[16] = {
+        0x30,0x26,0xb2,0x75,0x8e,0x66,0xcf,0x11,0xa6,0xd9,0x0,0xaa,0x0,0x62,0xce,0x6c
+    };
+    if (!memcmp(buffer, (const char*) ASF_GUID, 16)) {
+        *mime = MEDIA_MIMETYPE_CONTAINER_ASF;
+        *confidence = 0.25f;
+        ALOGI("TryAsfType SUCCESS");
+        return true;
+    }
+
+    return false;
+}
+static bool TryRmvbType(char* buffer,size_t len,const char**mime,float *confidence)
+{
+    if(len < 4)
+        return false;
+    if (buffer[0] == '.' && buffer[1] == 'R' && buffer[2] == 'M' && buffer[3] == 'F') {
+        *mime = MEDIA_MIMETYPE_CONTAINER_RMVB;
+        *confidence = 0.25f;
+         ALOGI("TryRmvbType SUCCESS");
+        return true;
+    }
+
+    return false;
+}
+
+static bool TryDsfType(char* buffer,size_t len,const char**mime,float *confidence)
+{
+    //ALOGI("TryDsfType %c%c%c%c", buffer[0], buffer[1], buffer[2], buffer[3]);
+    if(len < 4)
+        return false;
+    if (buffer[0] == 'D' && buffer[1] == 'S' && buffer[2] == 'D' && buffer[3] == ' ') {
+        *mime = MEDIA_MIMETYPE_CONTAINER_DSF;
+        *confidence = 0.25f;
+         ALOGI("TryDsfType SUCCESS");
+        return true;
+    }
+
+    return false;
+}
+
+#define MPEG_SCAN_BUFFER_SIZE       (128*1024)
+
+#define MPEGTS_HDR_SIZE             (4)
+
+#define MPEGTS_FOUND_MIN_HEADERS    (4)
+#define MPEGTS_FOUND_MAX_HEADERS    (10)
+#define MPEGTS_MAX_PACKET_SIZE      (208)
+#define MPEGTS_MIN_SYNC_SIZE        (MPEGTS_FOUND_MIN_HEADERS * MPEGTS_MAX_PACKET_SIZE)
+#define MPEGTS_MAX_SYNC_SIZE        (MPEGTS_FOUND_MAX_HEADERS * MPEGTS_MAX_PACKET_SIZE)
+#define MPEGTS_SCAN_LENGTH          (MPEGTS_MAX_SYNC_SIZE * 4)
+
+#define IS_MPEGTS_HEADER(data) (((data)[0] == 0x47) && \
+                                (((data)[1] & 0x80) == 0x00) && \
+                                (((data)[3] & 0x30) != 0x00))
+
+static char * Peek_data_from_buffer(char* pBuf, int32_t Buf_size, int32_t offset, int32_t peek_size)
+{
+    char * pPtr = NULL;
+
+    if (offset+peek_size < Buf_size) {
+        pPtr = pBuf + offset;
+    }
+
+    return pPtr;
+}
+
+/* Search ahead at intervals of packet_size for MPEG-TS headers */
+static int32_t mpeg_ts_probe_headers(char* pBuf, int32_t Buf_size, int32_t offset, int32_t packet_size)
+{
+    /* We always enter this function having found at least one header already */
+    int32_t found = 1;
+    char *data = NULL;
+
+    while (found < MPEGTS_FOUND_MAX_HEADERS) {
+        offset += packet_size;
+
+        data = Peek_data_from_buffer(pBuf, Buf_size, offset, MPEGTS_HDR_SIZE);
+        if (data == NULL || !IS_MPEGTS_HEADER(data))
+            return found;
+
+        found++;
+    }
+
+    return found;
+}
+static bool TryMpegTsType(char * pBuf, size_t buf_size)
+{
+    /* TS packet sizes to test: normal, DVHS packet size and
+    * FEC with 16 or 20 byte codes packet size. */
+    int16_t pack_sizes[] = { 188, 192, 204, 208 };
+    char *data = NULL;
+    int32_t size = 0;
+    int64_t skipped = 0;
+    int32_t found = 0;
+
+    while (skipped < MPEGTS_SCAN_LENGTH) {
+        if (size < MPEGTS_HDR_SIZE) {
+            data = Peek_data_from_buffer (pBuf, buf_size, skipped, MPEGTS_MIN_SYNC_SIZE);
+            if (!data)
+                break;
+            size = MPEGTS_MIN_SYNC_SIZE;
+        }
+
+        /* Have at least MPEGTS_HDR_SIZE bytes at this point */
+        if (IS_MPEGTS_HEADER (data)) {
+            //LOG_DEBUG ("possible mpeg-ts sync at offset %lld", skipped);
+            for (int32_t p = 0; p < 4; p++) {
+                /* Probe ahead at size pack_sizes[p] */
+                found = mpeg_ts_probe_headers (pBuf, buf_size, skipped, pack_sizes[p]);
+                if (found >= MPEGTS_FOUND_MIN_HEADERS) {
+                    return true;
+                }
+            }
+        }
+        data++;
+        skipped++;
+        size--;
+    }
+
+    return false;
+}
+
+#define MPEG_PES_ID_MIN         0xBD
+#define MPEG_PES_ID_MAX         0xFF
+#define IS_MPEG_PES_ID(b)       ((b)>= MPEG_PES_ID_MIN && (b)<= MPEG_PES_ID_MAX)
+#define IS_MPEG_SC_PREFIX(data) ( (((char *)(data))[0] == 0x00) &&  \
+                                (((char *)(data))[1] == 0x00) &&  \
+                                (((char *)(data))[2] == 0x01) )
+
+#define IS_PS_PACK_ID(b)        ((b) == 0xBA)
+#define IS_PS_SYS_HEADER_ID(b)  ((b) == 0xBB)
+
+
+#define IS_PS_PACK_HEADER(data) (IS_MPEG_SC_PREFIX(data) && IS_PS_PACK_ID(((char *)(data))[3]))
+
+#define IS_MPEG_PES_HEADER(data) (IS_MPEG_SC_PREFIX(data) && IS_MPEG_PES_ID(((char *)(data))[3]))
+
+#define MPEG2_MAX_PROBE_SIZE    (131072)  /* 128 * 1024 = 128kB should be 64 packs of the most common 2kB pack size. */
+
+#define MPEG2_MIN_SYS_HEADERS   (2)
+#define MPEG2_MAX_SYS_HEADERS   (5)
+
+/*
+ *  MPEG-1 Pack Header                                 bit
+ *  pack_start_code                                     32
+ *  '0010'                                               4
+ *  system_clock_reference_base [32..30]                 3
+ *  marker_bit (the value is  '1')                       1
+ *  system_clock_reference_base [29..15]                15
+ *  marker_bit                                           1
+ *  system_clock_reference_base [14..0]                 15
+ *  marker_bit                                           1
+ *  marker_bit                                           1                                              1
+ *  program_mux_rate                                    22
+ *  marker_bit                                           1
+ *  if (nextbits() = = system_header_start_code) {
+ *      system_header ()
+ *  }
+ */
+
+
+/*
+ *  MPEG-2 Pack Header                                 bit
+ *  pack_start_code                                     32
+ *  '01'                                                 2
+ *  system_clock_reference_base [32..30]                 3
+ *  marker_bit (the value is  '1')                       1
+ *  system_clock_reference_base [29..15]                15
+ *  marker_bit                                           1
+ *  system_clock_reference_base [14..0]                 15
+ *  marker_bit                                           1
+ *  system_clock_reference_extension                     9
+ *  marker_bit                                           1
+ *  program_mux_rate                                    22
+ *  marker_bit                                           1
+ *  marker_bit                                           1
+ *  reserved                                             5
+ *  pack_stuffing_length                                 3
+ *  for (i = 0; i < pack_stuffing_length; i++) {
+ *       stuffing_byte                                   8
+ *  }
+ *  if (nextbits() = = system_header_start_code) {
+ *      system_header ()
+ *  }
+ */
+
+static status_t is_mpeg_sys_pack_valid(char * data, uint32_t len, uint32_t * pack_size)
+{
+    // check the rest bytes after pack start code, the pack start code should already be check as valid.
+    uint32_t pack_stuffing_len;
+
+    if (len < 12)
+        return UNKNOWN_ERROR;
+
+    if ((data[4] & 0xF0) == 0x20) {
+        // find '0010', it is MPEG-1 PACK, now check the marker bits
+        if ((data[4] & 0x01) != 0x01 || (data[6] & 0x01) != 0x01 || \
+            (data[8] & 0x01) != 0x01 || (data[9] & 0x80) != 0x80 || (data[11] & 0x01) != 0x01)
+            return UNKNOWN_ERROR;
+
+        if (len >= 16 && !IS_MPEG_SC_PREFIX(data + 12))
+            return UNKNOWN_ERROR; //check next pack start code prefix failed
+
+        if (pack_size)
+            *pack_size = 12;
+        return OK;
+
+    } else if ((data[4] & 0xC0) == 0x40) {
+        // find '01', it is MPEG-2 PACK, now check the marker bits
+        if ((data[4] & 0x04) != 0x04 || (data[6] & 0x04) != 0x04 || \
+            (data[8] & 0x04) != 0x04 || (data[9] & 0x01) != 0x01 || (data[12] & 0x03) != 0x03)
+            return UNKNOWN_ERROR;
+
+        pack_stuffing_len = data[13] & 0x07;
+        if ((len >= pack_stuffing_len + 18) && !IS_MPEG_SC_PREFIX(data + pack_stuffing_len + 14))
+            return UNKNOWN_ERROR; //check next pack start code prefix failed
+
+        if (pack_size)
+            *pack_size = pack_stuffing_len + 14;
+        return OK;
+    }
+
+    return UNKNOWN_ERROR;
+}
+
+/*
+ *  PES Packet                                     bit
+ *  packet_start_code_prefix                        24
+ *  directory_stream_id                              8
+ *  PES_packet_length                               16
+ *  if (nextbits() == packet_start_code_prefix) {
+ *      pes_packet()
+ *  }
+ */
+
+static status_t is_mpeg_sys_pes_valid(char * data, uint32_t len, uint32_t * pack_size)
+{
+    // check the rest bytes after packet_start_code, the packet_start_code should already be check as valid.
+    uint32_t pes_packet_len;
+
+    if (len < 6)
+        return UNKNOWN_ERROR;
+
+    pes_packet_len = (data[4] << 8) | data[5];
+
+    if (pes_packet_len == 0 || ((len >= pes_packet_len + 10) && !IS_MPEG_SC_PREFIX(data + 6 + pes_packet_len)))
+        return UNKNOWN_ERROR;
+
+    if (pack_size)
+        *pack_size = 6 + pes_packet_len;
+    return OK;
+}
+
+/*
+ *  System Header                                     bit
+ *  system_header_start_code                           32
+ *  header_length                                      16
+ *  marker_bit                                          1
+ *  rate_bound                                         22
+ *  marker_bit                                          1
+ *  audio_bound                                         6
+ *  fixed_flag                                          1
+ *  CSPS_flag                                           1
+ *  system_audio_lock_flag                              1
+ *  system_video_lock_flag                              1
+ *  marker_bit                                          1
+ *  video_bound                                         5
+ *  packet_rate_restriction_flag                        1
+ *  reserved_bits                                       7
+ *  while (nextbits () == '1') {
+ *      stream_id                                       8
+ *      '11'                                            2
+ *      P-STD_buffer_bound_scale                        1
+ *      P-STD_buffer_size_bound                        13
+ *  }
+ */
+
+static status_t is_mpeg_sys_sys_valid(char * data, uint32_t len, uint32_t * pack_size)
+{
+    // check the rest bytes after system_header_start_code, the system_header_start_code should already be check as valid.
+    uint32_t sys_header_len;
+
+    if (len < 6)
+        return UNKNOWN_ERROR;
+
+    sys_header_len = (data[4] << 8) | data[5];
+
+    if (sys_header_len < 6 || ((len >= sys_header_len + 10) && !IS_MPEG_SC_PREFIX(data + sys_header_len + 6)))
+        return UNKNOWN_ERROR;
+
+    if (pack_size)
+        *pack_size = 6 + sys_header_len;
+
+    return OK;
+}
+
+/*
+ * Estimate Probability of Identify Random Data As MPEG System Stream
+ * 1. Check start code(32 bit): (1/2)^32
+ * 2. Search MPEG2_MIN_SYS_HEADERS headers at least: (1/2)^32^(MPEG2_MIN_SYS_HEADERS+1)
+ * 3. Probability of identify random data in MPEG2_MAX_PROBE_SIZE bytes:
+ *        (MPEG2_MAX_PROBE_SIZE - 4*(MPEG2_MIN_SYS_HEADERS+1))*8/((1/2)^32^(MPEG2_MIN_SYS_HEADERS+1))
+ * 4. MPEG2_MAX_PROBE_SIZE is 131072, MPEG2_MIN_SYS_HEADERS is 2, so probability is:
+ *        (131072 - 4*(2+1))*8/((1/2)^32^3)
+ *    the value is about the (1/2)^76
+ * 5. Since we also check marker bit and header length, the actual probability is smaller than this value.
+ */
+static bool TryMpegSysType(char * pBuf, int32_t buf_size)
+{
+    char *data, *end;
+    uint32_t pack_headers = 0;
+    uint32_t pes_headers = 0;
+    uint32_t pack_size;
+    uint32_t since_last_sync = 0;
+    int32_t len;
+
+    len = MPEG2_MAX_PROBE_SIZE;
+    do {
+        data = Peek_data_from_buffer (pBuf, buf_size, 0, 5 + len);
+        len -= 4096;
+    } while (data == NULL && len >= 32);
+
+    if (!data)
+        return false;
+
+    end = data + len;
+
+    while (data + 4 < end){
+        if (IS_MPEG_SC_PREFIX(data)) {
+            if (since_last_sync > 4)
+                pes_headers = pack_headers = 0; // only count continuous pes_headers/pack_headers
+
+            pack_size = 0;
+            if (IS_PS_PACK_ID(data[3])) {
+                if (OK == is_mpeg_sys_pack_valid(data, end - data, &pack_size))
+                    pack_headers++;
+            } else if (IS_MPEG_PES_ID(data[3])) {
+                if (OK == is_mpeg_sys_pes_valid(data, end - data, &pack_size)) {
+                    pes_headers++;
+                }
+            } else if (IS_PS_SYS_HEADER_ID(data[3])) {
+                if (OK == is_mpeg_sys_sys_valid(data, end - data, &pack_size))
+                    pack_headers++;
+            }
+
+            if (pack_size > 0) {
+                data += pack_size;
+                since_last_sync = 0;
+
+                if (pes_headers > 0 && (pack_headers + pes_headers) > MPEG2_MAX_SYS_HEADERS)
+                    return true;
+                else
+                    continue;
+            }
+        }
+        since_last_sync++;
+        data++;
+    }
+    // check pes_headers/pack_headers, pack headers are optional
+    if (pes_headers > 0 && (pack_headers + pes_headers) >= MPEG2_MIN_SYS_HEADERS)
+        return true;
+
+    return false;
+};
+
+
+
+static bool TryMpegType(DataSourceHelper *source,const char**mime,float *confidence)
+{
+
+    off64_t buffer_size = MPEG_SCAN_BUFFER_SIZE;
+
+    off64_t size;
+    if(source->getSize(&size) == OK){
+        if(size < buffer_size)
+            buffer_size = size;
+    }
+
+    void * buf= malloc(buffer_size);
+    if(buf == NULL)
+        return false;
+
+    if (source->readAt(0, buf, buffer_size) < buffer_size) {
+        free(buf);
+        return false;
+    }
+
+    if(TryMpegTsType((char*)buf, buffer_size)){
+        *mime = MEDIA_MIMETYPE_CONTAINER_MPEG2TS;
+        *confidence = 0.15;
+        free(buf);
+        ALOGI("TryMpegType TS SUCCESS");
+        return true;
+    }else if(TryMpegSysType((char*)buf, buffer_size)){
+        *mime = MEDIA_MIMETYPE_CONTAINER_MPEG2PS;
+        *confidence = 0.26; // slightly larger than MPEG2PSExtractor
+        free(buf);
+        ALOGI("TryMpegType PS SUCCESS");
+        return true;
+    }
+
+    free(buf);
+    return false;
+}
+
+static bool __attribute__ ((unused)) TryFlacType(DataSourceHelper *source, const char**mime, float *confidence)
+{
+    char buf[10];
+    int size = sizeof(buf)/sizeof(buf[0]);
+    int syncWordSize = 4;  //'fLaC'
+
+    if (source->readAt(0, buf, size) < size)
+        return false;
+
+    if (buf[0] == 'I' && buf[1] == 'D' && buf[2] == '3') {
+        // Skip the ID3v2 header.
+        uint32_t Id3Size;
+        uint32_t len = ((buf[6] & 0x7f) << 21)
+                    | ((buf[7] & 0x7f) << 14)
+                    | ((buf[8] & 0x7f) << 7)
+                    | (buf[9] & 0x7f);
+
+        if (len > 3 * 1024 * 1024)
+            len = 3 * 1024 * 1024;
+
+        len += 10;
+        Id3Size = len;
+
+        memset(buf, 0, sizeof(buf));
+        if (source->readAt(Id3Size, buf, syncWordSize) < syncWordSize)
+            return false;
+    }
+
+    if (buf[0] == 'f' && buf[1] == 'L' && buf[2] == 'a' && buf[3] == 'C') {
+        *mime = MEDIA_MIMETYPE_AUDIO_FLAC;
+        *confidence = 0.55;
+        return true;
+    }
+    return false;
+}
+
+static bool TryMkv(DataSourceHelper *source, const char**mime, float *confidence)
+{
+    long long offset = 0;
+    unsigned char scanByte = 0;
+    off64_t size = 0;
+    ssize_t n = 0;
+
+    source->getSize(&size);
+    const long long maxScanLen = (size >= 1024) ? 1024 : size;
+
+    while (offset < maxScanLen) {
+        n = source->readAt(offset, &scanByte, 1);
+        if (n <= 0)
+            return false;
+
+        if (scanByte == EBML_BYTE0)
+            break;
+
+        offset++;
+    }
+
+    n = source->readAt(offset, &scanByte, 1);
+    if (n <= 0)
+        return false;
+
+    // search EBML ID
+    int pos;
+    bool found = false;
+    for (pos = 0; pos < 4; pos++) {
+        if ((0x80 >> pos) & scanByte) {
+            found = true;
+            break;
+        }
+    }
+
+    if (!found)
+        return false;
+
+    long long header = scanByte;
+    const int len = pos + 1;
+
+    for (int i = 1; i < len; i++) {
+        header <<= 8;
+        n = source->readAt(offset + i, &scanByte, 1);
+        if (n <= 0)
+            return false;
+
+        header |= scanByte;
+    }
+
+    if (len != 4 || header != FSL_EBML_ID_HEADER)
+        return false;
+
+    ALOGI("TryMkv SUCCESS");
+    *mime = MEDIA_MIMETYPE_CONTAINER_MATROSKA;
+    *confidence = 0.65;// shall be larger than google's confidence 0.6
+    return true;
+
+}
+
+static const uint32_t kMask = 0xfffe0c00;
+
+static bool DetectAudioTypeBySource(DataSourceHelper *source, bool check_aac)
+{
+    off64_t inout_pos = 0;
+    off64_t post_id3_pos = 0;
+
+    if (source == NULL)
+        return false;
+
+    //Skip ID3 header
+    for (;;) {
+        uint8_t id3header[10];
+        if (source->readAt(inout_pos, id3header, sizeof(id3header))
+                < (ssize_t)sizeof(id3header)) {
+            // If we can't even read these 10 bytes, we might as well bail
+            // out, even if there _were_ 10 bytes of valid mp3 audio data...
+            return false;
+        }
+
+        if (memcmp("ID3", id3header, 3)) {
+            break;
+        }
+
+        // Skip the ID3v2 header.
+
+        size_t len =
+            ((id3header[6] & 0x7f) << 21)
+            | ((id3header[7] & 0x7f) << 14)
+            | ((id3header[8] & 0x7f) << 7)
+            | (id3header[9] & 0x7f);
+
+        if (len > 3 * 1024 * 1024)
+            len = 3 * 1024 * 1024;
+
+        len += 10;
+
+        inout_pos += len;
+    }
+
+    post_id3_pos = inout_pos;
+
+    off64_t pos = inout_pos;
+    if(check_aac){
+        uint8_t header[2];
+
+        if (source->readAt(pos, &header, 2) != 2) {
+            return false;
+        }
+
+        if ((header[0] == 0xff) && ((header[1] & 0xf6) == 0xf0)) {
+            return true;
+        }
+        return false;
+    }
+
+
+    bool valid = false;
+
+    const size_t kMaxReadBytes = 1024;
+    const size_t kMaxBytesChecked = 128 * 1024;
+    uint8_t buf[kMaxReadBytes];
+    ssize_t bytesToRead = kMaxReadBytes;
+    ssize_t totalBytesRead = 0;
+    ssize_t remainingBytes = 0;
+    bool reachEOS = false;
+    uint8_t *tmp = buf;
+
+    do {
+        if (pos >= (off64_t)(inout_pos + kMaxBytesChecked)) {
+            // Don't scan forever.
+            ALOGV("giving up at offset %lld", (long long)pos);
+            break;
+        }
+
+        if (remainingBytes < 4) {
+            if (reachEOS) {
+                break;
+            } else {
+                memcpy(buf, tmp, remainingBytes);
+                bytesToRead = kMaxReadBytes - remainingBytes;
+
+                /*
+                 * The next read position should start from the end of
+                 * the last buffer, and thus should include the remaining
+                 * bytes in the buffer.
+                 */
+                totalBytesRead = source->readAt(pos + remainingBytes,
+                                                buf + remainingBytes,
+                                                bytesToRead);
+                if (totalBytesRead <= 0) {
+                    break;
+                }
+                reachEOS = (totalBytesRead != bytesToRead);
+                totalBytesRead += remainingBytes;
+                remainingBytes = totalBytesRead;
+                tmp = buf;
+                continue;
+            }
+        }
+
+        uint32_t header = U32_AT(tmp);
+
+        size_t frame_size;
+        int sample_rate, num_channels, bitrate;
+        if (!GetMPEGAudioFrameSize(
+                    header, &frame_size,
+                    &sample_rate, &num_channels, &bitrate)) {
+            ++pos;
+            ++tmp;
+            --remainingBytes;
+            continue;
+        }
+
+        ALOGV("found possible 1st frame at %lld (header = 0x%08x)", (long long)pos, header);
+
+        // We found what looks like a valid frame,
+        // now find its successors.
+
+        off64_t test_pos = pos + frame_size;
+
+        valid = true;
+        for (int j = 0; j < 3; ++j) {
+            uint8_t tmp[4];
+            if (source->readAt(test_pos, tmp, 4) < 4) {
+                valid = false;
+                break;
+            }
+
+            uint32_t test_header = U32_AT(tmp);
+
+            ALOGV("subsequent header is %08x", test_header);
+
+            if ((test_header & kMask) != (header & kMask)) {
+                valid = false;
+                break;
+            }
+
+            size_t test_frame_size;
+            if (!GetMPEGAudioFrameSize(
+                        test_header, &test_frame_size)) {
+                valid = false;
+                break;
+            }
+
+            ALOGV("found subsequent frame #%d at %lld", j + 2, (long long)test_pos);
+
+            test_pos += test_frame_size;
+        }
+
+        if (valid) {
+           inout_pos = pos;
+        } else {
+            ALOGV("no dice, no valid sequence of frames found.");
+        }
+
+        ++pos;
+        ++tmp;
+        --remainingBytes;
+    } while (!valid);
+
+    return valid;
+
+}
+
+static bool TryMp3Type(DataSourceHelper *source,const char**mime,float *confidence)
+{
+    if(DetectAudioTypeBySource(source, false)){
+        *mime = MEDIA_MIMETYPE_AUDIO_MPEG;
+        *confidence = 0.25f;
+        return true;
+    }
+
+    return false;
+}
+static bool TryADTSType(DataSourceHelper *source,const char**mime,float *confidence)
+{
+    if(DetectAudioTypeBySource(source, true)){
+        *mime = MEDIA_MIMETYPE_AUDIO_AAC_ADTS;
+        *confidence = 0.25f;
+        return true;
+    }
+
+    return false;
+}
+
+typedef bool (*TRYTYPEFUNC)(char* buffer, size_t len, const char**mime, float *confidence);
+
+static TRYTYPEFUNC TryFunc[] = {
+    TryApeType,
+    TryAviType,
+    TryMp4Type,
+    TryFlvType,
+    TryAsfType,
+    TryRmvbType,
+    TryAACADIFType,
+    TryDsfType,
+};
+
+bool SniffIMX(
+        DataSourceHelper *source, float *confidence,void **meta)
+{
+    char tmp[16];
+    if (source->readAt(0, tmp, 16) < 16) {
+        ALOGE("SniffFSL read datasource fail!");
+        return false;
+    }
+
+    for(size_t i=0; i<sizeof(TryFunc)/sizeof(TRYTYPEFUNC); i++) {
+        if((*TryFunc[i])(&tmp[0], 16, (const char**)meta, confidence))
+            return true;
+    }
+
+    if(TryMpegType(source,(const char**)meta,confidence))
+        return true;
+    else if (TryMkv(source,(const char**)meta,confidence))
+        return true;
+    else if (TryMp3Type(source,(const char**)meta,confidence))
+        return true;
+    else if (TryADTSType(source,(const char**)meta,confidence))
+        return true;
+
+    return false;
+}
+}
diff --git a/extractor/ImxInspector.h b/extractor/ImxInspector.h
new file mode 100755
index 0000000..22a77a1
--- /dev/null
+++ b/extractor/ImxInspector.h
@@ -0,0 +1,20 @@
+/**
+ *  Copyright (c) 2016, Freescale Semiconductor Inc.,
+ *  All Rights Reserved.
+ *
+ *  The following programs are the sole property of Freescale Semiconductor Inc.,
+ *  and contain its proprietary and confidential information.
+ *
+ */
+#ifndef FSL_INSPECTOR_H_
+#define FSL_INSPECTOR_H_
+
+#include <media/MediaExtractorPluginHelper.h>
+
+namespace android {
+
+bool SniffIMX(
+        DataSourceHelper *source, float *confidence,void **meta);
+
+}
+#endif
diff --git a/extractor/Imx_ext.h b/extractor/Imx_ext.h
new file mode 100755
index 0000000..f50b58a
--- /dev/null
+++ b/extractor/Imx_ext.h
@@ -0,0 +1,47 @@
+/**
+ *  Copyright 2019,2020 NXP
+ *  All Rights Reserved.
+ */
+#ifndef IMX_EXT_H
+#define IMX_EXT_H
+#include <media/stagefright/MediaDefs.h>
+
+namespace android {
+
+#define AMEDIAFORMAT_KEY_SUB_FORMAT "vendor.sub-format.value"
+#define AMEDIAFORMAT_KEY_AUDIO_BLOCK_ALIGN "vendor.audio-block-align.value"
+#define AMEDIAFORMAT_KEY_BITS_PER_FRAME "vendor.bits-per-frame.value"
+#define AMEDIAFORMAT_KEY_IS_ADIF "is-adif"
+
+#define MEDIA_MIMETYPE_TEXT_SRT "text/srt"
+#define MEDIA_MIMETYPE_TEXT_SSA "text/ssa"
+#define MEDIA_MIMETYPE_TEXT_ASS "text/ass"
+
+#define MEDIA_MIMETYPE_CONTAINER_FLV "video/flv"
+#define MEDIA_MIMETYPE_CONTAINER_ASF "video/x-ms-wmv"
+#define MEDIA_MIMETYPE_CONTAINER_RMVB "video/rmff"
+#define MEDIA_MIMETYPE_CONTAINER_DSF "audio/dsf"
+
+
+#define MEDIA_MIMETYPE_VIDEO_DIVX4 "video/divx4"
+#define MEDIA_MIMETYPE_VIDEO_WMV "video/x-wmv"
+#define MEDIA_MIMETYPE_VIDEO_VC1 "video/x-vc1"
+
+#define MEDIA_MIMETYPE_VIDEO_JPEG "video/jpeg"
+
+#define MEDIA_MIMETYPE_VIDEO_REAL "video/x-pn-realvideo"
+#define MEDIA_MIMETYPE_VIDEO_SORENSON "video/x-flash-video"
+
+#define MEDIA_MIMETYPE_AUDIO_WMA "audio/x-wma"
+#define MEDIA_MIMETYPE_AUDIO_ADPCM "audio/adpcm"
+#define MEDIA_MIMETYPE_AUDIO_REAL "audio/x-pn-realaudio"
+#define MEDIA_MIMETYPE_AUDIO_APE "audio/x-monkeys-audio"
+#define MEDIA_MIMETYPE_AUDIO_AAC_FSL  "audio/aac-fsl"
+#define MEDIA_MIMETYPE_AUDIO_BSAC "audio/x-bsac"
+#define MEDIA_MIMETYPE_AUDIO_DSD  "audio/dsd"
+
+#undef AMEDIAFORMAT_KEY_BITS_PER_SAMPLE
+#define AMEDIAFORMAT_KEY_BITS_PER_SAMPLE "vendor.bits-per-sample.value"
+
+}
+#endif
\ No newline at end of file
diff --git a/extractor/exports.lds b/extractor/exports.lds
new file mode 100755
index 0000000..b1309ee
--- /dev/null
+++ b/extractor/exports.lds
@@ -0,0 +1 @@
+{ global: GETEXTRACTORDEF; local: *; };
