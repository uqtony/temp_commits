22919ea jenkins 2021-07-19

Download imx-android-11.0.0_2.2.0.tar.gz from nxp.com

Change-Id: I606ad59ac4caab2dc11debcf482be33ae5934c0c

diff --git a/CactusPlayer/AndroidManifest.xml b/CactusPlayer/AndroidManifest.xml
index 3c79939..8af0d4e 100755
--- a/CactusPlayer/AndroidManifest.xml
+++ b/CactusPlayer/AndroidManifest.xml
@@ -22,6 +22,7 @@
     <application
         android:name="com.freescale.cactusplayer.HdmiApplication"
         android:icon="@drawable/icn_media_play_pressed_holo_dark"
+        android:usesCleartextTraffic="true"
         android:label="@string/app_name" >
         
 		<activity
diff --git a/CactusPlayer/src/com/freescale/cactusplayer/VideoPlayer.java b/CactusPlayer/src/com/freescale/cactusplayer/VideoPlayer.java
index c86c00a..964a849 100755
--- a/CactusPlayer/src/com/freescale/cactusplayer/VideoPlayer.java
+++ b/CactusPlayer/src/com/freescale/cactusplayer/VideoPlayer.java
@@ -919,7 +919,7 @@ public class VideoPlayer extends Activity implements HdmiApplication.Callback,
         new MediaPlayer.OnErrorListener() {
             public boolean onError(MediaPlayer mp, int framework_err, int impl_err) {
                 Log.d(TAG, "Error: " + framework_err + "," + impl_err);
-                return true;
+                return false;
             }
         };
 
diff --git a/codec2/base/IMXC2ComponentBase.cpp b/codec2/base/IMXC2ComponentBase.cpp
old mode 100644
new mode 100755
index 9563796..6ae0b64
--- a/codec2/base/IMXC2ComponentBase.cpp
+++ b/codec2/base/IMXC2ComponentBase.cpp
@@ -15,7 +15,7 @@
  */
 
 /**
- *  Copyright 2019-2020 NXP
+ *  Copyright 2019-2021 NXP
  *  All Rights Reserved.
  *
  *  The following programs are the sole property of NXP,
@@ -132,6 +132,24 @@ void IMXC2ComponentBase::WorkHandler::onMessageReceived(const sp<AMessage> &msg)
             Reply(msg);
             break;
         }
+        case kWhatCodecNotify: {
+            int32_t what;
+            CHECK(msg->findInt32("what", &what));
+            switch (what) {
+                case kWhatClearInput:{
+                    int64_t frameIndex;
+                    CHECK(msg->findInt64("index", &frameIndex));
+                    if(C2_OK != thiz->onClearInput((uint64_t)frameIndex)){
+                        ALOGW("kWhatCodecNotify kWhatClearInput frameIndex %lld failed", (long long)frameIndex);
+                    }
+                    Reply(msg);
+                    break;
+                }
+                default:
+                    break;
+            }
+            break;
+        }
         default: {
             ALOGD("Unrecognized msg: %d", msg->what());
             break;
@@ -155,7 +173,8 @@ IMXC2ComponentBase::IMXC2ComponentBase(
     : mDummyReadView(DummyReadView()),
       mIntf(intf),
       mLooper(new ALooper),
-      mHandler(new WorkHandler) {
+      mHandler(new WorkHandler),
+      mIsFlushPending(false) {
 
     nCurFrameIndex = -1;
     nUsedFrameIndex = -1;
@@ -387,6 +406,7 @@ c2_status_t IMXC2ComponentBase::finish(
 
     std::unique_ptr<C2Work> work;
     uint64_t frameIndex;
+
     {
         // find one work : 1. input is used; 2. input ts match output ts
         Mutexed<PendingWork>::Locked pending(mPendingWork);
@@ -427,45 +447,14 @@ c2_status_t IMXC2ComponentBase::finish(
         if (work->worklets.front()->output.flags & C2FrameData::FLAG_END_OF_STREAM)
             bRecieveOutputEos = true;
 
+        ALOGV("finish timestamp=%lld output ts=%lld",(long long)timestamp, (long long)work->worklets.front()->output.ordinal.timestamp.peeku());
+
         Mutexed<ExecState>::Locked state(mExecState);
         std::shared_ptr<C2Component::Listener> listener = state->mListener;
         state.unlock();
         listener->onWorkDone_nb(shared_from_this(), vec(work));
 
-        {
-            //add expired time to avoid input buffer return immediately. the value should be less than 3 seconds
-            #define EXPIRED_TIME (2000000L)
-            std::unique_ptr<C2Work> unexpected;
-            Mutexed<PendingWork>::Locked pending(mPendingWork);
-
-            for (;;) {
-                auto iter = std::find_if(pending->begin(), pending->end(),
-                                     [timestamp, frameIndex](const std::unique_ptr<C2Work>& w) {
-                                         return (w->input.ordinal.timestamp != (-1)
-                                                    && w->input.ordinal.timestamp + EXPIRED_TIME < timestamp
-                                                    && w->input.ordinal.frameIndex < frameIndex
-                                                    && (w->input.flags & C2FrameData::FLAG_END_OF_STREAM) == 0);
-                                     });
-
-                if (iter != pending->end()) {
-                    unexpected = std::move(*iter);
-                    pending->erase(iter);
-                }
-
-                if (unexpected) {
-                    ALOGD("unexpected pending work ts=%lld, frameIndex=%lld",
-                        (long long)unexpected->input.ordinal.timestamp.peeku(),
-                        (long long)unexpected->input.ordinal.frameIndex.peeku());
-                    unexpected->result = C2_OK;
-                    Mutexed<ExecState>::Locked state(mExecState);
-                    std::shared_ptr<C2Component::Listener> listener = state->mListener;
-                    state.unlock();
-                    listener->onWorkDone_nb(shared_from_this(), vec(unexpected));
-                    continue;
-                } else
-                    break;
-            }
-        }
+        returnExpiredC2Work(timestamp, frameIndex);
 
         return C2_OK;
     } else {
@@ -474,6 +463,43 @@ c2_status_t IMXC2ComponentBase::finish(
         return C2_NOT_FOUND;
     }
 }
+//TODO: check output ts distance
+void IMXC2ComponentBase::returnExpiredC2Work(uint64_t timestamp,uint64_t frameIndex)
+{
+    //search and return C2Work which timestamp in mPendingWork earlier than current ts
+    //the expired time should be less than 3 seconds
+    #define EXPIRED_TIME (2000000L)
+    std::unique_ptr<C2Work> unexpected;
+    Mutexed<PendingWork>::Locked pending(mPendingWork);
+
+    for (;;) {
+        auto iter = std::find_if(pending->begin(), pending->end(),
+                             [timestamp, frameIndex](const std::unique_ptr<C2Work>& w) {
+                                 return (w->input.ordinal.timestamp != (-1)
+                                            && w->input.ordinal.timestamp + EXPIRED_TIME < timestamp
+                                            && w->input.ordinal.frameIndex < frameIndex
+                                            && (w->input.flags & C2FrameData::FLAG_END_OF_STREAM) == 0);
+                             });
+
+        if (iter != pending->end()) {
+            unexpected = std::move(*iter);
+            pending->erase(iter);
+        }
+
+        if (unexpected) {
+            ALOGD("unexpected pending work ts=%lld, frameIndex=%lld",
+                (long long)unexpected->input.ordinal.timestamp.peeku(),
+                (long long)unexpected->input.ordinal.frameIndex.peeku());
+            unexpected->result = C2_OK;
+            Mutexed<ExecState>::Locked state(mExecState);
+            std::shared_ptr<C2Component::Listener> listener = state->mListener;
+            state.unlock();
+            listener->onWorkDone_nb(shared_from_this(), vec(unexpected));
+            continue;
+        } else
+            break;
+    }
+}
 
 c2_status_t IMXC2ComponentBase::finishWithException(bool eos, bool force) {
     // if exception is eos, then just return eos, otherwise decoder meet corrupted stream, need report it.
@@ -534,20 +560,6 @@ c2_status_t IMXC2ComponentBase::finishWithException(bool eos, bool force) {
     return C2_OK;
 }
 
-C2Work* IMXC2ComponentBase::getPendingWorkByFrameIndex(uint64_t frameIndex) {
-    Mutexed<PendingWork>::Locked pending(mPendingWork);
-    auto workIter = std::find_if(pending->begin(), pending->end(),
-                                 [frameIndex](const std::unique_ptr<C2Work>& w) {
-                                     return w->input.ordinal.frameIndex == frameIndex;
-                                 });
-
-    if (workIter == pending->end()) {
-        ALOGV("Can't find pending work by bitstream ID: %llu", (unsigned long long)frameIndex);
-        return nullptr;
-    }
-    return workIter->get();
-}
-
 c2_status_t IMXC2ComponentBase::skipOnePendingWork(uint64_t frameIndex) {
     std::unique_ptr<C2Work> work;
     Mutexed<PendingWork>::Locked pending(mPendingWork);
@@ -579,9 +591,50 @@ c2_status_t IMXC2ComponentBase::skipOnePendingWork(uint64_t frameIndex) {
 
     ALOGV("skip pending work but pending queue is empty");
 
-    return C2_BAD_VALUE;
+    return C2_NOT_FOUND;
 }
+c2_status_t IMXC2ComponentBase::postClearInputMsg(uint64_t frameIndex)
+{
+    {
+        Mutexed<ExecState>::Locked state(mExecState);
+        if (state->mState != RUNNING) {
+            return C2_BAD_STATE;
+        }
+    }
+
+    if (frameIndex < nCurFrameIndex)
+        return onClearInput(frameIndex);
+
+    sp<AMessage> reply;
+    sp<AMessage> msg = new AMessage(WorkHandler::kWhatCodecNotify, mHandler);
+    msg->setInt32("what", kWhatClearInput);
+    msg->setInt64("index", frameIndex);
+    msg->postAndAwaitResponse(&reply);
 
+    return C2_OK;
+}
+c2_status_t IMXC2ComponentBase::onClearInput(uint64_t frameIndex)
+{
+    C2Work* work = nullptr;
+    Mutexed<PendingWork>::Locked pending(mPendingWork);
+    auto workIter = std::find_if(pending->begin(), pending->end(),
+                                 [frameIndex](const std::unique_ptr<C2Work>& w) {
+                                     return w->input.ordinal.frameIndex == frameIndex;
+                                 });
+
+    if (workIter != pending->end()) {
+        work = workIter->get();
+    }
+
+    //clear input buffer so CCodecBufferChannel::onInputBufferDone() will be called
+    if(work){
+        work->input.buffers.front().reset();
+        ALOGV("onClearInput index=%lld 
", (long long)frameIndex);
+        return C2_OK;
+    }
+
+    return C2_NOT_FOUND;
+}
 c2_status_t IMXC2ComponentBase::initOutputBlockPool() {
     c2_status_t err = C2_OK;
     // TODO: don't use query_vb
@@ -639,7 +692,7 @@ bool IMXC2ComponentBase::processQueue() {
     std::unique_ptr<C2Work> work;
     uint64_t generation;
     int32_t drainMode;
-    bool isFlushPending = false;
+    mIsFlushPending = false;
     bool hasQueuedWork = false;
 
     {
@@ -650,17 +703,18 @@ bool IMXC2ComponentBase::processQueue() {
 
         generation = queue->generation();
         drainMode = queue->drainMode();
-        isFlushPending = queue->popPendingFlush();
+        mIsFlushPending = queue->popPendingFlush();
         work = queue->pop_front();
         hasQueuedWork = !queue->empty();
     }
-    if (isFlushPending) {
+    if (mIsFlushPending) {
         ALOGV("processing pending flush");
         c2_status_t err = onFlush_sm();
         if (err != C2_OK) {
             ALOGD("flush err: %d", err);
             // TODO: error
         }
+        mIsFlushPending = false;
     }
 
     if (!mOutputBlockPool) {
diff --git a/codec2/base/IMXUtils.cpp b/codec2/base/IMXUtils.cpp
index dd1ab4d..2d54920 100755
--- a/codec2/base/IMXUtils.cpp
+++ b/codec2/base/IMXUtils.cpp
@@ -26,8 +26,10 @@ typedef struct {
 
 static NameMime NameMimeMap[] = {
         {"c2.imx.avc.decoder", MEDIA_MIMETYPE_VIDEO_AVC},
+        {"c2.imx.avc.decoder.secure", MEDIA_MIMETYPE_VIDEO_AVC},
         {"c2.imx.avc.encoder", MEDIA_MIMETYPE_VIDEO_AVC},
         {"c2.imx.hevc.decoder", MEDIA_MIMETYPE_VIDEO_HEVC},
+        {"c2.imx.hevc.decoder.secure", MEDIA_MIMETYPE_VIDEO_HEVC},
         {"c2.imx.hevc.encoder", MEDIA_MIMETYPE_VIDEO_HEVC},
         {"c2.imx.vp8.decoder", MEDIA_MIMETYPE_VIDEO_VP8},
         {"c2.imx.vp8.encoder", MEDIA_MIMETYPE_VIDEO_VP8},
diff --git a/codec2/base/include/IMXC2ComponentBase.h b/codec2/base/include/IMXC2ComponentBase.h
index d9531ff..296b643 100755
--- a/codec2/base/include/IMXC2ComponentBase.h
+++ b/codec2/base/include/IMXC2ComponentBase.h
@@ -37,7 +37,6 @@
 
 namespace android {
 
-
 class IMXC2ComponentBase
         : public C2Component, public std::enable_shared_from_this<IMXC2ComponentBase> {
 public:
@@ -129,11 +128,12 @@ protected:
 
     c2_status_t finishWithException(bool eos, bool force);
 
-    C2Work* getPendingWorkByTimestamp(uint64_t timestamp);
+    c2_status_t skipOnePendingWork(uint64_t frameIndex);
 
-    C2Work* getPendingWorkByFrameIndex(uint64_t frameIndex);
+    c2_status_t postClearInputMsg(uint64_t frameIndex);//async message to clear input buffer
+    c2_status_t onClearInput(uint64_t frameIndex);//sync handle to clear input buffer
 
-    c2_status_t skipOnePendingWork(uint64_t frameIndex);
+    void returnExpiredC2Work(uint64_t timestamp, uint64_t frameIndex);
 
     std::shared_ptr<C2Buffer> createLinearBuffer(
             const std::shared_ptr<C2LinearBlock> &block);
@@ -161,7 +161,6 @@ protected:
 private:
     c2_status_t initOutputBlockPool();
 
-
     const std::shared_ptr<C2ComponentInterface> mIntf;
 
     class WorkHandler : public AHandler {
@@ -173,6 +172,7 @@ private:
             kWhatStop,
             kWhatReset,
             kWhatRelease,
+            kWhatCodecNotify,
         };
 
         WorkHandler();
@@ -188,6 +188,11 @@ private:
         bool mRunning;
     };
 
+    //enum for kWhatCodecNotify
+    enum {
+        kWhatClearInput,
+    };
+
     enum {
         UNINITIALIZED,
         STOPPED,
@@ -243,6 +248,8 @@ private:
 
     //std::shared_ptr<C2BlockPool> mOutputBlockPool;
 
+    bool mIsFlushPending;
+
     IMXC2ComponentBase() = delete;
 };
 
diff --git a/codec2/process/common/ProcessBase.cpp b/codec2/process/common/ProcessBase.cpp
index e579ee4..448ced8 100644
--- a/codec2/process/common/ProcessBase.cpp
+++ b/codec2/process/common/ProcessBase.cpp
@@ -155,6 +155,10 @@ status_t ProcessBase::setConfig(ProcessConfig index, void* pConfig) {
             memcpy(&sInFormat, pConfig, sizeof(PROCESSBASE_FORMAT));
             break;
         }
+        case PROCESS_CONFIG_OUTPUT_FORMAT: {
+            memcpy(&sOutFormat, pConfig, sizeof(PROCESSBASE_FORMAT));
+            break;
+        }
 
         default: {
             ret = DoSetConfig(index, pConfig);
diff --git a/codec2/process/common/ProcessBase.h b/codec2/process/common/ProcessBase.h
index a847b73..d826b47 100644
--- a/codec2/process/common/ProcessBase.h
+++ b/codec2/process/common/ProcessBase.h
@@ -61,6 +61,7 @@ typedef enum {
     PROCESS_CONFIG_INPUT_FORMAT = 0,
     PROCESS_CONFIG_OUTPUT_FORMAT,
     PROCESS_CONFIG_INTRA_REFRESH,
+    PROCESS_CONFIG_PIXEL_FORMAT,
 } ProcessConfig;
 
 class ProcessBase : public AHandler {
diff --git a/codec2/process/g2d_post/G2dPostProcess.cpp b/codec2/process/g2d_post/G2dPostProcess.cpp
index 3d9d4d0..3590d62 100644
--- a/codec2/process/g2d_post/G2dPostProcess.cpp
+++ b/codec2/process/g2d_post/G2dPostProcess.cpp
@@ -343,7 +343,7 @@ void G2dPostProcess::setPostProcessParameters() {
     sOutFormat.height = sInFormat.height;
     sOutFormat.stride = sInFormat.width;
 
-    if(sInFormat.format == HAL_PIXEL_FORMAT_P010 || (sInFormat.flag & PROCESSBASE_FORMAT_FLAG_NV12)){
+    if(sInFormat.format == HAL_PIXEL_FORMAT_P010_TILED || (sInFormat.flag & PROCESSBASE_FORMAT_FLAG_NV12)){
         sOutFormat.format = HAL_PIXEL_FORMAT_YCbCr_420_SP;
         sOutFormat.bufferSize = sOutFormat.width * sOutFormat.height * 3/2;
         ALOGV("sOutFormat.format HAL_PIXEL_FORMAT_YCbCr_420_SP");
@@ -370,7 +370,7 @@ void G2dPostProcess::setPostProcessParameters() {
         G2DPP_LOG("it is interlaced source");
     }
 
-    if(sInFormat.format == HAL_PIXEL_FORMAT_P010){
+    if(sInFormat.format == HAL_PIXEL_FORMAT_P010_TILED){
         sSrcSurface.tiling = G2D_AMPHION_TILED_10BIT;
         ALOGV("10 bit video");
     }
diff --git a/codec2/process/g2d_pre/G2dPreProcess.cpp b/codec2/process/g2d_pre/G2dPreProcess.cpp
old mode 100755
new mode 100644
index 46e2eb6..abc13d9
--- a/codec2/process/g2d_pre/G2dPreProcess.cpp
+++ b/codec2/process/g2d_pre/G2dPreProcess.cpp
@@ -247,17 +247,11 @@ status_t G2dPreProcess::onInit() {
     pPPHandle->sOutput.format = G2D_YUYV;
     pPPHandle->sOutput.left = 0;
     pPPHandle->sOutput.top = 0;
-    pPPHandle->sOutput.right = sInFormat.width;
-    pPPHandle->sOutput.bottom = sInFormat.height;
-    pPPHandle->sOutput.width = sInFormat.width;
-    pPPHandle->sOutput.height = sInFormat.height;
-    pPPHandle->sOutput.stride = sInFormat.stride;
-
-    sOutFormat.width = pPPHandle->sOutput.width;
-    sOutFormat.height = pPPHandle->sOutput.height;
-    sOutFormat.stride = pPPHandle->sOutput.stride;
-    sOutFormat.format = HAL_PIXEL_FORMAT_YCbCr_422_I;
-    sOutFormat.bufferSize = sOutFormat.width * sOutFormat.height * 2;
+    pPPHandle->sOutput.right = sOutFormat.width;
+    pPPHandle->sOutput.bottom = sOutFormat.height;
+    pPPHandle->sOutput.width = sOutFormat.width;
+    pPPHandle->sOutput.height = sOutFormat.height;
+    pPPHandle->sOutput.stride = sOutFormat.stride;
 
     G2DPP_LOG("input right %d bottom %d", pPPHandle->sInput.right, pPPHandle->sInput.bottom);
     G2DPP_LOG("input aligned w h = %d x %d", alignedWidth, alignedHeight);
@@ -296,7 +290,25 @@ status_t G2dPreProcess::DoSetConfig(ProcessConfig index, void* pConfig) {
 }
 
 status_t G2dPreProcess::DoGetConfig(ProcessConfig index, void* pConfig) {
-    return BAD_VALUE; // not support any index yet
+
+    status_t ret = BAD_VALUE;
+
+    if (!pConfig)
+        return ret;
+
+    switch (index) {
+        case PROCESS_CONFIG_PIXEL_FORMAT: {
+            int* pixel_format = (int*)pConfig;
+            *pixel_format = HAL_PIXEL_FORMAT_YCbCr_422_I;
+            ret = OK;
+            break;
+        }
+        default: {
+            break;
+        }
+    }
+
+    return ret;
 }
 
 ProcessBase * CreatePreProcessInstance() {
diff --git a/codec2/process/isi_pre/IsiPreProcess.cpp b/codec2/process/isi_pre/IsiPreProcess.cpp
index ae58ba3..d6bb2cb 100644
--- a/codec2/process/isi_pre/IsiPreProcess.cpp
+++ b/codec2/process/isi_pre/IsiPreProcess.cpp
@@ -126,7 +126,7 @@ uint32_t IsiPreProcess::getV4l2Format(uint32_t color_format)
 status_t IsiPreProcess::prepareInputParams()
 {
     status_t ret = UNKNOWN_ERROR;
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     sInFormat.width = Align(sInFormat.width, mWidthAlign);
     //sInFormat.height = sInFormat.height;
@@ -149,7 +149,7 @@ status_t IsiPreProcess::prepareInputParams()
 status_t IsiPreProcess::prepareOutputParams()
 {
     status_t ret = UNKNOWN_ERROR;
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     sOutFormat.width = Align(sInFormat.width, mWidthAlign);
     sOutFormat.height = sInFormat.height;
@@ -173,7 +173,7 @@ status_t IsiPreProcess::prepareOutputParams()
 status_t IsiPreProcess::SetInputFormats()
 {
     int result = 0;
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     struct v4l2_format format;
     memset(&format, 0, sizeof(format));
@@ -223,7 +223,7 @@ status_t IsiPreProcess::SetInputFormats()
 status_t IsiPreProcess::SetOutputFormats()
 {
     int result = 0;
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     struct v4l2_format format;
     memset(&format, 0, sizeof(format));
@@ -279,7 +279,7 @@ status_t IsiPreProcess::SetOutputFormats()
 status_t IsiPreProcess::prepareInputBuffers()
 {
     int result = 0;
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     struct v4l2_requestbuffers reqbufs;
     memset(&reqbufs, 0, sizeof(reqbufs));
@@ -300,7 +300,7 @@ status_t IsiPreProcess::prepareInputBuffers()
 status_t IsiPreProcess::prepareOutputBuffers()
 {
     int result = 0;
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     struct v4l2_requestbuffers reqbufs;
     memset(&reqbufs, 0, sizeof(reqbufs));
@@ -346,7 +346,7 @@ status_t IsiPreProcess::HandlePollThread()
 }
 status_t IsiPreProcess::createPollThread()
 {
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     if(!bPollStarted){
         pthread_attr_t attr;
@@ -376,37 +376,52 @@ status_t IsiPreProcess::dequeueInputBuffer()
 {
     int result = 0;
     int input_id = -1;
-    Mutex::Autolock autoLock(mLock);
-    if(!bInputStreamOn)
-        return OK;
+    uint32_t index = 0;
 
-    struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane plane[kInputBufferPlaneNum];
-    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
-    memset(plane, 0, sizeof(v4l2_plane));
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
-    stV4lBuf.memory = mInMemType;
-    stV4lBuf.m.planes = plane;
-    stV4lBuf.length = kInputBufferPlaneNum;
-    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
-    if(result < 0)
-        return UNKNOWN_ERROR;
+    {
+        Mutex::Autolock autoLock(mIsiLock);
+        if(!bInputStreamOn)
+            return OK;
 
-    ALOGV("OUTPUT_MPLANE VIDIOC_DQBUF index=%d
", stV4lBuf.index);
+        struct v4l2_buffer stV4lBuf;
+        struct v4l2_plane plane[kInputBufferPlaneNum];
+        memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+        memset(plane, 0, sizeof(v4l2_plane));
+        stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        stV4lBuf.memory = mInMemType;
+        stV4lBuf.m.planes = plane;
+        stV4lBuf.length = kInputBufferPlaneNum;
+        result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+        if(result < 0)
+            return UNKNOWN_ERROR;
 
-    if(stV4lBuf.index >= 16)
-        return BAD_INDEX;
+        ALOGV("OUTPUT_MPLANE VIDIOC_DQBUF index=%d
", stV4lBuf.index);
 
-    ALOGV("dequeueInputBuffer NotifyInputBufferUsed id=%d",stV4lBuf.index);
+        if(stV4lBuf.index >= 16)
+            return BAD_INDEX;
+
+
+        index = stV4lBuf.index;
+    }
 
 
     int inId = 0;
-    int inFd = -1;
-    uint32_t inFlag = 0;
-    unsigned long inPhys;
+    bool notify = false;
+    {
+        int inFd = -1;
+        uint32_t inFlag = 0;
+        unsigned long inPhys;
 
-    if(OK == ProcessFrameGetNode(&sInMemInfo, stV4lBuf.index, &inPhys, &inId, &inFd, &inFlag)){
-        ProcessFrameClear(&sInMemInfo, stV4lBuf.index);
+        Mutex::Autolock autoLock(mLock);
+
+        if(OK == ProcessFrameGetNode(&sInMemInfo, index, &inPhys, &inId, &inFd, &inFlag)){
+            ProcessFrameClear(&sInMemInfo, index);
+            notify = true;
+        }
+    }
+
+    if(notify){
+        ALOGV("dequeueInputBuffer NotifyInputBufferUsed id=%d",index);
         NotifyProcessInputUsed(inId);
     }
 
@@ -415,50 +430,60 @@ status_t IsiPreProcess::dequeueInputBuffer()
 status_t IsiPreProcess::dequeueOutputBuffer()
 {
     int result = 0;
-    Mutex::Autolock autoLock(mLock);
-    if(!bOutputStreamOn)
-        return OK;
-
+    
     uint64_t ts = 0;
-    uint32_t out_len = 0;
     int keyFrame = 0;
-    uint32_t out_offset = 0;
-
-    struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane planes[kOutputBufferPlaneNum];
-    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
-    memset(planes, 0, sizeof(planes));
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-    stV4lBuf.memory = mOutMemType;
-    stV4lBuf.m.planes = planes;
-    stV4lBuf.length = kOutputBufferPlaneNum;
-    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
-    if(result < 0)
-        return UNKNOWN_ERROR;
-
-    if(stV4lBuf.index >= DEFAULT_PROCESS_BUFFER_NUM)
-        return BAD_INDEX;
-
-    out_len = stV4lBuf.m.planes[0].bytesused;
-    ts = (uint64_t)stV4lBuf.timestamp.tv_sec *1000000;
-    ts += stV4lBuf.timestamp.tv_usec;
-    keyFrame = (stV4lBuf.flags & V4L2_BUF_FLAG_KEYFRAME)?1:0;
-
-    ALOGV("CAPTURE_MPLANE VIDIOC_DQBUF index=%d, len=%d,ts=%lld,flag=%x",stV4lBuf.index, out_len, (long long)ts, stV4lBuf.flags);
-
-
+    uint32_t index = 0;
+
+    {
+        Mutex::Autolock autoLock(mIsiLock);
+        if(!bOutputStreamOn)
+            return OK;
+
+
+        struct v4l2_buffer stV4lBuf;
+        struct v4l2_plane planes[kOutputBufferPlaneNum];
+        memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+        memset(planes, 0, sizeof(planes));
+        stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        stV4lBuf.memory = mOutMemType;
+        stV4lBuf.m.planes = planes;
+        stV4lBuf.length = kOutputBufferPlaneNum;
+        result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+        if(result < 0)
+            return UNKNOWN_ERROR;
+
+        if(stV4lBuf.index >= DEFAULT_PROCESS_BUFFER_NUM)
+            return BAD_INDEX;
+        
+
+        ts = (uint64_t)stV4lBuf.timestamp.tv_sec *1000000;
+        ts += stV4lBuf.timestamp.tv_usec;
+        keyFrame = (stV4lBuf.flags & V4L2_BUF_FLAG_KEYFRAME)?1:0;
+        index = stV4lBuf.index;
+        ALOGV("CAPTURE_MPLANE VIDIOC_DQBUF index=%d, len=%d,ts=%lld,flag=%x",stV4lBuf.index, stV4lBuf.m.planes[0].bytesused, (long long)ts, stV4lBuf.flags);
+    }
+
+    bool notify = false;
     int outId = 0;
-    int outFd = -1;
     uint32_t outFlag = 0;
-    unsigned long outPhys;
 
-    if(OK == ProcessFrameGetNode(&sOutMemInfo, stV4lBuf.index, &outPhys, &outId, &outFd, &outFlag)){
-        //ProcessFrameClear(&sOutMemInfo, stV4lBuf.index);
-        if(keyFrame)
-            outFlag = FLAG_SYNC_FRAME;
-        NotifyProcessDone(outId, outFlag);
-        ALOGV("NotifyProcessDone blockId=%d,len=%d,ts=%lld,keyFrame=%x,out_offset=%d",outId, out_len, (long long)ts, keyFrame,out_offset);
+    {
+        int outFd = -1;
+        unsigned long outPhys;
+        Mutex::Autolock autoLock(mLock);
 
+        if(OK == ProcessFrameGetNode(&sOutMemInfo, index, &outPhys, &outId, &outFd, &outFlag)){
+            //ProcessFrameClear(&sOutMemInfo, stV4lBuf.index);
+            if(keyFrame)
+                outFlag = FLAG_SYNC_FRAME;
+            notify = true;
+        }
+    }
+
+    if(notify){
+        ALOGV("NotifyProcessDone blockId=%d,ts=%lld,keyFrame=%x,out_offset=%d",outId, (long long)ts, keyFrame);
+        NotifyProcessDone(outId, outFlag);
     }
 
     return OK;
@@ -500,6 +525,7 @@ status_t IsiPreProcess::queueInput()
         bSyncFrame = false;
     }
 
+    mIsiLock.lock();
     struct v4l2_buffer stV4lBuf;
     struct v4l2_plane plane[kInputBufferPlaneNum];
     memset(&stV4lBuf, 0, sizeof(stV4lBuf));
@@ -528,10 +554,12 @@ status_t IsiPreProcess::queueInput()
     result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
     if(result < 0){
         ALOGE("OUTPUT_MPLANE VIDIOC_QBUF failed, index=%d, result=%x",inIndex,result);
+        mIsiLock.unlock();
         return UNKNOWN_ERROR;
     }
 
     mInputQueue.pop();
+    mIsiLock.unlock();
 
     if(!bInputStreamOn)
         startInputStream();
@@ -577,6 +605,7 @@ status_t IsiPreProcess::queueOutput()
         bSyncFrame = false;
     }
     #endif
+    mIsiLock.lock();
 
     struct v4l2_buffer stV4lBuf;
     struct v4l2_plane planes[kOutputBufferPlaneNum];
@@ -611,11 +640,13 @@ status_t IsiPreProcess::queueOutput()
     result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
     if(result < 0){
         ALOGE("CAPTURE_MPLANE VIDIOC_QBUF failed, index=%d, result=%x",outIndex,result);
+        mIsiLock.unlock();
         return UNKNOWN_ERROR;
     }
 
     mAddOutCnt++;
     mOutputQueue.pop();
+    mIsiLock.unlock();
 
     if(!bOutputStreamOn && mAddOutCnt == DEFAULT_PROCESS_BUFFER_NUM)
         startOutputStream();
@@ -643,7 +674,7 @@ status_t IsiPreProcess::onProcess() {
 }
 status_t IsiPreProcess::startInputStream()
 {
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
     if(!bInputStreamOn){
         enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
         if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
@@ -655,7 +686,7 @@ status_t IsiPreProcess::startInputStream()
 }
 status_t IsiPreProcess::stopInputStream()
 {
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
     if(bInputStreamOn){
         enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
         if(0 == ioctl(mFd, VIDIOC_STREAMOFF, &buf_type)){
@@ -668,7 +699,7 @@ status_t IsiPreProcess::stopInputStream()
 }
 status_t IsiPreProcess::startOutputStream()
 {
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
     if(!bOutputStreamOn){
         enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
         if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
@@ -680,7 +711,7 @@ status_t IsiPreProcess::startOutputStream()
 }
 status_t IsiPreProcess::stopOutputStream()
 {
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     //call VIDIOC_STREAMOFF and ignore the result
     enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
@@ -692,7 +723,7 @@ status_t IsiPreProcess::stopOutputStream()
 }
 status_t IsiPreProcess::destroyInputBuffers()
 {
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     int result = 0;
     struct v4l2_requestbuffers reqbufs;
@@ -711,7 +742,7 @@ status_t IsiPreProcess::destroyInputBuffers()
 }
 status_t IsiPreProcess::destroyOutputBuffers()
 {
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     int result = 0;
     struct v4l2_requestbuffers reqbufs;
@@ -742,7 +773,7 @@ status_t IsiPreProcess::onDestroy()
 
     destroyPollThread();
 
-    Mutex::Autolock autoLock(mLock);
+    Mutex::Autolock autoLock(mIsiLock);
 
     if(pDev == NULL)
         return UNKNOWN_ERROR;
@@ -794,7 +825,26 @@ status_t IsiPreProcess::DoSetConfig(ProcessConfig index, void* pConfig) {
 }
 
 status_t IsiPreProcess::DoGetConfig(ProcessConfig index, void* pConfig) {
-    return BAD_VALUE; // not support any index yet
+
+    status_t ret = BAD_VALUE;
+
+    if (!pConfig)
+        return ret;
+
+    switch (index) {
+        case PROCESS_CONFIG_PIXEL_FORMAT: {
+            int* pixel_format = (int*)pConfig;
+            *pixel_format = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+            ret = OK;
+            break;
+        }
+        default: {
+            break;
+        }
+    }
+
+    return ret;
+
 }
 ProcessBase * CreatePreProcessInstance() {
     return static_cast<ProcessBase *>(new IsiPreProcess());
diff --git a/codec2/process/isi_pre/IsiPreProcess.h b/codec2/process/isi_pre/IsiPreProcess.h
index 21d69a1..d845985 100644
--- a/codec2/process/isi_pre/IsiPreProcess.h
+++ b/codec2/process/isi_pre/IsiPreProcess.h
@@ -48,7 +48,7 @@ private:
     uint32_t mWidthAlign;
     uint32_t mHeightAlign;
 
-    Mutex mLock;
+    Mutex mIsiLock;
 
     uint64_t mAddOutCnt;
     
diff --git a/codec2/store/Android.bp b/codec2/store/Android.bp
index 3072c85..5175b6e 100644
--- a/codec2/store/Android.bp
+++ b/codec2/store/Android.bp
@@ -11,10 +11,14 @@ cc_library_shared {
         "libcodec2_hidl@1.0",
         "liblog",
         "libcodec2_vndk",
+        "libion",
     ],
 
     include_dirs: [
         "vendor/nxp/imx_android_mm/codec2/include",
+        "device/nxp/common/kernel-headers",
+        "system/memory/libion",
+        "system/memory/libion/kernel-headers/linux",
     ],
 
     defaults: [
diff --git a/codec2/store/ImxC2Store.cpp b/codec2/store/ImxC2Store.cpp
index e404ec4..0cb95c3 100755
--- a/codec2/store/ImxC2Store.cpp
+++ b/codec2/store/ImxC2Store.cpp
@@ -20,6 +20,9 @@
 #include <C2AllocatorIon.h>
 #include <dlfcn.h>
 #include <C2_imx.h>
+#include <ion/ion.h>
+#include <linux/version.h>
+#include <ion_4.12.h>
 #include "RegistryParser.h"
 
 namespace android {
@@ -27,6 +30,10 @@ namespace android {
 typedef ::C2ComponentFactory* (*IMXCreateCodec2FactoryFunc)(C2String name);
 typedef void (*IMXDestroyCodec2FactoryFunc)(::C2ComponentFactory*);
 
+static int gNonSecureHeaps = 0;
+static int gSecureHeaps = 0;
+static void initIonHeaps();
+
 class ImxC2Store : public C2ComponentStore {
 public:
     ImxC2Store();
@@ -110,13 +117,17 @@ private:
             setDerivedInstance(this);
             struct Setter {
                 static C2R setIonUsage(bool /* mayBlock */, C2P<C2StoreIonUsageInfo> &me) {
-                    me.set().heapMask = ~0;
+                    me.set().heapMask = gNonSecureHeaps;
                     me.set().minAlignment = 0;
                     if (me.set().usage & (C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE)) {
                         me.set().allocFlags = 1;    //ION_FLAG_CACHED;
                     } else {
                         me.set().allocFlags = 0;
                     }
+                    if (me.set().usage & (C2MemoryUsage::READ_PROTECTED)) {
+                        me.set().allocFlags = 0;
+                        me.set().heapMask = gSecureHeaps;
+                    }
                     return C2R::Ok();
                 }
             };
@@ -283,6 +294,11 @@ c2_status_t ImxC2Store::ComponentBox::init()
                     else
                         ALOGE("Can't set audio dsp decoder to high priority!");
             }
+
+            // for secure decoder, rank it a bit lower then normal decoder
+            if (traits->name.find("decoder.secure") != std::string::npos) {
+                traits->rank += 1;
+            }
         }
         mTraits = traits;
     }
@@ -379,6 +395,8 @@ ImxC2Store::ImxC2Store()
         }
     }
 
+    initIonHeaps();
+
     ALOGV("ImxC2Store::ImxC2Store END");
 }
 
@@ -502,6 +520,56 @@ std::shared_ptr<C2ComponentStore> GetImxC2Store() {
     return store;
 }
 
+static void initIonHeaps() {
+    // init non secure heap and secure heap
+    int ionFd = ion_open();
+    if (ionFd < 0) {
+        ALOGE("ion open failed!");
+        return;
+    }
+    int heapCnt = 0;
+    int ret = ion_query_heap_cnt(ionFd, &heapCnt);
+    if (ret != 0 || heapCnt == 0) {
+        ALOGE("can't query heap count");
+        close(ionFd);
+        return;
+    }
+
+    struct ion_heap_data ihd[heapCnt];
+    memset(&ihd, 0, sizeof(ihd));
+    ret = ion_query_get_heaps(ionFd, heapCnt, &ihd);
+    if (ret != 0) {
+        ALOGE("can't get ion heaps");
+        close(ionFd);
+        return;
+    }
+
+    for (int i = 0; i < heapCnt; i++) {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 10, 1)
+        if (ihd[i].type == ION_HEAP_TYPE_SYSTEM_CONTIG) {
+            gNonSecureHeaps |= 1 << ihd[i].heap_id;
+            continue;
+        }
+        if (ihd[i].type == ION_HEAP_TYPE_DMA ||
+                ihd[i].type == ION_HEAP_TYPE_CARVEOUT) {
+#else
+        if (ihd[i].type == ION_HEAP_TYPE_DMA) {
+#endif
+            gNonSecureHeaps |=  1 << ihd[i].heap_id;
+            continue;
+        }
+        if (ihd[i].type == ION_HEAP_TYPE_SYSTEM) {
+            gNonSecureHeaps |= 1 << ihd[i].heap_id;
+            continue;
+        }
+        if (ihd[i].type == ION_HEAP_TYPE_UNMAPPED) {
+            gSecureHeaps = 1 << ihd[i].heap_id;  //we have only one secure heap
+            continue;
+        }
+    }
+    close(ionFd);
+}
+
 
 }
 
diff --git a/codec2/store/registry/c2_component_register_8mp b/codec2/store/registry/c2_component_register_8mp
index 1941931..ffcc806 100644
--- a/codec2/store/registry/c2_component_register_8mp
+++ b/codec2/store/registry/c2_component_register_8mp
@@ -20,11 +20,21 @@ component_name=c2.imx.avc.decoder;
 library_path=lib_imx_c2_videodec.so;
 $
 
+@
+component_name=c2.imx.avc.decoder.secure;
+library_path=lib_imx_c2_videodec.so;
+$
+
 @
 component_name=c2.imx.hevc.decoder;
 library_path=lib_imx_c2_videodec.so;
 $
 
+@
+component_name=c2.imx.hevc.decoder.secure;
+library_path=lib_imx_c2_videodec.so;
+$
+
 @
 component_name=c2.imx.vp8.decoder;
 library_path=lib_imx_c2_videodec.so;
diff --git a/codec2/v4l2_dev/V4l2Dev.cpp b/codec2/v4l2_dev/V4l2Dev.cpp
old mode 100644
new mode 100755
index de38183..c508e91
--- a/codec2/v4l2_dev/V4l2Dev.cpp
+++ b/codec2/v4l2_dev/V4l2Dev.cpp
@@ -32,23 +32,40 @@ namespace android {
 #define VPU_ENC_NODE "/dev/video13"
 
 #define MAX_VIDEO_SEARCH_NODE (20)
-static std::atomic<std::int32_t> gIsiIndex = -1;
+static std::atomic<std::int32_t> gDevIndex[V4L2_DEV_END] = {-1, -1, -1};
 
+static int is_v4l2_mplane(struct v4l2_capability *cap)
+{
+    if (cap->capabilities & (V4L2_CAP_VIDEO_CAPTURE_MPLANE
+			| V4L2_CAP_VIDEO_OUTPUT_MPLANE)
+			&& cap->capabilities & V4L2_CAP_STREAMING)
+        return true;
+
+    if (cap->capabilities & V4L2_CAP_VIDEO_M2M_MPLANE)
+        return true;
+
+    return false;
+}
 
 V4l2Dev::V4l2Dev()
 {
     memset((char*)sDevName, 0, MAX_DEV_NAME_LEN);
     nFd = -1;
     nEventFd = -1;
+    mStreamType = V4L2_PIX_FMT_H264;
+    nOutBufType = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    nCapBufType = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
 }
 int32_t V4l2Dev::Open(V4l2DEV_TYPE type){
 
     if(OK != SearchName(type))
         return -1;
-    
+
+    ALOGD("open dev name %s", (char*)sDevName);
+
     nFd = open ((char*)sDevName, O_RDWR | O_NONBLOCK);
 
-    if(nFd > 0){
+    if(nFd > 0) {
         struct v4l2_event_subscription  sub;
         memset(&sub, 0, sizeof(struct v4l2_event_subscription));
 
@@ -58,11 +75,11 @@ int32_t V4l2Dev::Open(V4l2DEV_TYPE type){
         sub.type = V4L2_EVENT_EOS;
         ioctl(nFd, VIDIOC_SUBSCRIBE_EVENT, &sub);
 
-        if(type == V4L2_DEV_DECODER){
-            sub.type = V4L2_EVENT_SKIP;
-            ioctl(nFd, VIDIOC_SUBSCRIBE_EVENT, &sub);
+        sub.type = V4L2_EVENT_CODEC_ERROR;
+        ioctl(nFd, VIDIOC_SUBSCRIBE_EVENT, &sub);
 
-            sub.type = V4L2_EVENT_CODEC_ERROR;
+        if(type == V4L2_DEV_DECODER) {
+            sub.type = V4L2_EVENT_SKIP;
             ioctl(nFd, VIDIOC_SUBSCRIBE_EVENT, &sub);
         }
 
@@ -85,83 +102,153 @@ status_t V4l2Dev::Close()
     }
     return OK;
 }
+
+status_t V4l2Dev::GetVideoBufferType(enum v4l2_buf_type *outType, enum v4l2_buf_type *capType)
+{
+    struct v4l2_capability cap;
+
+    if (ioctl(nFd, VIDIOC_QUERYCAP, &cap) != 0) {
+        ALOGE("%s failed", __FUNCTION__);
+        return BAD_VALUE;
+    }
+
+    if (is_v4l2_mplane(&cap)) {
+        nCapBufType = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        nOutBufType = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    } else {
+        nCapBufType = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+        nOutBufType = V4L2_BUF_TYPE_VIDEO_OUTPUT;
+    }
+
+    *outType = nOutBufType;
+    *capType = nCapBufType;
+
+    return OK;
+}
+
+bool V4l2Dev::CheckVsiV4l2DeviceType(V4l2DEV_TYPE type, int fd)
+{
+    if(type != V4L2_DEV_DECODER && type != V4L2_DEV_ENCODER)
+        return false;
+
+    bool isVsiV4l2Dev = false;
+
+    enum v4l2_buf_type outBufferType, capBufferType;
+
+    nFd = fd; // temporary set nFd to check if it's vsi v4l2 node
+
+    GetVideoBufferType(&outBufferType, &capBufferType);
+
+    if (type == V4L2_DEV_DECODER
+            && IsOutputFormatSupported(V4L2_PIX_FMT_H264)
+            && IsCaptureFormatSupported(V4L2_PIX_FMT_NV12)) {
+        isVsiV4l2Dev = true;
+    }
+    else if (type == V4L2_DEV_ENCODER
+                && IsOutputFormatSupported(V4L2_PIX_FMT_NV12)
+                && IsCaptureFormatSupported(V4L2_PIX_FMT_H264)) {
+        isVsiV4l2Dev = true;
+    }
+
+    nFd = -1;
+
+    if (!isVsiV4l2Dev) {
+        output_formats.clear();
+        capture_formats.clear();
+    }
+
+    return isVsiV4l2Dev;
+}
+
 status_t V4l2Dev::SearchName(V4l2DEV_TYPE type)
 {
-    //open device node directly to save search time.
+    int32_t index = 0;
+    int32_t fd = -1;
+    char name[MAX_DEV_NAME_LEN];
+    bool bGet = false;
+    struct v4l2_capability cap;
+
+    bool isDecNode, isEncNode, isIsiNode;
+    int32_t devType = (int32_t)type;
+
+    #ifdef AMPHION_V4L2
     if(type == V4L2_DEV_DECODER){
          strcpy((char *)sDevName, VPU_DEC_NODE );
          return OK;
     }else if(type == V4L2_DEV_ENCODER){
          strcpy((char *)sDevName, VPU_ENC_NODE );
          return OK;
-    }else if(type == V4L2_DEV_ISI && gIsiIndex > 0 && gIsiIndex < MAX_VIDEO_SEARCH_NODE){
-        int32_t isiIndex= gIsiIndex;
-        sprintf((char*)sDevName, "/dev/video%d", isiIndex);
-        ALOGV("SearchName get %s for isi device", (char *)sDevName);
+    }
+    #endif
+
+    if(devType >= V4L2_DEV_START && devType < V4L2_DEV_END && gDevIndex[devType] >= 0)
+    {
+        index = gDevIndex[devType];
+        sprintf((char*)sDevName, "/dev/video%d", index);
+        ALOGV("SearchName get %s for %d device", (char *)sDevName,devType);
         return OK;
     }
 
-    int32_t index = 0;
-    //isi node is /dev/video2 on board with due camera
-    int32_t fd = -1;
-    char name[MAX_DEV_NAME_LEN];
-    bool bGet = false;
-    struct v4l2_capability cap;
+    while(index < MAX_VIDEO_SEARCH_NODE) {
 
-    while(index < MAX_VIDEO_SEARCH_NODE){
+        isDecNode = isEncNode = isIsiNode = false;
 
         sprintf((char*)name, "/dev/video%d", index);
 
         fd = open ((char*)name, O_RDWR);
         if(fd < 0){
             ALOGV("open index %d failed
",index);
-            index ++;
-            continue;
+            goto SEARCH_NEXT;
         }
         if (ioctl (fd, VIDIOC_QUERYCAP, &cap) < 0) {
-            close(fd);
             ALOGV("VIDIOC_QUERYCAP %d failed
",index);
-            index ++;
-            continue;
+            goto SEARCH_NEXT;
         }
-        ALOGV("index %d name=%s
",index,(char*)cap.driver);
+        ALOGV("index %d name=%s, card name=%s
",index,(char*)cap.driver, (char*)cap.card);
+
+        isDecNode = (!strcmp((char*)cap.card, "vsi_v4l2dec") || !strcmp((char*)cap.card, "vpu B0"));
+        isEncNode = (!strcmp((char*)cap.card, "vsi_v4l2enc") || !strcmp((char*)cap.card, "vpu encoder"));
+        isIsiNode = (!strcmp((char*)cap.card, "mxc-isi-m2m"));
 
-        if(type == V4L2_DEV_ISI){
-            if(NULL == strstr((char*)cap.driver, "mxc-isi-m2m")){
-                close(fd);
-                index ++;
-                continue;
+        if ((type == V4L2_DEV_DECODER && isDecNode) || (type == V4L2_DEV_ENCODER && isEncNode)) {
+            bGet = true;
+            goto FIND_NODE;
+        } else if (type == V4L2_DEV_ISI && isIsiNode) {
+            // do more check for isi
+            if (!((cap.capabilities & (V4L2_CAP_VIDEO_M2M |
+                            V4L2_CAP_VIDEO_M2M_MPLANE)) ||
+                    ((cap.capabilities &
+                            (V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_VIDEO_CAPTURE_MPLANE)) &&
+                        (cap.capabilities &
+                            (V4L2_CAP_VIDEO_OUTPUT | V4L2_CAP_VIDEO_OUTPUT_MPLANE))))){
+                goto SEARCH_NEXT;
             }
-        }
 
-        if (!((cap.capabilities & (V4L2_CAP_VIDEO_M2M |
-                        V4L2_CAP_VIDEO_M2M_MPLANE)) ||
-                ((cap.capabilities &
-                        (V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_VIDEO_CAPTURE_MPLANE)) &&
-                    (cap.capabilities &
-                        (V4L2_CAP_VIDEO_OUTPUT | V4L2_CAP_VIDEO_OUTPUT_MPLANE))))){
-            close(fd);
-            index ++;
-            continue;
+            if((isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_OUTPUT)||
+                isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE)) &&
+                (isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_CAPTURE)||
+                isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE))){
+                goto FIND_NODE;
+            }
         }
-        ALOGV("index %d 
",index);
-        if((isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_OUTPUT)||
-            isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE)) &&
-            (isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_CAPTURE)||
-            isV4lBufferTypeSupported(fd,type,V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE))){
-            bGet = true;
+
+SEARCH_NEXT:
+        if (fd >= 0)
             close(fd);
-            ALOGV("get device %s 
",name);
-            strcpy((char *)sDevName, name);
-            break;
-        }
-        close(fd);
         index ++;
+        continue;
+FIND_NODE:
+        bGet = true;
+        close(fd);
+        ALOGD("get device %s 
",name);
+        strcpy((char *)sDevName, name);
+        break;
     }
 
-    if(bGet && type == V4L2_DEV_ISI && gIsiIndex < 0){
-        gIsiIndex = index;
-        ALOGV("SearchName set %d for isi device", index);
+    if(bGet && devType >= V4L2_DEV_START && devType < V4L2_DEV_END){
+        if(gDevIndex[devType] < 0)
+            gDevIndex[devType] = index;
+        ALOGV("SearchName set %d for %d device", index, devType);
     }
 
     if(bGet)
@@ -214,14 +301,16 @@ status_t V4l2Dev::QueryFormats(uint32_t format_type)
 {
     struct v4l2_fmtdesc fmt;
     int32_t i = 0;
-    if(format_type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE){
+    if(format_type == V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE || format_type == V4L2_BUF_TYPE_VIDEO_OUTPUT) {
         output_formats.clear();
         while(true){
-            fmt.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+            fmt.type = format_type;
             fmt.index = i;
-            if(ioctl(nFd,VIDIOC_ENUM_FMT,&fmt) < 0)
+            if (ioctl(nFd,VIDIOC_ENUM_FMT,&fmt) < 0) {
+                ALOGV("VIDIOC_ENUM_FMT fail");
                 break;
- 
+            }
+
             output_formats.push_back(fmt.pixelformat);
             ALOGV("QueryFormat add output format %x
",fmt.pixelformat);
             i++;
@@ -231,16 +320,16 @@ status_t V4l2Dev::QueryFormats(uint32_t format_type)
         else
             return UNKNOWN_ERROR;
     }
-    else if(format_type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE){
+    else if(format_type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE || format_type == V4L2_BUF_TYPE_VIDEO_CAPTURE) {
         capture_formats.clear();
         while(true){
-            fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+            fmt.type = format_type;
             fmt.index = i;
-            if(ioctl(nFd,VIDIOC_ENUM_FMT,&fmt) < 0)
+            if (ioctl(nFd,VIDIOC_ENUM_FMT,&fmt) < 0)
                 break;
 
             capture_formats.push_back(fmt.pixelformat);
-            ALOGV("QueryFormat add capture format %x
",fmt.pixelformat);
+            ALOGD("QueryFormat add capture format %x
",fmt.pixelformat);
             i++;
         }
 
@@ -251,14 +340,16 @@ status_t V4l2Dev::QueryFormats(uint32_t format_type)
     }
     return BAD_TYPE;
 }
+
 bool V4l2Dev::IsOutputFormatSupported(uint32_t format)
 {
+    ALOGD("IsOutputFormatSupported format=%x", format);
     if(output_formats.empty()){
-        status_t ret = QueryFormats(V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE);
+        status_t ret = QueryFormats(nOutBufType);
         if(ret != OK)
             return false;
     }
-    
+
     for (uint32_t i = 0; i < output_formats.size(); i++) {
         if(format == output_formats.at(i)){
             return true;
@@ -269,12 +360,13 @@ bool V4l2Dev::IsOutputFormatSupported(uint32_t format)
 }
 bool V4l2Dev::IsCaptureFormatSupported(uint32_t format)
 {
+    ALOGD("IsCaptureFormatSupported format=%x", format);
     if(capture_formats.empty()){
-        status_t ret = QueryFormats(V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
+        status_t ret = QueryFormats(nCapBufType);
         if(ret != OK)
             return false;
     }
-    
+
     for (uint32_t i = 0; i < capture_formats.size(); i++) {
         if(format == capture_formats.at(i)){
             return true;
@@ -283,6 +375,21 @@ bool V4l2Dev::IsCaptureFormatSupported(uint32_t format)
     return false;
 }
 
+status_t V4l2Dev::GetDefaultCaptureFormat(uint32_t *format)
+{
+    status_t ret = OK;
+
+    if(capture_formats.empty()){
+        ret = QueryFormats(nCapBufType);
+        if(ret != OK)
+            return ret;
+    }
+
+    *format = capture_formats.at(0);
+
+    return ret;
+}
+
 typedef struct{
     const char * mime;
     uint32_t v4l2_format;
@@ -290,11 +397,12 @@ typedef struct{
 
 static const V4L2_FORMAT_TABLE v4l2_format_table[]={
     { MEDIA_MIMETYPE_VIDEO_AVC, V4L2_PIX_FMT_H264 },
-    { MEDIA_MIMETYPE_VIDEO_HEVC, v4l2_fourcc('H', 'E', 'V', 'C') },
+    { MEDIA_MIMETYPE_VIDEO_HEVC, V4L2_PIX_FMT_HEVC},
     { MEDIA_MIMETYPE_VIDEO_H263, V4L2_PIX_FMT_H263 },
     { MEDIA_MIMETYPE_VIDEO_MPEG4, V4L2_PIX_FMT_MPEG4 },
     { MEDIA_MIMETYPE_VIDEO_MPEG2, V4L2_PIX_FMT_MPEG2 },
     { MEDIA_MIMETYPE_VIDEO_VP8, V4L2_PIX_FMT_VP8 },
+    { MEDIA_MIMETYPE_VIDEO_VP9, V4L2_PIX_FMT_VP9 },
     { MEDIA_MIMETYPE_VIDEO_VC1, V4L2_PIX_FMT_VC1_ANNEX_L },
     { MEDIA_MIMETYPE_VIDEO_XVID, V4L2_PIX_FMT_XVID },
     { MEDIA_MIMETYPE_VIDEO_REAL, v4l2_fourcc('R', 'V', '0', '0')},
@@ -314,17 +422,32 @@ typedef struct{
 
 //TODO: add android pixel format
 static const COLOR_FORMAT_TABLE color_format_table[]={
+#ifdef AMPHION_V4L2
     { HAL_PIXEL_FORMAT_NV12_TILED, V4L2_PIX_FMT_NV12 },
+    { HAL_PIXEL_FORMAT_P010_TILED, v4l2_fourcc('N', 'T', '1', '2')},
+    { HAL_PIXEL_FORMAT_YCbCr_420_P, V4L2_PIX_FMT_NV12 }, // workaround
+#else
+    { HAL_PIXEL_FORMAT_YCbCr_420_P, V4L2_PIX_FMT_YUV420 },
+#endif
+#ifdef HANTRO_V4L2
+    { HAL_PIXEL_FORMAT_P010, V4L2_PIX_FMT_NV12X},
+    { HAL_PIXEL_FORMAT_YCbCr_422_SP, V4L2_PIX_FMT_NV16},
+#endif
     { HAL_PIXEL_FORMAT_YCbCr_420_SP, V4L2_PIX_FMT_NV12 },
-    { HAL_PIXEL_FORMAT_YCbCr_420_888, V4L2_PIX_FMT_NV12 },
-    { HAL_PIXEL_FORMAT_P010, v4l2_fourcc('N', 'T', '1', '2')}
+    { HAL_PIXEL_FORMAT_YCbCr_422_I, V4L2_PIX_FMT_YUYV},
+    { HAL_PIXEL_FORMAT_RGB_565, V4L2_PIX_FMT_RGB565},
+    { HAL_PIXEL_FORMAT_RGB_888, V4L2_PIX_FMT_RGB24},
+    { HAL_PIXEL_FORMAT_RGBA_8888, V4L2_PIX_FMT_RGBA32},
+    { HAL_PIXEL_FORMAT_RGBX_8888, V4L2_PIX_FMT_RGBX32},
+    { HAL_PIXEL_FORMAT_BGRA_8888, V4L2_PIX_FMT_BGRA32},
 };
 status_t V4l2Dev::GetStreamTypeByMime(const char * mime, uint32_t * format_type)
 {
-    
+
     for( size_t i = 0; i < sizeof(v4l2_format_table)/sizeof(V4L2_FORMAT_TABLE); i++){
         if (!strcmp(mime, v4l2_format_table[i].mime)) {
-            *format_type = v4l2_format_table[i].v4l2_format;
+            mStreamType = v4l2_format_table[i].v4l2_format;
+            *format_type = mStreamType;
             return OK;
         }
     }
@@ -416,16 +539,7 @@ uint32_t V4l2Dev::Poll()
 
         if(pfd[0].revents & POLLPRI){
             ALOGV("[%p]POLLPRI 
",this);
-            ret = V4L2_DEV_POLL_EVENT;
-            return ret;
-        }
-
-        if(pfd[0].revents & POLLERR){
-            //char tembuf[1];
-            //read (mFd, tembuf, 1);
-            ret = V4L2_DEV_POLL_NONE;
-            usleep(2000);
-            return ret;
+            ret |= V4L2_DEV_POLL_EVENT;
         }
 
         if((pfd[0].revents & POLLIN) || (pfd[0].revents & POLLRDNORM)){
@@ -434,6 +548,13 @@ uint32_t V4l2Dev::Poll()
         if((pfd[0].revents & POLLOUT) || (pfd[0].revents & POLLWRNORM)){
             ret |= V4L2_DEV_POLL_OUTPUT;
         }
+
+        if(pfd[0].revents & POLLERR){
+            if (V4L2_DEV_POLL_NONE == ret){
+                usleep(2000);
+            }else
+                ALOGE("poll err has other flag 0x%x",pfd[0].revents);
+        }
     }
 
     ALOGV("Poll END,ret=%x
",ret);
@@ -510,6 +631,23 @@ status_t V4l2Dev::EnableLowLatencyDecoder(bool enabled)
     return OK;
 }
 
+status_t V4l2Dev::EnableSecureMode(bool enabled)
+{
+
+    int ret = 0;
+    struct v4l2_control ctl = { 0,0 };
+    ctl.id = V4L2_CID_SECUREMODE;
+    ctl.value = enabled;
+    ret = ioctl(nFd, VIDIOC_S_CTRL, &ctl);
+
+    if(ret < 0){
+        ALOGV("V4l2Dev::EnableSecureMode ret=%x
",ret);
+        return UNKNOWN_ERROR;
+    }
+
+    return OK;
+}
+
 status_t V4l2Dev::StopEncoder()
 {
     int ret = 0;
@@ -544,23 +682,26 @@ status_t V4l2Dev::SetEncoderParam(V4l2EncInputParam *param)
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_GOP_SIZE,param->nGOPSize);
 
     ALOGV("SetEncoderParam V4L2_CID_MPEG_VIDEO_GOP_SIZE ret=%x
",ret);
-    
+
     if(param->nH264_i_qp > 0)
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_I_FRAME_QP,param->nH264_i_qp);
     if(param->nH264_p_qp > 0)
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_P_FRAME_QP,param->nH264_p_qp);
+
     if(param->nH264_min_qp > 0)
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_MIN_QP,param->nH264_min_qp);
     if(param->nH264_max_qp > 0)
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_MAX_QP,param->nH264_max_qp);
+
     if(param->nMpeg4_i_qp > 0)
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_MPEG4_I_FRAME_QP,param->nMpeg4_i_qp);
     if(param->nMpeg4_p_qp > 0)
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_MPEG4_P_FRAME_QP,param->nMpeg4_p_qp);
+
     if(param->nIntraFreshNum > 0)
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_CYCLIC_INTRA_REFRESH_MB,param->nIntraFreshNum);
 
-    ALOGV("SetEncoderParam 1 ret=%x
",ret);
+    ALOGV("SetEncoderParam 1 ret=%x nIntraFreshNum=%d
",ret,param->nIntraFreshNum);
 
     //ignore result
     int32_t value= 1;
@@ -569,93 +710,23 @@ status_t V4l2Dev::SetEncoderParam(V4l2EncInputParam *param)
     else if(0 == param->nRotAngle || 180 == param->nRotAngle)
         SetCtrl(V4L2_CID_VFLIP,value);
 
-    ret = SetH264EncoderProfileAndLevel(param->nProfile, param->nLevel);
-    
-    ALOGV("SetH264EncoderProfileAndLevel ret=%x
",ret);
+    ret = SetEncoderProfileAndLevel(param->nProfile, param->nLevel);
+
+    ALOGV("SetEncoderProfileAndLevel ret=%x
",ret);
     return ret;
 }
-status_t V4l2Dev::SetH264EncoderProfileAndLevel(uint32_t profile, uint32_t level)
+status_t V4l2Dev::SetEncoderProfileAndLevel(uint32_t profile, uint32_t level)
 {
     int ret = 0;
-    int v4l2_profile = V4L2_MPEG_VIDEO_H264_PROFILE_BASELINE;
-    int v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_4_1;
 
-    switch(profile){
-        case PROFILE_AVC_BASELINE:
-        case PROFILE_AVC_CONSTRAINED_BASELINE:
-            v4l2_profile = V4L2_MPEG_VIDEO_H264_PROFILE_BASELINE;
-            break;
-        case PROFILE_AVC_MAIN:
-            v4l2_profile = V4L2_MPEG_VIDEO_H264_PROFILE_MAIN;
-            break;
-        case PROFILE_AVC_HIGH:
-            v4l2_profile = V4L2_MPEG_VIDEO_H264_PROFILE_HIGH;
-            break;
-        default:
-            break;
+    if (mStreamType == V4L2_PIX_FMT_H264) {
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_PROFILE, profile);
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_LEVEL, level);
+    } else if (mStreamType == V4L2_PIX_FMT_HEVC) {
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_HEVC_PROFILE, profile);
+        ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_HEVC_LEVEL, level);
     }
-
-    switch (level) {
-        case 10:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_1_0;
-            break;
-        case 9:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_1B;
-            break;
-        case 11:
-            //adjust according to cts's code
-            //v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_1_1;
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_1_0;
-            break;
-        case 12:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_1_2;
-            break;
-        case 13:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_1_3;
-            break;
-        case 20:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_2_0;
-            break;
-        case 21:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_2_1;
-            break;
-        case 22:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_2_2;
-            break;
-        case 30:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_3_0;
-            break;
-        case 31:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_3_1;
-            break;
-        case 32:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_3_2;
-            break;
-        case 40:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_4_0;
-            break;
-        case 41:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_4_1;
-            break;
-        case 42:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_4_2;
-            break;
-        case 50:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_5_0;
-            break;
-        case 51:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_5_1;
-            break;
-        case 52:
-            v4l2_level = V4L2_MPEG_VIDEO_H264_LEVEL_5_1;
-            break;
-        default:
-            break;
-    }
-
-    ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_PROFILE, v4l2_profile);
-    ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_H264_LEVEL, v4l2_level);
-    ALOGV("set profile=%d,level=%d,v4l2_profile=%d,v4l2_level=%d,ret=%d",profile,level,v4l2_profile,v4l2_level,ret);
+    ALOGV("set profile=%d,level=%d,ret=%d",profile,level,ret);
     return OK;
 }
 
@@ -730,19 +801,21 @@ static const V4L2_ISO_MAP v4l2_ycbcr_table[]={
     { 1, V4L2_YCBCR_ENC_709 },
     { 4, V4L2_YCBCR_ENC_BT470_6M },
     { 5, V4L2_YCBCR_ENC_601 },
+    { 6, V4L2_YCBCR_ENC_601 },
     { 7, V4L2_YCBCR_ENC_SMPTE240M },
     { 9, V4L2_YCBCR_ENC_BT2020 },
     { 10, V4L2_YCBCR_ENC_BT2020_CONST_LUM },
 };
-status_t V4l2Dev::GetColorAspectsInfo(struct v4l2_pix_format_mplane * pixel_fmt, VideoColorAspect * desc)
+status_t V4l2Dev::GetColorAspectsInfo(uint32_t colorspace, uint32_t xfer_func,
+                                            uint32_t ycbcr_enc, uint32_t quantization,
+                                            VideoColorAspect * desc)
 {
-
-    if(pixel_fmt == NULL || desc == NULL)
+    if(desc == NULL)
         return UNKNOWN_ERROR;
 
     desc->colourPrimaries = 0;
     for( size_t i = 0; i < sizeof(v4l2_color_table)/sizeof(V4L2_ISO_MAP); i++){
-        if (pixel_fmt->colorspace == v4l2_color_table[i].v4l2_value) {
+        if (colorspace == v4l2_color_table[i].v4l2_value) {
             desc->colourPrimaries = v4l2_color_table[i].iso_value;
             break;
         }
@@ -750,7 +823,7 @@ status_t V4l2Dev::GetColorAspectsInfo(struct v4l2_pix_format_mplane * pixel_fmt,
 
     desc->transferCharacteristics = 0;
     for( size_t i = 0; i < sizeof(v4l2_xfer_table)/sizeof(V4L2_ISO_MAP); i++){
-        if (pixel_fmt->xfer_func == v4l2_xfer_table[i].v4l2_value) {
+        if (xfer_func == v4l2_xfer_table[i].v4l2_value) {
             desc->transferCharacteristics = v4l2_xfer_table[i].iso_value;
             break;
         }
@@ -759,13 +832,20 @@ status_t V4l2Dev::GetColorAspectsInfo(struct v4l2_pix_format_mplane * pixel_fmt,
     //2, ColorAspects::MatrixUnspecified
     desc->matrixCoeffs = 2;
     for( size_t i = 0; i < sizeof(v4l2_ycbcr_table)/sizeof(V4L2_ISO_MAP); i++){
-        if (pixel_fmt->ycbcr_enc == v4l2_ycbcr_table[i].v4l2_value) {
+        if (ycbcr_enc == v4l2_ycbcr_table[i].v4l2_value) {
             desc->matrixCoeffs = v4l2_ycbcr_table[i].iso_value;
             break;
         }
     }
 
-    desc->fullRange = (pixel_fmt->quantization == V4L2_QUANTIZATION_FULL_RANGE) ? 1:0;
+    desc->fullRange = (quantization == V4L2_QUANTIZATION_FULL_RANGE) ? 1:0;
+
+    // if all parameters are not initialized, return error to notify user there's no color aspects info
+    if (0 == desc->colourPrimaries &&
+            0 == desc->transferCharacteristics &&
+            2 == desc->matrixCoeffs &&
+            V4L2_QUANTIZATION_DEFAULT == quantization)
+        return BAD_VALUE;
 
     ALOGV("getColorAspectsInfo success, p=%d,t=%d,m=%d,r=%d
",
         desc->colourPrimaries,desc->transferCharacteristics,desc->matrixCoeffs,desc->fullRange);
@@ -812,6 +892,10 @@ status_t V4l2Dev::SetEncoderBitrate(int32_t mode, int32_t bitrate){
     if(bitrate > 0){
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_BITRATE_MODE,mode);
         ret |= SetCtrl(V4L2_CID_MPEG_VIDEO_BITRATE,bitrate);
+
+        // optional
+        if (mode == V4L2_MPEG_VIDEO_BITRATE_MODE_CBR)
+            SetCtrl(V4L2_CID_MPEG_VIDEO_FRAME_RC_ENABLE,1);
     }
     ALOGV("SetEncoderBitrate mode=%d,bitrate=%d ret=%x
",mode, bitrate, ret);
     return ret;
diff --git a/codec2/v4l2_dev/V4l2Dev.h b/codec2/v4l2_dev/V4l2Dev.h
old mode 100644
new mode 100755
index faf85fa..8145af3
--- a/codec2/v4l2_dev/V4l2Dev.h
+++ b/codec2/v4l2_dev/V4l2Dev.h
@@ -1,5 +1,5 @@
 /**
- *  Copyright 2019 NXP
+ *  Copyright 2019-2021 NXP
  *  All Rights Reserved.
  *
  *  The following programs are the sole property of Freescale Semiconductor Inc.,
@@ -16,9 +16,11 @@
 namespace android {
 
 typedef enum{
-V4L2_DEV_DECODER = 0,
+V4L2_DEV_START = 0,
+V4L2_DEV_DECODER = V4L2_DEV_START,
 V4L2_DEV_ENCODER,
 V4L2_DEV_ISI,
+V4L2_DEV_END,
 }V4l2DEV_TYPE;
 
 
@@ -27,7 +29,6 @@ V4L2_DEV_ISI,
 #define V4L2_DEV_POLL_OUTPUT 2
 #define V4L2_DEV_POLL_CAPTURE 4
 
-
 #define MAX_DEV_NAME_LEN (16)
 
 typedef struct {
@@ -51,15 +52,19 @@ typedef struct {
     int32_t nProfile;
     int32_t nLevel;
     int32_t nRotAngle;
+    int32_t nFrameRate;
 } V4l2EncInputParam;
-    
+
 class V4l2Dev{
 public:
     explicit V4l2Dev();
     int32_t Open(V4l2DEV_TYPE type);
     status_t Close();
+    status_t GetVideoBufferType(enum v4l2_buf_type *outType, enum v4l2_buf_type *capType);
     bool IsOutputFormatSupported(uint32_t format);
     bool IsCaptureFormatSupported(uint32_t format);
+
+    status_t GetDefaultCaptureFormat(uint32_t *format);
     status_t GetFormatFrameInfo(uint32_t format, struct v4l2_frmsizeenum * info);
 
     status_t GetStreamTypeByMime(const char * mime, uint32_t * format_type);
@@ -67,20 +72,23 @@ public:
 
     status_t GetColorFormatByV4l2(uint32_t v4l2_format, uint32_t * color_format);
     status_t GetV4l2FormatByColor(uint32_t color_format, uint32_t * v4l2_format);
-    
+
     uint32_t Poll();
     status_t SetPollInterrupt();
     status_t ClearPollInterrupt();
     status_t ResetDecoder();
     status_t StopDecoder();
 
-    status_t GetColorAspectsInfo(struct v4l2_pix_format_mplane * pixel_fmt, VideoColorAspect * desc);
     status_t EnableLowLatencyDecoder(bool enabled);
+    status_t EnableSecureMode(bool enabled);
+    status_t GetColorAspectsInfo(uint32_t colorspace, uint32_t xfer_func,
+                                            uint32_t ycbcr_enc, uint32_t quantization,
+                                            VideoColorAspect * desc);
 
     //encoder functions
     status_t StopEncoder();
     status_t SetEncoderParam(V4l2EncInputParam *param);
-    status_t SetH264EncoderProfileAndLevel(uint32_t profile, uint32_t level);
+    status_t SetEncoderProfileAndLevel(uint32_t profile, uint32_t level);
     status_t SetFrameRate(uint32_t framerate);
     status_t SetForceKeyFrame();
     status_t SetColorAspectsInfo(VideoColorAspect * desc, struct v4l2_pix_format_mplane * pixel_fmt);
@@ -92,9 +100,14 @@ private:
 
     status_t SetCtrl(uint32_t id, int32_t value);
 
+    bool CheckVsiV4l2DeviceType(V4l2DEV_TYPE type, int fd);
+
     char sDevName[MAX_DEV_NAME_LEN];
     int32_t nFd;
     int32_t nEventFd;
+    int32_t mStreamType;
+    enum v4l2_buf_type nOutBufType;
+    enum v4l2_buf_type nCapBufType;
     std::vector<uint32_t> output_formats;
     std::vector<uint32_t> capture_formats;
 };
diff --git a/codec2/v4l2_dev/v4l2_dev.go b/codec2/v4l2_dev/v4l2_dev.go
index ab14dca..066975f 100644
--- a/codec2/v4l2_dev/v4l2_dev.go
+++ b/codec2/v4l2_dev/v4l2_dev.go
@@ -44,8 +44,14 @@ func v4l2Defaults(ctx android.LoadHookContext) {
     }
     p := &props{}
     var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
-    if strings.Contains(board, "IMX8Q") {
+    if (strings.Contains(board, "IMX8Q") || strings.Contains(board, "IMX8MP") || strings.Contains(board, "IMX8MQ") || strings.Contains(board, "IMX8MM")) {
         p.Target.Android.Enabled = proptools.BoolPtr(true)
+
+        if (strings.Contains(board, "IMX8Q")) {
+            Cflags = append(Cflags, "-DAMPHION_V4L2")
+        } else {
+            Cflags = append(Cflags, "-DHANTRO_V4L2")
+        }
     } else {
         p.Target.Android.Enabled = proptools.BoolPtr(false)
     }
diff --git a/codec2/video_dec/common/Android.bp b/codec2/video_dec/common/Android.bp
index e6bd41d..e2dd92b 100644
--- a/codec2/video_dec/common/Android.bp
+++ b/codec2/video_dec/common/Android.bp
@@ -69,6 +69,12 @@ cc_library_shared {
         "libcodec2_headers",
     ],
 
+    static_libs: [
+        "libwvtrustyclient",
+        "libtrusty",
+        "libtrustystorageinterface",
+        "libtrustystorage",
+    ],
 
     shared_libs: [
         "libcutils", // for properties
diff --git a/codec2/video_dec/common/IMXC2VideoDecoder.cpp b/codec2/video_dec/common/IMXC2VideoDecoder.cpp
old mode 100644
new mode 100755
index c500024..f6169c1
--- a/codec2/video_dec/common/IMXC2VideoDecoder.cpp
+++ b/codec2/video_dec/common/IMXC2VideoDecoder.cpp
@@ -12,6 +12,7 @@
 
 #include <media/stagefright/MediaDefs.h>
 #include <string.h>
+#include <sys/mman.h>
 #include <Codec2Mapper.h>
 
 #include "IMXC2VideoDecoder.h"
@@ -19,6 +20,10 @@
 #include "C2Config_imx.h"
 #include "IMXUtils.h"
 #include "graphics_ext.h"
+#include "Memory.h"
+#include "IonAllocator.h"
+
+#include <wv_client.h>
 
 namespace android {
 
@@ -504,6 +509,8 @@ public:
 
     uint32_t getVenderHalFormat() const { return mVendorHalPixelFormat->value; }
 
+    uint32_t getRawPixelFormat() const { return mPixelFormat->value; }
+
     static C2R Hdr10PlusInfoInputSetter(bool mayBlock, C2P<C2StreamHdr10PlusInfo::input> &me) {
         (void)mayBlock;
         (void)me;  // TODO: validate
@@ -552,7 +559,9 @@ IMXC2VideoDecoder::IMXC2VideoDecoder(const char* name, c2_node_id_t id, const st
       bSignalledError(false),
       bFlushDone(false),
       bPPEnabled(false),
-      bSupportColorAspects(false){
+      bSupportColorAspects(false),
+      bSecure(false),
+      bFirstInput(true){
 }
 
 IMXC2VideoDecoder::~IMXC2VideoDecoder() {
@@ -620,7 +629,6 @@ c2_status_t IMXC2VideoDecoder::onStop() {
     bSignalledError = false;
     bSignalOutputEos = false;
 
-    err = initInternalParam();
     return C2ERR(err);
 }
 
@@ -658,6 +666,8 @@ void IMXC2VideoDecoder::onReset() {
 void IMXC2VideoDecoder::onRelease() {
     ALOGV("onRelease");
     (void) releaseDecoder();
+    if (bSecure)
+        set_secure_pipe(0);
 }
 
 static void fillEmptyWork(const std::unique_ptr<C2Work> &work) {
@@ -723,8 +733,38 @@ void IMXC2VideoDecoder::processWork(const std::unique_ptr<C2Work> &work) {
     }
 
     const C2ConstLinearBlock block = work->input.buffers[0]->data().linearBlocks().front();
-    fd = block.handle()->data[0];
+
+    // enable secure mode conditions: secure decoder && secure memory
+    if (bFirstInput) {
+        bFirstInput = false;
+        if (mName.find("secure") != std::string::npos &&
+                mDecoder->canEnableSecureMode(block.handle()->data[0], size)) {
+            bSecure = true;
+            set_secure_pipe(1);
+
+            int secureMode = 1;
+            mDecoder->setConfig(DEC_CONFIG_SECURE_MODE, &secureMode);
+        } else {
+            bSecure = false;
+            set_secure_pipe(0);
+        }
+    }
+
+    // use fd2 to get clear input data in secure mode
+    if (bSecure) {
+        if (work->input.buffers.size() == 2) {
+            view = work->input.buffers[1]->data().linearBlocks().front().map().get();
+            if (view.error()) {
+                ALOGE("Could not get vitual address");
+                work->result = C2_BAD_VALUE;
+                return fillEmptyWork(work);
+            }
+        }
+    }
+
     inputBuffer = const_cast<uint8_t *>(view.data());
+
+    fd = block.handle()->data[0];
     timestamp = work->input.ordinal.timestamp.peeku();
     inputId = static_cast<int32_t>(work->input.ordinal.frameIndex.peeku() & 0x3FFFFFFF);
 
@@ -734,11 +774,6 @@ void IMXC2VideoDecoder::processWork(const std::unique_ptr<C2Work> &work) {
 
     ret = mDecoder->queueInput(inputBuffer, size, timestamp, flags, fd, inputId);
 
-    if (nUsedFrameIndex == nCurFrameIndex) {
-        work->input.buffers.front().reset();
-        ALOGV("input id %d is used 
", inputId);
-    }
-
     // codec data won't have a picture out, mark c2work as processed directly
     if ((flags & C2FrameData::FLAG_CODEC_CONFIG) || ret != OK) {
         work->workletsProcessed = 1u;
@@ -812,7 +847,12 @@ status_t IMXC2VideoDecoder::initInternalParam() {
     err = intf()->query_vb({&output_fmt,}, {}, C2_DONT_BLOCK, nullptr);
     if (err == C2_OK && output_fmt.value != 0) {
         uint32_t fmt = output_fmt.value;
-        ALOGV("SET DEC_CONFIG_HAL_PIXEL_FORMAT fmt=%x",fmt);
+        ALOGV("SET DEC_CONFIG_HAL_PIXEL_FORMAT 1 fmt=%x",fmt);
+        (void)mDecoder->setConfig(DEC_CONFIG_HAL_PIXEL_FORMAT, &fmt);
+    }else{
+        //query failed if no one set the pixel format, set default format to NV12
+        uint32_t fmt = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+        ALOGV("SET DEC_CONFIG_HAL_PIXEL_FORMAT 2 fmt=%x",fmt);
         (void)mDecoder->setConfig(DEC_CONFIG_HAL_PIXEL_FORMAT, &fmt);
     }
 
@@ -824,6 +864,12 @@ status_t IMXC2VideoDecoder::initInternalParam() {
         (void)mDecoder->setConfig(DEC_CONFIG_LOW_LATENCY, &enable);
     }
 
+    if (HAL_PIXEL_FORMAT_YV12 == mIntf->getRawPixelFormat()) {
+        // user force output pixel format to be YV12, while VPU don't support YV12, just use NV12
+        uint32_t force_fmt = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+        (void)mDecoder->setConfig(DEC_CONFIG_FORCE_PIXEL_FORMAT, &force_fmt);
+    }
+
     return OK;
 }
 
@@ -902,8 +948,7 @@ void IMXC2VideoDecoder::handleOutputPicture(GraphicBlockInfo* info, uint64_t tim
             nullptr);
 
         if (bPendingFmtChanged) {
-            //TODO: remove 4 buffers after resolve pause timeout issue
-            outputDelayValue = nOutBufferNum + 4;
+            outputDelayValue = nOutBufferNum;
 
             if (outputDelay.value < outputDelayValue) {
                 outputDelay.value = outputDelayValue;
@@ -912,7 +957,7 @@ void IMXC2VideoDecoder::handleOutputPicture(GraphicBlockInfo* info, uint64_t tim
             }
         }
 
-        ALOGV("configUpdate outputDelay.value=%d", outputDelay.value);
+        ALOGD("configUpdate outputDelay.value=%d", outputDelay.value);
         if(bPPEnabled){
             fmt.value = mIntf->getVenderHalFormat();
             ALOGV("handleOutputPicture bPPEnabled");
@@ -923,10 +968,9 @@ void IMXC2VideoDecoder::handleOutputPicture(GraphicBlockInfo* info, uint64_t tim
                     (const std::unique_ptr<C2Work> &work) mutable {
 
         uint32_t flags = 0;
-        if ((work->input.flags & C2FrameData::FLAG_END_OF_STREAM) &&
-                (c2_cntr64_t(timestamp) == work->input.ordinal.timestamp)) {
+        if (work->input.flags & C2FrameData::FLAG_END_OF_STREAM) {
             flags |= C2FrameData::FLAG_END_OF_STREAM;
-            ALOGV("signalling eos");
+            ALOGD("signalling output eos");
         }
         if (configUpdate) {
             work->worklets.front()->output.configUpdate.push_back(C2Param::Copy(crop));
@@ -1087,16 +1131,6 @@ void IMXC2VideoDecoder::notifyPictureReady(int32_t pictureId, uint64_t timestamp
     ALOGV("notifyPictureReady picture id=%d, ts=%lld", (int)pictureId, (long long)timestamp);
 
     GraphicBlockInfo* info = mDecoder->getGraphicBlockById(pictureId);
-    if (!info) {
-        /* notify error */
-        ALOGE("%s line %d: wrong pictureId %d", __FUNCTION__, __LINE__, pictureId);
-        return;
-    }
-
-    if (info->mState != GraphicBlockInfo::State::OWNED_BY_VPU) {
-        ALOGE("%s line %d: error graphic block state, expect OWNED_BY_VPU but get %d", __FUNCTION__, __LINE__, info->mState);
-        return;
-    }
 
     if (bPPEnabled) {
         uint32_t flag = 0;
@@ -1116,15 +1150,7 @@ void IMXC2VideoDecoder::notifyPictureReady(int32_t pictureId, uint64_t timestamp
 
 void IMXC2VideoDecoder::notifyInputBufferUsed(int32_t input_id) {
     nUsedFrameIndex = static_cast<uint64_t>(input_id);
-
-    C2Work* work = getPendingWorkByFrameIndex(nUsedFrameIndex);
-    if (!work) {
-        return;
-    }
-
-    // When the work is done, the input buffer shall be reset by component.
-    work->input.buffers.front().reset();
-    ALOGV("input id %d is used 
", (int)input_id);
+    (void)postClearInputMsg(nUsedFrameIndex);
 }
 
 void IMXC2VideoDecoder::notifySkipInputBuffer(int32_t input_id) {
@@ -1144,7 +1170,7 @@ void IMXC2VideoDecoder::notifyResetDone() {
 
 void IMXC2VideoDecoder::notifyError(status_t err) {
     bSignalledError = true;
-    finishWithException(false/*eos*/, false/*force*/);
+    (void)finishWithException(false/*eos*/, false/*force*/);
     ALOGE("video decoder notify with error %d", err);
 }
 
@@ -1154,7 +1180,7 @@ void IMXC2VideoDecoder::notifyEos() {
         mPostProcess->queueInput(0, 0, 0, 0, C2FrameData::FLAG_END_OF_STREAM, -1, -1);
         return;
     } else {
-        finishWithException(true/*eos*/, !bRecieveOutputEos);
+        (void)finishWithException(true/*eos*/, !bRecieveOutputEos);
     }
 
     // fill empty work and sigal eos
@@ -1228,14 +1254,14 @@ status_t IMXC2VideoDecoder::notifyProcessResetDone() {
 
 void IMXC2VideoDecoder::notifyProcessError() {
     bSignalledError = true;
-    finishWithException(false/*eos*/, false/*force*/);
+    (void)finishWithException(false/*eos*/, false/*force*/);
     ALOGE("post process notify with error");
 }
 
 void IMXC2VideoDecoder::notifyProcessEos() {
     ALOGV("get notifyProcessEos");
     // fill empty work and sigal eos
-    finishWithException(true/*eos*/, !bRecieveOutputEos);
+    (void)finishWithException(true/*eos*/, !bRecieveOutputEos);
     bRecieveOutputEos = true;
 }
 
diff --git a/codec2/video_dec/common/IMXC2VideoDecoder.h b/codec2/video_dec/common/IMXC2VideoDecoder.h
index dd5beb0..813d51b 100755
--- a/codec2/video_dec/common/IMXC2VideoDecoder.h
+++ b/codec2/video_dec/common/IMXC2VideoDecoder.h
@@ -88,6 +88,8 @@ private:
     bool bFlushDone;
     bool bPPEnabled;
     bool bSupportColorAspects;
+    bool bSecure;
+    bool bFirstInput;
 
     status_t initInternalParam();    // init internel paramters
     void releaseDecoder();    // release decoder instance
diff --git a/codec2/video_dec/common/VideoDecoderBase.cpp b/codec2/video_dec/common/VideoDecoderBase.cpp
old mode 100644
new mode 100755
index 20b91e5..e1415a0
--- a/codec2/video_dec/common/VideoDecoderBase.cpp
+++ b/codec2/video_dec/common/VideoDecoderBase.cpp
@@ -100,7 +100,6 @@ VideoDecoderBase::VideoDecoderBase()
       bAdaptiveMode(false),
       bSecureMode(false),
       bReceiveError(false),
-      bCodecDataReceived(false),
       bCodecDataQueued(false),
       mLooper(new ALooper),
       mClient(nullptr) {
@@ -182,13 +181,14 @@ status_t VideoDecoderBase::queueInput(
 
     bool codecdata = ((flags & C2FrameData::FLAG_CODEC_CONFIG) != 0);
 
-    if (codecdata) {
-        // previous csd is kept because it is not sent to decoder yet.
-        // if there is csd after flushing, clear previous csd
-        if (!bCodecDataReceived && !bCodecDataQueued && nCodecDataLen > 0) {
-            ALOGV("clear previous csd: nCodecDataLen %d", nCodecDataLen);
+    // in secure mode, codec data should be sent with physical address, so don't memcpy here
+    if (codecdata && !bSecureMode) {
+        // new codecdata is arrived, reset bCodecDataQueued to false and clear previous codecdata
+        if (bCodecDataQueued) {
+            bCodecDataQueued = false;
             nCodecDataLen = 0;
         }
+
         if (!pCodecDataBuf) {
             pCodecDataBuf = (uint8_t*)malloc(size);
         } else {
@@ -202,7 +202,6 @@ status_t VideoDecoderBase::queueInput(
 
         memcpy(pCodecDataBuf + nCodecDataLen, pInBuf, size);
         nCodecDataLen += size;
-        bCodecDataReceived = true;
         return OK;
     }
 
@@ -307,6 +306,16 @@ status_t VideoDecoderBase::decodeInternal(std::unique_ptr<IMXInputBuffer> input)
     return OK;
 }
 
+void VideoDecoderBase::GraphicBlockSetState(int32_t blockId, GraphicBlockInfo::State state)
+{
+    GraphicBlockInfo* pInfo = getGraphicBlockById(blockId);
+    if (pInfo) {
+        Mutex::Autolock autoLock(mGBLock);
+        pInfo->mState = state;
+    }
+}
+
+
 GraphicBlockInfo* VideoDecoderBase::getGraphicBlockById(int32_t blockId) {
     if (blockId < 0 || blockId >= static_cast<int32_t>(mGraphicBlocks.size())) {
         ALOGE("getGraphicBlockById failed: id=%d", blockId);
@@ -342,6 +351,7 @@ GraphicBlockInfo* VideoDecoderBase::getGraphicBlockByPhysAddr(unsigned long phys
 }
 
 GraphicBlockInfo* VideoDecoderBase::getFreeGraphicBlock() {
+    Mutex::Autolock autoLock(mGBLock);
     auto blockIter = std::find_if(mGraphicBlocks.begin(), mGraphicBlocks.end(),
                                   [](const GraphicBlockInfo& gb) {
                                       return gb.mState == GraphicBlockInfo::State::OWNED_BY_COMPONENT;;
@@ -357,7 +367,8 @@ GraphicBlockInfo* VideoDecoderBase::getFreeGraphicBlock() {
 }
 
 status_t VideoDecoderBase::removeGraphicBlockById(int32_t blockId) {
-    if (blockId < 0 || blockId >= static_cast<int32_t>(mGraphicBlocks.size())) {
+    Mutex::Autolock autoLock(mGBLock);
+    if (blockId < 0) {
         ALOGE("getGraphicBlockById failed: id=%d", blockId);
         return BAD_INDEX;
     }
@@ -367,7 +378,7 @@ status_t VideoDecoderBase::removeGraphicBlockById(int32_t blockId) {
                                   });
 
     if (blockIter == mGraphicBlocks.end()) {
-        ALOGV("%s line %d: failed: blockId=%d", __FUNCTION__, __LINE__, blockId);
+        ALOGE("%s line %d: failed: blockId=%d", __FUNCTION__, __LINE__, blockId);
         return BAD_INDEX;
     }
 
@@ -464,7 +475,7 @@ void VideoDecoderBase::onMessageReceived(const sp<AMessage> &msg) {
                 queue->pop_front();
             }
 
-            bCodecDataReceived = false;
+            bCodecDataQueued = false;
             bReleasingDecoder = false;
 
             int32_t err = onFlush();
@@ -516,7 +527,7 @@ status_t VideoDecoderBase::appendOutputBuffer(std::shared_ptr<C2GraphicBlock> bl
         ALOGV("previous output buffer returned to decoder, blockId %d", pInfo->mBlockId);
         pInfo->mDMABufFd = prvHandle->fd;
         pInfo->mGraphicBlock = std::move(block);
-        pInfo->mState = GraphicBlockInfo::State::OWNED_BY_COMPONENT;
+        GraphicBlockSetState(pInfo->mBlockId, GraphicBlockInfo::State::OWNED_BY_COMPONENT);
         *blockId = pInfo->mBlockId;
     } else {
         if (true == OutputBufferFull()) {
@@ -524,11 +535,15 @@ status_t VideoDecoderBase::appendOutputBuffer(std::shared_ptr<C2GraphicBlock> bl
         }
         GraphicBlockInfo info;
 
-        fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
-        int ret = pIonAllocator->getVaddrs(prvHandle->fd, prvHandle->size, (uint64_t&)info.mVirtAddr);
-        if (ret != 0) {
-            ALOGE("Ion get virtual address failed, fd %d", prvHandle->fd);
-            return BAD_VALUE;
+        if (bSecureMode) {
+            info.mVirtAddr  = 0;
+        } else {
+            fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
+            int ret = pIonAllocator->getVaddrs(prvHandle->fd, prvHandle->size, (uint64_t&)info.mVirtAddr);
+            if (ret != 0) {
+                ALOGE("Ion get virtual address failed, fd %d", prvHandle->fd);
+                return BAD_VALUE;
+            }
         }
 
         info.mDMABufFd = prvHandle->fd;
@@ -539,7 +554,8 @@ status_t VideoDecoderBase::appendOutputBuffer(std::shared_ptr<C2GraphicBlock> bl
         info.mBlockId = static_cast<int32_t>(mGraphicBlocks.size());
         info.mGraphicBlock = std::move(block);
         *blockId = info.mBlockId;
-        ALOGI("fetch a new buffer, blockId %d phys %p virt %p", info.mBlockId, (void*)info.mPhysAddr, (void*)info.mVirtAddr);
+        ALOGI("fetch a new buffer, blockId %d fd %d phys %p virt %p capacity %d",
+            info.mBlockId, info.mDMABufFd, (void*)info.mPhysAddr, (void*)info.mVirtAddr, info.mCapacity);
 
         Mutex::Autolock autoLock(mGBLock);
         mGraphicBlocks.push_back(std::move(info));
@@ -612,6 +628,20 @@ void VideoDecoderBase::NotifyPictureReady(int32_t pictureId, uint64_t timestamp)
     if (bReleasingDecoder)
         returnOutputBufferToDecoder(pictureId);
     else {
+        GraphicBlockInfo* info = getGraphicBlockById(pictureId);
+        if (!info) {
+            /* notify error */
+            ALOGE("%s line %d: wrong pictureId %d", __FUNCTION__, __LINE__, pictureId);
+            return;
+        }
+
+        if (info->mState != GraphicBlockInfo::State::OWNED_BY_VPU) {
+            ALOGE("%s line %d: error graphic block state, expect OWNED_BY_VPU but get %d", __FUNCTION__, __LINE__, info->mState);
+            return;
+        }
+
+        GraphicBlockSetState(pictureId, GraphicBlockInfo::State::OWNED_BY_CLIENT);
+
         Mutex::Autolock autoLock(mGBLock);
         mClient->notifyPictureReady(pictureId, timestamp);
     }
@@ -632,6 +662,31 @@ int VideoDecoderBase::getBlockPoolAllocatorId()
 
     return -1;
 }
+
+int VideoDecoderBase::migrateGraphicBuffers()
+{
+    int32_t i = 0;
+    std::vector<int32_t> droppedBlockIds;
+
+    for (auto& info : mGraphicBlocks) {
+        if (info.mState == GraphicBlockInfo::State::OWNED_BY_CLIENT)
+            droppedBlockIds.push_back(info.mBlockId);
+    }
+
+    for (auto& id : droppedBlockIds) {
+        status_t ret = removeGraphicBlockById(id);
+        ALOGV("remove block %d, ret %d", id, ret);
+    }
+
+    for (auto& info : mGraphicBlocks) {
+        info.mBlockId = i++;
+    }
+
+    ALOGV("migrateGraphicBuffers %d", i);
+
+    return i;
+}
+
 } // namespace android
 
 /* end of file */
diff --git a/codec2/video_dec/common/VideoDecoderBase.h b/codec2/video_dec/common/VideoDecoderBase.h
old mode 100644
new mode 100755
index 2f0ceeb..08b8867
--- a/codec2/video_dec/common/VideoDecoderBase.h
+++ b/codec2/video_dec/common/VideoDecoderBase.h
@@ -30,6 +30,8 @@ typedef enum {
     DEC_CONFIG_HDR10_STATIC_INFO,
     DEC_CONFIG_COLOR_ASPECTS,
     DEC_CONFIG_LOW_LATENCY,
+    DEC_CONFIG_SECURE_MODE,
+    DEC_CONFIG_FORCE_PIXEL_FORMAT,
 } DecConfig;
 
 typedef struct {
@@ -148,6 +150,7 @@ public:
     status_t setConfig(DecConfig index, void* pConfig);
     status_t getConfig(DecConfig index, void* pConfig);
     virtual bool checkIfPostProcessNeeded() {return false;}
+    virtual bool canEnableSecureMode(int fd, int size) {(void)fd; (void)size; return false;}
 
     status_t setGraphicBlockPool(const std::shared_ptr<C2BlockPool> &pool);
     status_t queueInput(uint8_t *pInBuf, uint32_t size, uint64_t timestamp, uint32_t flags, int fd, int id);
@@ -159,13 +162,14 @@ public:
     status_t removeGraphicBlockById(int32_t blockId);
     void returnOutputBufferToDecoder(int32_t blockId);
     status_t queueOutput(int32_t blockId);
+    void GraphicBlockSetState(int32_t blockId, GraphicBlockInfo::State state);
 protected:
 
     enum {
-        kInputBufferCount = 8,
-        kInputBufferSizeFor1080p = 1024 * 1024,
+        kInputBufferCount = 4,
+        kInputBufferSizeFor1080p = 2 * 1024 * 1024,
         // Input bitstream buffer size for up to 4k streams.
-        kInputBufferSizeFor4k = 4 * kInputBufferSizeFor1080p,
+        kInputBufferSizeFor4k = 4 * 1024 * 1024,
         kDefaultOutputBufferCount = 8,
     };
 
@@ -187,8 +191,6 @@ protected:
     bool bAdaptiveMode;
     bool bSecureMode;
     bool bReceiveError;
-
-    bool bCodecDataReceived;
     bool bCodecDataQueued;
 
     VideoFormat mInputFormat;
@@ -219,6 +221,7 @@ protected:
 
     status_t outputFormatChanged();
     int getBlockPoolAllocatorId();
+    int migrateGraphicBuffers();
 
     void ClearPictureBuffer();
     void NotifyPictureReady(int32_t pictureId, uint64_t timestamp);
diff --git a/codec2/video_dec/v4l2_dec/V4l2Dec.cpp b/codec2/video_dec/v4l2_dec/V4l2Dec.cpp
index 8559e60..9f18e70 100644
--- a/codec2/video_dec/v4l2_dec/V4l2Dec.cpp
+++ b/codec2/video_dec/v4l2_dec/V4l2Dec.cpp
@@ -1,5 +1,5 @@
 /**
- *  Copyright 2018-2019 NXP
+ *  Copyright 2018-2021 NXP
  *  All Rights Reserved.
  *
  *  The following programs are the sole property of Freescale Semiconductor Inc.,
@@ -34,15 +34,30 @@ namespace android {
 #define IMX_V4L2_BUF_FLAG_TIMESTAMP_INVALID    0x00400000
 
 #define Align(ptr,align)    (((uint32_t)(ptr)+(align)-1)/(align)*(align))
-#define FRAME_ALIGN     (512)
-#define DEFAULT_OUTPUT_BUFFER_COUNT 6
+#define AMPHION_FRAME_ALIGN     (512)
+
+// Surface maxDequeueBuffers depends on outputDelay
+// some clips request many buffers, V4l2Dec::allocateOutputBuffers() fails
+// if Surface maxDequeueBuffers don't have so many buffers.
+#define DEFAULT_OUTPUT_BUFFER_COUNT 16
+
+//stride and slice height are both 16 for g1 decoder
+//stride is 16 and slice height is 8 for g2 decoder
+#define IS_G2_DECODER   (!strcmp(mMime,MEDIA_MIMETYPE_VIDEO_HEVC) || !strcmp(mMime, MEDIA_MIMETYPE_VIDEO_VP9))
+#define HANTRO_FRAME_ALIGN (8)
+#define HANTRO_FRAME_ALIGN_WIDTH (HANTRO_FRAME_ALIGN*2)
+#define HANTRO_FRAME_ALIGN_HEIGHT (IS_G2_DECODER ? HANTRO_FRAME_ALIGN : HANTRO_FRAME_ALIGN_WIDTH)
+
+#define FRAME_SURPLUS	(4)
 
 V4l2Dec::V4l2Dec(const char* mime):
     mMime(mime),
     mPollThread(0),
     mFetchThread(0),
     pDev(NULL),
-    mFd(-1){
+    mFd(-1),
+    mOutBufType(V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE),
+    mCapBufType(V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE){
 
     bPollStarted = false;
     bPollStopped = false;
@@ -52,15 +67,29 @@ V4l2Dec::V4l2Dec(const char* mime):
     bInputStreamOn = false;
     bOutputStreamOn = false;
 
-    bCodecDataQueued = false;
-
-    bNeedPostProcess = true;
     bMpeg2 = false;
     bH264 = false;
 
+    bNeedPostProcess = false;
+    bForcePixelFormat = false;
+
+    bSawInputEos = false;
+    bNewSegment = true;
+    bPendingFlush = false;
+
     mState = UNINITIALIZED;
 
     mVpuOwnedOutputBufferNum = 0;
+    mRegisteredOutBufNum = 0;
+
+// TODO: remove macro AMPHION_V4L2, use pDev->GetFormatFrameInfo to get align size
+#ifdef AMPHION_V4L2
+    mFrameAlignW = AMPHION_FRAME_ALIGN;
+    mFrameAlignH = AMPHION_FRAME_ALIGN;
+#else
+    mFrameAlignW = HANTRO_FRAME_ALIGN_WIDTH;
+    mFrameAlignH = HANTRO_FRAME_ALIGN_HEIGHT;
+#endif
 
     mInputFormat.bufferNum = kInputBufferCount;
     mInputFormat.bufferSize = kInputBufferSizeFor4k;
@@ -70,7 +99,9 @@ V4l2Dec::V4l2Dec(const char* mime):
 
     mOutputFormat.width = DEFAULT_FRM_WIDTH;
     mOutputFormat.height = DEFAULT_FRM_HEIGHT;
-    mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_NV12_TILED;
+
+    mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+
     //use bufferNum to check if need fetch buffer, so default is 0
     mOutputFormat.minBufferNum = 0;
     mOutputFormat.bufferNum = 0;
@@ -93,6 +124,9 @@ V4l2Dec::V4l2Dec(const char* mime):
     mInFormat = V4L2_PIX_FMT_H264;
     mOutFormat = V4L2_PIX_FMT_NV12;
 
+    bHasColorAspect = false;
+    bHasHdr10StaticInfo = false;
+    memset(&sHdr10StaticInfo,0,sizeof(DecStaticHDRInfo));
     memset(&mIsoColorAspect,0,sizeof(VideoColorAspect));
 }
 V4l2Dec::~V4l2Dec()
@@ -113,6 +147,11 @@ status_t V4l2Dec::onInit(){
     if(mFd < 0)
         return ret;
 
+    ret = pDev->GetVideoBufferType(&mOutBufType, &mCapBufType);
+    if (ret != OK)
+        return ret;
+
+
     mState = UNINITIALIZED;
 
     mLastInputTs = -1;
@@ -162,8 +201,15 @@ status_t V4l2Dec::onStart()
 
     ret = prepareOutputParams();
     if(ret != OK){
-        ALOGD("prepareOutputParams not ok");
-        mOutputFormat.pixelFormat = HAL_PIXEL_FORMAT_NV12_TILED;
+        uint32_t v4l2_format = 0;
+        uint32_t pixel_format = 0;
+        if(OK != pDev->GetDefaultCaptureFormat(&v4l2_format)){
+            ALOGE("could not get supported pixel format pixel_format=0x%x",pixel_format);
+            return ret;
+        }
+        mOutFormat = v4l2_format;
+        if(OK == pDev->GetColorFormatByV4l2(mOutFormat, &pixel_format))
+            mOutputFormat.pixelFormat = pixel_format;
         ret = prepareOutputParams();
         if(ret != OK){
             ALOGE("prepareOutputParams failed");
@@ -181,6 +227,13 @@ status_t V4l2Dec::onStart()
     if(ret != OK)
         return ret;
 
+    // workaround for MA-17234: CTS read framebuffer too often lead to buffer pool time out.
+    // need to allocate framebuffer as cacheable for these videos.
+    if ((mInFormat == V4L2_PIX_FMT_H264 || mInFormat == V4L2_PIX_FMT_VP8 || mInFormat == V4L2_PIX_FMT_HEVC) &&
+        (mInputFormat.width == 1920 && mInputFormat.height == 1080)) {
+        nOutBufferUsage = (uint64_t)(C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE | GRALLOC_USAGE_PRIVATE_2);
+    }
+
     mState = RUNNING;
 
     if(mOutputFormat.bufferNum > 0)
@@ -190,6 +243,7 @@ status_t V4l2Dec::onStart()
     mOutCnt = 0;
     mLastInputTs = -1;
     mLastInputId = 0;
+    bCodecDataQueued = false;
     ALOGV("onStart ret=%d",ret);
     return ret;
 }
@@ -224,6 +278,15 @@ status_t V4l2Dec::prepareInputParams()
         mInputFormat.bufferNum = 3;
     }
 
+    if (mInputFormat.width >= 3840 && mInputFormat.height >= 2160)
+        mInputFormat.bufferSize = kInputBufferSizeFor4k;
+    else {
+        // set bufferSize large enough to avoid this case: 176x144 -> 1920x1080
+        mInputFormat.bufferSize = Align(mInputFormat.width * mInputFormat.height * 2, 4096);
+        if (mInputFormat.bufferSize < kInputBufferSizeFor1080p)
+            mInputFormat.bufferSize = kInputBufferSizeFor1080p;
+    }
+    ALOGV("prepareInputParams bufferSize=%d",mInputFormat.bufferSize);
     #if 0
     struct v4l2_frmsizeenum info;
     memset(&info, 0, sizeof(v4l2_frmsizeenum));
@@ -240,49 +303,74 @@ status_t V4l2Dec::prepareInputParams()
 status_t V4l2Dec::SetInputFormats()
 {
     int result = 0;
+    uint32_t alignedWidth;
     Mutex::Autolock autoLock(mLock);
 
+    alignedWidth = Align(mInputFormat.width, mFrameAlignW);
+
     struct v4l2_format format;
     memset(&format, 0, sizeof(format));
-    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
-    format.fmt.pix_mp.num_planes = 1;
-    format.fmt.pix_mp.pixelformat = mInFormat;
-    format.fmt.pix_mp.plane_fmt[0].sizeimage = mInputFormat.bufferSize;
-    format.fmt.pix_mp.plane_fmt[0].bytesperline = Align(mInputFormat.width, FRAME_ALIGN);
-    format.fmt.pix_mp.width = mInputFormat.width;
-    format.fmt.pix_mp.height = mInputFormat.height;
-    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+    format.type = mOutBufType;
+
+    if (V4L2_TYPE_IS_MULTIPLANAR(mOutBufType)) {
+        format.fmt.pix_mp.num_planes = 1;
+        format.fmt.pix_mp.pixelformat = mInFormat;
+        format.fmt.pix_mp.plane_fmt[0].sizeimage = mInputFormat.bufferSize;
+        format.fmt.pix_mp.plane_fmt[0].bytesperline = alignedWidth;
+        format.fmt.pix_mp.width = mInputFormat.width;
+        format.fmt.pix_mp.height = mInputFormat.height;
+        format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+    } else {
+        format.fmt.pix.pixelformat = mInFormat;
+		format.fmt.pix.width = mInputFormat.width;
+		format.fmt.pix.height = mInputFormat.height;
+		format.fmt.pix.bytesperline = mInputFormat.width;
+		format.fmt.pix.sizeimage = mInputFormat.bufferSize;
+    }
 
     result = ioctl (mFd, VIDIOC_S_FMT, &format);
-    if(result != 0)
+    if(result != 0) {
+        ALOGE("ioctl VIDIOC_S_FMT failed, result=%d", result);
         return UNKNOWN_ERROR;
+    }
 
     memset(&format, 0, sizeof(format));
-    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    format.type = mOutBufType;
 
     result = ioctl (mFd, VIDIOC_G_FMT, &format);
-    if(result != 0)
+    if(result != 0) {
+        ALOGE("ioctl VIDIOC_G_FMT failed, result=%d", result);
         return UNKNOWN_ERROR;
+    }
 
-    if(format.fmt.pix_mp.pixelformat != mInFormat){
-        ALOGE("SetInputFormats mInFormat mismatch");
-        return UNKNOWN_ERROR;
+    uint32_t retFormat, retWidth, retHeight, retSizeimage;
+
+    if (V4L2_TYPE_IS_MULTIPLANAR(mOutBufType)) {
+        retFormat = format.fmt.pix_mp.pixelformat;
+        retHeight = format.fmt.pix_mp.height;
+        retWidth = format.fmt.pix_mp.width;
+        retSizeimage = format.fmt.pix_mp.plane_fmt[0].sizeimage;
+    } else {
+        retFormat = format.fmt.pix.pixelformat;
+        retHeight = format.fmt.pix.height;
+        retWidth = format.fmt.pix.width;
+        retSizeimage = format.fmt.pix.sizeimage;
     }
 
-    if( format.fmt.pix_mp.width != mInputFormat.width ||
-        format.fmt.pix_mp.height != mInputFormat.height){
-        ALOGE("SetInputFormats resolution mismatch");
+    if(retFormat != mInFormat){
+        ALOGE("SetInputFormats mInFormat mismatch");
         return UNKNOWN_ERROR;
     }
 
-    if(format.fmt.pix_mp.plane_fmt[0].bytesperline != Align(mInputFormat.width, FRAME_ALIGN)){
-        ALOGE("SetInputFormats stride mismatch");
+    if(retWidth != mInputFormat.width || retHeight != mInputFormat.height){
+        ALOGE("SetInputFormats resolution mismatch");
         return UNKNOWN_ERROR;
     }
 
-    if(format.fmt.pix_mp.plane_fmt[0].sizeimage != mInputFormat.bufferSize){
-        ALOGE("SetInputFormats bufferSize mismatch");
-        return UNKNOWN_ERROR;
+    if(retSizeimage != mInputFormat.bufferSize){
+        ALOGW("SetInputFormats bufferSize mismatch retSizeimage %d input bufferSize %d",
+                retSizeimage, mInputFormat.bufferSize);
+        mInputFormat.bufferSize = retSizeimage;
     }
 
     return OK;
@@ -296,17 +384,32 @@ status_t V4l2Dec::prepareOutputParams()
     if(ret != OK)
         return ret;
 
-    if(!pDev->IsCaptureFormatSupported(mOutFormat)){
-        ALOGE("output format not suppoted");
-        return ret;
+    ALOGV("prepareOutputParams begin pixelFormat=0x%x,mOutFormat=0x%x",mOutputFormat.pixelFormat, mOutFormat);
+
+    if(!pDev->IsCaptureFormatSupported(mOutFormat)) {
+        return UNKNOWN_ERROR;
     }
 
-    if(mOutFormat == V4L2_PIX_FMT_NV12 || mOutFormat == HAL_PIXEL_FORMAT_NV12_TILED){
+    if(mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_YCbCr_420_SP ||
+        mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_NV12_TILED ||
+        mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_P010) {
         //update output frame width & height
-        mOutputFormat.width = Align(mOutputFormat.rect.right, FRAME_ALIGN);
-        mOutputFormat.height = Align(mOutputFormat.rect.bottom, FRAME_ALIGN);
-        mOutputPlaneSize[0] = mOutputFormat.width * mOutputFormat.height;
-        mOutputPlaneSize[1] = mOutputPlaneSize[0]/2;
+        mOutputFormat.width = Align(mOutputFormat.rect.right, mFrameAlignW);
+        mOutputFormat.height = Align(mOutputFormat.rect.bottom, mFrameAlignH);
+
+        //TODO: use pxlfmt2bpp
+        if (V4L2_TYPE_IS_MULTIPLANAR(mCapBufType)) {
+            mOutputPlaneSize[0] = mOutputFormat.width * mOutputFormat.height;
+            mOutputPlaneSize[1] = mOutputPlaneSize[0]/2;
+        } else {
+            mOutputPlaneSize[0] = mOutputFormat.width * mOutputFormat.height * 3 / 2;
+        }
+
+        if (mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_P010) {
+            mOutputPlaneSize[0] = mOutputPlaneSize[0] * 5 / 4;
+            mOutputPlaneSize[1] = mOutputPlaneSize[1] * 5 / 4;
+        }
+        ALOGV("prepareOutputParams pixel format =0x%x,success",mOutputFormat.pixelFormat);
     }else
         return UNKNOWN_ERROR;
 
@@ -315,25 +418,37 @@ status_t V4l2Dec::prepareOutputParams()
 status_t V4l2Dec::SetOutputFormats()
 {
     int result = 0;
+    uint32_t alignedWidth;
     Mutex::Autolock autoLock(mLock);
 
     struct v4l2_format format;
     memset(&format, 0, sizeof(format));
-    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-    format.fmt.pix_mp.num_planes = kOutputBufferPlaneNum;
-    format.fmt.pix_mp.pixelformat = mOutFormat;
-
-    mOutputFormat.width = Align(mOutputFormat.width, FRAME_ALIGN);
-    mOutputFormat.height = Align(mOutputFormat.height, FRAME_ALIGN);
-
-    format.fmt.pix_mp.width = mOutputFormat.width;
-    format.fmt.pix_mp.height = mOutputFormat.height;
-    ALOGV("SetOutputFormats w=%d,h=%d",format.fmt.pix_mp.width,format.fmt.pix_mp.height);
-    format.fmt.pix_mp.plane_fmt[0].sizeimage = mOutputPlaneSize[0];
-    format.fmt.pix_mp.plane_fmt[0].bytesperline = Align(mOutputFormat.width, FRAME_ALIGN);
-    format.fmt.pix_mp.plane_fmt[1].sizeimage = mOutputPlaneSize[1];
-    format.fmt.pix_mp.plane_fmt[1].bytesperline = Align(mOutputFormat.width, FRAME_ALIGN);
-    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+    format.type = mCapBufType;
+
+    alignedWidth = Align(mOutputFormat.width, mFrameAlignW);
+
+    mOutputFormat.width = Align(mOutputFormat.width, mFrameAlignW);
+    mOutputFormat.height = Align(mOutputFormat.height, mFrameAlignH);
+
+    if (V4L2_TYPE_IS_MULTIPLANAR(mCapBufType)) {
+        format.fmt.pix_mp.num_planes = kOutputBufferPlaneNum;
+        format.fmt.pix_mp.pixelformat = mOutFormat;
+        format.fmt.pix_mp.width = mOutputFormat.width;
+        format.fmt.pix_mp.height = mOutputFormat.height;
+        format.fmt.pix_mp.plane_fmt[0].sizeimage = mOutputPlaneSize[0];
+        format.fmt.pix_mp.plane_fmt[0].bytesperline = alignedWidth;
+        format.fmt.pix_mp.plane_fmt[1].sizeimage = mOutputPlaneSize[1];
+        format.fmt.pix_mp.plane_fmt[1].bytesperline = alignedWidth;
+        format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+    } else {
+        format.fmt.pix.pixelformat = mOutFormat;
+		format.fmt.pix.width = mOutputFormat.width;
+		format.fmt.pix.height = mOutputFormat.height;
+		format.fmt.pix.bytesperline = alignedWidth;
+		format.fmt.pix.sizeimage = mOutputPlaneSize[0];
+    }
+
+    ALOGV("SetOutputFormats w=%d,h=%d,fmt=0x%x",mOutputFormat.width, mOutputFormat.height, mOutFormat);
 
     result = ioctl (mFd, VIDIOC_S_FMT, &format);
     if(result != 0){
@@ -342,33 +457,35 @@ status_t V4l2Dec::SetOutputFormats()
     }
 
     memset(&format, 0, sizeof(struct v4l2_format));
-    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    format.type = mCapBufType;
 
     result = ioctl (mFd, VIDIOC_G_FMT, &format);
     if(result < 0)
         return UNKNOWN_ERROR;
 
+    uint32_t retFormat, retWidth, retHeight, retBytesperline, retSizeimage;
 
-    if(format.fmt.pix_mp.pixelformat != mOutFormat){
-        ALOGE("SetOutputFormats mOutFormat mismatch");
-        return UNKNOWN_ERROR;
-    }
-
-    if( format.fmt.pix_mp.width > mOutputFormat.width ||
-        format.fmt.pix_mp.height > mOutputFormat.height){
-        ALOGE("SetOutputFormats resolution mismatch,w=%d,h=%d,output w=%d,h=%d",
-            format.fmt.pix_mp.width,format.fmt.pix_mp.height,mOutputFormat.width, mOutputFormat.height);
-        return UNKNOWN_ERROR;
-    }
+    if (V4L2_TYPE_IS_MULTIPLANAR(mCapBufType)) {
+        retFormat = format.fmt.pix_mp.pixelformat;
 
-    if(format.fmt.pix_mp.plane_fmt[0].bytesperline != Align(mOutputFormat.width, FRAME_ALIGN)){
-        ALOGE("SetOutputFormats stride mismatch");
-        return UNKNOWN_ERROR;
+        if(format.fmt.pix_mp.plane_fmt[0].sizeimage !=  mOutputPlaneSize[0] ||
+            format.fmt.pix_mp.plane_fmt[1].sizeimage !=  mOutputPlaneSize[1]){
+            ALOGE("SetOutputFormats bufferSize mismatch");
+            return UNKNOWN_ERROR;
+        }
+    } else {
+        retFormat = format.fmt.pix.pixelformat;
+
+        if(format.fmt.pix.sizeimage !=  mOutputPlaneSize[0]) {
+            ALOGW("SetOutputFormats bufferSize mismatch, %d -> %d",
+                mOutputPlaneSize[0], format.fmt.pix.sizeimage);
+            mOutputPlaneSize[0] = format.fmt.pix.sizeimage;
+            mOutputFormat.bufferSize = mOutputPlaneSize[0];
+        }
     }
 
-    if(format.fmt.pix_mp.plane_fmt[0].sizeimage !=  mOutputPlaneSize[0] ||
-        format.fmt.pix_mp.plane_fmt[1].sizeimage !=  mOutputPlaneSize[1]){
-        ALOGE("SetOutputFormats bufferSize mismatch");
+    if(retFormat != mOutFormat){
+        ALOGE("SetOutputFormats mOutFormat mismatch");
         return UNKNOWN_ERROR;
     }
 
@@ -384,7 +501,7 @@ V4l2Dec::InputRecord::InputRecord()
 V4l2Dec::InputRecord::~InputRecord() {}
 
 V4l2Dec::OutputRecord::OutputRecord()
-    : at_device(false), picture_id(0), flag(0), mGraphicBlock(NULL) {
+    : at_device(false), picture_id(0), flag(0) {
     memset(&planes, 0, sizeof(VideoFramePlane)*kOutputBufferPlaneNum);
 }
 
@@ -399,7 +516,7 @@ status_t V4l2Dec::prepareInputBuffers()
     struct v4l2_requestbuffers reqbufs;
     memset(&reqbufs, 0, sizeof(reqbufs));
     reqbufs.count = mInputFormat.bufferNum;
-    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.type = mOutBufType;
     reqbufs.memory = mInMemType;
 
     ALOGV("prepareInputBuffers count=%d",reqbufs.count);
@@ -445,21 +562,31 @@ status_t V4l2Dec::createInputBuffers()
     memset(&planes, 0, sizeof(planes));
 
     for (size_t i = 0; i < mInputBufferMap.size(); i++) {
-        stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        stV4lBuf.type = mOutBufType;
         stV4lBuf.memory = V4L2_MEMORY_MMAP;
         stV4lBuf.index = i;
-        stV4lBuf.length = kInputBufferPlaneNum;
-        stV4lBuf.m.planes = &planes;
+
+        if (V4L2_TYPE_IS_MULTIPLANAR(mOutBufType)) {
+            stV4lBuf.length = kInputBufferPlaneNum;
+            stV4lBuf.m.planes = &planes;
+        }
         result = ioctl(mFd, VIDIOC_QUERYBUF, &stV4lBuf);
         if(result < 0)
             return UNKNOWN_ERROR;
 
         planes.length = mInputFormat.bufferSize;
 
-        ptr = mmap(NULL, planes.length,
-            PROT_READ | PROT_WRITE, /* recommended */
-            MAP_SHARED,             /* recommended */
-            mFd, planes.m.mem_offset);
+        if (V4L2_TYPE_IS_MULTIPLANAR(mOutBufType)) {
+            ptr = mmap(NULL, planes.length,
+                    PROT_READ | PROT_WRITE, /* recommended */
+                    MAP_SHARED,             /* recommended */
+                    mFd, planes.m.mem_offset);
+        } else {
+		    ptr = mmap(NULL, stV4lBuf.length,
+    				PROT_READ | PROT_WRITE,
+    				MAP_SHARED,
+    				mFd, stV4lBuf.m.offset);
+        }
 
         if(ptr != MAP_FAILED){
             tmp = (uint64_t)ptr;
@@ -495,7 +622,7 @@ status_t V4l2Dec::destroyInputBuffers()
     struct v4l2_requestbuffers reqbufs;
     memset(&reqbufs, 0, sizeof(reqbufs));
     reqbufs.count = 0;
-    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.type = mOutBufType;
     reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
 
     result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
@@ -512,85 +639,28 @@ status_t V4l2Dec::destroyInputBuffers()
 }
 status_t V4l2Dec::importOutputBuffers(std::vector<GraphicBlockInfo> buffers)
 {
-#if 0
-    uint32_t out_buf_count = buffers.size();
-
-    if(out_buf_count != mOutputFormat.bufferNum){
-        ALOGE("importOutputBuffers failed");
-        return UNKNOWN_ERROR;
-    }
-
-    out_buf_count = 32; // add 4 + 3 buffers to align with CCodecBufferChannel
-    mLock.lock();
-    int result = 0;
-    struct v4l2_requestbuffers reqbufs;
-    memset(&reqbufs, 0, sizeof(reqbufs));
-    reqbufs.count = out_buf_count;
-    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-    reqbufs.memory = mOutMemType;
-
-    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
-
-    if(result != 0){
-        mLock.unlock();
-        return UNKNOWN_ERROR;
-    }
-
-    mOutputBufferMap.resize(out_buf_count);
+    {
+        Mutex::Autolock autoLock(mLock);
+        if(mState == STOPPING)
+            return OK;
 
-    for (size_t i = 0; i < mOutputBufferMap.size(); i++) {
-        OutputRecord& output_record = mOutputBufferMap[i];
+        mState = RUNNING;
 
-        if (i < buffers.size()) {
+        int result = 0;
+        struct v4l2_requestbuffers reqbufs;
+        memset(&reqbufs, 0, sizeof(reqbufs));
+        reqbufs.count = 32;
+        reqbufs.type = mCapBufType;
+        reqbufs.memory = mOutMemType;
 
-        output_record.planes[0].fd = buffers[i].mDMABufFd;
-        output_record.planes[0].vaddr = buffers[i].mVirtAddr;
-        output_record.planes[0].paddr = buffers[i].mPhysAddr;
-        output_record.planes[0].size = mOutputPlaneSize[0];
-        output_record.planes[0].length = 0;
-        output_record.planes[0].offset = 0;
-        output_record.planes[1].fd = buffers[i].mDMABufFd;
-        output_record.planes[1].vaddr = buffers[i].mVirtAddr + mOutputPlaneSize[0];
-        output_record.planes[1].paddr = buffers[i].mPhysAddr + mOutputPlaneSize[0];
-        output_record.planes[1].size = mOutputPlaneSize[1];
-        output_record.planes[1].length = 0;
-        output_record.planes[1].offset = mOutputPlaneSize[0];
+        result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
 
-        output_record.at_device = false;
-        output_record.picture_id = buffers[i].mBlockId;
-        } else {
-            output_record.planes[0].fd = 0;
-            output_record.planes[0].vaddr = 0;
-            output_record.planes[0].paddr = 0;
-            output_record.at_device = false;
-            output_record.picture_id = -1;
+        if(result != 0){
+            return UNKNOWN_ERROR;
         }
+        if (!bNeedPostProcess)
+             mOutputBufferMap.resize(32);
     }
-#else
-    if(mState == STOPPING)
-        return OK;
-
-    mState = RUNNING;
-    mLock.lock();
-
-    int result = 0;
-    struct v4l2_requestbuffers reqbufs;
-    memset(&reqbufs, 0, sizeof(reqbufs));
-    reqbufs.count = 32;
-    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-    reqbufs.memory = mOutMemType;
-
-    result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
-
-    if(result != 0){
-        mLock.unlock();
-        return UNKNOWN_ERROR;
-    }
-    if (!bNeedPostProcess)
-        mOutputBufferMap.resize(32);
-
-    mLock.unlock();
-#endif
 
     createFetchThread();
     return OK;
@@ -605,7 +675,7 @@ status_t V4l2Dec::destroyOutputBuffers()
     struct v4l2_requestbuffers reqbufs;
     memset(&reqbufs, 0, sizeof(reqbufs));
     reqbufs.count = 0;
-    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.type = mCapBufType;
     reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
 
     result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
@@ -615,6 +685,7 @@ status_t V4l2Dec::destroyOutputBuffers()
         //return UNKNOWN_ERROR;
     }
 
+    mRegisteredOutBufNum = 0;
     mOutputBufferMap.clear();
     ClearPictureBuffer();//call it here or in base class
     ALOGV("destroyOutputBuffers success");
@@ -648,9 +719,12 @@ status_t V4l2Dec::HandlePollThread()
 }
 status_t V4l2Dec::HandleFetchThread()
 {
+    int64_t waitUs = ALooper::GetNowUs();
+
     while(bFetchStarted){
         // only start fetching when vpu output buffer isn't enough
         if (mVpuOwnedOutputBufferNum >= mOutputFormat.bufferNum || RUNNING != mState) {
+            waitUs = ALooper::GetNowUs();
             usleep(5000);
             continue;
         }
@@ -670,6 +744,11 @@ status_t V4l2Dec::HandleFetchThread()
                 if (OK == ret) {
                     gbInfo = getFreeGraphicBlock();
                 } else if (WOULD_BLOCK == ret) {
+                    if (bNewSegment && mVpuOwnedOutputBufferNum < mOutputFormat.minBufferNum &&
+                            ALooper::GetNowUs() - waitUs > 1000000) {
+                        // can't fetch more buffer after flush, migrate current buffer and fetch new
+                        migrateOutputBuffers();
+                    }
                     usleep(1000);
                     continue;
                 } else {
@@ -680,6 +759,7 @@ status_t V4l2Dec::HandleFetchThread()
             }
             ALOGV("HandleFetchThread queueOutput 2 BEGIN");
             queueOutput(gbInfo);
+            waitUs = ALooper::GetNowUs();
         }
     }
     ALOGV("HandleFetchThread stopped");
@@ -781,14 +861,18 @@ status_t V4l2Dec::decodeInternal(std::unique_ptr<IMXInputBuffer> input)
     if(input == nullptr)
         return BAD_VALUE;
 
-    if(STOPPED == mState || UNINITIALIZED == mState)
-        onStart();
+    if(STOPPED == mState || UNINITIALIZED == mState) {
+        if (OK != onStart())
+            return BAD_VALUE;
+    }
 
     if (!bCodecDataQueued && pCodecDataBuf && nCodecDataLen > 0) {
+        ALOGV("queue codecdata, len: %d", nCodecDataLen);
+
         bCodecDataQueued = true;
-        ALOGV("queue codecdata");
+
         status_t ret = decodeInternal(std::make_unique<IMXInputBuffer>(
-                                        pCodecDataBuf, -1, -1, nCodecDataLen, -1, false, true));
+                                                pCodecDataBuf, -1, -1, nCodecDataLen, -1, false, true));
         if (ret != OK) {
             ALOGE("queue codecdata failed with ret %d", ret);
             return ret;
@@ -801,8 +885,9 @@ status_t V4l2Dec::decodeInternal(std::unique_ptr<IMXInputBuffer> input)
     bool eos = input->eos;
 
     if (eos) {
-        ALOGV("get input eos, call stopDecoder");
+        ALOGD("get input eos, call stopDecoder");
         Mutex::Autolock autoLock(mLock);
+        bSawInputEos = true;
         if (OK != pDev->StopDecoder())
             ALOGW("Stop Decoder failed
");
         return OK;
@@ -839,7 +924,6 @@ status_t V4l2Dec::decodeInternal(std::unique_ptr<IMXInputBuffer> input)
 
         if(codec_data_nal && !has_other_nal){
             ALOGV("SKIP SPS or PPS");
-            NotifyInputBufferUsed(input->id);
             //return bad value then client IMXC2VideoDecoder will handle it
             return BAD_VALUE;
         }
@@ -867,9 +951,25 @@ QueueOneBuffer:
     ALOGV("decodeInternal input->BUF=%p, index=%d, len=%zu, ts=%lld, fd=%d",input->pInBuffer, index, input->size, ts, fd);
 
     if(mInMemType == V4L2_MEMORY_MMAP){
-        memcpy((void*)(uintptr_t)(mInputBufferMap[index].plane.vaddr + buf_length), input->pInBuffer, input->size);
+        uint32_t offset = 0;
+        if (bSecureMode) {
+#ifdef HANTRO_V4L2
+            // vsi vpu reserve 16 bytes to save physical address
+            fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
+            uint64_t paddr;
+            if (pIonAllocator->getPhys(fd, input->size, (uint64_t&)paddr) == 0) {
+                memcpy((void*)(uintptr_t)mInputBufferMap[index].plane.vaddr, &paddr, sizeof(uint64_t));
+                offset += 16;
+            } else {
+                ALOGE("can't get physical address in secure mode");
+                return BAD_VALUE;
+            }
+#endif
+        }
+
+        memcpy((void*)(uintptr_t)(mInputBufferMap[index].plane.vaddr + offset), input->pInBuffer, input->size);
         buf_length += input->size;
-        dumpInputBuffer((void*)(uintptr_t)mInputBufferMap[index].plane.vaddr, buf_length);
+        dumpInputBuffer((void*)(uintptr_t)(mInputBufferMap[index].plane.vaddr + offset), buf_length);
     }
 
     if(mInputBufferMap[index].at_device){
@@ -877,53 +977,60 @@ QueueOneBuffer:
     }
 
     struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane plane;
     memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+    struct v4l2_plane plane;//kInputBufferPlaneNum
     memset(&plane, 0, sizeof(plane));
 
-    plane.bytesused = buf_length;
-    plane.length = mInputFormat.bufferSize;
-    plane.data_offset = 0;
-
-    if(mInMemType == V4L2_MEMORY_MMAP)
-        plane.m.mem_offset = 0;
-    else if(mInMemType == V4L2_MEMORY_USERPTR)
-        plane.m.userptr = (unsigned long)mInputBufferMap[index].plane.vaddr;
-    else if(mInMemType == V4L2_MEMORY_DMABUF)
-        plane.m.fd = mInputBufferMap[index].plane.fd;
-
-
     stV4lBuf.index = index;
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    stV4lBuf.type = mOutBufType;
 
     if(ts >= 0){
         stV4lBuf.timestamp.tv_sec = ts / 1000000;
         stV4lBuf.timestamp.tv_usec = ts % 1000000;
         v4l2_flags |= (V4L2_BUF_FLAG_TIMESTAMP_MASK | V4L2_BUF_FLAG_TIMESTAMP_COPY);
-    }else{
+    }
+    else{
         stV4lBuf.timestamp.tv_sec = -1;
         stV4lBuf.timestamp.tv_usec = 0;
         v4l2_flags |= IMX_V4L2_BUF_FLAG_TIMESTAMP_INVALID;
     }
-
     stV4lBuf.memory = mInMemType;
-    stV4lBuf.m.planes = &plane;
-    stV4lBuf.length = kInputBufferPlaneNum;
     stV4lBuf.flags = v4l2_flags;
 
-    ALOGV("VIDIOC_QBUF OUTPUT_MPLANE BEGIN index=%d,len=%d, ts=%lld
",
-        stV4lBuf.index, plane.bytesused, (long long)ts);
+    if (V4L2_TYPE_IS_MULTIPLANAR(mOutBufType)) {
+
+        plane.bytesused = buf_length;
+        plane.length = mInputFormat.bufferSize;
+        plane.data_offset = 0;
+
+        if(mInMemType == V4L2_MEMORY_MMAP)
+            plane.m.mem_offset = 0;
+        else if(mInMemType == V4L2_MEMORY_USERPTR)
+            plane.m.userptr = (unsigned long)mInputBufferMap[index].plane.vaddr;
+        else if(mInMemType == V4L2_MEMORY_DMABUF)
+            plane.m.fd = mInputBufferMap[index].plane.fd;
+
+        stV4lBuf.m.planes = &plane;
+        stV4lBuf.length = kInputBufferPlaneNum;
+    } else {
+        stV4lBuf.bytesused = buf_length;
+        stV4lBuf.length = mInputFormat.bufferSize;
+    }
+
+    ALOGV("VIDIOC_QBUF OUTPUT BEGIN index=%d,len=%d, ts=%lld
",
+        stV4lBuf.index, buf_length, (long long)ts);
+
 
     result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
     if(result < 0){
-        ALOGE("VIDIOC_QBUF OUTPUT_MPLANE failed, index=%d",index);
+        ALOGE("VIDIOC_QBUF OUTPUT failed, index=%d",index);
         mLock.unlock();
         return UNKNOWN_ERROR;
     }
 
     mInputBufferMap[index].at_device = true;
-    ALOGV("VIDIOC_QBUF OUTPUT_MPLANE END index=%d,len=%d, ts=%lld
",
-        stV4lBuf.index, plane.bytesused, (long long)ts);
+    ALOGV("VIDIOC_QBUF OUTPUT END index=%d,len=%d, ts=%lld
",
+        stV4lBuf.index, buf_length, (long long)ts);
 
     if(bMpeg2 && !input->csd){
         if(ts >= 0 && mLastInputTs == ts){
@@ -935,60 +1042,66 @@ QueueOneBuffer:
     }
 
     mInCnt++;
+
     mLock.unlock();
 
     if(!bInputStreamOn)
         startInputStream();
 
-    if (input->id >= 0) {
-        ALOGV("NotifyInputBufferUsed id=%d",input->id);
-        NotifyInputBufferUsed(input->id);
-    }
-
     //if one frame was split into several input buffer, then skip previous input id
     if(returnEmptyWork && mLastInputId > 0){
         ALOGV("NotifySkipInputBuffer id=%d",mLastInputId);
         NotifySkipInputBuffer(mLastInputId);
     }
+
     return OK;
 }
 status_t V4l2Dec::dequeueInputBuffer()
 {
     int result = 0;
     int input_id = -1;
-
+    struct v4l2_buffer stV4lBuf;
 
     if(!bInputStreamOn || mState != RUNNING )
         return OK;
+    {
+        Mutex::Autolock autoLock(mLock);
 
-    Mutex::Autolock autoLock(mLock);
+        if(!bInputStreamOn || mState != RUNNING)
+            return OK;
 
-    if(!bInputStreamOn || mState != RUNNING)
-        return OK;
+        memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+        stV4lBuf.type = mOutBufType;
+        stV4lBuf.memory = mInMemType;
 
-    struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane planes[kInputBufferPlaneNum];
-    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
-    memset(planes, 0, sizeof(planes));
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
-    stV4lBuf.memory = mInMemType;
-    stV4lBuf.m.planes = planes;
-    stV4lBuf.length = kInputBufferPlaneNum;
-    ALOGV("VIDIOC_DQBUF OUTPUT_MPLANE BEGIN");
-    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
-    if(result < 0)
-        return UNKNOWN_ERROR;
+        if (V4L2_TYPE_IS_MULTIPLANAR(mOutBufType)) {
+            struct v4l2_plane planes[kInputBufferPlaneNum];
+            memset(planes, 0, sizeof(planes));
+            stV4lBuf.m.planes = planes;
+            stV4lBuf.length = kInputBufferPlaneNum;
+        }
 
-    if(stV4lBuf.index >= mInputFormat.bufferNum)
-        return BAD_INDEX;
+        ALOGV("VIDIOC_DQBUF OUTPUT BEGIN");
+        result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+        if(result < 0)
+            return UNKNOWN_ERROR;
 
-    ALOGV("VIDIOC_DQBUF OUTPUT_MPLANE END index=%d",stV4lBuf.index);
-    if(!mInputBufferMap[stV4lBuf.index].at_device){
-        ALOGE("dequeueInputBuffer index=%d, not at_device",stV4lBuf.index);
+        if(stV4lBuf.index >= mInputFormat.bufferNum)
+            return BAD_INDEX;
+
+        ALOGV("VIDIOC_DQBUF OUTPUT END index=%d",stV4lBuf.index);
+        if(!mInputBufferMap[stV4lBuf.index].at_device){
+            ALOGE("dequeueInputBuffer index=%d, not at_device",stV4lBuf.index);
+        }
+
+        input_id = mInputBufferMap[stV4lBuf.index].input_id;
+        mInputBufferMap[stV4lBuf.index].input_id = -1;
+        mInputBufferMap[stV4lBuf.index].at_device = false;
     }
-    mInputBufferMap[stV4lBuf.index].at_device = false;
-    input_id = mInputBufferMap[stV4lBuf.index].input_id;
-    mInputBufferMap[stV4lBuf.index].input_id = -1;
+
+    if(input_id >= 0)
+        NotifyInputBufferUsed(input_id);
+
 
     return OK;
 }
@@ -1027,6 +1140,7 @@ status_t V4l2Dec::queueOutput(GraphicBlockInfo* pInfo)
     fd[0] = pInfo->mDMABufFd;
     fd[1] = pInfo->mDMABufFd;
 
+
     //try to get index
     for(int32_t i = 0; i < mOutputBufferMap.size(); i++){
         if(pInfo->mPhysAddr == mOutputBufferMap[i].planes[0].paddr){
@@ -1052,6 +1166,7 @@ status_t V4l2Dec::queueOutput(GraphicBlockInfo* pInfo)
                 mOutputBufferMap[i].picture_id = pInfo->mBlockId;
                 mOutputBufferMap[i].at_device = false;
                 index = i;
+                ++mRegisteredOutBufNum;
                 break;
             }
         }
@@ -1072,39 +1187,49 @@ status_t V4l2Dec::queueOutput(GraphicBlockInfo* pInfo)
     memset(&stV4lBuf, 0, sizeof(stV4lBuf));
     memset(&planes, 0, sizeof(planes));
 
-
-    if(mOutMemType == V4L2_MEMORY_DMABUF){
-        planes[0].m.fd = fd[0];
-        planes[1].m.fd = fd[1];
-    }else if(mOutMemType == V4L2_MEMORY_USERPTR){
-        planes[0].m.userptr = vaddr[0];
-        planes[1].m.userptr = vaddr[1];
-    }
-
-    planes[0].length = mOutputBufferMap[index].planes[0].size;
-    planes[1].length = mOutputBufferMap[index].planes[1].size;
-
-    planes[0].data_offset = mOutputBufferMap[index].planes[0].offset;
-    planes[1].data_offset = mOutputBufferMap[index].planes[1].offset;
-
     stV4lBuf.index = index;
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    stV4lBuf.type = mCapBufType;
     stV4lBuf.memory = mOutMemType;
-    stV4lBuf.m.planes = &planes[0];
-    stV4lBuf.length = kOutputBufferPlaneNum;
     stV4lBuf.flags = 0;
 
-    ALOGV("VIDIOC_QBUF CAPTURE_MPLANE BEGIN index=%d blockId=%d
",index, pInfo->mBlockId);
+    if (V4L2_TYPE_IS_MULTIPLANAR(mCapBufType)) {
+        if (mOutMemType == V4L2_MEMORY_DMABUF) {
+            planes[0].m.fd = fd[0];
+            planes[1].m.fd = fd[1];
+        } else if(mOutMemType == V4L2_MEMORY_USERPTR) {
+            planes[0].m.userptr = vaddr[0];
+            planes[1].m.userptr = vaddr[1];
+        }
+
+        planes[0].length = mOutputBufferMap[index].planes[0].size;
+        planes[1].length = mOutputBufferMap[index].planes[1].size;
+
+        planes[0].data_offset = mOutputBufferMap[index].planes[0].offset;
+        planes[1].data_offset = mOutputBufferMap[index].planes[1].offset;
+
+        stV4lBuf.m.planes = &planes[0];
+        stV4lBuf.length = kOutputBufferPlaneNum;
+    } else {
+        if (mOutMemType == V4L2_MEMORY_USERPTR) {
+            stV4lBuf.length = mOutputPlaneSize[0];
+            stV4lBuf.m.userptr = (unsigned long)vaddr[0];
+        } else if (mOutMemType == V4L2_MEMORY_DMABUF) {
+            stV4lBuf.length = mOutputPlaneSize[0];
+            stV4lBuf.m.fd = fd[0];
+        }
+    }
+
+    ALOGV("VIDIOC_QBUF CAPTURE BEGIN index=%d blockId=%d fd=%d
",index, pInfo->mBlockId, fd[0]);
 
     result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
     if(result < 0){
-        ALOGE("VIDIOC_QBUF CAPTURE_MPLANE failed, index=%d",index);
+        ALOGE("VIDIOC_QBUF CAPTURE failed, index=%d, result=%d",index, result);
         mLock.unlock();
         return UNKNOWN_ERROR;
     }
 
-    ALOGV("VIDIOC_QBUF CAPTURE_MPLANE END index=%d blockId=%d
",index, pInfo->mBlockId);
-    pInfo->mState = GraphicBlockInfo::State::OWNED_BY_VPU;
+    ALOGV("VIDIOC_QBUF CAPTURE END index=%d blockId=%d
",index, pInfo->mBlockId);
+    GraphicBlockSetState(pInfo->mBlockId, GraphicBlockInfo::State::OWNED_BY_VPU);
 
     mVpuOwnedOutputBufferNum++;
     mOutputBufferMap[index].at_device = true;
@@ -1117,11 +1242,13 @@ status_t V4l2Dec::queueOutput(GraphicBlockInfo* pInfo)
 
 status_t V4l2Dec::startInputStream()
 {
+    ALOGV("%s", __FUNCTION__);
     Mutex::Autolock autoLock(mLock);
     if(!bInputStreamOn){
-        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        enum v4l2_buf_type buf_type = mOutBufType;
         if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
             bInputStreamOn = true;
+            ALOGV("%s OK", __FUNCTION__);
         }
     }
     return OK;
@@ -1131,9 +1258,10 @@ status_t V4l2Dec::stopInputStream()
     ALOGV("%s", __FUNCTION__);
     Mutex::Autolock autoLock(mLock);
     if(bInputStreamOn){
-        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        enum v4l2_buf_type buf_type = mOutBufType;
         if(0 == ioctl(mFd, VIDIOC_STREAMOFF, &buf_type)){
             bInputStreamOn = false;
+            ALOGV("%s OK", __FUNCTION__);
         }
     }
 
@@ -1150,9 +1278,10 @@ status_t V4l2Dec::startOutputStream()
     ALOGV("%s", __FUNCTION__);
     Mutex::Autolock autoLock(mLock);
     if(!bOutputStreamOn){
-        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        enum v4l2_buf_type buf_type = mCapBufType;
         if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
             bOutputStreamOn = true;
+            ALOGV("%s OK", __FUNCTION__);
         }
     }
     return OK;
@@ -1162,15 +1291,16 @@ status_t V4l2Dec::stopOutputStream()
     ALOGV("%s", __FUNCTION__);
     Mutex::Autolock autoLock(mLock);
     //call VIDIOC_STREAMOFF and ignore the result
-    enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    enum v4l2_buf_type buf_type = mCapBufType;
     (void)ioctl(mFd, VIDIOC_STREAMOFF, &buf_type);
+    ALOGV("%s OK", __FUNCTION__);
     bOutputStreamOn = false;
 
+
     // return capture buffer to component
     for(int32_t i = 0; i < mOutputBufferMap.size(); i++){
         if(mOutputBufferMap[i].planes[0].paddr > 0 && mOutputBufferMap[i].at_device) {
-            GraphicBlockInfo *gbInfo = getGraphicBlockById(mOutputBufferMap[i].picture_id);
-            gbInfo->mState = GraphicBlockInfo::State::OWNED_BY_COMPONENT;
+            GraphicBlockSetState(mOutputBufferMap[i].picture_id, GraphicBlockInfo::State::OWNED_BY_COMPONENT);
             mOutputBufferMap[i].at_device = false;
             ALOGV("return capture buffer %d ", mOutputBufferMap[i].picture_id);
         }
@@ -1180,48 +1310,83 @@ status_t V4l2Dec::stopOutputStream()
 
     return OK;
 }
+
 status_t V4l2Dec::dequeueOutputBuffer()
 {
     int result = 0;
+    int byteused = 0;
+    bool outputEos = false;
+    int64_t ts = 0;
+    struct v4l2_buffer stV4lBuf;
+    struct v4l2_plane planes[kOutputBufferPlaneNum];
 
     if(!bOutputStreamOn || mState != RUNNING)
         return OK;
+    {
+        Mutex::Autolock autoLock(mLock);
 
-    Mutex::Autolock autoLock(mLock);
+        if(!bOutputStreamOn || mState != RUNNING)
+            return OK;
 
-    if(!bOutputStreamOn || mState != RUNNING)
-        return OK;
+        if (bNewSegment)
+            bNewSegment = false;
+
+        memset(&stV4lBuf, 0, sizeof(stV4lBuf));
+        memset(planes, 0, sizeof(planes));
+        stV4lBuf.type = mCapBufType;
+        stV4lBuf.memory = mOutMemType;
+
+        if (V4L2_TYPE_IS_MULTIPLANAR(mCapBufType)) {
+            stV4lBuf.m.planes = planes;
+            stV4lBuf.length = kOutputBufferPlaneNum;
+        }
+
+        ALOGV("VIDIOC_DQBUF CAPTURE BEGIN");
+        result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
+        if(result < 0) {
+            ALOGV("%s VIDIOC_DQBUF err=%d", __FUNCTION__, result);
+            return UNKNOWN_ERROR;
+        }
+
+        if(stV4lBuf.index >= 32/*mOutputFormat.bufferNum*/) {
+            ALOGI("dequeueOutputBuffer error");
+            return BAD_INDEX;
+        }
+
+        if (V4L2_TYPE_IS_MULTIPLANAR(mCapBufType))
+            byteused = stV4lBuf.m.planes[0].bytesused + stV4lBuf.m.planes[1].bytesused;
+        else
+            byteused = stV4lBuf.bytesused;
+
+        if (byteused == 0 || (stV4lBuf.flags & V4L2_BUF_FLAG_LAST)) {
+            outputEos = true;
+            ALOGI("decoder get output eos 
");
+        }
+
+        ts = (int64_t)stV4lBuf.timestamp.tv_sec *1000000;
+        ts += stV4lBuf.timestamp.tv_usec;
+
+        ALOGV("VIDIOC_DQBUF CAPTURE END index=%d ts=%lld byteused=%d flags %x",
+            stV4lBuf.index, (long long)ts, byteused, stV4lBuf.flags);
+
+        mOutputBufferMap[stV4lBuf.index].at_device = false;
+        mVpuOwnedOutputBufferNum--;
+        mOutCnt ++;
 
-    int64_t ts = 0;
-    struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane planes[kOutputBufferPlaneNum];
-    memset(&stV4lBuf, 0, sizeof(stV4lBuf));
-    memset(planes, 0, sizeof(planes));
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-    stV4lBuf.memory = mOutMemType;
-    stV4lBuf.m.planes = planes;
-    stV4lBuf.length = kOutputBufferPlaneNum;
-    ALOGV("VIDIOC_DQBUF CAPTURE_MPLANE BEGIN");
-    result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
-    if(result < 0) {
-        ALOGV("%s VIDIOC_DQBUF err=%d", __FUNCTION__, result);
-        return UNKNOWN_ERROR;
     }
 
-    if(stV4lBuf.index >= 32/*mOutputFormat.bufferNum*/) {
-        ALOGI("dequeueOutputBuffer error");
-        return BAD_INDEX;
+    if (byteused > 0) {
+        dumpOutputBuffer((void*)(uintptr_t)mOutputBufferMap[stV4lBuf.index].planes[0].vaddr, byteused);
+        NotifyPictureReady(mOutputBufferMap[stV4lBuf.index].picture_id, ts);
+    } else {
+        returnOutputBufferToDecoder(mOutputBufferMap[stV4lBuf.index].picture_id);
     }
 
-    ts = (int64_t)stV4lBuf.timestamp.tv_sec *1000000;
-    ts += stV4lBuf.timestamp.tv_usec;
+    if(outputEos) {
+        handleDecEos();
+        mState = STOPPED;
+    }
 
-    ALOGV("VIDIOC_DQBUF CAPTURE_MPLANE END index=%d ts=%lld",stV4lBuf.index, (long long)ts);
-    mVpuOwnedOutputBufferNum--;
-    mOutCnt ++;
-    mOutputBufferMap[stV4lBuf.index].at_device = false;
-    dumpOutputBuffer((void*)(uintptr_t)mOutputBufferMap[stV4lBuf.index].planes[0].vaddr,mOutputFormat.bufferSize);
-    NotifyPictureReady(mOutputBufferMap[stV4lBuf.index].picture_id, ts);
     return OK;
 }
 status_t V4l2Dec::onDequeueEvent()
@@ -1232,7 +1397,7 @@ status_t V4l2Dec::onDequeueEvent()
 
     result = ioctl(mFd, VIDIOC_DQEVENT, &event);
     if(result == 0){
-        ALOGV("onDequeueEvent type=%d",event.type);
+        ALOGD("onDequeueEvent type=%x",event.type);
         switch(event.type){
             case V4L2_EVENT_SOURCE_CHANGE:
                 if(event.u.src_change.changes & V4L2_EVENT_SRC_CH_RESOLUTION){
@@ -1245,11 +1410,10 @@ status_t V4l2Dec::onDequeueEvent()
             {
                 Mutex::Autolock autoLock(mLock);
                 usleep(1000);
-                if(STOPPING != mState)
-                    NotifyEOS();//send eos event
-                bPollStarted = false;
-                bFetchStarted = false;
-                mState = STOPPED;
+                if (bSawInputEos) {
+                    handleDecEos();
+                    mState = STOPPED;
+                }
                 break;
             }
             case V4L2_EVENT_CODEC_ERROR:
@@ -1257,7 +1421,7 @@ status_t V4l2Dec::onDequeueEvent()
                 NotifyError(UNKNOWN_ERROR);//send error event
                 break;
             case V4L2_EVENT_SKIP:
-                NotifySkipInputBuffer(-1/*unused*/);
+                handleDecSkipEvent(event.u.data[0]);
                 break;
             default:
                 break;
@@ -1267,6 +1431,37 @@ status_t V4l2Dec::onDequeueEvent()
     return OK;
 }
 
+void V4l2Dec::handleDecEos() {
+    ALOGD("handleDecEos state %d ", mState);
+
+    if (STOPPED == mState)
+        return; // already in stopped state
+
+    if (STOPPING != mState)
+        NotifyEOS();//send eos event
+
+    bPollStarted = false;
+    bFetchStarted = false;
+}
+
+void V4l2Dec::handleDecSkipEvent(int bufferidx) {
+    // sometimes bufferidx is not set by VPU, so just skip a generic input buffer here
+    if (bufferidx < 0 || bufferidx >= mInputFormat.bufferNum) {
+        NotifySkipInputBuffer(-1/*unused*/);
+        return;
+    }
+
+    int id = mInputBufferMap[bufferidx].input_id;
+
+    if (!mInputBufferMap[bufferidx].at_device || id < 0) {
+        return;
+    }
+
+    ALOGV("bufferidx %d, skip input id #%d", bufferidx, id);
+
+    NotifySkipInputBuffer(id);
+}
+
 status_t V4l2Dec::DoSetConfig(DecConfig index, void* pConfig) {
     if (!pConfig)
         return BAD_VALUE;
@@ -1290,12 +1485,13 @@ status_t V4l2Dec::DoSetConfig(DecConfig index, void* pConfig) {
             ALOGV("vc1 sub-format 0x%x mVc1Format %d", *format, mVc1Format);
             break;
         }
+        case DEC_CONFIG_FORCE_PIXEL_FORMAT:
+            bForcePixelFormat = true;
+            // fall-through
         case DEC_CONFIG_HAL_PIXEL_FORMAT:{
             uint32_t* format = (uint32_t*)pConfig;
-            if(*format == HAL_PIXEL_FORMAT_NV12_TILED)
-                bNeedPostProcess = false;
-            else
-                bNeedPostProcess = true;
+            detectPostProcess(*format);
+            mOutputFormat.pixelFormat = *format;
             ALOGV("set DEC_CONFIG_HAL_PIXEL_FORMAT fmt=0x%x,bNeedPostProcess=%d",*format, bNeedPostProcess);
             break;
         }
@@ -1308,6 +1504,15 @@ status_t V4l2Dec::DoSetConfig(DecConfig index, void* pConfig) {
                 bLowLatency = false;
             break;
         }
+        case DEC_CONFIG_SECURE_MODE: {
+            if (*(int*)pConfig) {
+                bSecureMode = true;
+                nOutBufferUsage = (uint64_t)(GRALLOC_USAGE_PRIVATE_2 | C2MemoryUsage::READ_PROTECTED);
+                if (OK != pDev->EnableSecureMode(bSecureMode))
+                    ALOGW("EnableSecureMode failed");
+            }
+            break;
+        }
         default:
             ret = BAD_VALUE;
             break;
@@ -1333,6 +1538,8 @@ status_t V4l2Dec::DoGetConfig(DecConfig index, void* pConfig) {
             break;
         }
         case DEC_CONFIG_COLOR_ASPECTS:{
+            if (!bHasColorAspect)
+                return BAD_VALUE;
             DecIsoColorAspects* isocolor = (DecIsoColorAspects*)pConfig;
 
             isocolor->colourPrimaries = mIsoColorAspect.colourPrimaries;
@@ -1341,6 +1548,13 @@ status_t V4l2Dec::DoGetConfig(DecConfig index, void* pConfig) {
             isocolor->fullRange = mIsoColorAspect.fullRange;
             break;
         }
+        case DEC_CONFIG_HDR10_STATIC_INFO: {
+            if (bHasHdr10StaticInfo | bHasColorAspect)
+                memcpy(pConfig, &sHdr10StaticInfo, sizeof(DecStaticHDRInfo));
+            else
+                ret = BAD_VALUE;
+            break;
+        }
         default:
             ret = BAD_VALUE;
             break;
@@ -1362,6 +1576,8 @@ status_t V4l2Dec::allocateOutputBuffers() {
 
     fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
 
+    ALOGD("allocateOutputBuffers mOutputFormat.bufferNum=%d", mOutputFormat.bufferNum);
+
     mOutputBufferMap.resize(mOutputFormat.bufferNum);
 
     for (int i = 0; i < mOutputFormat.bufferNum; i++) {
@@ -1412,6 +1628,7 @@ status_t V4l2Dec::allocateOutputBuffers() {
         info.mCapacity = mOutputFormat.bufferSize;
         info.mState = GraphicBlockInfo::State::OWNED_BY_COMPONENT;
         mGraphicBlocks.push_back(std::move(info));
+
         ALOGV("Ion allocate fd=%d phys_addr=%p vaddr=%p
",fd, (void*)phys_addr, (void*)virt_addr);
         ALOGV("mOutputBufferMap[%d] phys %p, at_device %d", i,
             (void*)mOutputBufferMap[i].planes[0].paddr, mOutputBufferMap[i].at_device);
@@ -1454,47 +1671,104 @@ status_t V4l2Dec::handleFormatChanged() {
     ALOGV("outputFormatChanged BEGIN");
     {
         Mutex::Autolock autoLock(mLock);
+
+        if (bNewSegment)
+            bNewSegment = false;
+
         pre_state = mState;
         mState = RES_CHANGING;
         int result = 0;
         struct v4l2_format format;
         uint32_t pixel_format = 0;
+        uint32_t v4l2_pixel_format = 0;
+        uint32_t newWidth, newHeight, newBytesperline;
         memset(&format, 0, sizeof(struct v4l2_format));
 
-        format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        format.type = mCapBufType;
         result = ioctl (mFd, VIDIOC_G_FMT, &format);
 
         if(result < 0)
             return UNKNOWN_ERROR;
 
-        ret = pDev->GetColorFormatByV4l2( format.fmt.pix_mp.pixelformat, &pixel_format);
+        if (V4L2_TYPE_IS_MULTIPLANAR(mCapBufType)) {
+            v4l2_pixel_format = format.fmt.pix_mp.pixelformat;
+            newWidth = format.fmt.pix_mp.width;
+            newHeight = format.fmt.pix_mp.height;
+            newBytesperline = format.fmt.pix_mp.plane_fmt[0].bytesperline;
+            mOutputPlaneSize[0] = format.fmt.pix_mp.plane_fmt[0].sizeimage;
+            mOutputPlaneSize[1] = format.fmt.pix_mp.plane_fmt[1].sizeimage;
+            mOutputFormat.bufferSize = mOutputPlaneSize[0] + mOutputPlaneSize[1];
+            mOutputFormat.interlaced = ((format.fmt.pix_mp.field == V4L2_FIELD_INTERLACED) ? true: false);
+
+            ret = pDev->GetColorAspectsInfo(format.fmt.pix_mp.colorspace,
+                                       format.fmt.pix_mp.xfer_func,
+                                       format.fmt.pix_mp.ycbcr_enc,
+                                       format.fmt.pix_mp.quantization,
+                                       &mIsoColorAspect);
+        } else {
+            v4l2_pixel_format = format.fmt.pix.pixelformat;
+            newWidth = format.fmt.pix.width;
+            newHeight = format.fmt.pix.height;
+            newBytesperline = format.fmt.pix.bytesperline;
+            mOutputPlaneSize[0] = format.fmt.pix.sizeimage;
+            mOutputFormat.bufferSize = mOutputPlaneSize[0];
+            mOutputFormat.interlaced = false;
+
+            ret = pDev->GetColorAspectsInfo(format.fmt.pix.colorspace,
+                                       format.fmt.pix.xfer_func,
+                                       format.fmt.pix.ycbcr_enc,
+                                       format.fmt.pix.quantization,
+                                       &mIsoColorAspect);
+        }
+
+        if (OK == ret)
+            bHasColorAspect = true;
+
+        bool forceNV12 = false;
+
+#ifdef CUT_10BIT_TO_8BIT
+        forceNV12 = true;
+#else
+        if (mOutFormat == V4L2_PIX_FMT_NV12 && bForcePixelFormat)
+            forceNV12 = true;
+#endif
+
+        if (forceNV12 && V4L2_PIX_FMT_NV12X == v4l2_pixel_format) {
+            v4l2_pixel_format = V4L2_PIX_FMT_NV12;
+            if (V4L2_TYPE_IS_MULTIPLANAR(mCapBufType)) {
+                mOutputPlaneSize[0] = newWidth * newHeight;
+                mOutputPlaneSize[1] = mOutputPlaneSize[0]/2;
+                mOutputFormat.bufferSize = mOutputPlaneSize[0] + mOutputPlaneSize[1];
+            } else {
+                mOutputPlaneSize[0] = newWidth * newHeight * 3 / 2;
+                mOutputFormat.bufferSize = mOutputPlaneSize[0];
+            }
+        }
+
+        ret = pDev->GetColorFormatByV4l2(v4l2_pixel_format, &pixel_format);
         if(ret != OK)
             return ret;
 
+        mOutFormat = v4l2_pixel_format;
         mOutputFormat.pixelFormat = static_cast<int>(pixel_format);
-        if(mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_P010){
+
+#ifdef AMPHION_V4L2
+        if(mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_P010_TILED){
             bNeedPostProcess = true;
-            mOutFormat = format.fmt.pix_mp.pixelformat;
-            ALOGV("10bit video stride=%d",format.fmt.pix_mp.plane_fmt[0].bytesperline);
+            ALOGV("10bit video stride=%d", newBytesperline);
         }
+#endif
+
 
-        mOutputFormat.width = Align(format.fmt.pix_mp.width, FRAME_ALIGN);
-        mOutputFormat.height = Align(format.fmt.pix_mp.height, FRAME_ALIGN);
+        mOutputFormat.width = Align(newWidth, mFrameAlignW);
+        mOutputFormat.height = Align(newHeight, mFrameAlignH);
         mOutputFormat.stride = mOutputFormat.width;
 
         //for 10bit video, stride is larger than width, should use stride to allocate buffer
-        if(mOutputFormat.width < format.fmt.pix_mp.plane_fmt[0].bytesperline){
-            mOutputFormat.stride = format.fmt.pix_mp.plane_fmt[0].bytesperline;
+        if(mOutputFormat.width < newBytesperline){
+            mOutputFormat.stride = newBytesperline;
         }
 
-        mOutputFormat.interlaced = ((format.fmt.pix_mp.field == V4L2_FIELD_INTERLACED) ? true: false);
-        mOutputFormat.bufferSize = format.fmt.pix_mp.plane_fmt[0].sizeimage + format.fmt.pix_mp.plane_fmt[1].sizeimage;
-
-        mOutputPlaneSize[0] = format.fmt.pix_mp.plane_fmt[0].sizeimage;
-        mOutputPlaneSize[1] = format.fmt.pix_mp.plane_fmt[1].sizeimage;
-
-        pDev->GetColorAspectsInfo( &format.fmt.pix_mp, &mIsoColorAspect);
-
         struct v4l2_control ctl;
         memset(&ctl, 0, sizeof(struct v4l2_control));
 
@@ -1503,23 +1777,55 @@ status_t V4l2Dec::handleFormatChanged() {
         if(result < 0)
             return UNKNOWN_ERROR;
 
-        mOutputFormat.minBufferNum = ctl.value+1;
+        mOutputFormat.minBufferNum = ctl.value;
+        mOutputFormat.bufferNum = mOutputFormat.minBufferNum;
 
-        if(mOutputFormat.minBufferNum > mOutputFormat.bufferNum)
-            mOutputFormat.bufferNum = mOutputFormat.minBufferNum;
+#ifdef AMPHION_V4L2
+        mOutputFormat.bufferNum += 1;
+#endif
+#ifdef HANTRO_V4L2
+        // vsi vpu need more buffer because:
+        // 1. 4K HDR10 video reach performance
+        // 2. pass android.media.cts.MediaCodecPlayerTest#testPlaybackSwitchViews
+        mOutputFormat.bufferNum += FRAME_SURPLUS;
+
+        // surfaceflinger do sw csc for 422sp, need cached buffer to improve performance
+        if(mOutputFormat.pixelFormat == HAL_PIXEL_FORMAT_YCbCr_422_SP){
+            ALOGI("YUV422SP: use cached buffer");
+            nOutBufferUsage |= C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE;
+        }
+#endif
 
-        if (!bNeedPostProcess) {
-            // workaround: surface setMaxDequeuedBufferCount: numOutputSlots + numInputSlots + depth + kRenderingDepth
-            // as default, kRenderingDepth = 3, depth = 0, numInputSlots = 4, numOutputSlots = outputDelayValue + 4
-            // 4 is value of kSmoothnessFactor
-            // so if we return bufferNum directly, surface will setMaxDequeuedBufferCount as bufferNum + 4 + 4 + 3,
-            // it's too much for VPU, we can cut some here to avoid it exceed the max value(32).
-            if (mOutputFormat.bufferNum >= 18)
-                mOutputFormat.bufferNum -= (4+4);
+        // query hdr10 meta
+        struct v4l2_ext_control ctrl;
+        struct v4l2_ext_controls ctrls;
+        struct v4l2_hdr10_meta hdr10meta;
+
+        ctrls.controls = &ctrl;
+        ctrls.count = 1;
+        ctrl.id = V4L2_CID_HDR10META;
+        ctrl.ptr = (void *)&hdr10meta;
+        ctrl.size = sizeof(struct v4l2_hdr10_meta);
+        result = ioctl(mFd, VIDIOC_G_EXT_CTRLS, &ctrls);
+        if(0 == result && hdr10meta.hasHdr10Meta) {
+            ALOGV("has hdr10 meta");
+            bHasHdr10StaticInfo = true;
+            sHdr10StaticInfo.mR[0] = (uint16_t)hdr10meta.redPrimary[0];
+            sHdr10StaticInfo.mR[1] = (uint16_t)hdr10meta.redPrimary[1];
+            sHdr10StaticInfo.mG[0] = (uint16_t)hdr10meta.greenPrimary[0];
+            sHdr10StaticInfo.mG[1] = (uint16_t)hdr10meta.greenPrimary[1];
+            sHdr10StaticInfo.mB[0] = (uint16_t)hdr10meta.bluePrimary[0];
+            sHdr10StaticInfo.mB[1] = (uint16_t)hdr10meta.bluePrimary[1];
+            sHdr10StaticInfo.mW[0] = (uint16_t)hdr10meta.whitePoint[0];
+            sHdr10StaticInfo.mW[1] = (uint16_t)hdr10meta.whitePoint[1];
+            sHdr10StaticInfo.mMaxDisplayLuminance = (uint16_t)(hdr10meta.maxMasteringLuminance/10000);
+            sHdr10StaticInfo.mMinDisplayLuminance = (uint16_t)hdr10meta.minMasteringLuminance;
+            sHdr10StaticInfo.mMaxContentLightLevel = (uint16_t)hdr10meta.maxContentLightLevel;
+            sHdr10StaticInfo.mMaxFrameAverageLightLevel = (uint16_t)hdr10meta.maxFrameAverageLightLevel;
         }
 
         struct v4l2_crop crop;
-        crop.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        crop.type = mCapBufType;
 
         result = ioctl (mFd, VIDIOC_G_CROP, &crop);
         if(result < 0)
@@ -1537,12 +1843,14 @@ status_t V4l2Dec::handleFormatChanged() {
         mOutputFormat.rect.left = crop.c.left;
     }
 
-    ALOGV("outputFormatChanged w=%d,h=%d,buf cnt=%d, buffer size[0]=%d,size[1]=%d",
-        mOutputFormat.width, mOutputFormat.height, mOutputFormat.minBufferNum, mOutputPlaneSize[0], mOutputPlaneSize[1]);
+    ALOGD("outputFormatChanged w=%d,h=%d, minBufferNum=%d, bufferNum=%d, buffer size[0]=%d,size[1]=%d, pixelFormat=0x%x",
+        mOutputFormat.width, mOutputFormat.height,
+        mOutputFormat.minBufferNum, mOutputFormat.bufferNum,
+        mOutputPlaneSize[0], mOutputPlaneSize[1], mOutputFormat.pixelFormat);
 
     ALOGV("mIsoColorAspect c=%d,t=%d,m=%d,f=%d",mIsoColorAspect.colourPrimaries, mIsoColorAspect.transferCharacteristics,mIsoColorAspect.matrixCoeffs, mIsoColorAspect.fullRange);
-    if(pre_state == STOPPING || pre_state == FLUSHING){
-        ALOGI("do not handle resolution while flushing or stopping");
+    if(pre_state == STOPPING){
+        ALOGI("do not handle resolution while stopping");
         return OK;
     }
 
@@ -1554,12 +1862,18 @@ status_t V4l2Dec::handleFormatChanged() {
         stopOutputStream();
         // clear capture buffer
         mOutputBufferMap.clear();
-
-        SetOutputFormats();
+        mRegisteredOutBufNum = 0;
     }
 
+    SetOutputFormats();
+
     outputFormatChanged();
 
+    // onFlush is pended during resolution changing, now we handle it.
+    if (bPendingFlush) {
+        onFlush();
+    }
+
     ALOGV("outputFormatChanged end");
     return OK;
 }
@@ -1611,15 +1925,17 @@ status_t V4l2Dec::onFlush()
     int pre_state;
     {
         Mutex::Autolock autoLock(mLock);
+        // pend flush if in RES_CHANGING state, MA-18872
+        if (mState == RES_CHANGING) {
+            bPendingFlush = true;
+            return OK;
+        }
         pre_state = mState;
         if(mState != STOPPING)
             mState = FLUSHING;
     }
     status_t ret = UNKNOWN_ERROR;
 
-    // let codecdata queue again after each seek
-    bCodecDataQueued = false;
-
     ret = stopInputStream();
     if(ret != OK)
         return ret;
@@ -1628,12 +1944,20 @@ status_t V4l2Dec::onFlush()
     if(ret != OK)
         return ret;
 
-    mState = pre_state;
+    {
+        Mutex::Autolock autoLock(mLock);
+        mState = pre_state;
+    }
+
     mInCnt = 0;
     mOutCnt = 0;
     mLastInputTs = -1;
     mLastInputId = 0;
     bReceiveError = false;
+    bSawInputEos = false;
+    bNewSegment = true;
+    bPendingFlush = false;
+
     ALOGV("%s end", __FUNCTION__);
     return ret;
 }
@@ -1648,32 +1972,19 @@ status_t V4l2Dec::onStop()
     mState = STOPPING;
     }
     ret = onFlush();
-    if(ret != OK){
-        return ret;
-    }
 
-    ret = destroyPollThread();
-    if(ret != OK){
-        return ret;
-    }
+    // don't exit halfway, try to execute till end to avoid memory leak
+    ret |= destroyPollThread();
 
-    ret = destroyFetchThread();
-    if(ret != OK){
-        return ret;
-    }
+    ret |= destroyFetchThread();
 
-    ret = destroyInputBuffers();
-    if(ret != OK){
-        return ret;
-    }
+    ret |= destroyInputBuffers();
 
-    ret = destroyOutputBuffers();
-    if(ret != OK){
-        return ret;
-    }
+    ret |= destroyOutputBuffers();
 
     Mutex::Autolock autoLock(mLock);
-    mState = STOPPED;
+    if (OK == ret)
+        mState = STOPPED;
 
     if(pDev != NULL)
         pDev->ResetDecoder();
@@ -1705,9 +2016,44 @@ status_t V4l2Dec::onDestroy()
     return OK;
 }
 
+void V4l2Dec::detectPostProcess(int pixelFormat) {
+
+#ifdef AMPHION_V4L2
+    switch(pixelFormat){
+        case HAL_PIXEL_FORMAT_NV12_TILED:
+            bNeedPostProcess = false;
+            break;
+        case HAL_PIXEL_FORMAT_YCbCr_420_SP:
+        case HAL_PIXEL_FORMAT_YCbCr_422_I:
+        case HAL_PIXEL_FORMAT_P010_TILED:
+        default:
+            ALOGV("bNeedPostProcess");
+            bNeedPostProcess = true;
+            break;
+    }
+    return;
+#else
+    bNeedPostProcess = false;
+    return;
+#endif
+}
 bool V4l2Dec::checkIfPostProcessNeeded() {
     return bNeedPostProcess;
 }
+
+bool V4l2Dec::canEnableSecureMode(int fd, int size) {
+#ifdef HANTRO_V4L2
+    #define isSecureMemory(addr) ((addr) >= 0xE0000000 && (addr) <= 0xF0000000)
+
+    fsl::IonAllocator * pIonAllocator = fsl::IonAllocator::getInstance();
+    uint64_t paddr;
+
+    return (pIonAllocator->getPhys(fd, size, (uint64_t&)paddr) == 0 && isSecureMemory(paddr));
+#else
+    return false;
+#endif
+}
+
 void V4l2Dec::ParseVpuLogLevel()
 {
     int level=0;
@@ -1785,11 +2131,44 @@ void V4l2Dec::dumpOutputBuffer(void* inBuf, uint32_t size)
     return;
 }
 bool V4l2Dec::OutputBufferFull() {
-    if(mOutputBufferMap.size() > mOutputFormat.bufferNum)
+    if(mRegisteredOutBufNum >= mOutputFormat.bufferNum)
         return true;
     return false;
 }
 
+void V4l2Dec::migrateOutputBuffers()
+{
+    // only migrate output buffers allocated by BufferQueue
+    if (!bNewSegment || bNeedPostProcess)
+        return;
+
+    ALOGI("migrateOutputBuffers...");
+
+    // 1. migrate mGraphicBlocks
+    int32_t migrateBufNum = migrateGraphicBuffers();
+    if (mVpuOwnedOutputBufferNum != migrateBufNum)
+        ALOGW("migrateGraphicBuffers mismatch, own %d , migrate %d", mVpuOwnedOutputBufferNum, migrateBufNum);
+
+    mRegisteredOutBufNum = 0;
+
+    // 2. migrate outputbuffermap
+    for (auto& outRecord : mOutputBufferMap) {
+        GraphicBlockInfo *gbInfo = nullptr;
+        uint64_t paddr = outRecord.planes[0].paddr;
+
+        gbInfo = getGraphicBlockByPhysAddr(paddr);
+        if (gbInfo) {
+            ALOGD("migrate outputbuffermap %d -> %d ", outRecord.picture_id, gbInfo->mBlockId);
+            outRecord.picture_id = gbInfo->mBlockId;
+            ++mRegisteredOutBufNum;
+        } else {
+            memset(&outRecord, 0, sizeof(OutputRecord));
+        }
+    }
+
+    bNewSegment = false;
+}
+
 VideoDecoderBase * CreateVideoDecoderInstance(const char* mime) {
     return static_cast<VideoDecoderBase *>(new V4l2Dec(mime));
 }
diff --git a/codec2/video_dec/v4l2_dec/V4l2Dec.h b/codec2/video_dec/v4l2_dec/V4l2Dec.h
old mode 100644
new mode 100755
index 569b4cb..64b0281
--- a/codec2/video_dec/v4l2_dec/V4l2Dec.h
+++ b/codec2/video_dec/v4l2_dec/V4l2Dec.h
@@ -24,6 +24,7 @@ public:
     status_t onDestroy() override;
 
     bool checkIfPostProcessNeeded() override;
+    bool canEnableSecureMode(int fd, int size) override;
 
     status_t prepareOutputBuffers();
     status_t destroyOutputBuffers();
@@ -44,6 +45,8 @@ protected:
     status_t allocateOutputBuffers() override;
     status_t freeOutputBuffers() override;
     bool OutputBufferFull() override;
+    void detectPostProcess(int pixelFormat);
+
 private:
     enum {
         kInputBufferPlaneNum = 1,
@@ -79,7 +82,6 @@ private:
         VideoFramePlane planes[kOutputBufferPlaneNum];
         int32_t picture_id;     // picture buffer id as returned to PictureReady().
         uint32_t flag;
-        std::shared_ptr<C2GraphicBlock> mGraphicBlock;
     };
 
     enum {
@@ -97,6 +99,8 @@ private:
 
     V4l2Dev* pDev;
     int32_t mFd;
+    enum v4l2_buf_type mOutBufType;
+    enum v4l2_buf_type mCapBufType;
 
     enum v4l2_memory mInMemType;//support userptr and dma
     enum v4l2_memory mOutMemType;//support userptr and dma
@@ -122,9 +126,15 @@ private:
     bool bH264;
     bool bLowLatency;
 
+    bool bSawInputEos;
+    bool bNewSegment;
+    bool bPendingFlush;
+    bool bForcePixelFormat;
+
     int mState;
 
     uint32_t mVpuOwnedOutputBufferNum;
+    uint32_t mRegisteredOutBufNum;
 
     uint32_t mOutputPlaneSize[kOutputBufferPlaneNum];
     uint32_t mOutFormat;//v4l2 output format
@@ -137,8 +147,15 @@ private:
     uint64_t mLastInputTs;
     int mLastInputId;
 
+    uint32_t mFrameAlignW;
+    uint32_t mFrameAlignH;
+
+    bool bHasColorAspect;
     VideoColorAspect mIsoColorAspect;
 
+    bool bHasHdr10StaticInfo;
+    DecStaticHDRInfo sHdr10StaticInfo;
+
     status_t prepareInputParams();
     status_t SetInputFormats();
     status_t prepareOutputParams();
@@ -163,6 +180,9 @@ private:
 
     status_t onDequeueEvent();
 
+    void handleDecEos();
+    void handleDecSkipEvent(int bufferidx);
+
     static void *PollThreadWrapper(void *);
     status_t HandlePollThread();
     static void *FetchThreadWrapper(void *);
@@ -172,6 +192,8 @@ private:
     void ParseVpuLogLevel();
     void dumpInputBuffer(void* inBuf, uint32_t size);
     void dumpOutputBuffer(void* buf, uint32_t size);
+
+    void migrateOutputBuffers();
 };
 
 
diff --git a/codec2/video_dec/v4l2_dec/v4l2_dec.go b/codec2/video_dec/v4l2_dec/v4l2_dec.go
index 7a6feb2..a63afcc 100644
--- a/codec2/video_dec/v4l2_dec/v4l2_dec.go
+++ b/codec2/video_dec/v4l2_dec/v4l2_dec.go
@@ -46,9 +46,18 @@ func v4l2Defaults(ctx android.LoadHookContext) {
     var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
     if strings.Contains(board, "IMX8Q") {
         p.Target.Android.Enabled = proptools.BoolPtr(true)
+        Cflags = append(Cflags, "-DAMPHION_V4L2")
+    } else if (strings.Contains(board, "IMX8MP") || strings.Contains(board, "IMX8MQ") || strings.Contains(board, "IMX8MM")) {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+        Cflags = append(Cflags, "-DHANTRO_V4L2")
     } else {
         p.Target.Android.Enabled = proptools.BoolPtr(false)
     }
+
+    if (strings.Contains(board, "IMX8MP") || strings.Contains(board, "IMX8MM")) {
+        Cflags = append(Cflags, "-DCUT_10BIT_TO_8BIT")
+    }
+
     if ctx.Config().VendorConfig("IMXPLUGIN").String("CFG_SECURE_DATA_PATH") == "y" {
         Cflags = append(Cflags, "-DALWAYS_ENABLE_SECURE_PLAYBACK")
     }
diff --git a/codec2/video_dec/video_dec.go b/codec2/video_dec/video_dec.go
index 476a785..41c99d3 100644
--- a/codec2/video_dec/video_dec.go
+++ b/codec2/video_dec/video_dec.go
@@ -45,15 +45,15 @@ func video_decDefaults(ctx android.LoadHookContext) {
     p.Target.Android.Enabled = proptools.BoolPtr(false)
     var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
     if strings.Contains(board, "IMX8MM") {
-        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_dec")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_v4l2_dec")
         Shared_libs = append(Shared_libs, "lib_imx_c2_process_dummy_post")
         p.Target.Android.Enabled = proptools.BoolPtr(true)
     } else if strings.Contains(board, "IMX8MQ") {
-        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_dec")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_v4l2_dec")
         Shared_libs = append(Shared_libs, "lib_imx_c2_process_dummy_post")
         p.Target.Android.Enabled = proptools.BoolPtr(true)
     } else if strings.Contains(board, "IMX8MP") {
-        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_dec")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_v4l2_dec")
         Shared_libs = append(Shared_libs, "lib_imx_c2_process_dummy_post")
         p.Target.Android.Enabled = proptools.BoolPtr(true)
     } else if strings.Contains(board, "IMX8Q") {
diff --git a/codec2/video_dec/vpuwrapper_dec/vpuwrapper_dec.go b/codec2/video_dec/vpuwrapper_dec/vpuwrapper_dec.go
index f5ee7e2..205bdf1 100644
--- a/codec2/video_dec/vpuwrapper_dec/vpuwrapper_dec.go
+++ b/codec2/video_dec/vpuwrapper_dec/vpuwrapper_dec.go
@@ -44,7 +44,7 @@ func vpuwrapperDefaults(ctx android.LoadHookContext) {
     p := &props{}
     var vpu_type string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_VPU_TYPE")
     if strings.Contains(vpu_type, "hantro") {
-        p.Target.Android.Enabled = proptools.BoolPtr(true)
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
     } else {
         p.Target.Android.Enabled = proptools.BoolPtr(false)
     }
diff --git a/codec2/video_enc/common/IMXC2VideoEncoder.cpp b/codec2/video_enc/common/IMXC2VideoEncoder.cpp
index eb9cdf9..07522b3 100755
--- a/codec2/video_enc/common/IMXC2VideoEncoder.cpp
+++ b/codec2/video_enc/common/IMXC2VideoEncoder.cpp
@@ -29,6 +29,7 @@
 #include "graphics_ext.h"
 #include "Memory.h"
 #include "IMXUtils.h"
+#include "Codec2BufferUtils.h"
 
 #include <sys/mman.h>
 
@@ -158,7 +159,7 @@ public:
 
         addParameter(
                 DefineParam(mFrameRate, C2_PARAMKEY_FRAME_RATE)
-                .withDefault(new C2StreamFrameRateInfo::output(0u, 30.))
+                .withDefault(new C2StreamFrameRateInfo::output(0u, 15.))
                 // TODO: More restriction?
                 .withFields({C2F(mFrameRate, value).greaterThan(0.)})
                 .withSetter(Setter<decltype(*mFrameRate)>::StrictValueWithNoDeps)
@@ -465,7 +466,7 @@ public:
     }
 
     uint32_t getLevel_l() const {
-        struct Level {
+        /*struct Level {
             C2Config::level_t c2Level;
             uint32_t avcLevel;
         };
@@ -493,6 +494,8 @@ public:
         }
         ALOGD("Unrecognized level: %x", mProfileLevel->level);
         return 41;
+        */
+        return mProfileLevel->level;
     }
 
     uint32_t getSyncFramePeriod_l() const {
@@ -557,6 +560,7 @@ IMXC2VideoEncoder::IMXC2VideoEncoder(
       bStarted(false),
       bCodecDataReceived(false),
       bPPEnabled(false),
+      bSignalledError(false),
       nOutBufferNum(8),
       nCurInTimestamp(-1),
       nCurOutTimestamp(-1),
@@ -605,6 +609,29 @@ c2_status_t IMXC2VideoEncoder::onInit() {
     if(gEncoderInstance > max_count)
         return C2_NO_MEMORY;
 
+    /* create video encoder instance and open device */
+    const char* mime = Name2MimeType((const char*)mName.c_str());
+    if (mime == nullptr) {
+        ALOGE("Unsupported component name: %s", mName.c_str());
+        return C2_BAD_VALUE;
+    }
+
+    mEncoder = CreateVideoEncoderInstance(mime);
+    if (!mEncoder) {
+        ALOGE("CreateVideoEncoderInstance for mime(%s) failed 
", mime);
+        return C2_CORRUPTED;
+    }
+    if (OK != mEncoder->RegisterLooper()) {
+        ALOGE("mEncoder register handle fail");
+        return C2_BAD_VALUE;
+    }
+
+    if (OK != mEncoder->OpenDevice()) {
+        ALOGE("mEncoder OpenDevice fail");
+        releaseComponent();
+        return C2_BAD_VALUE;
+    }
+
     return C2_OK;
 }
 
@@ -612,6 +639,9 @@ c2_status_t IMXC2VideoEncoder::onStop() {
     status_t err = C2_OK;
 
     IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
+
+    bSignalledError = false;
+
     if (mPreProcess) {
         err = mPreProcess->stop();
         CHECK_AND_RETURN_C2_ERR(err);
@@ -643,6 +673,8 @@ c2_status_t IMXC2VideoEncoder::onFlush_sm() {
 
     IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
 
+    bSignalledError = false;
+
     if (mPreProcess) {
         err = mPreProcess->flush();
         CHECK_AND_RETURN_C2_ERR(err);
@@ -735,6 +767,11 @@ void IMXC2VideoEncoder::processWork(const std::unique_ptr<C2Work> &work) {
 
     std::shared_ptr<C2Buffer> inputBuffer = nullptr;
 
+    if (bSignalledError) {
+        work->result = C2_BAD_VALUE;
+        return fillEmptyWork(work);
+    }
+
     if (!work->input.buffers.empty()) {
         std::shared_ptr<const C2GraphicView> view;
         inputBuffer = work->input.buffers[0];
@@ -746,6 +783,16 @@ void IMXC2VideoEncoder::processWork(const std::unique_ptr<C2Work> &work) {
             work->workletsProcessed = 1u;
             return;
         }
+
+        if(!bStarted){
+            const C2GraphicView *const rawBuf = view.get();
+            if(IsNV12(*rawBuf))
+                mPixelFormat->value = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+            else if(IsI420(*rawBuf))
+                mPixelFormat->value = HAL_PIXEL_FORMAT_YCbCr_420_P;
+        }
+
+        ALOGV("pixel format get from view=0x%x",mPixelFormat->value);
     } else {
         if (bStarted && (work->input.flags & C2FrameData::FLAG_END_OF_STREAM)) {
             drainInternal(DRAIN_COMPONENT_WITH_EOS);
@@ -761,6 +808,7 @@ void IMXC2VideoEncoder::processWork(const std::unique_ptr<C2Work> &work) {
 
     if (mPixelFormat->value == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
         mPixelFormat->value = prvHandle->format;
+        ALOGV("prvHandle->format=0x%x",prvHandle->format);
     }
 
     uint32_t size = mSize->width * mSize->height * pxlfmt2bpp(mPixelFormat->value) / 8;
@@ -837,29 +885,14 @@ status_t IMXC2VideoEncoder::initComponent() {
     int profile = 0, level = 0;
     int IDRInterval;
     int pixelFmt = mPixelFormat->value; //default value
+    int process_pixel_format = 0;
+
     std::shared_ptr<C2StreamGopTuning::output> gop;
     std::shared_ptr<C2StreamColorAspectsInfo::output> c2Aspects;
     EncIsoColorAspects colorAspects;
 
     IMX_VIDEO_ENC_API_TRACE("%s, line %d 
", __FUNCTION__, __LINE__);
 
-    const char* mime = Name2MimeType((const char*)mName.c_str());
-    if (mime == nullptr) {
-        ALOGE("Unsupported component name: %s", mName.c_str());
-        return C2_BAD_VALUE;
-    }
-
-    mEncoder = CreateVideoEncoderInstance(mime);
-    if (!mEncoder) {
-        ALOGE("CreateVideoEncoderInstance for mime(%s) failed 
", mime);
-        return C2_CORRUPTED;
-    }
-    err = mEncoder->RegisterLooper();
-    if (err) {
-        ALOGE("mEncoder register handle fail");
-    }
-
-
     if (!bGetBlockPool) {
         if (OK != mEncoder->setLinearBlockPool(mOutputBlockPool))
             return BAD_VALUE;
@@ -872,6 +905,8 @@ status_t IMXC2VideoEncoder::initComponent() {
         gop = mIntf->getGop_l();
         c2Aspects = mIntf->getColorAspects_l();
 
+        const char* mime = Name2MimeType((const char*)mName.c_str());
+
         if (mime == MEDIA_MIMETYPE_VIDEO_HEVC || mime == MEDIA_MIMETYPE_VIDEO_AVC) {
             profile = mIntf->getProfile_l();
             level = mIntf->getLevel_l();
@@ -912,9 +947,11 @@ status_t IMXC2VideoEncoder::initComponent() {
     }
 
     bPPEnabled = mEncoder->checkIfPreProcessNeeded(pixelFmt);
+    ALOGD("ori input pixel format: %x bPPEnabled: %d", pixelFmt, bPPEnabled);
 
 
     if (bPPEnabled) {
+
         // init preprocess component
         mPreProcess = CreatePreProcessInstance();
 
@@ -922,35 +959,20 @@ status_t IMXC2VideoEncoder::initComponent() {
             goto RELEASE_ENCODER;
         }
 
-        PROCESSBASE_FORMAT inFmt, outFmt;
-        inFmt.width = mSize->width;
-        inFmt.height = mSize->height;
-        inFmt.format = pixelFmt;
-        inFmt.stride = mSize->width;
-        inFmt.bufferSize = inFmt.width * inFmt.height * pxlfmt2bpp(inFmt.format) / 8;
-
-        ALOGI("init preprocess w=%d,h=%d,pixelFmt=%x,bufferSize=%d",mSize->width,mSize->height, pixelFmt, inFmt.bufferSize);
-        err = mPreProcess->setConfig(PROCESS_CONFIG_INPUT_FORMAT, &inFmt);
-        if (err) {
-            goto RELEASE_ENCODER;
-        }
-
-        err = mPreProcess->init((ProcessBase::Client*)this, mOutputBlockPool);
-        if (err) {
-            goto RELEASE_ENCODER;
-        }
-
-        err = mPreProcess->getConfig(PROCESS_CONFIG_OUTPUT_FORMAT, &outFmt);
+        err = mPreProcess->getConfig(PROCESS_CONFIG_PIXEL_FORMAT, &process_pixel_format);
         if (err) {
             goto RELEASE_ENCODER;
         }
-
-        pixelFmt = outFmt.format;
     }
 
     EncInputParam inPara;
     memset(&inPara, 0, sizeof(EncInputParam));
-    inPara.eColorFormat = pixelFmt;
+
+    if(bPPEnabled)
+        inPara.eColorFormat = process_pixel_format;
+    else
+        inPara.eColorFormat = pixelFmt;
+
     inPara.nPicWidth = mSize->width;
     inPara.nPicHeight = mSize->height;
     inPara.nWidthStride = mSize->width;
@@ -985,9 +1007,51 @@ status_t IMXC2VideoEncoder::initComponent() {
         goto RELEASE_ENCODER;
     }
 
+    if (bPPEnabled){
+        VideoFormat vFormat;
+        err = mEncoder->getConfig(ENC_CONFIG_INPUT_FORMAT, &vFormat);
+        if (err) {
+            goto RELEASE_ENCODER;
+        }
+
+        PROCESSBASE_FORMAT inFmt, outFmt;
+        inFmt.width = mSize->width;
+        inFmt.height = mSize->height;
+        inFmt.format = pixelFmt;
+        inFmt.stride = mSize->width;
+        inFmt.bufferSize = inFmt.width * inFmt.height * pxlfmt2bpp(inFmt.format) / 8;
+
+        //use the buffer size get from v4l2 encoder, it may not equal to stride*height*pxlfmt2bpp(inFmt.format) / 8
+        outFmt.width = mSize->width;
+        outFmt.height = mSize->height;
+        outFmt.format = process_pixel_format;
+        outFmt.stride = outFmt.width;
+        outFmt.bufferSize = vFormat.bufferSize;
+
+        ALOGI("init preprocess input w=%d,h=%d,pixelFmt=%x,bufferSize=%d",mSize->width,mSize->height, pixelFmt, inFmt.bufferSize);
+        ALOGI("init preprocess output w=%d,h=%d, stride=%d, pixelFmt=%x,bufferSize=%d",outFmt.width,outFmt.height, outFmt.stride, process_pixel_format, outFmt.bufferSize);
+
+        err = mPreProcess->setConfig(PROCESS_CONFIG_INPUT_FORMAT, &inFmt);
+        if (err) {
+            goto RELEASE_ENCODER;
+        }
+
+        err = mPreProcess->setConfig(PROCESS_CONFIG_OUTPUT_FORMAT, &outFmt);
+        if (err) {
+            goto RELEASE_ENCODER;
+        }
+
+        err = mPreProcess->init((ProcessBase::Client*)this, mOutputBlockPool);
+        if (err) {
+            goto RELEASE_ENCODER;
+        }
+    }
+
+
     return C2_OK;
 
 RELEASE_ENCODER:
+    ALOGE("encoder initComponent error");
     // release encoder if init failed, in case of upper layer don't call release
     releaseComponent();
     return C2_CORRUPTED;
@@ -1120,16 +1184,7 @@ status_t IMXC2VideoEncoder::handleInputUsed(int inputId) {
     if (nUsedFrameIndex == nCurFrameIndex)
         return OK; // will handle this in processQueue later
 
-    C2Work* work = getPendingWorkByFrameIndex(nUsedFrameIndex);
-    if (!work) {
-        ALOGW("%s: can't find C2Work for id %d 
", __FUNCTION__, inputId);
-        return BAD_VALUE;
-    }
-
-    // When the work is done, the input buffer shall be reset by component.
-    work->input.buffers.front().reset();
-    ALOGV("input id %d is used 
", inputId);
-
+    (void)postClearInputMsg(nUsedFrameIndex);
     return OK;
 }
 
@@ -1222,11 +1277,12 @@ void IMXC2VideoEncoder::notifyResetDone() {
 }
 
 void IMXC2VideoEncoder::notifyEos() {
-    finishWithException(true/*eos*/, false/*force*/);
+    (void)finishWithException(true/*eos*/, false/*force*/);
 }
 
 void IMXC2VideoEncoder::notifyError(status_t err) {
     (void)err;
+    bSignalledError = true;
 }
 
 status_t IMXC2VideoEncoder::fetchProcessBuffer(int *bufferId, unsigned long *phys) {
diff --git a/codec2/video_enc/common/IMXC2VideoEncoder.h b/codec2/video_enc/common/IMXC2VideoEncoder.h
index 6899edc..170cb3c 100755
--- a/codec2/video_enc/common/IMXC2VideoEncoder.h
+++ b/codec2/video_enc/common/IMXC2VideoEncoder.h
@@ -83,6 +83,7 @@ private:
     bool bStarted;
     bool bCodecDataReceived;
     bool bPPEnabled;
+    bool bSignalledError;
 
     uint32_t nOutBufferNum;
 
diff --git a/codec2/video_enc/common/VideoEncoderBase.cpp b/codec2/video_enc/common/VideoEncoderBase.cpp
old mode 100755
new mode 100644
index 6b74284..901da9b
--- a/codec2/video_enc/common/VideoEncoderBase.cpp
+++ b/codec2/video_enc/common/VideoEncoderBase.cpp
@@ -58,6 +58,7 @@ VideoFormat::VideoFormat() {
     minBufferNum = 0;
     width = DEFAULT_FRM_WIDTH;
     height = DEFAULT_FRM_HEIGHT;
+    stride = DEFAULT_FRM_WIDTH;
     bufferNum = 0;
     bufferSize = 0;
     interlaced = false;
@@ -228,7 +229,14 @@ status_t VideoEncoderBase::getConfig(EncConfig index, void* pConfig) {
     if (!pConfig)
         return BAD_VALUE;
 
-    return DoGetConfig(index, pConfig);
+    switch (index) {
+        case ENC_CONFIG_INPUT_FORMAT:
+            memcpy(pConfig, &mInputFormat, sizeof(VideoFormat));
+            break;
+        default:
+            return DoGetConfig(index, pConfig);
+    }
+    return OK;
 }
 
 status_t VideoEncoderBase::allocateOutputBuffers() {
diff --git a/codec2/video_enc/common/VideoEncoderBase.h b/codec2/video_enc/common/VideoEncoderBase.h
old mode 100755
new mode 100644
index 96cf4de..1144b05
--- a/codec2/video_enc/common/VideoEncoderBase.h
+++ b/codec2/video_enc/common/VideoEncoderBase.h
@@ -26,6 +26,7 @@ typedef enum {
     ENC_CONFIG_FRAME_RATE,
     ENC_CONFIG_INTRA_REFRESH,
     ENC_CONFIG_COLOR_FORMAT,
+    ENC_CONFIG_INPUT_FORMAT,
 } EncConfig;
 
 typedef struct {
@@ -91,6 +92,7 @@ struct VideoFormat {
     uint32_t minBufferNum;
     uint32_t width;
     uint32_t height;
+    uint32_t stride;
     uint32_t bufferNum;
     uint32_t bufferSize;
     bool interlaced;
@@ -179,6 +181,7 @@ public:
     virtual status_t DoGetConfig(EncConfig index, void* pConfig) {return OK;}
     virtual status_t getCodecData(uint8_t** pCodecData, uint32_t* size);
     virtual bool checkIfPreProcessNeeded(int pixelFormat);
+    virtual status_t OpenDevice() {return OK;}
 
     //status_t setClient(Client* client);
     status_t setLinearBlockPool(const std::shared_ptr<C2BlockPool>& pool);
diff --git a/codec2/video_enc/v4l2_enc/Android.bp b/codec2/video_enc/v4l2_enc/Android.bp
index e149895..85c7a20 100644
--- a/codec2/video_enc/v4l2_enc/Android.bp
+++ b/codec2/video_enc/v4l2_enc/Android.bp
@@ -1,4 +1,4 @@
-imx_c2_v4l2_dec_defaults {
+imx_c2_v4l2_enc_defaults {
     name: "imx_c2_v4l2_enc_default",
 }
 
@@ -44,6 +44,7 @@ cc_library_shared {
         "frameworks/av/media/codec2/components/base/include",    
         "vendor/nxp/imx_android_mm/codec2/video_enc/common",
         "vendor/nxp/imx_android_mm/codec2/include",
+        "vendor/nxp/imx_android_mm/codec2/base/include",
         "vendor/nxp/imx_android_mm/codec2/v4l2_dev",
         "vendor/nxp-opensource/imx/include",
 	],
@@ -56,6 +57,7 @@ cc_library_shared {
         "libcutils",
         "lib_imx_c2_v4l2_dev",
         "lib_imx_c2_videoenc_common",
+        "lib_imx_c2_componentbase",
     ],
 
     sanitize: {
diff --git a/codec2/video_enc/v4l2_enc/FrameConverter.cpp b/codec2/video_enc/v4l2_enc/FrameConverter.cpp
index 73a757a..59eebdd 100755
--- a/codec2/video_enc/v4l2_enc/FrameConverter.cpp
+++ b/codec2/video_enc/v4l2_enc/FrameConverter.cpp
@@ -15,11 +15,12 @@
 namespace android {
 status_t FrameConverter::Create(uint32_t format)
 {
-    if(format != V4L2_PIX_FMT_H264)
+    if(format != V4L2_PIX_FMT_H264 && format != V4L2_PIX_FMT_HEVC)
         return UNKNOWN_ERROR;
     nFormat = format;
     pSpsPps = NULL;
     nLen = 0;
+    mIsH264 = (format == V4L2_PIX_FMT_H264);
     return OK;
 }
 status_t FrameConverter::ConvertToCodecData(
@@ -70,7 +71,7 @@ status_t FrameConverter::ConvertToCodecData(
         }else if(naltype == 0x0c){//skip coda padding bytes
             skipLen += 4+size;
         }
-        
+
         if(pNext==NULL){
             goto search_finish;
         }
@@ -124,17 +125,27 @@ search_finish:
 status_t FrameConverter::CheckSpsPps(uint8_t* pInData, uint32_t nSize, uint32_t* nConsumeLen)
 {
     uint8_t* pPre=pInData;
-    uint32_t spsSize=0, ppsSize=0;
-    uint8_t *sps=NULL, *pps=NULL;
+    uint32_t spsSize=0, ppsSize=0, vpsSize = 0;
     uint8_t* pNext=NULL;
     uint8_t naltype;
     int32_t length=(int32_t)nSize;
     uint8_t* pTemp=NULL,*pFilled=NULL;
     uint32_t skipLen=0;
+    uint32_t spsTypeValue, ppsTypeValue, vpsTypeValue;
 
     if(pInData == NULL || nConsumeLen == NULL)
         return UNKNOWN_ERROR;
 
+    if (mIsH264) {
+        vpsTypeValue = 0xFF; //  invalid vps type value for h264
+        spsTypeValue = 7;
+        ppsTypeValue = 8;
+    } else {
+        vpsTypeValue = 32;
+        spsTypeValue = 33;
+        ppsTypeValue = 34;
+    }
+
     /*search boundary of sps and pps */
     if(false==FindStartCode(pInData,length,&pPre)){
         goto search_finish;
@@ -156,16 +167,17 @@ status_t FrameConverter::CheckSpsPps(uint8_t* pInData, uint32_t nSize, uint32_t*
         else{
             size=length; //last nal
         }
-        naltype=pPre[0] & 0x1f;
+        naltype = mIsH264 ? (pPre[0] & 0x1f) : ((pPre[0] >> 1) & 0x3F);
+
         ALOGD("find one nal, type: 0x%x, size: %d 
",naltype,size);
-        if (naltype==7) { /* SPS */
-            sps=pPre;
-            spsSize=size;
+        if (naltype == vpsTypeValue) { /* VPS */
+            vpsSize = size + 4;
+        } else if (naltype == spsTypeValue) { /* SPS */
+            spsSize = size + 4;
         }
-        else if (naltype==8) { /* PPS */
-            pps= pPre;
-            ppsSize=size;
-        }else if(naltype == 0x0c){//skip coda padding bytes
+        else if (naltype == ppsTypeValue) { /* PPS */
+            ppsSize = size + 4;
+        } else if(naltype == 0x0c){//skip coda padding bytes
             skipLen += 4+size;
         }
 
@@ -181,11 +193,11 @@ status_t FrameConverter::CheckSpsPps(uint8_t* pInData, uint32_t nSize, uint32_t*
     }
 
 search_finish:
-    if((sps==NULL)||(pps==NULL)){
+    if(0 == ppsSize || 0 == spsSize || (!mIsH264 && 0 == vpsSize)){
         return UNKNOWN_ERROR;
     }
 
-    nLen = spsSize+ppsSize+skipLen+4+4;
+    nLen = vpsSize+spsSize+ppsSize+skipLen;
 
     if(nSize < nLen)
         return UNKNOWN_ERROR;
@@ -271,7 +283,7 @@ bool FrameConverter::FindStartCode(uint8_t* pData, uint32_t nSize,uint8_t** ppSt
     uint32_t startcode=0xFFFFFFFF;
     uint8_t* p=pData;
     uint8_t* pEnd=pData+nSize;
-    
+
     if(nSize < 4){
         *ppStart=NULL;
         return false;
diff --git a/codec2/video_enc/v4l2_enc/FrameConverter.h b/codec2/video_enc/v4l2_enc/FrameConverter.h
index cf3680d..80d20ab 100755
--- a/codec2/video_enc/v4l2_enc/FrameConverter.h
+++ b/codec2/video_enc/v4l2_enc/FrameConverter.h
@@ -27,7 +27,8 @@ private:
     uint32_t nFormat;
     uint32_t nLen;
     uint8_t* pSpsPps;
-    
+    bool mIsH264;
+
     bool FindStartCode(uint8_t* pData, uint32_t nSize,uint8_t** ppStart);
 
 };
diff --git a/codec2/video_enc/v4l2_enc/V4l2Enc.cpp b/codec2/video_enc/v4l2_enc/V4l2Enc.cpp
index 9f2722a..248a68a 100644
--- a/codec2/video_enc/v4l2_enc/V4l2Enc.cpp
+++ b/codec2/video_enc/v4l2_enc/V4l2Enc.cpp
@@ -1,5 +1,5 @@
 /**
- *  Copyright 2019 NXP
+ *  Copyright 2019-2021 NXP
  *  All Rights Reserved.
  *
  *  The following programs are the sole property of Freescale Semiconductor Inc.,
@@ -9,10 +9,14 @@
 #define LOG_TAG "V4l2Enc"
 
 #include "V4l2Enc.h"
+#include <media/stagefright/MediaDefs.h>
 #include <media/stagefright/MediaErrors.h>
+#include <C2Config.h>
 #include "graphics_ext.h"
 #include <sys/mman.h>
 #include "C2_imx.h"
+#include "IMXUtils.h"
+
 #include <linux/imx_vpu.h>
 
 namespace android {
@@ -29,6 +33,135 @@ namespace android {
 
 #define DEFAULT_INPUT_BUFFER_COUNT (16)
 
+typedef struct {
+    int32_t c2Value;
+    int32_t v4l2Value;
+} C2V4l2Map;
+
+static const C2V4l2Map HevcProfileMapTable[] = {
+    {PROFILE_HEVC_MAIN,       V4L2_MPEG_VIDEO_HEVC_PROFILE_MAIN},
+    {PROFILE_HEVC_MAIN_10,    V4L2_MPEG_VIDEO_HEVC_PROFILE_MAIN_10},
+    {PROFILE_HEVC_MAIN_STILL, V4L2_MPEG_VIDEO_HEVC_PROFILE_MAIN_STILL_PICTURE},
+};
+
+static const C2V4l2Map HevcLevelMapTable[] = {
+    {LEVEL_HEVC_MAIN_1,   V4L2_MPEG_VIDEO_HEVC_LEVEL_1},
+    {LEVEL_HEVC_MAIN_2,   V4L2_MPEG_VIDEO_HEVC_LEVEL_2},
+    {LEVEL_HEVC_MAIN_2_1, V4L2_MPEG_VIDEO_HEVC_LEVEL_2_1},
+    {LEVEL_HEVC_MAIN_3,   V4L2_MPEG_VIDEO_HEVC_LEVEL_3},
+    {LEVEL_HEVC_MAIN_3_1, V4L2_MPEG_VIDEO_HEVC_LEVEL_3_1},
+    {LEVEL_HEVC_MAIN_4,   V4L2_MPEG_VIDEO_HEVC_LEVEL_4},
+    {LEVEL_HEVC_MAIN_4_1, V4L2_MPEG_VIDEO_HEVC_LEVEL_4_1},
+    {LEVEL_HEVC_MAIN_5,   V4L2_MPEG_VIDEO_HEVC_LEVEL_5},
+    {LEVEL_HEVC_MAIN_5_1, V4L2_MPEG_VIDEO_HEVC_LEVEL_5_1},
+};
+
+static const C2V4l2Map H264ProfileMapTable[] = {
+    {PROFILE_AVC_BASELINE,             V4L2_MPEG_VIDEO_H264_PROFILE_BASELINE},
+    {PROFILE_AVC_CONSTRAINED_BASELINE, V4L2_MPEG_VIDEO_H264_PROFILE_CONSTRAINED_BASELINE},
+    {PROFILE_AVC_MAIN,                 V4L2_MPEG_VIDEO_H264_PROFILE_MAIN},
+    {PROFILE_AVC_HIGH,                 V4L2_MPEG_VIDEO_H264_PROFILE_HIGH},
+};
+
+static const C2V4l2Map H264LevelMapTable[] = {
+    {LEVEL_AVC_1,   V4L2_MPEG_VIDEO_H264_LEVEL_1_0},
+    {LEVEL_AVC_1B,  V4L2_MPEG_VIDEO_H264_LEVEL_1B},
+    {LEVEL_AVC_1_1, V4L2_MPEG_VIDEO_H264_LEVEL_1_1},
+    {LEVEL_AVC_1_2, V4L2_MPEG_VIDEO_H264_LEVEL_1_2},
+    {LEVEL_AVC_1_3, V4L2_MPEG_VIDEO_H264_LEVEL_1_3},
+    {LEVEL_AVC_2,   V4L2_MPEG_VIDEO_H264_LEVEL_2_0},
+    {LEVEL_AVC_2_1, V4L2_MPEG_VIDEO_H264_LEVEL_2_1},
+    {LEVEL_AVC_2_2, V4L2_MPEG_VIDEO_H264_LEVEL_2_2},
+    {LEVEL_AVC_3,   V4L2_MPEG_VIDEO_H264_LEVEL_3_0},
+    {LEVEL_AVC_3_1, V4L2_MPEG_VIDEO_H264_LEVEL_3_1},
+    {LEVEL_AVC_3_2, V4L2_MPEG_VIDEO_H264_LEVEL_3_2},
+    {LEVEL_AVC_4,   V4L2_MPEG_VIDEO_H264_LEVEL_4_0},
+    {LEVEL_AVC_4_1, V4L2_MPEG_VIDEO_H264_LEVEL_4_1},
+    {LEVEL_AVC_4_2, V4L2_MPEG_VIDEO_H264_LEVEL_4_2},
+    {LEVEL_AVC_5,   V4L2_MPEG_VIDEO_H264_LEVEL_5_0},
+    {LEVEL_AVC_5_1, V4L2_MPEG_VIDEO_H264_LEVEL_5_1},
+};
+
+static int32_t C2ToV4l2ProfileLevel(int32_t c2value, const char* mime, bool isProfile)
+{
+    int i, tableLen;
+    const C2V4l2Map * pTable;
+
+    if (!strcmp(mime, MEDIA_MIMETYPE_VIDEO_HEVC)) {
+        if (isProfile) {
+            pTable = HevcProfileMapTable;
+            tableLen = sizeof(HevcProfileMapTable)/sizeof(HevcProfileMapTable[0]);
+        } else {
+            pTable = HevcLevelMapTable;
+            tableLen = sizeof(HevcLevelMapTable)/sizeof(HevcLevelMapTable[0]);
+        }
+    } else if (!strcmp(mime, MEDIA_MIMETYPE_VIDEO_AVC)) {
+        if (isProfile) {
+            pTable = H264ProfileMapTable;
+            tableLen = sizeof(H264ProfileMapTable)/sizeof(H264ProfileMapTable[0]);
+        } else {
+            pTable = H264LevelMapTable;
+            tableLen = sizeof(H264LevelMapTable)/sizeof(H264LevelMapTable[0]);
+        }
+    } else
+        return 0;
+
+    for (i = 0; i < tableLen; i++) {
+        if (pTable[i].c2Value == c2value)
+            return pTable[i].v4l2Value;
+    }
+
+    ALOGW("Can't convert c2 value %d, return a lowest value as default", c2value);
+    return pTable[0].v4l2Value;
+}
+
+/* table for max frame size for each video level */
+typedef struct {
+    int level;
+    int size;    // mbPerFrame, (Width / 16) * (Height / 16)
+}EncLevelSizeMap;
+
+/* H264 level size map table, sync with h1 h264 encoder */
+static const EncLevelSizeMap H264LevelSizeMapTable[] = {
+    {LEVEL_AVC_1,   99},
+    {LEVEL_AVC_1B,  99},
+    {LEVEL_AVC_1_1, 396},
+    {LEVEL_AVC_1_2, 396},
+    {LEVEL_AVC_1_3, 396},
+    {LEVEL_AVC_2,   396},
+    {LEVEL_AVC_2_1, 792},
+    {LEVEL_AVC_2_2, 1620},
+    {LEVEL_AVC_3,   1620},
+    {LEVEL_AVC_3_1, 3600},
+    {LEVEL_AVC_3_2, 5120},
+    {LEVEL_AVC_4,   8192},
+    {LEVEL_AVC_4_1, 8192},
+    {LEVEL_AVC_4_2, 8704},
+    {LEVEL_AVC_5,   22080},
+    {LEVEL_AVC_5_1, 65025},
+};
+
+static uint32_t CheckH264Level(uint32_t width, uint32_t height, uint32_t level)
+{
+    // adjust H264 level based on video resolution because h1 encoder will check this.
+    int i, mbPerFrame, tableLen;
+    mbPerFrame = ((width + 15) / 16) * ((height + 15) / 16);
+    tableLen = sizeof(H264LevelSizeMapTable)/sizeof(H264LevelSizeMapTable[0]);
+
+    for (i = 0; i < tableLen; i++) {
+        if (level == H264LevelSizeMapTable[i].level) {
+          if (mbPerFrame <= H264LevelSizeMapTable[i].size)
+            break;
+        else if (i + 1 < tableLen)
+            level = H264LevelSizeMapTable[i + 1].level;
+        else
+            break;
+      }
+    }
+
+    return level;
+}
+
 V4l2Enc::V4l2Enc(const char* mime):
     mMime(mime),
     mPollThread(0),
@@ -63,14 +196,23 @@ V4l2Enc::V4l2Enc(const char* mime):
     mOutputFormat.bufferNum = kDefaultOutputBufferCount;
     mOutputFormat.interlaced = false;
 
-    memset(&mEncParam, 0, sizeof(V4l2EncInputParam));
-    memset(&mIsoColorAspect, 0, sizeof(VideoColorAspect));
-    memset(&mInputPlaneSize[0], 0, kInputBufferPlaneNum * sizeof(uint32_t));
+    mCropWidth = mInputFormat.width;
+    mCropHeight = mInputFormat.height;
+
+    mInBufType = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    mOutBufType = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
 
     //V4L2_MEMORY_USERPTR; V4L2_MEMORY_DMABUF; V4L2_MEMORY_MMAP
     mInMemType = V4L2_MEMORY_DMABUF;
     mOutMemType = V4L2_MEMORY_MMAP;
 
+    mInPlaneNum = 2;
+    mOutPlaneNum = kOutputBufferPlaneNum;
+
+    memset(&mEncParam, 0, sizeof(V4l2EncInputParam));
+    memset(&mIsoColorAspect, 0, sizeof(VideoColorAspect));
+    memset(&mInputPlaneSize[0], 0, kMaxInputBufferPlaneNum * sizeof(uint32_t));
+    bNeedFrameConverter = false;
     mConverter = NULL;
 
     bPreProcess = false;
@@ -85,7 +227,8 @@ V4l2Enc::~V4l2Enc()
     ALOGV("V4l2Enc::~V4l2Enc");
     onDestroy();
 }
-status_t V4l2Enc::onInit(){
+
+status_t V4l2Enc::OpenDevice() {
     status_t ret = UNKNOWN_ERROR;
 
     if(pDev == NULL){
@@ -100,37 +243,37 @@ status_t V4l2Enc::onInit(){
     if(mFd < 0)
         return ret;
 
-    mFrameOutNum = 0;
-
-    ret = prepareOutputParams();
-
-    ParseVpuLogLevel();
-    mState = UNINITIALIZED;
-
-    return ret;
+    return OK;
 }
-status_t V4l2Enc::onStart()
-{
-
+status_t V4l2Enc::onInit(){
     status_t ret = UNKNOWN_ERROR;
 
-    bPollStarted = false;
-    bFetchStarted = false;
-    bInputStreamOn = false;
-    bOutputStreamOn = false;
-    bSyncFrame = false;
-    bHasCodecData = false;
+    ret = pDev->GetVideoBufferType(&mInBufType, &mOutBufType);
+    if (ret != OK)
+        return ret;
+
+    if(!strcmp(mMime, "video/avc") || !strcmp(mMime, "video/hevc"))
+        bNeedFrameConverter = true;
 
     mFrameOutNum = 0;
 
-    if(!strcmp(mMime, "video/avc")){
+    ret = prepareOutputParams();
+
+    ParseVpuLogLevel();
+
+    if(bNeedFrameConverter){
         mConverter = new FrameConverter();
         if(mConverter == NULL){
             ret = UNKNOWN_ERROR;
             return ret;
         }
         ALOGV("NEW FrameConverter");
-        ret = mConverter->Create(V4L2_PIX_FMT_H264);
+
+        ret = mConverter->Create(mOutFormat);
+        if (ret != OK) {
+            ALOGE("create converter failed, mOutFormat 0x%x", mOutFormat);
+            return ret;
+        }
     }
 
     ret = SetOutputFormats();
@@ -154,14 +297,6 @@ status_t V4l2Enc::onStart()
         return ret;
     }
 
-    if(mInputBufferMap.empty() || (mInputFormat.bufferSize != mInputPlaneSize[0] + mInputPlaneSize[1])){
-
-        ret = prepareInputBuffers();
-        ALOGV("onStart prepareInputBuffers ret=%d",ret);
-        if(ret != OK)
-            return ret;
-    }
-
     ret = pDev->SetEncoderParam(&mEncParam);
     if(ret != OK){
         ALOGE("SetEncoderParam failed");
@@ -174,6 +309,31 @@ status_t V4l2Enc::onStart()
         return ret;
     }
 
+    mState = PREPARED;
+
+    return ret;
+}
+status_t V4l2Enc::onStart()
+{
+
+    status_t ret = UNKNOWN_ERROR;
+
+    bPollStarted = false;
+    bFetchStarted = false;
+    bInputStreamOn = false;
+    bOutputStreamOn = false;
+    bSyncFrame = false;
+    bHasCodecData = false;
+
+    mFrameOutNum = 0;
+
+    if(mInputBufferMap.empty() || (mInputFormat.bufferSize != mInputPlaneSize[0] + mInputPlaneSize[1])){
+
+        ret = prepareInputBuffers();
+        ALOGV("onStart prepareInputBuffers ret=%d",ret);
+        if(ret != OK)
+            return ret;
+    }
 
     //allocate output buffers
     for(int32_t i = 0; i < mOutputFormat.bufferNum; i++){
@@ -216,8 +376,6 @@ status_t V4l2Enc::prepareOutputParams()
         mOutputFormat.bufferNum = 2;
     }
     ALOGV("bufferNum=%d,bufferSize=%d",mOutputFormat.bufferNum, mOutputFormat.bufferSize);
-    mWidthAlign = 1;
-    mHeightAlign = 1;
 
     struct v4l2_frmsizeenum info;
     memset(&info, 0, sizeof(v4l2_frmsizeenum));
@@ -228,6 +386,8 @@ status_t V4l2Enc::prepareOutputParams()
 
     mWidthAlign = info.stepwise.step_width;
     mHeightAlign = info.stepwise.step_height;
+    if(mWidthAlign < 1)
+        mWidthAlign = 1;
 
     return OK;
 }
@@ -238,48 +398,69 @@ status_t V4l2Enc::SetOutputFormats()
 
     mOutputFormat.width = Align(mOutputFormat.width, mWidthAlign);
     mOutputFormat.height = Align(mOutputFormat.height, mHeightAlign);
+    mOutputFormat.stride = mOutputFormat.width;
 
     struct v4l2_format format;
     memset(&format, 0, sizeof(format));
-    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-    format.fmt.pix_mp.num_planes = kOutputBufferPlaneNum;
-    format.fmt.pix_mp.pixelformat = mOutFormat;
-    format.fmt.pix_mp.plane_fmt[0].sizeimage = mOutputFormat.bufferSize;
-    format.fmt.pix_mp.plane_fmt[0].bytesperline = Align(mOutputFormat.width, mWidthAlign);
-    format.fmt.pix_mp.width = mOutputFormat.width;
-    format.fmt.pix_mp.height = mOutputFormat.height;
-    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+    format.type = mOutBufType;
+
+    if (V4L2_TYPE_IS_MULTIPLANAR(format.type)) {
+        format.fmt.pix_mp.num_planes = mOutPlaneNum;
+        format.fmt.pix_mp.pixelformat = mOutFormat;
+        format.fmt.pix_mp.plane_fmt[0].sizeimage = mOutputFormat.bufferSize;
+        format.fmt.pix_mp.plane_fmt[0].bytesperline = Align(mOutputFormat.width, mWidthAlign);
+        format.fmt.pix_mp.width = mOutputFormat.width;
+        format.fmt.pix_mp.height = mOutputFormat.height;
+        format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+    } else {
+        format.fmt.pix.pixelformat = mOutFormat;
+		format.fmt.pix.width = mOutputFormat.width;
+		format.fmt.pix.height = mOutputFormat.height;
+		format.fmt.pix.bytesperline = Align(mOutputFormat.width, mWidthAlign);
+		format.fmt.pix.sizeimage = mOutputFormat.bufferSize;
+        format.fmt.pix.field = V4L2_FIELD_NONE;
+    }
 
     result = ioctl (mFd, VIDIOC_S_FMT, &format);
     if(result != 0)
         return UNKNOWN_ERROR;
 
     memset(&format, 0, sizeof(format));
-    format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    format.type = mOutBufType;
 
     result = ioctl (mFd, VIDIOC_G_FMT, &format);
     if(result != 0)
         return UNKNOWN_ERROR;
 
-    if(format.fmt.pix_mp.pixelformat != mOutFormat){
-        ALOGE("SetOutputFormats mInFormat mismatch");
-        return UNKNOWN_ERROR;
+    uint32_t retFormat, retWidth, retHeight, retBytesperline, retSizeimage;
+
+    if (V4L2_TYPE_IS_MULTIPLANAR(format.type)) {
+        retFormat = format.fmt.pix_mp.pixelformat;
+        retHeight = format.fmt.pix_mp.height;
+        retWidth = format.fmt.pix_mp.width;
+        retSizeimage = format.fmt.pix_mp.plane_fmt[0].sizeimage;
+        retBytesperline = format.fmt.pix_mp.plane_fmt[0].bytesperline;
+    } else {
+        retFormat = format.fmt.pix.pixelformat;
+        retHeight = format.fmt.pix.height;
+        retWidth = format.fmt.pix.width;
+        retSizeimage = format.fmt.pix.sizeimage;
+        retBytesperline = format.fmt.pix.bytesperline;
     }
 
-    if( format.fmt.pix_mp.width != mOutputFormat.width ||
-        format.fmt.pix_mp.height != mOutputFormat.height){
-        ALOGE("SetOutputFormats resolution mismatch");
+    if(retFormat != mOutFormat){
+        ALOGE("SetOutputFormats mInFormat mismatch");
         return UNKNOWN_ERROR;
     }
 
-    if(format.fmt.pix_mp.plane_fmt[0].bytesperline != Align(mOutputFormat.width, mWidthAlign)){
-        ALOGE("SetOutputFormats stride mismatch");
+    if(retWidth != mOutputFormat.width || retHeight != mOutputFormat.height){
+        ALOGE("SetOutputFormats resolution mismatch");
         return UNKNOWN_ERROR;
     }
 
-    if(format.fmt.pix_mp.plane_fmt[0].sizeimage != mOutputFormat.bufferSize){
-        ALOGE("SetOutputFormats bufferSize mismatch");
-        return UNKNOWN_ERROR;
+    if(retSizeimage != mOutputFormat.bufferSize){
+        mOutputFormat.bufferSize = retSizeimage;
+        ALOGW("SetOutputFormats bufferSize mismatch");
     }
 
     return OK;
@@ -300,19 +481,71 @@ status_t V4l2Enc::prepareInputParams()
         return ret;
     }
 
-    if(mInFormat == V4L2_PIX_FMT_NV12){
-        //update output frame width & height
-        mInputFormat.width = Align(mInputFormat.width, mWidthAlign);
-        mInputFormat.height = Align(mInputFormat.height, mHeightAlign);
+    //update output frame width & height
+    mCropWidth = mInputFormat.width;
+    mCropHeight = mInputFormat.height;
+    mInputFormat.width = Align(mInputFormat.width, mWidthAlign);
+    mInputFormat.height = Align(mInputFormat.height, mHeightAlign);
+    mInputFormat.stride = mInputFormat.width;
+    memset(&mInputPlaneSize[0], 0, kMaxInputBufferPlaneNum * sizeof(uint32_t));
+    ALOGV("prepareInputParams width=%d,height=%d,mWidthAlign=%d,mInFormat=0x%x",mInputFormat.width, mInputFormat.height, (int)mWidthAlign,mInFormat);
 
-        mInputPlaneSize[0] = mInputFormat.width * mInputFormat.height;
-        mInputPlaneSize[1] = mInputPlaneSize[0]/2;
-        mInputFormat.bufferSize = mInputPlaneSize[0] + mInputPlaneSize[1];
-        ALOGV("prepareInputParams w=%d,h=%d,input buffer size=%d",mInputFormat.width, mInputFormat.height, mInputFormat.bufferSize);
-
-    }else{
-        ALOGE("encoder input format not NV12");
-        return UNKNOWN_ERROR;
+    switch (mInFormat) {
+        case V4L2_PIX_FMT_NV12:
+        {
+            if (V4L2_TYPE_IS_MULTIPLANAR(mInBufType)) {
+                mInPlaneNum = 2;
+                mInputPlaneSize[0] = mInputFormat.stride * mInputFormat.height;
+                mInputPlaneSize[1] = mInputPlaneSize[0]/2;
+                mInputFormat.bufferSize = mInputPlaneSize[0] + mInputPlaneSize[1];
+            } else {
+                ALOGE("Shouldn't enter here");
+                return BAD_VALUE;
+            }
+            break;
+        }
+        case V4L2_PIX_FMT_YUV420:
+        {
+            if (V4L2_TYPE_IS_MULTIPLANAR(mInBufType)) {
+                // YUV420 buffer width is align with 32, so actual buffer width is Align(mInputFormat.width, 32)
+                mInPlaneNum = 3;
+                mInputFormat.width = Align(mInputFormat.width, 32);
+                mInputFormat.stride = mInputFormat.width;
+                mInputPlaneSize[0] = mInputFormat.stride * mInputFormat.height;
+                mInputPlaneSize[1] = mInputPlaneSize[0]/4;
+                mInputPlaneSize[2] = mInputPlaneSize[1];
+                mInputFormat.bufferSize = mInputPlaneSize[0] + mInputPlaneSize[1] + mInputPlaneSize[2];
+            } else {
+                ALOGE("Shouldn't enter here");
+                return BAD_VALUE;
+            }
+            break;
+        }
+        case V4L2_PIX_FMT_YUYV:
+        case V4L2_PIX_FMT_RGB565:
+        case V4L2_PIX_FMT_RGB24:
+        case V4L2_PIX_FMT_RGBA32:
+        case V4L2_PIX_FMT_RGBX32:
+        case V4L2_PIX_FMT_BGRA32:
+        {
+            mInPlaneNum = 1;
+            if (V4L2_TYPE_IS_MULTIPLANAR(mInBufType)) {
+                mInputPlaneSize[0] = mInputFormat.stride * mInputFormat.height * pxlfmt2bpp(mInputFormat.pixelFormat) / 8;
+                mInputFormat.bufferSize = mInputPlaneSize[0];
+
+                //bytesperline should be twice of width when yuyv format
+                mInputFormat.stride = mInputFormat.width * pxlfmt2bpp(mInputFormat.pixelFormat) / 8;
+
+                ALOGV("mInputFormat.bufferSize 2 = %d",mInputFormat.bufferSize);
+            } else {
+                ALOGE("Shouldn't enter here");
+                return BAD_VALUE;
+            }
+            break;
+        }
+        default:
+            ALOGE("encoder input format 0x%x is not supported", mInFormat);
+            return UNKNOWN_ERROR;
     }
 
     return OK;
@@ -324,16 +557,29 @@ status_t V4l2Enc::SetInputFormats()
 
     struct v4l2_format format;
     memset(&format, 0, sizeof(format));
-    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
-    format.fmt.pix_mp.num_planes = kInputBufferPlaneNum;
-    format.fmt.pix_mp.pixelformat = mInFormat;
-    format.fmt.pix_mp.width = mInputFormat.width;
-    format.fmt.pix_mp.height = mInputFormat.height;
-    format.fmt.pix_mp.plane_fmt[0].sizeimage = mInputPlaneSize[0];
-    format.fmt.pix_mp.plane_fmt[0].bytesperline = Align(mInputFormat.width, mWidthAlign);
-    format.fmt.pix_mp.plane_fmt[1].sizeimage = mInputPlaneSize[1];
-    format.fmt.pix_mp.plane_fmt[1].bytesperline = Align(mInputFormat.width, mWidthAlign);
-    format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+    format.type = mInBufType;
+
+    ALOGV("SetInputFormats stride=%d,w=%d,w align=%d,pixelFormat=0x%x",mInputFormat.stride,mInputFormat.width, mWidthAlign,mInputFormat.pixelFormat);
+
+    if (V4L2_TYPE_IS_MULTIPLANAR(format.type)) {
+        format.fmt.pix_mp.num_planes = mInPlaneNum;
+        format.fmt.pix_mp.pixelformat = mInFormat;
+        format.fmt.pix_mp.width = mInputFormat.width;
+        format.fmt.pix_mp.height = mInputFormat.height;
+        format.fmt.pix_mp.field = V4L2_FIELD_NONE;
+
+        for (int i = 0; i < format.fmt.pix_mp.num_planes; i++) {
+            format.fmt.pix_mp.plane_fmt[i].sizeimage = mInputPlaneSize[i];
+            format.fmt.pix_mp.plane_fmt[i].bytesperline = mInputFormat.stride;
+        }
+    } else {
+        format.fmt.pix.pixelformat = mInFormat;
+        format.fmt.pix.width = mInputFormat.width;
+        format.fmt.pix.height = mInputFormat.height;
+        format.fmt.pix.sizeimage = mInputPlaneSize[0];
+        format.fmt.pix.bytesperline = mInputFormat.stride;
+        format.fmt.pix.field = V4L2_FIELD_NONE;
+    }
 
     pDev->SetColorAspectsInfo(&mIsoColorAspect, &format.fmt.pix_mp);
 
@@ -344,28 +590,62 @@ status_t V4l2Enc::SetInputFormats()
     }
 
     memset(&format, 0, sizeof(struct v4l2_format));
-    format.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    format.type = mInBufType;
 
     result = ioctl (mFd, VIDIOC_G_FMT, &format);
     if(result < 0)
         return UNKNOWN_ERROR;
 
+    uint32_t retFormat;
 
-    if(format.fmt.pix_mp.pixelformat != mInFormat){
-        ALOGE("SetInputFormats mOutFormat mismatch");
-        return UNKNOWN_ERROR;
+    if (V4L2_TYPE_IS_MULTIPLANAR(format.type)) {
+        retFormat = format.fmt.pix_mp.pixelformat;
+        mInPlaneNum = format.fmt.pix_mp.num_planes;
+
+        for (int i = 0; i < format.fmt.pix_mp.num_planes; i++) {
+            if (format.fmt.pix_mp.plane_fmt[i].sizeimage != mInputPlaneSize[i]) {
+                ALOGW("SetInputFormats bufferSize mismatch, changed from %d to %d ",
+                        mInputPlaneSize[i], format.fmt.pix_mp.plane_fmt[i].sizeimage);
+                mInputPlaneSize[i] = format.fmt.pix_mp.plane_fmt[i].sizeimage;
+            }
+            ALOGV("plane_fmt[%d] sizeimage=%d,bytesperline=%d",i, format.fmt.pix_mp.plane_fmt[i].sizeimage, format.fmt.pix_mp.plane_fmt[0].bytesperline);
+        }
+
+        mInputFormat.bufferSize = mInputPlaneSize[0] + mInputPlaneSize[1] + mInputPlaneSize[2];
+
+        if(mInPlaneNum > 1){
+            mInputFormat.stride = format.fmt.pix_mp.plane_fmt[0].bytesperline;
+        }
+
+        ALOGV("SetInputFormats get mInPlaneNum=%d mInputFormat.stride=%d,mInputFormat.bufferSize=%d",mInPlaneNum,mInputFormat.stride,mInputFormat.bufferSize);
+    } else {
+        retFormat = format.fmt.pix.pixelformat;
+        mInPlaneNum = 1;
+
+        if(format.fmt.pix.sizeimage != mInputPlaneSize[0]){
+            ALOGW("SetInputFormats bufferSize mismatch, changed from %d to %d",
+                    mInputPlaneSize[0], format.fmt.pix.sizeimage);
+            mInputPlaneSize[0] = format.fmt.pix.sizeimage;
+        }
     }
 
-    if(format.fmt.pix_mp.width != mInputFormat.width ||
-        format.fmt.pix_mp.height != mInputFormat.height){
-        ALOGE("SetInputFormats resolution mismatch");
+    if(retFormat != mInFormat){
+        ALOGE("SetInputFormats mInputFormat mismatch, expect 0x%x, actual 0x%x", mInFormat, retFormat);
         return UNKNOWN_ERROR;
     }
 
-    if(format.fmt.pix_mp.plane_fmt[0].sizeimage != mInputPlaneSize[0] ||
-        format.fmt.pix_mp.plane_fmt[1].sizeimage != mInputPlaneSize[1]){
-        ALOGE("SetInputFormats bufferSize mismatch");
-        return UNKNOWN_ERROR;
+    if (mCropWidth != mInputFormat.width || mCropHeight != mInputFormat.height) {
+        struct v4l2_selection selection;
+        selection.type = V4L2_BUF_TYPE_VIDEO_OUTPUT;
+        selection.target = V4L2_SEL_TGT_CROP;
+        selection.r.left = 0;
+        selection.r.top = 0;
+        selection.r.width = mCropWidth;
+        selection.r.height = mCropHeight;
+
+        result = ioctl(mFd, VIDIOC_S_SELECTION, &selection);
+        ALOGV("VIDIOC_S_SELECTION ret=%d (%d %d %d %d)", result,
+            selection.r.left, selection.r.top, selection.r.width, selection.r.height);
     }
 
     ALOGV("SetInputFormats success");
@@ -374,7 +654,7 @@ status_t V4l2Enc::SetInputFormats()
 
 V4l2Enc::InputRecord::InputRecord()
     : at_device(false), input_id(-1), ts(-1) {
-    memset(&planes, 0, kInputBufferPlaneNum * sizeof(VideoFramePlane));
+    memset(&planes, 0, kMaxInputBufferPlaneNum * sizeof(VideoFramePlane));
 }
 
 V4l2Enc::InputRecord::~InputRecord() {}
@@ -394,7 +674,7 @@ status_t V4l2Enc::prepareInputBuffers()
     struct v4l2_requestbuffers reqbufs;
     memset(&reqbufs, 0, sizeof(reqbufs));
     reqbufs.count = mInputFormat.bufferNum;
-    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.type = mInBufType;
     reqbufs.memory = mInMemType;
     ALOGV("prepareInputBuffers VIDIOC_REQBUFS bufferNum=%d",reqbufs.count);
     result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
@@ -406,7 +686,7 @@ status_t V4l2Enc::prepareInputBuffers()
     ALOGV("prepareInputBuffers mInputBufferMap resize=%d",reqbufs.count);
     mInputBufferMap.resize(reqbufs.count);
 
-    ALOGV("prepareInputBuffers total input=%d size=%d",mOutputFormat.bufferNum, mOutputBufferMap.size());
+    ALOGV("prepareInputBuffers total input=%d size=%d",mInputFormat.bufferNum, mInputBufferMap.size());
 
     for (size_t i = 0; i < mInputBufferMap.size(); i++) {
         mInputBufferMap[i].at_device = false;
@@ -424,7 +704,7 @@ status_t V4l2Enc::prepareOutputBuffers()
     struct v4l2_requestbuffers reqbufs;
     memset(&reqbufs, 0, sizeof(reqbufs));
     reqbufs.count = mOutputFormat.bufferNum;
-    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.type = mOutBufType;
     reqbufs.memory = mOutMemType;
 
     result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
@@ -446,7 +726,7 @@ status_t V4l2Enc::prepareOutputBuffers()
         mOutputBufferMap[i].flag = 0;
     }
 
-    ALOGV("VIDIOC_REQBUFS CAPTURE_MPLANE success input=%d size=%d",mOutputFormat.bufferNum, mOutputBufferMap.size());
+    ALOGV("prepareOutputBuffers output=%d size=%d",mOutputFormat.bufferNum, mOutputBufferMap.size());
 
     return OK;
 }
@@ -460,13 +740,13 @@ status_t V4l2Enc::destroyInputBuffers()
     struct v4l2_requestbuffers reqbufs;
     memset(&reqbufs, 0, sizeof(reqbufs));
     reqbufs.count = 0;
-    reqbufs.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    reqbufs.type = mInBufType;
     reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
 
     result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
 
     if(result != 0)
-        return UNKNOWN_ERROR;
+        ALOGW("%s result=%d", __FUNCTION__, result);
 
     mInputBufferMap.clear();
     ALOGV("destroyInputBuffers success");
@@ -482,13 +762,13 @@ status_t V4l2Enc::destroyOutputBuffers()
     struct v4l2_requestbuffers reqbufs;
     memset(&reqbufs, 0, sizeof(reqbufs));
     reqbufs.count = 0;
-    reqbufs.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    reqbufs.type = mOutBufType;
     reqbufs.memory = V4L2_MEMORY_MMAP;//use mmap to free buffer
 
     result = ioctl(mFd, VIDIOC_REQBUFS, &reqbufs);
 
     if(result != 0)
-        return UNKNOWN_ERROR;
+        ALOGW("%s result=%d", __FUNCTION__, result);
 
     mOutputBufferMap.clear();
     //clearOutputFrameBuffer();//call it here or in base class
@@ -538,7 +818,7 @@ status_t V4l2Enc::HandleFetchThread()
             usleep(1000);
             continue;
         }
-        
+
         bool fetch = false;
         int32_t currNum = (mFrameOutNum % mOutputFormat.bufferNum);
 
@@ -619,7 +899,7 @@ status_t V4l2Enc::createFetchThread()
         pthread_attr_t attr;
         pthread_attr_init(&attr);
         pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
-        
+
         bFetchStarted = true;
         pthread_create(&mFetchThread, &attr, FetchThreadWrapper, this);
         pthread_attr_destroy(&attr);
@@ -651,7 +931,10 @@ status_t V4l2Enc::encodeInternal(std::unique_ptr<IMXInputBuffer> input)
     if(input == nullptr)
         return BAD_VALUE;
 
-    if(STOPPED == mState || UNINITIALIZED == mState)
+    if(UNINITIALIZED == mState)
+        return BAD_VALUE;
+
+    if(STOPPED == mState || PREPARED == mState)
         onStart();
 
     mLock.lock();
@@ -685,26 +968,12 @@ status_t V4l2Enc::encodeInternal(std::unique_ptr<IMXInputBuffer> input)
 
     //try to get index
     for(int32_t i = 0; i < mInputBufferMap.size(); i++){
-        if((mInputBufferMap[i].planes[0].addr == (uint64_t)input->pInputPhys)
-            && !mInputBufferMap[i].at_device){
+        if(mInputBufferMap[i].input_id == -1 && !mInputBufferMap[i].at_device){
             index = i;
             break;
         }
     }
 
-    //index not found
-    if(index < 0){
-        for(int32_t i = 0; i < mInputBufferMap.size(); i++){
-            if(0 == mInputBufferMap[i].planes[0].addr){
-                mInputBufferMap[i].planes[0].fd = input->fd;
-                mInputBufferMap[i].planes[0].addr = (uint64_t)input->pInputPhys;
-                mInputBufferMap[i].planes[0].offset = 0;
-                index = i;
-                break;
-            }
-        }
-    }
-
     if(index < 0){
         mLock.unlock();
         ALOGE("encodeInternal invalid index");
@@ -724,49 +993,91 @@ status_t V4l2Enc::encodeInternal(std::unique_ptr<IMXInputBuffer> input)
     }
 
     struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane planes[kInputBufferPlaneNum];
+    struct v4l2_plane planes[kMaxInputBufferPlaneNum];
     memset(&stV4lBuf, 0, sizeof(stV4lBuf));
-    memset(&planes[0], 0, kInputBufferPlaneNum * sizeof(struct v4l2_plane));
+    memset(&planes[0], 0, mInPlaneNum * sizeof(struct v4l2_plane));
 
-    planes[0].bytesused = mInputPlaneSize[0];
-    planes[0].length = mInputPlaneSize[0];
-    planes[0].data_offset = 0;
-
-    if(bPreProcess){
-        planes[1].bytesused = mInputPlaneSize[1];
-        planes[1].length = mInputPlaneSize[1];
-        planes[1].data_offset = 0;
-    }else{
-        planes[1].bytesused = mInputPlaneSize[0]+ mInputPlaneSize[1];
-        planes[1].length = mInputPlaneSize[0] + mInputPlaneSize[1];
-        planes[1].data_offset = mInputPlaneSize[0];
+    switch(mInPlaneNum){
+        case 1:
+        {
+            // mInputPlaneSize[0] may differ from mInputFormat.bufferSize because of alignment
+            planes[0].bytesused = mInputFormat.bufferSize;
+            planes[0].length = mInputPlaneSize[0];
+            planes[0].data_offset = 0;
+            break;
+        }
+        case 2:
+        {
+            planes[0].bytesused = mInputPlaneSize[0];
+            planes[0].length = mInputPlaneSize[0];
+            planes[0].data_offset = 0;
+
+            if(bPreProcess){
+                planes[1].bytesused = mInputPlaneSize[1];
+                planes[1].length = mInputPlaneSize[1];
+                planes[1].data_offset = 0;
+            }else{
+                planes[1].bytesused = mInputPlaneSize[0] + mInputPlaneSize[1];
+                planes[1].length = mInputPlaneSize[0] + mInputPlaneSize[1];
+                planes[1].data_offset = mInputPlaneSize[0];
+            }
+            break;
+        }
+        case 3:
+        {
+            planes[0].bytesused = mInputPlaneSize[0];
+            planes[0].length = mInputPlaneSize[0];
+            planes[0].data_offset = 0;
+
+            //GraphicInputBuffers allocate HAL_PIXEL_FORMAT_YV12, need to switch UV for HAL_PIXEL_FORMAT_YCbCr_420_P
+            planes[2].bytesused = mInputPlaneSize[0] + mInputPlaneSize[1];
+            planes[2].length = mInputPlaneSize[0] + mInputPlaneSize[1];
+            planes[2].data_offset = mInputPlaneSize[0];
+
+            planes[1].bytesused = mInputPlaneSize[0] + mInputPlaneSize[1] + mInputPlaneSize[2];
+            planes[1].length = mInputPlaneSize[0] + mInputPlaneSize[1] + mInputPlaneSize[2];
+            planes[1].data_offset = mInputPlaneSize[0]+mInputPlaneSize[1];
+            break;
+        }
+        default:
+            mLock.unlock();
+            ALOGE("encodeInternal invalid mInPlaneNum=%d",mInPlaneNum);
+            return UNKNOWN_ERROR;
     }
 
     if(mInMemType == V4L2_MEMORY_USERPTR){
         planes[0].m.userptr = mInputBufferMap[index].planes[0].addr = (uint64_t)input->pInputVirt;
-        planes[1].m.userptr = mInputBufferMap[index].planes[1].addr = (uint64_t)input->pInputVirt;
+
+        if (mInPlaneNum > 1)
+            planes[1].m.userptr = mInputBufferMap[index].planes[1].addr = (uint64_t)input->pInputVirt;
+
     }else if(mInMemType == V4L2_MEMORY_DMABUF){
+#ifdef AMPHION_V4L2
         if(bPreProcess)
             planes[0].m.fd = mInputBufferMap[index].planes[0].fd = (int)(uint64_t)input->pInputPhys;
         else
+#endif
             planes[0].m.fd = mInputBufferMap[index].planes[0].fd = input->fd;
 
-        planes[1].m.fd = mInputBufferMap[index].planes[1].fd = input->fd;
+        if(mInPlaneNum > 1)
+            planes[1].m.fd = mInputBufferMap[index].planes[1].fd = input->fd;
 
+        if(mInPlaneNum > 2)
+            planes[2].m.fd = mInputBufferMap[index].planes[2].fd = input->fd;
     }
 
     stV4lBuf.index = index;
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    stV4lBuf.type = mInBufType;
     if((int64_t)input->timestamp > 0){
         stV4lBuf.timestamp.tv_sec = (int64_t)input->timestamp/1000000;
         stV4lBuf.timestamp.tv_usec = (int64_t)input->timestamp - stV4lBuf.timestamp.tv_sec * 1000000;
     }
     stV4lBuf.memory = mInMemType;
     stV4lBuf.m.planes = &planes[0];
-    stV4lBuf.length = kInputBufferPlaneNum;
+    stV4lBuf.length = mInPlaneNum;
     stV4lBuf.flags = v4l2_flags;
 
-    ALOGV("V4l2Enc OUTPUT_MPLANE VIDIOC_QBUF index=%d,len=%d, ts=%lld,fd0=%d,fd1=%d
",
+    ALOGV("V4l2Enc OUTPUT VIDIOC_QBUF index=%d,len=%d, ts=%lld,fd0=%d,fd1=%d
",
         stV4lBuf.index, planes[0].bytesused, (long long)input->timestamp,planes[0].m.fd, planes[1].m.fd);
 
     result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
@@ -778,7 +1089,7 @@ status_t V4l2Enc::encodeInternal(std::unique_ptr<IMXInputBuffer> input)
 
     mInputBufferMap[index].at_device = true;
 
-    dumpInputBuffer(input->fd, mInputPlaneSize[0]+ mInputPlaneSize[1]);
+    dumpInputBuffer(input->fd, mInputFormat.bufferSize);
     mLock.unlock();
 
     if(!bInputStreamOn)
@@ -802,13 +1113,13 @@ status_t V4l2Enc::dequeueInputBuffer()
         return OK;
 
     struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane planes[kInputBufferPlaneNum];
+    struct v4l2_plane planes[mInPlaneNum];
     memset(&stV4lBuf, 0, sizeof(stV4lBuf));
     memset(planes, 0, sizeof(planes));
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+    stV4lBuf.type = mInBufType;
     stV4lBuf.memory = mInMemType;
     stV4lBuf.m.planes = planes;
-    stV4lBuf.length = kInputBufferPlaneNum;
+    stV4lBuf.length = mInPlaneNum;
     result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
     if(result < 0)
         return UNKNOWN_ERROR;
@@ -834,7 +1145,7 @@ status_t V4l2Enc::queueOutput(int buffer_id, int fd, unsigned long nVaddr)
 {
     int result = 0;
     int32_t index = -1;
-    
+
     if(!bFetchStarted || STOPPING == mState || FLUSHING == mState){
         ALOGV("queueOutput return 1");
         return OK;
@@ -855,7 +1166,7 @@ status_t V4l2Enc::queueOutput(int buffer_id, int fd, unsigned long nVaddr)
 
         //try to get index
         for(int32_t i = 0; i < mOutputBufferMap.size(); i++){
-            if((fd == mOutputBufferMap[i].plane.fd || nVaddr == mOutputBufferMap[i].plane.addr) 
+            if((fd == mOutputBufferMap[i].plane.fd || nVaddr == mOutputBufferMap[i].plane.addr)
                 && !mInputBufferMap[i].at_device){
                 index = i;
                 break;
@@ -898,7 +1209,7 @@ status_t V4l2Enc::queueOutput(int buffer_id, int fd, unsigned long nVaddr)
     }
 
     struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane planes[kOutputBufferPlaneNum];
+    struct v4l2_plane planes[mOutPlaneNum];
     memset(&stV4lBuf, 0, sizeof(stV4lBuf));
     memset(&planes[0], 0, sizeof(struct v4l2_plane));
 
@@ -915,17 +1226,17 @@ status_t V4l2Enc::queueOutput(int buffer_id, int fd, unsigned long nVaddr)
     }
 
     stV4lBuf.index = index;
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    stV4lBuf.type = mOutBufType;
     stV4lBuf.memory = mOutMemType;
     stV4lBuf.m.planes = &planes[0];
-    stV4lBuf.length = kOutputBufferPlaneNum;
+    stV4lBuf.length = mOutPlaneNum;
     stV4lBuf.flags = 0;
 
-    ALOGV("CAPTURE_MPLANE VIDIOC_QBUF index=%d
",index);
+    ALOGV("CAPTURE VIDIOC_QBUF index=%d
",index);
 
     result = ioctl(mFd, VIDIOC_QBUF, &stV4lBuf);
     if(result < 0){
-        ALOGE("VIDIOC_QBUF failed, index=%d",index);
+        ALOGE("VIDIOC_QBUF CAPTURE failed, index=%d, result=%d",index, result);
         mLock.unlock();
         return UNKNOWN_ERROR;
     }
@@ -943,7 +1254,7 @@ status_t V4l2Enc::startInputStream()
 {
     Mutex::Autolock autoLock(mLock);
     if(!bInputStreamOn){
-        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        enum v4l2_buf_type buf_type = mInBufType;
         if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
             bInputStreamOn = true;
             ALOGV("VIDIOC_STREAMON OUTPUT_MPLANE success");
@@ -955,7 +1266,7 @@ status_t V4l2Enc::stopInputStream()
 {
     Mutex::Autolock autoLock(mLock);
     if(bInputStreamOn){
-        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
+        enum v4l2_buf_type buf_type = mInBufType;
         if(0 == ioctl(mFd, VIDIOC_STREAMOFF, &buf_type)){
             bInputStreamOn = false;
             ALOGV("VIDIOC_STREAMOFF OUTPUT_MPLANE success");
@@ -974,7 +1285,7 @@ status_t V4l2Enc::startOutputStream()
 {
     Mutex::Autolock autoLock(mLock);
     if(!bOutputStreamOn){
-        enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+        enum v4l2_buf_type buf_type = mOutBufType;
         if(0 == ioctl(mFd, VIDIOC_STREAMON, &buf_type)){
             bOutputStreamOn = true;
             ALOGV("VIDIOC_STREAMON CAPTURE_MPLANE success");
@@ -988,7 +1299,7 @@ status_t V4l2Enc::stopOutputStream()
     int result = 0;
 
     //call VIDIOC_STREAMOFF and ignore the result
-    enum v4l2_buf_type buf_type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    enum v4l2_buf_type buf_type = mOutBufType;
     result = ioctl(mFd, VIDIOC_STREAMOFF, &buf_type);
     bOutputStreamOn = false;
     ALOGV("VIDIOC_STREAMOFF CAPTURE_MPLANE ret %d", result);
@@ -1014,13 +1325,13 @@ status_t V4l2Enc::dequeueOutputBuffer()
     uint32_t out_offset = 0;
 
     struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane planes[kOutputBufferPlaneNum];
+    struct v4l2_plane planes[mOutPlaneNum];
     memset(&stV4lBuf, 0, sizeof(stV4lBuf));
     memset(planes, 0, sizeof(planes));
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+    stV4lBuf.type = mOutBufType;
     stV4lBuf.memory = mOutMemType;
     stV4lBuf.m.planes = planes;
-    stV4lBuf.length = kOutputBufferPlaneNum;
+    stV4lBuf.length = mOutPlaneNum;
     result = ioctl(mFd, VIDIOC_DQBUF, &stV4lBuf);
     if(result < 0)
         return UNKNOWN_ERROR;
@@ -1037,25 +1348,36 @@ status_t V4l2Enc::dequeueOutputBuffer()
 
     if(!bHasCodecData && mConverter != NULL){
         uint8_t* vAddr = (uint8_t*)mOutputBufferMap[stV4lBuf.index].plane.addr;
-        if(OK ==  mConverter->CheckSpsPps(vAddr, out_len, &out_offset))
+        if(OK ==  mConverter->CheckSpsPps(vAddr, out_len, &out_offset)) {
             bHasCodecData = true;
+            ALOGE("CHECK SPSPPS success");
+        }
+        else
+            ALOGE("CHECK SPSPPS fail");
     }
 
     int blockId = 0;
-    int fd;
+    int fd = -1;
+    int byteused = 0;
     unsigned long nOutPhy;
     unsigned long nOutVirt;
+    uint32_t outBufLen = mOutputFormat.bufferSize;
 
     if(mOutMemType == V4L2_MEMORY_MMAP){
-        if (OK == FetchOutputBuffer(&blockId, &fd, &nOutPhy, &nOutVirt, &out_len))
+        if (OK == FetchOutputBuffer(&blockId, &fd, &nOutPhy, &nOutVirt, &outBufLen))
             memcpy((void*)nOutVirt, (void*)mOutputBufferMap[stV4lBuf.index].plane.addr, out_len);
         else
             return UNKNOWN_ERROR;
         dumpOutputBuffer((void*)nOutVirt, out_len);
     }
 
-    if(stV4lBuf.flags & V4L2_BUF_FLAG_LAST){
-        ALOGV("get last frame");
+    if (V4L2_TYPE_IS_MULTIPLANAR(mOutBufType))
+        byteused = stV4lBuf.m.planes[0].bytesused;
+    else
+        byteused = stV4lBuf.bytesused;
+
+    if(byteused == 0 || stV4lBuf.flags & V4L2_BUF_FLAG_LAST){
+        ALOGI("get last frame");
         NotifyEOS();
         bPollStarted = false;
         bFetchStarted = false;
@@ -1117,6 +1439,7 @@ status_t V4l2Enc::DoSetConfig(EncConfig index, void* pConfig) {
             }
             ALOGV("SetConfig ENC_CONFIG_BIT_RATE src=%d,tar=%d",mEncParam.nBitRate,tar);
             mEncParam.nBitRate = tar;
+            bSyncFrame = true;
             break;
         }
         case ENC_CONFIG_INTRA_REFRESH:
@@ -1132,6 +1455,33 @@ status_t V4l2Enc::DoSetConfig(EncConfig index, void* pConfig) {
             mInputFormat.pixelFormat = (*(int*)pConfig);
             break;
         }
+        case ENC_CONFIG_FRAME_RATE:
+        {
+            int frameRate = (*(int*)pConfig);
+            if (mEncParam.nFrameRate != frameRate) {
+                //hantro encoder do not support dynamic set fps, so just adjust the bitrate.
+                #ifdef HANTRO_V4L2
+                int bps;
+                bps = mEncParam.nBitRate * mEncParam.nFrameRate / frameRate;
+                if(bps > 60000000)
+                    bps = 60000000;
+                Mutex::Autolock autoLock(mLock);
+                pDev->SetEncoderBitrate(V4L2_MPEG_VIDEO_BITRATE_MODE_CBR, bps);
+                ALOGV("SetConfig ENC_CONFIG_FRAME_RATE, change bitrate %d -> %d. change frame rate %d -> %d",
+                    mEncParam.nBitRate, bps, mEncParam.nFrameRate, frameRate);
+                mEncParam.nBitRate = bps;
+                mEncParam.nFrameRate = frameRate;
+                bSyncFrame = true;
+                #else
+                Mutex::Autolock autoLock(mLock);
+                mTargetFps = mEncParam.nFrameRate = frameRate;
+                pDev->SetFrameRate(mTargetFps);
+                ALOGV("SetConfig ENC_CONFIG_FRAME_RATE,  change frame rate %d -> %d",
+                    mEncParam.nFrameRate, frameRate);
+                #endif
+            }
+            break;
+        }
         default:
             ret = BAD_VALUE;
             break;
@@ -1218,9 +1568,9 @@ status_t V4l2Enc::onFlush()
     ALOGV("onFlush BEGIN");
     int pre_state;
     {
-    Mutex::Autolock autoLock(mLock);
-    pre_state = mState;
-    mState = FLUSHING;
+        Mutex::Autolock autoLock(mLock);
+        pre_state = mState;
+        mState = FLUSHING;
     }
 
     ret = stopInputStream();
@@ -1239,38 +1589,24 @@ status_t V4l2Enc::onFlush()
 status_t V4l2Enc::onStop()
 {
     status_t ret = UNKNOWN_ERROR;
-  
+
     ALOGV("onStop BEGIN");
     {
     Mutex::Autolock autoLock(mLock);
     mState = STOPPING;
     }
     ret = onFlush();
-    if(ret != OK)
-        return ret;
 
-    ret = destroyFetchThread();
-    if(ret != OK)
-        return ret;
-
-    ALOGV("onStop destroyFetchThread success");
-    ret = destroyPollThread();
-    if(ret != OK)
-        return ret;
+    // don't exit halfway, try to execute till end to avoid memory leak
+    ret |= destroyFetchThread();
 
-    ALOGV("onStop destroyPollThread success");
+    ret |= destroyPollThread();
 
-    ret = destroyInputBuffers();
-    if(ret != OK)
-        return ret;
+    ret |= destroyInputBuffers();
 
-    ret = freeOutputBuffers();
-    if(ret != OK)
-        return ret;
+    ret |= freeOutputBuffers();
 
-    ret = destroyOutputBuffers();
-    if(ret != OK)
-        return ret;
+    ret |= destroyOutputBuffers();
 
     if(mConverter != NULL){
         mConverter->Destroy();
@@ -1278,7 +1614,8 @@ status_t V4l2Enc::onStop()
     }
     ALOGV("onStop END ret=%d",ret);
 
-    mState = STOPPED;
+    if (OK == ret)
+        mState = STOPPED;
     return ret;
 }
 status_t V4l2Enc::onDestroy()
@@ -1303,6 +1640,7 @@ status_t V4l2Enc::onDestroy()
     ALOGV("onDestroy END");
     return OK;
 }
+
 void V4l2Enc::initEncInputParamter(EncInputParam *pInPara) {
     if(pInPara == NULL)
         return;
@@ -1315,19 +1653,20 @@ void V4l2Enc::initEncInputParamter(EncInputParam *pInPara) {
     mEncParam.nBitRateMode = V4L2_MPEG_VIDEO_BITRATE_MODE_CBR;
     mEncParam.nGOPSize = pInPara->nGOPSize;
     mEncParam.nIntraFreshNum = pInPara->nRefreshIntra;
-    mEncParam.nProfile = pInPara->nProfile;
-    mEncParam.nLevel = pInPara->nLevel;
+    mEncParam.nFrameRate = pInPara->nFrameRate;
+
+    mEncParam.nProfile = C2ToV4l2ProfileLevel(pInPara->nProfile, mMime, true);
+    mEncParam.nLevel = C2ToV4l2ProfileLevel(pInPara->nLevel, mMime, false);
 
-    mInputFormat.pixelFormat = pInPara->eColorFormat;
     mWidth = pInPara->nPicWidth;
     mHeight = pInPara->nPicHeight;
 
     mInputFormat.bufferNum = DEFAULT_INPUT_BUFFER_COUNT;
-    mInputFormat.bufferSize = mWidth * mHeight * 3/2;
+    mInputFormat.bufferSize = mWidth * mHeight * pxlfmt2bpp(pInPara->eColorFormat) / 8;
     mInputFormat.width = mWidth;
     mInputFormat.height = mHeight;
     mInputFormat.interlaced = false;
-    mInputFormat.pixelFormat = HAL_PIXEL_FORMAT_YCbCr_420_SP;
+    mInputFormat.pixelFormat = pInPara->eColorFormat;
 
     mOutputFormat.width = mWidth;
     mOutputFormat.height = mHeight;
@@ -1342,7 +1681,7 @@ void V4l2Enc::initEncInputParamter(EncInputParam *pInPara) {
 
     ALOGD("initEncInputParamter nRotAngle=%d,nBitRate=%d,nGOPSize=%d,nRefreshIntra=%d,mTargetFps=%d",
         pInPara->nRotAngle, pInPara->nBitRate, pInPara->nGOPSize, pInPara->nRefreshIntra,mTargetFps);
-    
+
     return;
 }
 status_t V4l2Enc::getCodecData(uint8_t** pCodecData, uint32_t* size) {
@@ -1352,9 +1691,11 @@ status_t V4l2Enc::getCodecData(uint8_t** pCodecData, uint32_t* size) {
     else
         return UNKNOWN_ERROR;
 }
-bool V4l2Enc::checkIfPreProcessNeeded(int pixelFormat) 
+bool V4l2Enc::checkIfPreProcessNeeded(int pixelFormat)
 {
+#if 1
     switch (pixelFormat) {
+#ifndef HANTRO_VC8000E
     case HAL_PIXEL_FORMAT_RGB_565:
     case HAL_PIXEL_FORMAT_RGB_888:
     case HAL_PIXEL_FORMAT_RGBA_8888:
@@ -1363,10 +1704,31 @@ bool V4l2Enc::checkIfPreProcessNeeded(int pixelFormat)
         ALOGV("bPreProcess TRUE");
         bPreProcess = true;
         return true;
+#endif
     default:
         bPreProcess = false;
         return false;
     }
+
+#else
+    //check format with v4l2 driver format
+    uint32_t v4l2_format = 0;
+    if(OK != pDev->GetV4l2FormatByColor(pixelFormat, &v4l2_format)){
+        bPreProcess = true;
+        return true;
+    }
+
+    if(pDev->IsOutputFormatSupported(v4l2_format)){
+        bPreProcess = false;
+        ALOGV("checkIfPreProcessNeeded v4l2_format=0x%x, bPreProcess = false",v4l2_format);
+        return false;
+    }
+
+    ALOGV("checkIfPreProcessNeeded v4l2_format=0x%x, bPreProcess = true",v4l2_format);
+    bPreProcess = true;
+    return true;
+#endif
+
 }
 
 status_t V4l2Enc::allocateOutputBuffer(int32_t index)
@@ -1376,21 +1738,21 @@ status_t V4l2Enc::allocateOutputBuffer(int32_t index)
 
     uint8_t * ptr = NULL;
     struct v4l2_buffer stV4lBuf;
-    struct v4l2_plane planes[kOutputBufferPlaneNum];
+    struct v4l2_plane planes[mOutPlaneNum];
 
     if(index > mOutputFormat.bufferNum)
         return UNKNOWN_ERROR;
 
-    stV4lBuf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-    stV4lBuf.memory = V4L2_MEMORY_MMAP;
+    stV4lBuf.type = mOutBufType;
+    stV4lBuf.memory = mOutMemType;
     stV4lBuf.index = index;
-    stV4lBuf.length = kOutputBufferPlaneNum;
+    stV4lBuf.length = mOutPlaneNum;
     stV4lBuf.m.planes = planes;
 
     result = ioctl(mFd, VIDIOC_QUERYBUF, &stV4lBuf);
     if(result < 0)
         return UNKNOWN_ERROR;
-        
+
     planes[0].length = mOutputFormat.bufferSize;
 
     ptr = (uint8_t *)mmap(NULL, planes[0].length,
@@ -1437,7 +1799,7 @@ void V4l2Enc::ParseVpuLogLevel()
     int level=0;
     FILE* fpVpuLog;
     nDebugFlag = 0;
-    
+
     fpVpuLog=fopen(VPU_ENCODER_LOG_LEVELFILE, "r");
     if (NULL==fpVpuLog){
         return;
diff --git a/codec2/video_enc/v4l2_enc/V4l2Enc.h b/codec2/video_enc/v4l2_enc/V4l2Enc.h
old mode 100644
new mode 100755
index 9154149..cf080ca
--- a/codec2/video_enc/v4l2_enc/V4l2Enc.h
+++ b/codec2/video_enc/v4l2_enc/V4l2Enc.h
@@ -1,5 +1,5 @@
 /**
- *  Copyright 2019 NXP
+ *  Copyright 2019-2021 NXP
  *  All Rights Reserved.
  *
  *  The following programs are the sole property of Freescale Semiconductor Inc.,
@@ -34,6 +34,7 @@ protected:
     void initEncInputParamter(EncInputParam *pInPara) override;
     status_t getCodecData(uint8_t** pCodecData, uint32_t* size) override;
     bool checkIfPreProcessNeeded(int pixelFormat) override;
+    status_t OpenDevice() override;
 
     status_t onInit() override;
     status_t onStart();
@@ -45,9 +46,8 @@ protected:
 
 private:
     enum {
-        kInputBufferPlaneNum = 2,
+        kMaxInputBufferPlaneNum = 3,
         kOutputBufferPlaneNum = 1,
-
     };
 
     struct VideoFramePlane {
@@ -63,7 +63,7 @@ private:
         InputRecord();
         ~InputRecord();
         bool at_device;    // held by device.
-        VideoFramePlane planes[kInputBufferPlaneNum];
+        VideoFramePlane planes[kMaxInputBufferPlaneNum];
         int32_t input_id;
         int64_t ts;
     };
@@ -82,6 +82,7 @@ private:
 
     enum {
         UNINITIALIZED,
+        PREPARED,
         STOPPED,
         RUNNING,
         STOPPING,
@@ -98,15 +99,23 @@ private:
     enum v4l2_memory mInMemType;//support userptr and dma
     enum v4l2_memory mOutMemType;//support userptr and dma
 
+    enum v4l2_buf_type mInBufType;
+    enum v4l2_buf_type mOutBufType;
+
+    uint32_t mInPlaneNum;
+    uint32_t mOutPlaneNum;
+
     V4l2EncInputParam mEncParam;
     uint32_t mTargetFps;
-    
-    
+
+
     uint32_t mInFormat;//v4l2 output format
     uint32_t mOutFormat;//v4l2 capture format
-    uint32_t mInputPlaneSize[kInputBufferPlaneNum];
+    uint32_t mInputPlaneSize[kMaxInputBufferPlaneNum];
     uint32_t mWidthAlign;
     uint32_t mHeightAlign;
+    uint32_t mCropWidth;
+    uint32_t mCropHeight;
 
     std::vector<InputRecord> mInputBufferMap;
     std::vector<OutputRecord> mOutputBufferMap;
@@ -123,6 +132,7 @@ private:
     bool bHasCodecData;
     bool bStarted;
     bool bPreProcess;
+    bool bNeedFrameConverter;
     FrameConverter * mConverter;
 
     uint64_t mFrameOutNum;
diff --git a/codec2/video_enc/v4l2_enc/v4l2_enc.go b/codec2/video_enc/v4l2_enc/v4l2_enc.go
index 34b4636..c16e971 100644
--- a/codec2/video_enc/v4l2_enc/v4l2_enc.go
+++ b/codec2/video_enc/v4l2_enc/v4l2_enc.go
@@ -46,6 +46,14 @@ func v4l2Defaults(ctx android.LoadHookContext) {
     var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
     if strings.Contains(board, "IMX8Q") {
         p.Target.Android.Enabled = proptools.BoolPtr(true)
+        Cflags = append(Cflags, "-DAMPHION_V4L2")
+    } else if strings.Contains(board, "IMX8MP") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+        Cflags = append(Cflags, "-DHANTRO_V4L2")
+        Cflags = append(Cflags, "-DHANTRO_VC8000E")
+    } else if strings.Contains(board, "IMX8MM") {
+        p.Target.Android.Enabled = proptools.BoolPtr(true)
+        Cflags = append(Cflags, "-DHANTRO_V4L2")
     } else {
         p.Target.Android.Enabled = proptools.BoolPtr(false)
     }
diff --git a/codec2/video_enc/video_enc.go b/codec2/video_enc/video_enc.go
index d4016be..f3c51ff 100644
--- a/codec2/video_enc/video_enc.go
+++ b/codec2/video_enc/video_enc.go
@@ -45,11 +45,11 @@ func video_encDefaults(ctx android.LoadHookContext) {
     p.Target.Android.Enabled = proptools.BoolPtr(false)
     var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
     if strings.Contains(board, "IMX8MM") {
-        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_enc")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_v4l2_enc")
 		Shared_libs = append(Shared_libs, "lib_imx_c2_process_g2d_pre")
         p.Target.Android.Enabled = proptools.BoolPtr(true)
     }else if strings.Contains(board, "IMX8MP") {
-        Shared_libs = append(Shared_libs, "lib_imx_c2_vpuwrapper_enc")
+        Shared_libs = append(Shared_libs, "lib_imx_c2_v4l2_enc")
         Shared_libs = append(Shared_libs, "lib_imx_c2_process_g2d_pre")
         p.Target.Android.Enabled = proptools.BoolPtr(true)
     }else if strings.Contains(board, "IMX8Q") {
diff --git a/codec2/video_enc/vpuwrapper_enc/vpuwrapper_enc.go b/codec2/video_enc/vpuwrapper_enc/vpuwrapper_enc.go
index 219428c..9e03b74 100644
--- a/codec2/video_enc/vpuwrapper_enc/vpuwrapper_enc.go
+++ b/codec2/video_enc/vpuwrapper_enc/vpuwrapper_enc.go
@@ -45,10 +45,10 @@ func vpuwrapper_encDefaults(ctx android.LoadHookContext) {
     p.Target.Android.Enabled = proptools.BoolPtr(false)
     var board string = ctx.Config().VendorConfig("IMXPLUGIN").String("BOARD_SOC_TYPE")
     if strings.Contains(board, "IMX8MM") {
-        p.Target.Android.Enabled = proptools.BoolPtr(true)
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
         Cflags = append(Cflags, "-DHANTRO_H1")
     } else if strings.Contains(board, "IMX8MP") {
-        p.Target.Android.Enabled = proptools.BoolPtr(true)
+        p.Target.Android.Enabled = proptools.BoolPtr(false)
         Cflags = append(Cflags, "-DHANTRO_VC8000E")
     }
     if ctx.Config().VendorConfig("IMXPLUGIN").String("CFG_SECURE_DATA_PATH") == "y" {
diff --git a/extractor/ImxExtractor.cpp b/extractor/ImxExtractor.cpp
index 2b27f31..2e873c7 100755
--- a/extractor/ImxExtractor.cpp
+++ b/extractor/ImxExtractor.cpp
@@ -3299,32 +3299,91 @@ status_t ImxExtractor::SetMkvCrpytBufferInfo(TrackInfo *pInfo, MediaBufferHelper
 
     //parse the struct from http://www.webmproject.org/docs/webm-encryption/
     if (buffer_ptr[0] & 0x1) {
-        if(buffer_len < 9)
-            return ERROR_MALFORMED;
+        bool subsample = buffer_ptr[0] & 0x2;
 
-        buffer_len -= 9;
+        if(!subsample){
 
-        //full-sample encrypted block format
-        int32 plainSizes[] = { 0 };
-        int32 encryptedSizes[] = { buffer_len };
-        uint8 ctrCounter[16] = { 0 };
+            if(buffer_len < 9)
+                return ERROR_MALFORMED;
 
-        uint8 *keyId = NULL;
-        size_t keySize = 0;
+            buffer_len -= 9;
 
-        memcpy(ctrCounter, buffer_ptr + 1, 8);
+            //full-sample encrypted block format
+            int32 plainSizes[] = { 0 };
+            int32 encryptedSizes[] = { buffer_len };
+            uint8 ctrCounter[16] = { 0 };
 
-        AMediaFormat *trackMeta = pInfo->mMeta;
+            uint8 *keyId = NULL;
+            size_t keySize = 0;
 
-        CHECK(AMediaFormat_getBuffer(trackMeta, AMEDIAFORMAT_KEY_CRYPTO_KEY, (void**)&keyId, &keySize));
+            memcpy(ctrCounter, buffer_ptr + 1, 8);
 
+            AMediaFormat *trackMeta = pInfo->mMeta;
 
-        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, (void*)keyId, keySize);
-        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_IV, (void*)ctrCounter, 16);
-        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_PLAIN_SIZES, (void*)plainSizes, sizeof(plainSizes));
-        AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_ENCRYPTED_SIZES, (void*)encryptedSizes, sizeof(encryptedSizes));
+            CHECK(AMediaFormat_getBuffer(trackMeta, AMEDIAFORMAT_KEY_CRYPTO_KEY, (void**)&keyId, &keySize));
+
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, (void*)keyId, keySize);
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_IV, (void*)ctrCounter, 16);
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_PLAIN_SIZES, (void*)plainSizes, sizeof(plainSizes));
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_ENCRYPTED_SIZES, (void*)encryptedSizes, sizeof(encryptedSizes));
+
+            buf->set_range(9, buffer_len);
+
+        }else{
+ 
+            //TODO: these code need verify
+            if (buffer_len < 10) {
+                return ERROR_MALFORMED;
+            }
+            uint8_t num_partition  = buffer_ptr[9];
+            if (buffer_len - 10 < num_partition * sizeof(uint32_t)) {
+                return ERROR_MALFORMED;
+            }
+            std::vector<uint32_t> plainSizes, encryptedSizes;
+            uint8 ctrCounter[16] = { 0 };
+            uint8 *keyId = NULL;
+            size_t keySize = 0;
+
+            memcpy(ctrCounter, buffer_ptr + 1, 8);
+
+            uint32_t offset = 0;
+            uint32_t last_offset = 0;
+            uint32_t subsample_len = 0;
+ 
+            uint32_t headerLen = 10 + num_partition * sizeof(uint32_t);
+            const uint32_t *ptr = reinterpret_cast<const uint32_t*>(buffer_ptr[10]);
+
+            for (uint32_t i = 0; i < num_partition; i++) {
+                offset = ntohl(ptr[i]);
 
-        buf->set_range(9, buffer_len);
+                if (offset >  buffer_len - headerLen) {
+                    return ERROR_MALFORMED;
+                }
+                subsample_len = offset - last_offset;
+                if (i % 2) {
+                    plainSizes.push_back(subsample_len);
+                } else {
+                    encryptedSizes.push_back(subsample_len);
+                }
+                last_offset = offset;
+            }
+
+            if (plainSizes.size() > encryptedSizes.size()) {
+                encryptedSizes.push_back(0);
+            }
+
+            AMediaFormat *trackMeta = pInfo->mMeta;
+            CHECK(AMediaFormat_getBuffer(trackMeta, AMEDIAFORMAT_KEY_CRYPTO_KEY, (void**)&keyId, &keySize));
+
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_KEY, (void*)keyId, keySize);
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_IV, (void*)ctrCounter, 16);
+
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_PLAIN_SIZES,
+                    plainSizes.data(), plainSizes.size()*sizeof(uint32_t));
+            AMediaFormat_setBuffer(meta, AMEDIAFORMAT_KEY_CRYPTO_ENCRYPTED_SIZES,
+                    encryptedSizes.data(), encryptedSizes.size()*sizeof(uint32_t));
+            buf->set_range(offset, buffer_len - offset);
+        }
 
     } else {
         //unencrypted block format
diff --git a/mediacodec-profile/imx8mm/media_codecs_c2.xml b/mediacodec-profile/imx8mm/media_codecs_c2.xml
index aa49f91..5de5597 100644
--- a/mediacodec-profile/imx8mm/media_codecs_c2.xml
+++ b/mediacodec-profile/imx8mm/media_codecs_c2.xml
@@ -74,8 +74,8 @@
     </Decoders>
     <Encoders>
         <MediaCodec name="c2.imx.avc.encoder" type="video/avc" >
-            <Limit name="size" min="132x96" max="1920x1088" />
-            <Limit name="alignment" value="8x8" />
+            <Limit name="size" min="144x96" max="1920x1088" />
+            <Limit name="alignment" value="4x2" />
             <Limit name="block-size" value="16x16" />
             <Limit name="blocks-per-second" min="1" max="244800" />
             <Limit name="bitrate" range="1-60000000" />
@@ -85,8 +85,8 @@
             <Feature name="intra-refresh" />
         </MediaCodec>
         <MediaCodec name="c2.imx.vp8.encoder" type="video/x-vnd.on2.vp8" >
-            <Limit name="size" min="132x96" max="1920x1088" />
-            <Limit name="alignment" value="8x8" />
+            <Limit name="size" min="144x96" max="1920x1088" />
+            <Limit name="alignment" value="4x2" />
             <Limit name="block-size" value="16x16" />
             <Limit name="blocks-per-second" min="1" max="244800" />
             <Limit name="bitrate" range="1-60000000" />
diff --git a/mediacodec-profile/imx8mm/media_codecs_performance_c2.xml b/mediacodec-profile/imx8mm/media_codecs_performance_c2.xml
old mode 100644
new mode 100755
index 297b423..c476008
--- a/mediacodec-profile/imx8mm/media_codecs_performance_c2.xml
+++ b/mediacodec-profile/imx8mm/media_codecs_performance_c2.xml
@@ -18,16 +18,16 @@
 <MediaCodecs>
     <Encoders>
         <MediaCodec name="c2.imx.vp8.encoder" type="video/x-vnd.on2.vp8" update="true">
-            <Limit name="measured-frame-rate-320x180" range="580-580" />
-            <Limit name="measured-frame-rate-640x360" range="258-258" />
-            <Limit name="measured-frame-rate-1280x720" range="77-77" />
-            <Limit name="measured-frame-rate-1920x1080" range="35-35" />
+            <Limit name="measured-frame-rate-320x180" range="304-306" />
+            <Limit name="measured-frame-rate-640x360" range="182-183" />
+            <Limit name="measured-frame-rate-1280x720" range="76-76" />
+            <Limit name="measured-frame-rate-1920x1080" range="39-40" />
         </MediaCodec>
         <MediaCodec name="c2.imx.avc.encoder" type="video/avc" update="true">
-            <Limit name="measured-frame-rate-320x240" range="568-577" />
-            <Limit name="measured-frame-rate-720x480" range="190-190" />
-            <Limit name="measured-frame-rate-1280x720" range="79-80" />
-            <Limit name="measured-frame-rate-1920x1080" range="36-36" />
+            <Limit name="measured-frame-rate-320x240" range="281-284" />
+            <Limit name="measured-frame-rate-720x480" range="141-141" />
+            <Limit name="measured-frame-rate-1280x720" range="76-76" />
+            <Limit name="measured-frame-rate-1920x1080" range="38-38" />
         </MediaCodec>
         <MediaCodec name="c2.android.hevc.encoder" type="video/hevc" update="true">
             <Limit name="measured-frame-rate-320x240" range="37-45" />
@@ -53,29 +53,29 @@
     </Encoders>
     <Decoders>
         <MediaCodec name="c2.imx.avc.decoder" type="video/avc" update="true">
-            <Limit name="measured-frame-rate-320x240" range="864-1035" />
-            <Limit name="measured-frame-rate-720x480" range="498-580" />
-            <Limit name="measured-frame-rate-1280x720" range="266-281" />
-            <Limit name="measured-frame-rate-1920x1080" range="130-132" />
+            <Limit name="measured-frame-rate-320x240" range="564-566" />
+            <Limit name="measured-frame-rate-720x480" range="473-479" />
+            <Limit name="measured-frame-rate-1280x720" range="276-280" />
+            <Limit name="measured-frame-rate-1920x1080" range="128-129" />
         </MediaCodec>
         <MediaCodec name="c2.imx.vp8.decoder" type="video/x-vnd.on2.vp8" update="true">
-            <Limit name="measured-frame-rate-320x180" range="855-1137" />
-            <Limit name="measured-frame-rate-640x360" range="704-877" />
-            <Limit name="measured-frame-rate-1280x720" range="298-313" />
-            <Limit name="measured-frame-rate-1920x1080" range="141-141" />
+            <Limit name="measured-frame-rate-320x180" range="570-577" />
+            <Limit name="measured-frame-rate-640x360" range="558-567" />
+            <Limit name="measured-frame-rate-1280x720" range="323-326" />
+            <Limit name="measured-frame-rate-1920x1080" range="148-148" />
         </MediaCodec>
         <MediaCodec name="c2.imx.vp9.decoder" type="video/x-vnd.on2.vp9" update="true">
-            <Limit name="measured-frame-rate-320x240" range="859-1094" />
-            <Limit name="measured-frame-rate-640x360" range="706-917" />
-            <Limit name="measured-frame-rate-1280x720" range="431-480" />
-            <Limit name="measured-frame-rate-1920x1080" range="291-324" />
+            <Limit name="measured-frame-rate-320x240" range="700-733" />
+            <Limit name="measured-frame-rate-640x360" range="610-651" />
+            <Limit name="measured-frame-rate-1280x720" range="396-405" />
+            <Limit name="measured-frame-rate-1920x1080" range="267-270" />
         </MediaCodec>
         <MediaCodec name="c2.imx.hevc.decoder" type="video/hevc" update="true">
-            <Limit name="measured-frame-rate-352x288" range="858-1083" />
-            <Limit name="measured-frame-rate-640x360" range="834-974" />
-            <Limit name="measured-frame-rate-720x480" range="738-856" />
-            <Limit name="measured-frame-rate-1280x720" range="484-580" />
-            <Limit name="measured-frame-rate-1920x1080" range="288-337" />
+            <Limit name="measured-frame-rate-352x288" range="565-566" />
+            <Limit name="measured-frame-rate-640x360" range="563-567" />
+            <Limit name="measured-frame-rate-720x480" range="478-519" />
+            <Limit name="measured-frame-rate-1280x720" range="359-433" />
+            <Limit name="measured-frame-rate-1920x1080" range="294-298" />
         </MediaCodec>
         <MediaCodec name="c2.android.h263.decoder" type="video/3gpp" update="true">
             <Limit name="measured-frame-rate-176x144" range="549-655" />
diff --git a/mediacodec-profile/imx8mp/media_codecs_c2.xml b/mediacodec-profile/imx8mp/media_codecs_c2.xml
index b37d35a..f129db7 100644
--- a/mediacodec-profile/imx8mp/media_codecs_c2.xml
+++ b/mediacodec-profile/imx8mp/media_codecs_c2.xml
@@ -21,7 +21,7 @@
     <Include href="media_codecs_c2_dsp_wma.xml" />
     <Include href="media_codecs_c2_dsp.xml" />
     <Decoders>
-       <MediaCodec name="c2.imx.avc.decoder" type="video/avc" >
+        <MediaCodec name="c2.imx.avc.decoder" type="video/avc" >
             <Limit name="size" min="48x48" max="1920x1088" />
             <Limit name="alignment" value="2x2" />
             <Limit name="block-size" value="16x16" />
@@ -34,6 +34,20 @@
             <Limit name="performance-point-1280x720" value="240" />
             <Feature name="adaptive-playback" />
         </MediaCodec>
+        <MediaCodec name="c2.imx.avc.decoder.secure" type="video/avc" >
+            <Limit name="size" min="48x48" max="1920x1088" />
+            <Limit name="alignment" value="2x2" />
+            <Limit name="block-size" value="16x16" />
+            <Limit name="blocks-per-second" min="1" max="1036800" />
+            <Limit name="bitrate" range="1-50000000" />
+            <Limit name="concurrent-instances" max="32" />
+            <Limit name="performance-point-4096x2304" value="28" />
+            <Limit name="performance-point-3840x2160" value="30" />
+            <Limit name="performance-point-1920x1080" value="120" />
+            <Limit name="performance-point-1280x720" value="240" />
+            <Feature name="secure-playback" required="true" />
+            <Feature name="adaptive-playback" />
+        </MediaCodec>
         <MediaCodec name="c2.imx.hevc.decoder" type="video/hevc" >
             <Limit name="size" min="144x144" max="1920x1088" />
             <Limit name="alignment" value="2x2" />
@@ -47,6 +61,20 @@
             <Limit name="performance-point-1280x720" value="240" />
             <Feature name="adaptive-playback" />
         </MediaCodec>
+        <MediaCodec name="c2.imx.hevc.decoder.secure" type="video/hevc" >
+            <Limit name="size" min="144x144" max="1920x1088" />
+            <Limit name="alignment" value="2x2" />
+            <Limit name="block-size" value="16x16" />
+            <Limit name="blocks-per-second" min="1" max="2073600" />
+            <Limit name="bitrate" range="1-100000000"/>
+            <Limit name="concurrent-instances" max="32" />
+            <Limit name="performance-point-4096x2304" value="28" />
+            <Limit name="performance-point-3840x2160" value="30" />
+            <Limit name="performance-point-1920x1080" value="120" />
+            <Limit name="performance-point-1280x720" value="240" />
+            <Feature name="secure-playback" required="true" />
+            <Feature name="adaptive-playback" />
+        </MediaCodec>
         <MediaCodec name="c2.imx.vp8.decoder" type="video/x-vnd.on2.vp8" >
             <Limit name="size" min="48x48" max="1920x1088" />
             <Limit name="alignment" value="2x2" />
@@ -77,8 +105,8 @@
     </Decoders>
     <Encoders>
         <MediaCodec name="c2.imx.avc.encoder" type="video/avc" >
-            <Limit name="size" min="132x96" max="1920x1088" />
-            <Limit name="alignment" value="4x4" />
+            <Limit name="size" min="132x128" max="1920x1088" />
+            <Limit name="alignment" value="2x2" />
             <Limit name="block-size" value="16x16" />
             <Limit name="blocks-per-second" min="1" max="244800" />
             <Limit name="bitrate" range="1-60000000" />
@@ -88,8 +116,8 @@
             <Feature name="intra-refresh" />
         </MediaCodec>
         <MediaCodec name="c2.imx.hevc.encoder" type="video/hevc" >
-            <Limit name="size" min="132x96" max="1920x1088" />
-            <Limit name="alignment" value="8x8" />
+            <Limit name="size" min="144x144" max="1920x1088" />
+            <Limit name="alignment" value="2x2" />
             <Limit name="block-size" value="16x16" />
             <Limit name="blocks-per-second" min="1" max="244800" />
             <Limit name="bitrate" range="1-60000000" />
